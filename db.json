{"meta":{"version":1,"warehouse":"2.2.0"},"models":{"Asset":[{"_id":"source/CNAME","path":"CNAME","modified":0,"renderable":0},{"_id":"source/images/weibo-which-motherboard.png","path":"images/weibo-which-motherboard.png","modified":0,"renderable":0},{"_id":"themes/next/source/images/avatar.gif","path":"images/avatar.gif","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc-nd.svg","path":"images/cc-by-nc-nd.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc-sa.svg","path":"images/cc-by-nc-sa.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by-nd.svg","path":"images/cc-by-nd.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc.svg","path":"images/cc-by-nc.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by-sa.svg","path":"images/cc-by-sa.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by.svg","path":"images/cc-by.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/placeholder.gif","path":"images/placeholder.gif","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-zero.svg","path":"images/cc-zero.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/loading.gif","path":"images/loading.gif","modified":0,"renderable":1},{"_id":"themes/next/source/images/quote-l.svg","path":"images/quote-l.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/searchicon.png","path":"images/searchicon.png","modified":0,"renderable":1},{"_id":"themes/next/source/images/quote-r.svg","path":"images/quote-r.svg","modified":0,"renderable":1},{"_id":"themes/next/source/css/main.styl","path":"css/main.styl","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/affix.js","path":"js/src/affix.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/hook-duoshuo.js","path":"js/src/hook-duoshuo.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/bootstrap.js","path":"js/src/bootstrap.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/motion.js","path":"js/src/motion.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/scrollspy.js","path":"js/src/scrollspy.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/post-details.js","path":"js/src/post-details.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/utils.js","path":"js/src/utils.js","modified":0,"renderable":1},{"_id":"themes/next/source/vendors/font-awesome/HELP-US-OUT.txt","path":"vendors/font-awesome/HELP-US-OUT.txt","modified":0,"renderable":1},{"_id":"themes/next/source/vendors/font-awesome/bower.json","path":"vendors/font-awesome/bower.json","modified":0,"renderable":1},{"_id":"themes/next/source/vendors/fastclick/LICENSE","path":"vendors/fastclick/LICENSE","modified":0,"renderable":1},{"_id":"themes/next/source/vendors/fastclick/bower.json","path":"vendors/fastclick/bower.json","modified":0,"renderable":1},{"_id":"themes/next/source/vendors/fastclick/README.md","path":"vendors/fastclick/README.md","modified":0,"renderable":1},{"_id":"themes/next/source/vendors/jquery_lazyload/README.md","path":"vendors/jquery_lazyload/README.md","modified":0,"renderable":1},{"_id":"themes/next/source/vendors/jquery_lazyload/CONTRIBUTING.md","path":"vendors/jquery_lazyload/CONTRIBUTING.md","modified":0,"renderable":1},{"_id":"themes/next/source/vendors/jquery_lazyload/bower.json","path":"vendors/jquery_lazyload/bower.json","modified":0,"renderable":1},{"_id":"themes/next/source/vendors/jquery_lazyload/jquery.lazyload.js","path":"vendors/jquery_lazyload/jquery.lazyload.js","modified":0,"renderable":1},{"_id":"themes/next/source/vendors/jquery_lazyload/jquery.scrollstop.js","path":"vendors/jquery_lazyload/jquery.scrollstop.js","modified":0,"renderable":1},{"_id":"themes/next/source/vendors/velocity/bower.json","path":"vendors/velocity/bower.json","modified":0,"renderable":1},{"_id":"themes/next/source/vendors/velocity/velocity.min.js","path":"vendors/velocity/velocity.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/vendors/velocity/velocity.ui.js","path":"vendors/velocity/velocity.ui.js","modified":0,"renderable":1},{"_id":"themes/next/source/vendors/velocity/velocity.ui.min.js","path":"vendors/velocity/velocity.ui.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/vendors/jquery/index.js","path":"vendors/jquery/index.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/schemes/pisces.js","path":"js/src/schemes/pisces.js","modified":0,"renderable":1},{"_id":"themes/next/source/vendors/fancybox/source/fancybox_loading@2x.gif","path":"vendors/fancybox/source/fancybox_loading@2x.gif","modified":0,"renderable":1},{"_id":"themes/next/source/vendors/fancybox/source/blank.gif","path":"vendors/fancybox/source/blank.gif","modified":0,"renderable":1},{"_id":"themes/next/source/vendors/fancybox/source/fancybox_loading.gif","path":"vendors/fancybox/source/fancybox_loading.gif","modified":0,"renderable":1},{"_id":"themes/next/source/vendors/fancybox/source/fancybox_overlay.png","path":"vendors/fancybox/source/fancybox_overlay.png","modified":0,"renderable":1},{"_id":"themes/next/source/vendors/fancybox/source/fancybox_sprite.png","path":"vendors/fancybox/source/fancybox_sprite.png","modified":0,"renderable":1},{"_id":"themes/next/source/vendors/fancybox/source/fancybox_sprite@2x.png","path":"vendors/fancybox/source/fancybox_sprite@2x.png","modified":0,"renderable":1},{"_id":"themes/next/source/vendors/fancybox/source/jquery.fancybox.css","path":"vendors/fancybox/source/jquery.fancybox.css","modified":0,"renderable":1},{"_id":"themes/next/source/vendors/fancybox/source/jquery.fancybox.pack.js","path":"vendors/fancybox/source/jquery.fancybox.pack.js","modified":0,"renderable":1},{"_id":"themes/next/source/vendors/fancybox/source/jquery.fancybox.js","path":"vendors/fancybox/source/jquery.fancybox.js","modified":0,"renderable":1},{"_id":"themes/next/source/vendors/font-awesome/css/font-awesome.css.map","path":"vendors/font-awesome/css/font-awesome.css.map","modified":0,"renderable":1},{"_id":"themes/next/source/vendors/font-awesome/css/font-awesome.min.css","path":"vendors/font-awesome/css/font-awesome.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/vendors/font-awesome/css/font-awesome.css","path":"vendors/font-awesome/css/font-awesome.css","modified":0,"renderable":1},{"_id":"themes/next/source/vendors/font-awesome/fonts/fontawesome-webfont.woff2","path":"vendors/font-awesome/fonts/fontawesome-webfont.woff2","modified":0,"renderable":1},{"_id":"themes/next/source/vendors/fastclick/lib/fastclick.js","path":"vendors/fastclick/lib/fastclick.js","modified":0,"renderable":1},{"_id":"themes/next/source/vendors/fastclick/lib/fastclick.min.js","path":"vendors/fastclick/lib/fastclick.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/vendors/ua-parser-js/dist/ua-parser.pack.js","path":"vendors/ua-parser-js/dist/ua-parser.pack.js","modified":0,"renderable":1},{"_id":"themes/next/source/vendors/ua-parser-js/dist/ua-parser.min.js","path":"vendors/ua-parser-js/dist/ua-parser.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/vendors/font-awesome/fonts/FontAwesome.otf","path":"vendors/font-awesome/fonts/FontAwesome.otf","modified":0,"renderable":1},{"_id":"themes/next/source/vendors/font-awesome/fonts/fontawesome-webfont.eot","path":"vendors/font-awesome/fonts/fontawesome-webfont.eot","modified":0,"renderable":1},{"_id":"themes/next/source/vendors/font-awesome/fonts/fontawesome-webfont.woff","path":"vendors/font-awesome/fonts/fontawesome-webfont.woff","modified":0,"renderable":1},{"_id":"themes/next/source/vendors/velocity/velocity.js","path":"vendors/velocity/velocity.js","modified":0,"renderable":1},{"_id":"themes/next/source/vendors/fancybox/source/helpers/fancybox_buttons.png","path":"vendors/fancybox/source/helpers/fancybox_buttons.png","modified":0,"renderable":1},{"_id":"themes/next/source/vendors/fancybox/source/helpers/jquery.fancybox-buttons.css","path":"vendors/fancybox/source/helpers/jquery.fancybox-buttons.css","modified":0,"renderable":1},{"_id":"themes/next/source/vendors/fancybox/source/helpers/jquery.fancybox-media.js","path":"vendors/fancybox/source/helpers/jquery.fancybox-media.js","modified":0,"renderable":1},{"_id":"themes/next/source/vendors/fancybox/source/helpers/jquery.fancybox-buttons.js","path":"vendors/fancybox/source/helpers/jquery.fancybox-buttons.js","modified":0,"renderable":1},{"_id":"themes/next/source/vendors/fancybox/source/helpers/jquery.fancybox-thumbs.css","path":"vendors/fancybox/source/helpers/jquery.fancybox-thumbs.css","modified":0,"renderable":1},{"_id":"source/images/weibo-cannot-boot.png","path":"images/weibo-cannot-boot.png","modified":0,"renderable":0},{"_id":"themes/next/source/vendors/fancybox/source/helpers/jquery.fancybox-thumbs.js","path":"vendors/fancybox/source/helpers/jquery.fancybox-thumbs.js","modified":0,"renderable":1},{"_id":"themes/next/source/vendors/font-awesome/fonts/fontawesome-webfont.ttf","path":"vendors/font-awesome/fonts/fontawesome-webfont.ttf","modified":0,"renderable":1},{"_id":"themes/next/source/vendors/font-awesome/fonts/fontawesome-webfont.svg","path":"vendors/font-awesome/fonts/fontawesome-webfont.svg","modified":0,"renderable":1}],"Cache":[{"_id":"source/.DS_Store","hash":"7a635d1b3e71206668d3eadeb44134758092f32b","modified":1471513983000},{"_id":"source/CNAME","hash":"10cbd40f0de2ea1319192b1002535c600a5deedb","modified":1471511705000},{"_id":"themes/next/.DS_Store","hash":"39151d7f4eacdee9c294c66ef9d7ef8110e337df","modified":1471340399000},{"_id":"themes/next/.bowerrc","hash":"80e096fdc1cf912ee85dd9f7e6e77fd40cf60f10","modified":1462448086000},{"_id":"themes/next/.editorconfig","hash":"792fd2bd8174ece1a75d5fd24ab16594886f3a7f","modified":1462448086000},{"_id":"themes/next/.gitignore","hash":"efec790f5b7a0256763e1cc08f12c4f0aff509f6","modified":1462448086000},{"_id":"themes/next/.hound.yml","hash":"b76daa84c9ca3ad292c78412603370a367cc2bc3","modified":1462448086000},{"_id":"themes/next/.javascript_ignore","hash":"d619ee13031908cd72666e4ff652d2ea3483b1c3","modified":1462448086000},{"_id":"themes/next/.jshintrc","hash":"9928f81bd822f6a8d67fdbc909b517178533bca9","modified":1462448086000},{"_id":"themes/next/README.en.md","hash":"565ba52b3825b85a9f05b41183caca7f18b741d4","modified":1462448086000},{"_id":"themes/next/_config.yml","hash":"f5aad0c9a9a76759a5306156e977b59b3cf23d28","modified":1471511566000},{"_id":"themes/next/README.md","hash":"500b5606eb6a09c979d16128f8b00f4bf9bc95ac","modified":1462448086000},{"_id":"themes/next/bower.json","hash":"f89c6700a11d81e067cc97273ca6bf96cb88c8f9","modified":1462448086000},{"_id":"themes/next/gulpfile.coffee","hash":"26e5b1b945704c8bc78b928feede895c4c111c95","modified":1462448086000},{"_id":"themes/next/package.json","hash":"63e9c0f1dd9e5d7f51b4ae383981ef939a2ed45d","modified":1462448086000},{"_id":"source/_posts/2010-02-15-run-class-file-in-java-command-line.md","hash":"b274271cd70f3d0a6244d9c546a5fee9199cde0c","modified":1471512064000},{"_id":"themes/next/.github/CONTRIBUTING.md","hash":"5ab257af816986cd0e53f9527a92d5934ac70ae9","modified":1462448086000},{"_id":"themes/next/.github/ISSUE_TEMPLATE.md","hash":"c2024ded82143807c28a299c5fe6b927ef3525ff","modified":1462448086000},{"_id":"source/_posts/2010-03-28-extract-text-from-pdf-using-pdfbox.md","hash":"482400f7bdbd5c772f3de5305453536dc1746ee3","modified":1471512064000},{"_id":"source/_posts/2010-04-01-read-and-write-images-using-java-imageio.md","hash":"01c438cb28e3890b6e57896467ea80d99ce3a765","modified":1471512064000},{"_id":"source/_posts/2010-03-31-java-qa-tools.md","hash":"cdf4fcc8ce1feb6a7d94de80b47829022b3d780c","modified":1471512064000},{"_id":"source/_posts/2010-04-17-tex-resources-for-newbies.md","hash":"dbd6389c1de0422b954b5d7cf60f91c3dc0efc74","modified":1471512064000},{"_id":"source/_posts/2011-06-23-using-javac-to-compile-multi-java-files.md","hash":"644a045736b1d0a9f804722a3bf58c798042ae34","modified":1471512064000},{"_id":"source/_posts/2010-05-28-text-classification-algorithm-based-on-naive-bayes.md","hash":"d4dd30b69f4980392617d96e699b125c74521971","modified":1471512064000},{"_id":"source/_posts/2012-01-02-ssh-passwordless-login-configuration.md","hash":"eb8d751863efc7e0485f139632625a77ebc8e7df","modified":1471512064000},{"_id":"source/_posts/2012-01-03-hadoop-installation-on-ubuntu.md","hash":"c7a36f02b9517e5127301f7a67c6253440180d1f","modified":1471512064000},{"_id":"source/_posts/2012-04-23-install-and-configure-a-centos-server-from-scratch.md","hash":"7278af830597ca17b67a8a6db262114d1004e63c","modified":1471512064000},{"_id":"source/_posts/2012-04-18-create-a-bootable-vmware-esxi-5-usb-stick.md","hash":"45c622998e075fda85141c0e66a83138f98cde67","modified":1471512064000},{"_id":"source/_posts/2012-08-11-configure-tomcat-jmx-to-allow-visualvm-connect-tomcat.md","hash":"312aa3231a52a7b8cb8d254413bc7ef1841016dc","modified":1471512064000},{"_id":"source/_posts/2013-03-22-some-popular-programming-contest-websites.md","hash":"164d322a1b6760b069a202d962d148ff0b288182","modified":1471512064000},{"_id":"source/_posts/2013-02-25-differences-between-knn-and-kmeans.md","hash":"adb18fad9218d434e638bd430050fabd60c848e0","modified":1471512064000},{"_id":"source/_posts/2013-02-26-numerical-or-scientific-computation-library.md","hash":"b1a24cd30429302f31f9a0c6a8a83cba51e8332f","modified":1471512064000},{"_id":"source/_posts/2013-03-27-some-classical-machine-learning-tutorials.md","hash":"22c7c11fbcbb46fd62142ff9ec50a293a9eab81c","modified":1471512064000},{"_id":"source/_posts/2013-04-04-excellent-algorithm-gif-animations.md","hash":"5b491565ef3fa3fa0c46511e76a873caa116e607","modified":1471512064000},{"_id":"source/_posts/2013-04-01-using-github-and-octoperss-to-create-a-free-blog.md","hash":"ec998b120871250d3021a5a088d128e233b88714","modified":1471512064000},{"_id":"source/_posts/2013-04-02-my-octopress-configuration.md","hash":"d2d464191425a84ae277c76eb19bdce8efc6c33b","modified":1471512064000},{"_id":"source/_posts/2013-04-12-latex-distributions-and-editors.md","hash":"cbcd4bc399f75d7e1b08962f6a64b8dbef03638f","modified":1471512064000},{"_id":"source/_posts/2013-06-11-read-spark-source-code-using-scala-ide.md","hash":"26b1d2e5d19e128bf897905adc7984891a07ce1a","modified":1471512064000},{"_id":"source/_posts/2013-04-05-concise-scala.md","hash":"39b17e7460765f5f6d4b42d00ca99574e15a0e2c","modified":1471512064000},{"_id":"source/_posts/2013-06-14-installing-spark-on-centos.md","hash":"b41946441eb43e8230b22051b665e73552e3b8f3","modified":1471512064000},{"_id":"source/_posts/2013-06-17-installing-spark-on-centos-cn.md","hash":"0599ca1208afc9059f79f785224ef2a8085689da","modified":1471512064000},{"_id":"source/_posts/2013-10-17-installing-spark-on-centos-cn.md","hash":"2eb1e5bfc5c7b6a547b354ba6141f00e3474db76","modified":1471512064000},{"_id":"source/_posts/2013-07-07-mahout-kmeans-results-analysis.md","hash":"8f82edd6b4679c084806a4051a8ea3ef79d69c3a","modified":1471512064000},{"_id":"source/_posts/2013-07-04-installing-mahout.md","hash":"1c38290c01acd75325816d54b5cf39f25783520c","modified":1471512064000},{"_id":"source/_posts/2013-10-16-ansible-tutorial.md","hash":"78b878f8c0aaee40e2e33e9316ec4d613c7d0d3f","modified":1471512064000},{"_id":"source/_posts/2013-10-25-docker-installation.md","hash":"0de199109de5d87cd325dcdf0499501e9fd26143","modified":1471512064000},{"_id":"source/_posts/2013-10-26-docker-tutorial.md","hash":"366ad0b10243176cea58016d187da4769516fecb","modified":1471512064000},{"_id":"source/_posts/2014-01-20-Running-Nutch-in-Eclipse.md","hash":"6cdd9afd38626695397767dde782ef6c7a1cb42c","modified":1471512064000},{"_id":"source/_posts/2013-10-27-build-spark-cluster-with-docker.md","hash":"c1dc6d6a0e8415966dd852b9a1c59ec78f39fdf6","modified":1471512064000},{"_id":"source/_posts/2013-10-28-install-and-configure-a-ubuntu-server-from-scratch.md","hash":"3f2375355817f285147d1318f13d0dc24347739c","modified":1471512064000},{"_id":"source/_posts/2014-01-21-nutch-tutorial-17.md","hash":"011cbacd3bd51025bb1d4453fbceae242dff4110","modified":1471512064000},{"_id":"source/_posts/2013-12-23-run-mahout-nbc.md","hash":"8a7c94cddfcf3ae5f18f183adbbd05461bbf59a3","modified":1471512064000},{"_id":"source/_posts/2014-01-24-cluster-time-sync-using-ntp.md","hash":"5198ce81f89c15be3f247b8f9c6defb99b4baf57","modified":1471512064000},{"_id":"source/_posts/2014-01-22-install-docker-on-centos65.md","hash":"b2f0d6fa277436929e13fcac2953df4fd68cd5a6","modified":1471512064000},{"_id":"source/_posts/2014-01-23-centos-6-dot-4-upgrade-kernel.md","hash":"043a78948eff977fc5a02c96e90274e2244ceb88","modified":1471512064000},{"_id":"source/_posts/2014-01-26-boot-space-insufficient.md","hash":"917eaddc49689ea6264a34eeebca075c0dd8500a","modified":1471512064000},{"_id":"source/_posts/2014-01-27-ansible-tutorial.md","hash":"c7a2e955b652f2d412d8cde76b4119b79b1a28c0","modified":1471512064000},{"_id":"source/_posts/2014-01-25-rdesktop-tutorial.md","hash":"5b70c0ef55169686b015d95560ca04b9a5fbb763","modified":1471512064000},{"_id":"source/_posts/2014-01-28-restore-octopress-at-a-new-computer.md","hash":"6dd1529f11c73f881dc5a98febdc4156975b6d8d","modified":1471512064000},{"_id":"source/_posts/2014-01-29-my-ansible-playbook.md","hash":"a6679801f0c4cc21f2755982c9f3498dcc3e7787","modified":1471512064000},{"_id":"source/_posts/2014-02-02-hadoop-installatioin-on-centos.md","hash":"1c30aff1e1220f10e4077529b2262676d8c2e316","modified":1471512064000},{"_id":"source/_posts/2014-01-31-install-uek-for-centos.md","hash":"e88fc6a9582e89c7b342ebb3bd1557d57895a554","modified":1471512064000},{"_id":"source/_posts/2014-01-30-spark-development-environment.md","hash":"e9f386811b53b8f9cf06ffc8af11718817552429","modified":1471512064000},{"_id":"source/_posts/2014-02-01-nutch-tutorial.md","hash":"d37a3c2df53749284cb4c333a4fe3cf9aace641e","modified":1471512064000},{"_id":"source/_posts/2014-02-03-hadoop-multiple-users.md","hash":"2eed61f68326441a49c00a1e7d2b948d26e99eae","modified":1471512064000},{"_id":"source/_posts/2014-02-04-running-nutch-on-hadoop-cluster.md","hash":"92add58f30ce5ab574db28d1be02459e459d2cdf","modified":1471512064000},{"_id":"source/_posts/2014-02-05-hadoop-2-installatioin-on-centos.md","hash":"c50d170705b227bb65d16a9463f9d5767801818d","modified":1471512064000},{"_id":"source/_posts/2014-02-06-hadoop-multiple-users.md","hash":"c213b946b9bc75e97ae03e68d6498c7f44c4a15f","modified":1471512064000},{"_id":"source/_posts/2014-02-07-install-zookeeper-on-centos.md","hash":"2663d612599b19c3978a0217dc5172360b9394df","modified":1471512064000},{"_id":"source/_posts/2014-02-08-install-hbase-on-centos.md","hash":"fc7b9f25c2c27c8024f00827662e405d326f9091","modified":1471512064000},{"_id":"source/_posts/2014-02-12-install-texlive-2013-iso.md","hash":"149f73264914f863c749af9bc1d0ab679a7f42d7","modified":1471512064000},{"_id":"source/_posts/2014-02-14-compile-hadoop-220-on-centos.md","hash":"830b749be9a8d0f3ca6ef4eae2b21f01e14020c7","modified":1471512064000},{"_id":"source/_posts/2014-02-20-writing-nutch-plugins.md","hash":"a0e72876225cd77850db91c8b6970c775242f7b9","modified":1471512064000},{"_id":"source/_posts/2014-04-24-working-os-x-10-dot-9-mavericks-vmware-image-for-windows-os.md","hash":"9ef23f6088d244bd73aecc29e6538b53a003f304","modified":1471512064000},{"_id":"source/_posts/2014-04-03-caffe-installation.md","hash":"80e66c388d0dcc43d239a7111ae5e087e8fcb91b","modified":1471512064000},{"_id":"source/_posts/2014-04-17-install-and-configure-a-ubuntu-server-from-scratch.md","hash":"d3f316f1a61409eb886bedb64d2ff563bead2b4c","modified":1471512064000},{"_id":"source/_posts/2014-04-25-install-os-x-mavericks-on-windows-using-vmware-workstation.md","hash":"7dc6d73f7410cfd492f6b1d99a4c139ca6c17a40","modified":1471512064000},{"_id":"source/_posts/2014-08-06-install-scikit-learn-with-python3.md","hash":"bb34b0137dc4c3a40660ccb84a7ab206bf77a251","modified":1471512064000},{"_id":"source/_posts/2016-08-13-my-deep-learning-workstation-assemble-process-note.md","hash":"f20d2aea20b64293fd87158238ac6ccba87c7750","modified":1471516563000},{"_id":"source/_posts/2016-08-14-dual-install-windows-ubuntu.md","hash":"0aa4bb10179234c90d09be43dcc2b41276ba9069","modified":1471515557000},{"_id":"source/_posts/2016-08-17-deep-learning-cuda-development-environment.md","hash":"125ed49d0b6d0a7a0715966bebccc2090c5f5ded","modified":1471515822000},{"_id":"themes/next/languages/de.yml","hash":"786afba25cfc98845a20d9901823ebeebcd1cbbf","modified":1462448086000},{"_id":"themes/next/languages/fr-FR.yml","hash":"1a084623c39de74301f3e92f9388a3a815a542ca","modified":1462448086000},{"_id":"themes/next/languages/en.yml","hash":"f03799cbdb5a33064ead080bcac4baca1f6bc5f9","modified":1462448086000},{"_id":"themes/next/languages/default.yml","hash":"9db835c0543ade5a89bc80ec5a898203227cf3d8","modified":1462448086000},{"_id":"themes/next/languages/ja.yml","hash":"a2c7b6301b5474aab798946fb700289df237c3cf","modified":1462448086000},{"_id":"themes/next/languages/id.yml","hash":"147c01e41b931085ad14250fa900c2249dcbbdd7","modified":1462448086000},{"_id":"themes/next/languages/pt.yml","hash":"ca239b39bf65c9462e59d51b12f0fe566d453197","modified":1462448086000},{"_id":"themes/next/languages/ru.yml","hash":"cc7b964a46587aea0e57b0a5269d8fd25570858e","modified":1462448086000},{"_id":"themes/next/languages/zh-hk.yml","hash":"519ab3d817ec3bc5bfc91159c494b6b3c170bea7","modified":1462448086000},{"_id":"themes/next/languages/zh-Hans.yml","hash":"bea452bc49aed171a210d09bd6cddc4e846ea8ab","modified":1462448086000},{"_id":"themes/next/languages/zh-tw.yml","hash":"6b1f345aaefc13e6723dc8a6741b59ac05c20dfd","modified":1462448086000},{"_id":"themes/next/layout/_layout.swig","hash":"74157f6cfd679ea11febec632542793f37c5e5d4","modified":1462448086000},{"_id":"themes/next/layout/archive.swig","hash":"b5b59d70fc1563f482fa07afd435752774ad5981","modified":1462448086000},{"_id":"themes/next/layout/category.swig","hash":"6422d196ceaff4220d54b8af770e7e957f3364ad","modified":1462448086000},{"_id":"themes/next/layout/index.swig","hash":"427d0b95b854e311ae363088ab39a393bf8fdc8b","modified":1462448086000},{"_id":"themes/next/layout/page.swig","hash":"8019d02232a6dd1a665b6a4d2daef8e5dd2f0049","modified":1462448086000},{"_id":"themes/next/layout/post.swig","hash":"e2e512142961ddfe77eba29eaa88f4a2ee43ae18","modified":1462448086000},{"_id":"themes/next/layout/tag.swig","hash":"07cf49c49c39a14dfbe9ce8e7d7eea3d4d0a4911","modified":1462448086000},{"_id":"themes/next/scripts/merge-configs.js","hash":"0c56be2e85c694247cfa327ea6d627b99ca265e8","modified":1462448086000},{"_id":"themes/next/test/.jshintrc","hash":"096ed6df627373edd820f24d46b8baf528dee61d","modified":1462448086000},{"_id":"themes/next/test/helpers.js","hash":"a1f5de25154c3724ffc24a91ddc576cdbd60864f","modified":1462448086000},{"_id":"themes/next/test/intern.js","hash":"11fa8a4f5c3b4119a179ae0a2584c8187f907a73","modified":1462448086000},{"_id":"themes/next/source/fonts/.gitkeep","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1462448086000},{"_id":"source/images/weibo-which-motherboard.png","hash":"467bfc39938c3cc0f7bee1b8983477a53ba182d0","modified":1471157470000},{"_id":"themes/next/layout/_macro/reward.swig","hash":"37e5b7c42ec17b9b6b786c5512bcc481a21c974e","modified":1462448086000},{"_id":"themes/next/layout/_macro/post.swig","hash":"1ca03011bed92614832b1343b65be92183957dc5","modified":1462448086000},{"_id":"themes/next/layout/_macro/post-collapse.swig","hash":"43c3433155ccd9abcbe7dce2e6bfa1f3a66af18b","modified":1462448086000},{"_id":"themes/next/layout/_partials/comments.swig","hash":"82a9bc2ba60ce68419128ff60624bd74b15dfb78","modified":1462448086000},{"_id":"themes/next/layout/_macro/sidebar.swig","hash":"b883289054ee54a374caad5d4883591beb94bd8b","modified":1462448086000},{"_id":"themes/next/layout/_macro/wechat-subscriber.swig","hash":"85327c2174d09c6d69c9033592e6c8f7eb7ac3ba","modified":1462448086000},{"_id":"themes/next/layout/_partials/duoshuo-hot-articles.swig","hash":"5d4638c46aef65bf32a01681495b62416ccc98db","modified":1462448086000},{"_id":"themes/next/layout/_partials/footer.swig","hash":"0ce71d8322ea7dea82d9371fa2fe13949aa870e3","modified":1462448086000},{"_id":"themes/next/layout/_partials/header.swig","hash":"963a765dc00e6ac43cfc53ffaf5725eb854cf95e","modified":1462448086000},{"_id":"themes/next/layout/_partials/pagination.swig","hash":"9e8e21d194ef44d271b1cca0bc1448c14d7edf4f","modified":1462448086000},{"_id":"themes/next/layout/_partials/head.swig","hash":"f83b1c55bedd2c1a3eb734c72c6997795a4e5f99","modified":1462448086000},{"_id":"themes/next/layout/_partials/search.swig","hash":"011b9d6c9f0a2f4654908ea20b9391f9b7981271","modified":1462448086000},{"_id":"themes/next/layout/_scripts/baidu-push.swig","hash":"82d060fe055d6e423bbc9199f82dfe5c68e74779","modified":1462448086000},{"_id":"themes/next/layout/_scripts/boostrap.swig","hash":"03aaebe9d50f6acb007ec38cc04acd1cfceb404d","modified":1462448086000},{"_id":"themes/next/layout/_scripts/vendors.swig","hash":"0b91cadecead8e0b5211cc42b085998d94af503a","modified":1462448086000},{"_id":"themes/next/layout/_scripts/commons.swig","hash":"766b2bdda29523ed6cd8d7aa197f996022f8fd94","modified":1462448086000},{"_id":"themes/next/scripts/tags/center-quote.js","hash":"535fc542781021c4326dec24d8495cbb1387634a","modified":1462448086000},{"_id":"themes/next/scripts/tags/group-pictures.js","hash":"49252824cd53184dc9b97b2f2d87ff28e1b3ef27","modified":1462448086000},{"_id":"themes/next/scripts/tags/full-image.js","hash":"3acce36db0feb11a982c6c799aa6b6b47df2827c","modified":1462448086000},{"_id":"themes/next/source/images/avatar.gif","hash":"264082bb3a1af70d5499c7d22b0902cb454b6d12","modified":1462448086000},{"_id":"themes/next/source/images/cc-by-nc-nd.svg","hash":"c6524ece3f8039a5f612feaf865d21ec8a794564","modified":1462448086000},{"_id":"themes/next/source/images/cc-by-nc-sa.svg","hash":"3031be41e8753c70508aa88e84ed8f4f653f157e","modified":1462448086000},{"_id":"themes/next/source/images/cc-by-nd.svg","hash":"c563508ce9ced1e66948024ba1153400ac0e0621","modified":1462448086000},{"_id":"themes/next/source/images/cc-by-nc.svg","hash":"8d39b39d88f8501c0d27f8df9aae47136ebc59b7","modified":1462448086000},{"_id":"themes/next/source/images/cc-by-sa.svg","hash":"aa4742d733c8af8d38d4c183b8adbdcab045872e","modified":1462448086000},{"_id":"themes/next/source/images/cc-by.svg","hash":"28a0a4fe355a974a5e42f68031652b76798d4f7e","modified":1462448086000},{"_id":"themes/next/source/images/placeholder.gif","hash":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1462448086000},{"_id":"themes/next/source/images/cc-zero.svg","hash":"87669bf8ac268a91d027a0a4802c92a1473e9030","modified":1462448086000},{"_id":"themes/next/source/images/loading.gif","hash":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1462448086000},{"_id":"themes/next/source/images/quote-l.svg","hash":"94e870b4c8c48da61d09522196d4dd40e277a98f","modified":1462448086000},{"_id":"themes/next/source/images/searchicon.png","hash":"67727a6a969be0b2659b908518fa6706eed307b8","modified":1462448086000},{"_id":"themes/next/source/images/quote-r.svg","hash":"e60ae504f9d99b712c793c3740c6b100d057d4ec","modified":1462448086000},{"_id":"themes/next/source/css/main.styl","hash":"20702c48d6053c92c5bcdbc68e8d0ef1369848a0","modified":1462448086000},{"_id":"themes/next/layout/_scripts/schemes/mist.swig","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1462448086000},{"_id":"themes/next/layout/_scripts/schemes/muse.swig","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1462448086000},{"_id":"themes/next/source/css/_mixins/Mist.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1462448086000},{"_id":"themes/next/source/css/_mixins/Muse.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1462448086000},{"_id":"themes/next/source/css/_mixins/custom.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1462448086000},{"_id":"themes/next/source/css/_variables/Muse.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1462448086000},{"_id":"themes/next/source/css/_variables/custom.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1462448086000},{"_id":"themes/next/layout/_partials/head/external-fonts.swig","hash":"7ce76358411184482bb0934e70037949dd0da8ca","modified":1462448086000},{"_id":"themes/next/layout/_partials/search/swiftype.swig","hash":"959b7e04a96a5596056e4009b73b6489c117597e","modified":1462448086000},{"_id":"themes/next/layout/_partials/search/tinysou.swig","hash":"eefe2388ff3d424694045eda21346989b123977c","modified":1462448086000},{"_id":"themes/next/layout/_partials/search/localsearch.swig","hash":"ff5523d5dacaa77a55a24e50e6e6530c3b98bfad","modified":1462448086000},{"_id":"themes/next/layout/_partials/share/add-this.swig","hash":"c07f7b2f264e5215b8ed42d67e8cef2477558364","modified":1462448086000},{"_id":"themes/next/layout/_partials/share/duoshuo_share.swig","hash":"89c5a5240ecb223acfe1d12377df5562a943fd5d","modified":1462448086000},{"_id":"themes/next/layout/_partials/share/baidushare.swig","hash":"7ca5cb4daa58b3504e17f3e02975e794bc634658","modified":1462448086000},{"_id":"themes/next/layout/_partials/share/jiathis.swig","hash":"63315fcf210799f894208c9f512737096df84962","modified":1462448086000},{"_id":"themes/next/layout/_scripts/pages/post-details.swig","hash":"069d1357c717572256e5cdee09574ebce529cbae","modified":1462448086000},{"_id":"themes/next/layout/_scripts/schemes/pisces.swig","hash":"a44acf9b0d0f44ef3dfc767376a95c984cc127de","modified":1462448086000},{"_id":"themes/next/layout/_scripts/third-party/analytics.swig","hash":"0a89c04055bade7baa5962f1d5aefe438d83a244","modified":1462448086000},{"_id":"themes/next/layout/_scripts/third-party/comments.swig","hash":"907b931d775d32405d02a25b3b0a3ac03bf804d0","modified":1462448086000},{"_id":"themes/next/layout/_scripts/third-party/lean-analytics.swig","hash":"069bb17fb1db3bc7c85c88efa3ed94ab6becbe2c","modified":1462448086000},{"_id":"themes/next/layout/_scripts/third-party/localsearch.swig","hash":"1561bd0c107d725252c6d746e9ac177fc18f93bf","modified":1462448086000},{"_id":"themes/next/layout/_scripts/third-party/mathjax.swig","hash":"5bafc33f57508d1d04a9930165240f6e9efa8d6d","modified":1462448086000},{"_id":"themes/next/layout/_scripts/third-party/tinysou.swig","hash":"cb3a5d36dbe1630bab84e03a52733a46df7c219b","modified":1462448086000},{"_id":"themes/next/source/css/_custom/custom.styl","hash":"328d9a9696cc2ccf59c67d3c26000d569f46344c","modified":1462448086000},{"_id":"themes/next/source/css/_mixins/Pisces.styl","hash":"715d5b40dc52f319fe4bff0325beb874774d9bd9","modified":1462448086000},{"_id":"themes/next/source/css/_mixins/base.styl","hash":"78a83c38f69a8747bb74e420e6c9eeef1ea76525","modified":1462448086000},{"_id":"themes/next/source/css/_variables/Mist.styl","hash":"c8d35a6b9e3bff6d8fdb66de853065af9d37562d","modified":1462448086000},{"_id":"themes/next/source/css/_variables/Pisces.styl","hash":"3ead77befa064d6327dc7afd0a5af7be59a5f196","modified":1462448086000},{"_id":"themes/next/source/css/_variables/base.styl","hash":"17624186f7a1f28daddea258d044f8e03b2f4bea","modified":1462448086000},{"_id":"themes/next/source/js/src/affix.js","hash":"978e0422b5bf1b560236d8d10ebc1adcf66392e3","modified":1462448086000},{"_id":"themes/next/source/js/src/hook-duoshuo.js","hash":"a6119070c0119f33e08b29da7d2cce2635eb40a0","modified":1462448086000},{"_id":"themes/next/source/js/src/bootstrap.js","hash":"39bf93769d9080fa01a9a875183b43198f79bc19","modified":1462448086000},{"_id":"themes/next/source/js/src/motion.js","hash":"269414e84df544a4ccb88519f6abae4943db3c67","modified":1462448086000},{"_id":"themes/next/source/js/src/scrollspy.js","hash":"fe4da1b9fe73518226446f5f27d2831e4426fc35","modified":1462448086000},{"_id":"themes/next/source/js/src/post-details.js","hash":"2038f54e289b6da5def09689e69f623187147be5","modified":1462448086000},{"_id":"themes/next/source/js/src/utils.js","hash":"e5cb720894c4bc28ca8f10b33df127fb394018d9","modified":1462448086000},{"_id":"themes/next/source/vendors/fancybox/.gitattributes","hash":"2db21acfbd457452462f71cc4048a943ee61b8e0","modified":1462448086000},{"_id":"themes/next/source/vendors/fancybox/.bower.json","hash":"cc40a9b11e52348e554c84e4a5c058056f6b7aeb","modified":1462448086000},{"_id":"themes/next/source/vendors/font-awesome/.bower.json","hash":"7da985a99674e54f514d4fd9fcd3bcea6e7e41d5","modified":1462448086000},{"_id":"themes/next/source/vendors/font-awesome/.gitignore","hash":"69d152fa46b517141ec3b1114dd6134724494d83","modified":1462448086000},{"_id":"themes/next/source/vendors/font-awesome/.npmignore","hash":"dcf470ab3a358103bb896a539cc03caeda10fa8b","modified":1462448086000},{"_id":"themes/next/source/vendors/font-awesome/HELP-US-OUT.txt","hash":"69a4c537d167b68a0ccf1c6febd138aeffca60d6","modified":1462448086000},{"_id":"themes/next/source/vendors/fastclick/.bower.json","hash":"93ebd5b35e632f714dcf1753e1f6db77ec74449b","modified":1462448086000},{"_id":"themes/next/source/vendors/font-awesome/bower.json","hash":"279a8a718ab6c930a67c41237f0aac166c1b9440","modified":1462448086000},{"_id":"themes/next/source/vendors/fastclick/LICENSE","hash":"dcd5b6b43095d9e90353a28b09cb269de8d4838e","modified":1462448086000},{"_id":"themes/next/source/vendors/fastclick/bower.json","hash":"13379463c7463b4b96d13556b46faa4cc38d81e6","modified":1462448086000},{"_id":"themes/next/source/vendors/jquery/.bower.json","hash":"91745c2cc6c946c7275f952b2b0760b880cea69e","modified":1462448086000},{"_id":"themes/next/source/vendors/fastclick/README.md","hash":"1decd8e1adad2cd6db0ab50cf56de6035156f4ea","modified":1462448086000},{"_id":"themes/next/source/vendors/jquery_lazyload/.bower.json","hash":"b7638afc93e9cd350d0783565ee9a7da6805ad8e","modified":1462448086000},{"_id":"themes/next/source/vendors/jquery_lazyload/README.md","hash":"895d50fa29759af7835256522e9dd7dac597765c","modified":1462448086000},{"_id":"themes/next/source/vendors/jquery_lazyload/CONTRIBUTING.md","hash":"4891864c24c28efecd81a6a8d3f261145190f901","modified":1462448086000},{"_id":"themes/next/source/vendors/jquery_lazyload/bower.json","hash":"65bc85d12197e71c40a55c0cd7f6823995a05222","modified":1462448086000},{"_id":"themes/next/source/vendors/jquery_lazyload/jquery.lazyload.js","hash":"481fd478650e12b67c201a0ea41e92743f8b45a3","modified":1462448086000},{"_id":"themes/next/source/vendors/jquery_lazyload/jquery.scrollstop.js","hash":"0e9a81785a011c98be5ea821a8ed7d411818cfd1","modified":1462448086000},{"_id":"themes/next/source/vendors/velocity/.bower.json","hash":"05f960846f1c7a93dab1d3f9a1121e86812e8c88","modified":1462448086000},{"_id":"themes/next/source/vendors/velocity/bower.json","hash":"2ec99573e84c7117368beccb9e94b6bf35d2db03","modified":1462448086000},{"_id":"themes/next/source/vendors/velocity/velocity.min.js","hash":"2f1afadc12e4cf59ef3b405308d21baa97e739c6","modified":1462448086000},{"_id":"themes/next/source/vendors/velocity/velocity.ui.js","hash":"6a1d101eab3de87527bb54fcc8c7b36b79d8f0df","modified":1462448086000},{"_id":"themes/next/source/vendors/velocity/velocity.ui.min.js","hash":"ed5e534cd680a25d8d14429af824f38a2c7d9908","modified":1462448086000},{"_id":"themes/next/source/vendors/jquery/index.js","hash":"41b4bfbaa96be6d1440db6e78004ade1c134e276","modified":1462448086000},{"_id":"themes/next/layout/_scripts/third-party/comments/disqus.swig","hash":"3491d3cebabc8a28857200db28a1be65aad6adc2","modified":1462448086000},{"_id":"themes/next/layout/_scripts/third-party/analytics/busuanzi-counter.swig","hash":"4fcbf57c4918528ab51d3d042cff92cf5aefb599","modified":1462448086000},{"_id":"themes/next/layout/_scripts/third-party/comments/duoshuo.swig","hash":"8c7af79407d223486fba72b8150fe045a553bf70","modified":1462448086000},{"_id":"themes/next/layout/_scripts/third-party/analytics/baidu-analytics.swig","hash":"7c43d66da93cde65b473a7d6db2a86f9a42647d6","modified":1462448086000},{"_id":"themes/next/layout/_scripts/third-party/analytics/facebook-sdk.swig","hash":"334176d838ee528e58468d8bc74ff3a6d3f25b2b","modified":1462448086000},{"_id":"themes/next/layout/_scripts/third-party/analytics/google-analytics.swig","hash":"30a23fa7e816496fdec0e932aa42e2d13098a9c2","modified":1462448086000},{"_id":"themes/next/layout/_scripts/third-party/analytics/cnzz-analytics.swig","hash":"44e761721e8ad787ef571a3cc57bbc12d318a2a3","modified":1462448086000},{"_id":"themes/next/layout/_scripts/third-party/analytics/tencent-analytics.swig","hash":"3658414379e0e8a34c45c40feadc3edc8dc55f88","modified":1462448086000},{"_id":"themes/next/source/css/_common/components/buttons.styl","hash":"0dfb4b3ba3180d7285e66f270e1d3fa0f132c3d2","modified":1462448086000},{"_id":"themes/next/source/css/_common/components/comments.styl","hash":"471f1627891aca5c0e1973e09fbcb01e1510d193","modified":1462448086000},{"_id":"themes/next/source/css/_common/components/back-to-top.styl","hash":"b49efc66bd055a2d0be7deabfcb02ee72a9a28c8","modified":1462448086000},{"_id":"themes/next/source/css/_common/components/components.styl","hash":"10994990d6e0b4d965a728a22cf7f6ee29cae9f6","modified":1462448086000},{"_id":"themes/next/source/css/_common/components/pagination.styl","hash":"711c8830886619d4f4a0598b0cde5499dce50c62","modified":1462448086000},{"_id":"themes/next/source/css/_common/components/tag-cloud.styl","hash":"dd8a3b22fc2f222ac6e6c05bd8a773fb039169c0","modified":1462448086000},{"_id":"themes/next/source/css/_common/outline/outline.styl","hash":"2186be20e317505cd31886f1291429cc21f76703","modified":1462448086000},{"_id":"themes/next/source/css/_common/scaffolding/base.styl","hash":"5304f99581da3a31de3ecec959b7adf9002fde83","modified":1462448086000},{"_id":"themes/next/source/css/_common/scaffolding/helpers.styl","hash":"54c90cf7bdbf5c596179d8dae6e671bad1292662","modified":1462448086000},{"_id":"themes/next/source/css/_common/scaffolding/normalize.styl","hash":"ece571f38180febaf02ace8187ead8318a300ea7","modified":1462448086000},{"_id":"themes/next/source/css/_common/scaffolding/scaffolding.styl","hash":"013619c472c7e4b08311c464fcbe9fcf5edde603","modified":1462448086000},{"_id":"themes/next/source/css/_common/scaffolding/tables.styl","hash":"64f5d56c08d74a338813df1265580ca0cbf0190b","modified":1462448086000},{"_id":"themes/next/source/css/_schemes/Pisces/_full-image.styl","hash":"938d39eedc6e3d33918c1145a5bf1e79991d3fcf","modified":1462448086000},{"_id":"themes/next/source/css/_schemes/Pisces/_brand.styl","hash":"be22ad34f546a07f6d56b424338cdd898683eea4","modified":1462448086000},{"_id":"themes/next/source/css/_schemes/Pisces/_layout.styl","hash":"8d7cecde4933900c7df2db9d0a98f5f82f88dc93","modified":1462448086000},{"_id":"themes/next/source/css/_schemes/Pisces/_menu.styl","hash":"d09280e5b79f3b573edb30f30c7a5f03ac640986","modified":1462448086000},{"_id":"themes/next/source/css/_schemes/Pisces/_posts.styl","hash":"2f878213cb24c5ddc18877f6d15ec5c5f57745ac","modified":1462448086000},{"_id":"themes/next/source/css/_schemes/Pisces/index.styl","hash":"1b10ba2d3ad0c063c418dc94a0b7e0db4b342c53","modified":1462448086000},{"_id":"themes/next/source/css/_schemes/Pisces/_sidebar.styl","hash":"d4b7bd610ca03dbb2f5b66631c0e84a79fb4660b","modified":1462448086000},{"_id":"themes/next/source/css/_schemes/Muse/_layout.styl","hash":"6ed60cc621bac096c0ed7534fa25b1a52dc571d4","modified":1462448086000},{"_id":"themes/next/source/css/_schemes/Muse/_logo.styl","hash":"8829bc556ca38bfec4add4f15a2f028092ac6d46","modified":1462448086000},{"_id":"themes/next/source/css/_schemes/Muse/_menu.styl","hash":"c2c6c4f6434b4f94aac2af5861cd769427f0ee10","modified":1462448086000},{"_id":"themes/next/source/css/_schemes/Muse/_search.styl","hash":"1452cbe674cc1d008e1e9640eb4283841058fc64","modified":1462448086000},{"_id":"themes/next/source/css/_schemes/Muse/index.styl","hash":"a0e2030a606c934fb2c5c7373aaae04a1caac4c5","modified":1462448086000},{"_id":"themes/next/source/css/_schemes/Mist/_base.styl","hash":"c2d079788d6fc2e9a191ccdae94e50d55bf849dc","modified":1462448086000},{"_id":"themes/next/source/css/_schemes/Mist/_header.styl","hash":"5ae7906dc7c1d9468c7f4b4a6feddddc555797a1","modified":1462448086000},{"_id":"themes/next/source/css/_schemes/Mist/_menu.styl","hash":"b0dcca862cd0cc6e732e33d975b476d744911742","modified":1462448086000},{"_id":"themes/next/source/css/_schemes/Mist/_posts-expanded.styl","hash":"4303776991ef28f5742ca51c7dffe6f12f0acf34","modified":1462448086000},{"_id":"themes/next/source/css/_schemes/Mist/_logo.styl","hash":"38e5df90c8689a71c978fd83ba74af3d4e4e5386","modified":1462448086000},{"_id":"themes/next/source/css/_schemes/Mist/_search.styl","hash":"1452cbe674cc1d008e1e9640eb4283841058fc64","modified":1462448086000},{"_id":"themes/next/source/css/_schemes/Mist/index.styl","hash":"9a5581a770af8964064fef7afd3e16963e45547f","modified":1462448086000},{"_id":"themes/next/source/js/src/schemes/pisces.js","hash":"7506e7490c69a200831393c38d25e91c156bd471","modified":1462448086000},{"_id":"themes/next/source/vendors/fancybox/source/fancybox_loading@2x.gif","hash":"273b123496a42ba45c3416adb027cd99745058b0","modified":1462448086000},{"_id":"themes/next/source/vendors/fancybox/source/blank.gif","hash":"2daeaa8b5f19f0bc209d976c02bd6acb51b00b0a","modified":1462448086000},{"_id":"themes/next/source/vendors/fancybox/source/fancybox_loading.gif","hash":"1a755fb2599f3a313cc6cfdb14df043f8c14a99c","modified":1462448086000},{"_id":"themes/next/source/vendors/fancybox/source/fancybox_overlay.png","hash":"b3a4ee645ba494f52840ef8412015ba0f465dbe0","modified":1462448086000},{"_id":"themes/next/source/vendors/fancybox/source/fancybox_sprite.png","hash":"17df19f97628e77be09c352bf27425faea248251","modified":1462448086000},{"_id":"themes/next/source/vendors/fancybox/source/fancybox_sprite@2x.png","hash":"30c58913f327e28f466a00f4c1ac8001b560aed8","modified":1462448086000},{"_id":"themes/next/source/vendors/fancybox/source/jquery.fancybox.css","hash":"5f163444617b6cf267342f06ac166a237bb62df9","modified":1462448086000},{"_id":"themes/next/source/vendors/fancybox/source/jquery.fancybox.pack.js","hash":"53360764b429c212f424399384417ccc233bb3be","modified":1462448086000},{"_id":"themes/next/source/vendors/fancybox/source/jquery.fancybox.js","hash":"1cf3d47b5ccb7cb6e9019c64f2a88d03a64853e4","modified":1462448086000},{"_id":"themes/next/source/vendors/font-awesome/css/font-awesome.css.map","hash":"0189d278706509412bac4745f96c83984e1d59f4","modified":1462448086000},{"_id":"themes/next/source/vendors/font-awesome/css/font-awesome.min.css","hash":"05ea25bc9b3ac48993e1fee322d3bc94b49a6e22","modified":1462448086000},{"_id":"themes/next/source/vendors/font-awesome/css/font-awesome.css","hash":"3b87c2560832748cd06f9bfd2fd6ea8edbdae8c7","modified":1462448086000},{"_id":"themes/next/source/vendors/font-awesome/fonts/fontawesome-webfont.woff2","hash":"574ea2698c03ae9477db2ea3baf460ee32f1a7ea","modified":1462448086000},{"_id":"themes/next/source/vendors/fastclick/lib/fastclick.js","hash":"06cef196733a710e77ad7e386ced6963f092dc55","modified":1462448086000},{"_id":"themes/next/source/vendors/fastclick/lib/fastclick.min.js","hash":"2cae0f5a6c5d6f3cb993015e6863f9483fc4de18","modified":1462448086000},{"_id":"themes/next/source/vendors/ua-parser-js/dist/ua-parser.pack.js","hash":"214dad442a92d36af77ed0ca1d9092b16687f02f","modified":1462448086000},{"_id":"themes/next/source/vendors/ua-parser-js/dist/ua-parser.min.js","hash":"38628e75e4412cc6f11074e03e1c6d257aae495b","modified":1462448086000},{"_id":"themes/next/source/vendors/font-awesome/fonts/FontAwesome.otf","hash":"0112e96f327d413938d37c1693806f468ffdbace","modified":1462448086000},{"_id":"themes/next/source/vendors/font-awesome/fonts/fontawesome-webfont.eot","hash":"b3c2f08e73320135b69c23a3908b87a12053a2f6","modified":1462448086000},{"_id":"themes/next/source/vendors/font-awesome/fonts/fontawesome-webfont.woff","hash":"507970402e328b2baeb05bde73bf9ded4e2c3a2d","modified":1462448086000},{"_id":"themes/next/source/vendors/velocity/velocity.js","hash":"e63dc7cea055ca60a95d286f32349d88b10c5a4d","modified":1462448086000},{"_id":"themes/next/source/css/_common/components/footer/footer.styl","hash":"8994ffcce84deac0471532f270f97c44fea54dc0","modified":1462448086000},{"_id":"themes/next/source/css/_common/components/header/header.styl","hash":"ae1ca14e51de67b07dba8f61ec79ee0e2e344574","modified":1462448086000},{"_id":"themes/next/source/css/_common/components/header/headerband.styl","hash":"d27448f199fc2f9980b601bc22b87f08b5d64dd1","modified":1462448086000},{"_id":"themes/next/source/css/_common/components/header/menu.styl","hash":"c890ce7fe933abad7baf39764a01894924854e92","modified":1462448086000},{"_id":"themes/next/source/css/_common/components/header/site-meta.styl","hash":"6c00f6e0978f4d8f9a846a15579963728aaa6a17","modified":1462448086000},{"_id":"themes/next/source/css/_common/components/header/site-nav.styl","hash":"49c2b2c14a1e7fcc810c6be4b632975d0204c281","modified":1462448086000},{"_id":"themes/next/source/css/_common/components/highlight/highlight.styl","hash":"4da051c7f3924fa2db1e73c55b2baf1c2c150255","modified":1462448086000},{"_id":"themes/next/source/css/_common/components/highlight/theme.styl","hash":"90f8f9706cd7fe829cf06e9959a65fd3f8b994fa","modified":1462448086000},{"_id":"themes/next/source/css/_common/components/pages/archive.styl","hash":"7778920dd105fa4de3a7ab206eeba30b1a7bac45","modified":1462448086000},{"_id":"themes/next/source/css/_common/components/pages/categories.styl","hash":"4eff5b252d7b614e500fc7d52c97ce325e57d3ab","modified":1462448086000},{"_id":"themes/next/source/css/_common/components/pages/pages.styl","hash":"3c46efd6601e268093ce6d7b1471d18501878f0d","modified":1462448086000},{"_id":"themes/next/source/css/_common/components/pages/post-detail.styl","hash":"9bf4362a4d0ae151ada84b219d39fbe5bb8c790e","modified":1462448086000},{"_id":"themes/next/source/css/_common/components/post/post-collapse.styl","hash":"8fae54591877a73dff0b29b2be2e8935e3c63575","modified":1462448086000},{"_id":"themes/next/source/css/_common/components/post/post-eof.styl","hash":"2cdc094ecf907a02fce25ad4a607cd5c40da0f2b","modified":1462448086000},{"_id":"themes/next/source/css/_common/components/post/post-expand.styl","hash":"b25132fe6a7ad67059a2c3afc60feabb479bdd75","modified":1462448086000},{"_id":"themes/next/source/css/_common/components/post/post-gallery.styl","hash":"387ce23bba52b22a586b2dfb4ec618fe1ffd3926","modified":1462448086000},{"_id":"themes/next/source/css/_common/components/post/post-meta.styl","hash":"d543d1377c1f61b70e3adb6da0eb12797552e5f2","modified":1462448086000},{"_id":"themes/next/source/css/_common/components/post/post-more-link.styl","hash":"15063d79b5befc21820baf05d6f20cc1c1787477","modified":1462448086000},{"_id":"themes/next/source/css/_common/components/post/post-nav.styl","hash":"cbca4842a54950e2934b3b8f3cd940f122111aef","modified":1462448086000},{"_id":"themes/next/source/css/_common/components/post/post-reward.styl","hash":"e792c8dc41561c96d128e9b421187f1c3dc978a0","modified":1462448086000},{"_id":"themes/next/source/css/_common/components/post/post-tags.styl","hash":"a352ae5b1f8857393bf770d2e638bf15f0c9585d","modified":1462448086000},{"_id":"themes/next/source/css/_common/components/post/post-type.styl","hash":"10251257aceecb117233c9554dcf8ecfef8e2104","modified":1462448086000},{"_id":"themes/next/source/css/_common/components/post/post-title.styl","hash":"963105a531403d7aad6d9e5e23e3bfabb8ec065a","modified":1462448086000},{"_id":"themes/next/source/css/_common/components/post/post.styl","hash":"4eb18b12fa0ea6c35925d9a64f64e2a7dae8c7fd","modified":1462448086000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-author-links.styl","hash":"2e7ec9aaa3293941106b1bdd09055246aa3c3dc6","modified":1462448086000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-author.styl","hash":"920343e41c124221a17f050bbb989494d44f7a24","modified":1462448086000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-blogroll.styl","hash":"c44f6a553ec7ea5508f2054a13be33a62a15d3a9","modified":1462448086000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-feed-link.styl","hash":"9486ddd2cb255227db102d09a7df4cae0fabad72","modified":1462448086000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-toc.styl","hash":"7690b9596ec3a49befbe529a5a2649abec0faf76","modified":1462448086000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-nav.styl","hash":"45fa7193435a8eae9960267438750b4c9fa9587f","modified":1462448086000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-toggle.styl","hash":"2d3abbc85b979a648e0e579e45f16a6eba49d1e7","modified":1462448086000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar.styl","hash":"234facd038f144bd0fe09a31ed1357c5d74c517f","modified":1462448086000},{"_id":"themes/next/source/css/_common/components/sidebar/site-state.styl","hash":"3623e7fa4324ec1307370f33d8f287a9e20a5578","modified":1462448086000},{"_id":"themes/next/source/css/_common/components/tags/blockquote-center.styl","hash":"c2abe4d87148e23e15d49ee225bc650de60baf46","modified":1462448086000},{"_id":"themes/next/source/css/_common/components/tags/group-pictures.styl","hash":"4851b981020c5cbc354a1af9b831a2dcb3cf9d39","modified":1462448086000},{"_id":"themes/next/source/css/_common/components/tags/full-image.styl","hash":"618f73450cf541f88a4fddc3d22898aee49d105d","modified":1462448086000},{"_id":"themes/next/source/css/_common/components/tags/tags.styl","hash":"8e66c2635d48e11de616bb29c4b1323698eebc0a","modified":1462448086000},{"_id":"themes/next/source/css/_common/components/third-party/baidushare.styl","hash":"93b08815c4d17e2b96fef8530ec1f1064dede6ef","modified":1462448086000},{"_id":"themes/next/source/css/_common/components/third-party/busuanzi-counter.styl","hash":"b03f891883446f3a5548b7cc90d29c77e62f1053","modified":1462448086000},{"_id":"themes/next/source/css/_common/components/third-party/duoshuo.styl","hash":"2340dd9b3202c61d73cc708b790fac5adddbfc7f","modified":1462448086000},{"_id":"themes/next/source/css/_common/components/third-party/jiathis.styl","hash":"327b5f63d55ec26f7663185c1a778440588d9803","modified":1462448086000},{"_id":"themes/next/source/css/_common/components/third-party/localsearch.styl","hash":"795d94561888d31cb7a6ff4a125596809ea69b7d","modified":1462448086000},{"_id":"themes/next/source/css/_common/components/third-party/third-party.styl","hash":"3afc459442c132c480d1d832f1a872f1070bb048","modified":1462448086000},{"_id":"themes/next/source/css/_schemes/Muse/sidebar/sidebar-blogroll.styl","hash":"8b8e8cbce98a9296c8fd77f512ae85d945f65d40","modified":1462448086000},{"_id":"themes/next/source/css/_schemes/Mist/sidebar/sidebar-blogroll.styl","hash":"8b8e8cbce98a9296c8fd77f512ae85d945f65d40","modified":1462448086000},{"_id":"themes/next/source/css/_schemes/Mist/outline/outline.styl","hash":"5dc4859c66305f871e56cba78f64bfe3bf1b5f01","modified":1462448086000},{"_id":"themes/next/source/vendors/fancybox/source/helpers/fancybox_buttons.png","hash":"e385b139516c6813dcd64b8fc431c364ceafe5f3","modified":1462448086000},{"_id":"themes/next/source/vendors/fancybox/source/helpers/jquery.fancybox-buttons.css","hash":"1a9d8e5c22b371fcc69d4dbbb823d9c39f04c0c8","modified":1462448086000},{"_id":"themes/next/source/vendors/fancybox/source/helpers/jquery.fancybox-media.js","hash":"3bdf69ed2469e4fb57f5a95f17300eef891ff90d","modified":1462448086000},{"_id":"themes/next/source/vendors/fancybox/source/helpers/jquery.fancybox-buttons.js","hash":"91e41741c2e93f732c82aaacec4cfc6e3f3ec876","modified":1462448086000},{"_id":"themes/next/source/vendors/fancybox/source/helpers/jquery.fancybox-thumbs.css","hash":"4ac329c16a5277592fc12a37cca3d72ca4ec292f","modified":1462448086000},{"_id":"source/images/weibo-cannot-boot.png","hash":"75ad836981d95618c913f357b43deb35447546a4","modified":1471158438000},{"_id":"themes/next/source/vendors/fancybox/source/helpers/jquery.fancybox-thumbs.js","hash":"53e194f4a72e649c04fb586dd57762b8c022800b","modified":1462448086000},{"_id":"themes/next/source/vendors/font-awesome/fonts/fontawesome-webfont.ttf","hash":"27cf1f2ec59aece6938c7bb2feb0e287ea778ff9","modified":1462448086000},{"_id":"themes/next/source/vendors/font-awesome/fonts/fontawesome-webfont.svg","hash":"2b3c8ba7008cc014d8fb37abc6f9f49aeda83824","modified":1462448086000},{"_id":"public/2016-08-17-deep-learning-cuda-development-environment/index.html","hash":"71a3c23f1b160289075b91161e034634feb1a27d","modified":1471517820312},{"_id":"public/2016-08-14-dual-install-windows-ubuntu/index.html","hash":"6adcae9d4d3fe177704c810b6294c3334f0e612e","modified":1471517820334},{"_id":"public/2016-08-13-my-deep-learning-workstation-assemble-process-note/index.html","hash":"9a2c30eb7be80460aba86046378c6b995ab63ae5","modified":1471517820335},{"_id":"public/2014-08-06-install-scikit-learn-with-python3/index.html","hash":"f210f450392449067a197af8c350952944b4181f","modified":1471517820335},{"_id":"public/2014-04-24-working-os-x-10-dot-9-mavericks-vmware-image-for-windows-os/index.html","hash":"bcc174fe4d657300c260a5aaca405c2942c7963c","modified":1471517820335},{"_id":"public/2014-04-03-caffe-installation/index.html","hash":"cd53f8cd82fef1d4704f779a4e4a157d546473c7","modified":1471517820336},{"_id":"public/2014-02-20-writing-nutch-plugins/index.html","hash":"18b8f83e4375b99c2c972cb941734d80874a343c","modified":1471517820336},{"_id":"public/2014-02-14-compile-hadoop-220-on-centos/index.html","hash":"4a64f2e1d851984d17c640f6a14f5b0bb420071a","modified":1471517820336},{"_id":"public/2014-02-08-install-hbase-on-centos/index.html","hash":"7e7e41e8cd0461aaf94a8ee6328f18803be2fc9b","modified":1471517820336},{"_id":"public/2014-02-07-install-zookeeper-on-centos/index.html","hash":"f415631baed9b07d7699e3334a61699952698376","modified":1471517820336},{"_id":"public/2014-02-06-hadoop-multiple-users/index.html","hash":"6bf1b430050a17839dc2accd366b3409fab36d42","modified":1471517820336},{"_id":"public/2014-02-05-hadoop-2-installatioin-on-centos/index.html","hash":"05f09f77b76936b000071f20ab791014bc1e92d0","modified":1471517820336},{"_id":"public/2014-02-04-running-nutch-on-hadoop-cluster/index.html","hash":"51d8731f269d27905d4fc904316c6a717b8038d9","modified":1471517820336},{"_id":"public/2014-02-03-hadoop-multiple-users/index.html","hash":"912c3f3122b7602d16179a563d0702aff8ca5196","modified":1471517820336},{"_id":"public/2014-02-02-hadoop-installatioin-on-centos/index.html","hash":"5947ad87d431b2930b64a57517c7e830434e3a6f","modified":1471517820336},{"_id":"public/2014-02-01-nutch-tutorial/index.html","hash":"4dccb9177f983abf7b8584cb06d046fc332a7018","modified":1471517820336},{"_id":"public/2014-01-31-install-uek-for-centos/index.html","hash":"7f20691d727cf3e0fe7ecf99abde1a7a68fadecd","modified":1471517820336},{"_id":"public/2014-01-30-spark-development-environment/index.html","hash":"8e015f05ba764bf66bca6f783436d1a62f2a6878","modified":1471517820337},{"_id":"public/2014-01-29-my-ansible-playbook/index.html","hash":"16033ef829996b7a3022a52da998001d0f1738f3","modified":1471517820337},{"_id":"public/2014-01-28-restore-octopress-at-a-new-computer/index.html","hash":"a1e3ecdbe6762d8596e03d77cd563dffba61b7cc","modified":1471517820337},{"_id":"public/2014-01-27-ansible-tutorial/index.html","hash":"123775e548b18cd2fd15b758fa43d1ea35173d78","modified":1471517820337},{"_id":"public/2014-01-26-boot-space-insufficient/index.html","hash":"37f707242578488ddd411de61e3679d11283ebc8","modified":1471517820338},{"_id":"public/2014-01-25-rdesktop-tutorial/index.html","hash":"580bcc0b554e6f8ed9f16a6ad9fe12039df9dc28","modified":1471517820338},{"_id":"public/2014-01-24-cluster-time-sync-using-ntp/index.html","hash":"ff0875409bbcabb8f40cba2811a5fec148f165db","modified":1471517820338},{"_id":"public/2014-01-23-centos-6-dot-4-upgrade-kernel/index.html","hash":"fb6522f1a4ad04915de7d7318e66568c3629246a","modified":1471517820338},{"_id":"public/2014-01-22-install-docker-on-centos65/index.html","hash":"f7c54df4e708bd5f3fcb0d3c02c87e1c206de32a","modified":1471517820338},{"_id":"public/2014-01-21-nutch-tutorial-17/index.html","hash":"8d85832755ea8d309a601a52c9539e8c17a00e6e","modified":1471517820338},{"_id":"public/2014-01-20-Running-Nutch-in-Eclipse/index.html","hash":"c9dee7af3f90e0ab1f138a5d5c86e4b1e87a8461","modified":1471517820338},{"_id":"public/2013-12-23-run-mahout-nbc/index.html","hash":"b5f90ef263dcffb90af2e97796b0c907c6ab2a15","modified":1471517820339},{"_id":"public/2013-10-27-build-spark-cluster-with-docker/index.html","hash":"5ebf8b9a3303a066e567ca62b095c51d18209dc5","modified":1471517820339},{"_id":"public/2013-10-26-docker-tutorial/index.html","hash":"5b03310f6c6f1f1ab7d86164ecb1e6e5abd9dc02","modified":1471517820339},{"_id":"public/2013-10-25-docker-installation/index.html","hash":"83a0f9e6af4b9ca3792d102f158a32693dc47ee4","modified":1471517820339},{"_id":"public/2013-10-17-installing-spark-on-centos-cn/index.html","hash":"e9b55f37f4f2a16d090ac03bdcb74e69c8ff6855","modified":1471517820339},{"_id":"public/2013-04-05-concise-scala/index.html","hash":"c3d08a5c89a624955aa4d50d3f6f6af9654fa44a","modified":1471517820339},{"_id":"public/2013-06-17-installing-spark-on-centos-cn/index.html","hash":"4dee94c98a9567dbbade8f97444fe8cf30819a00","modified":1471517820340},{"_id":"public/2013-06-14-installing-spark-on-centos/index.html","hash":"5b61a0c6bb6f0c4375468c0f22c18af2b007b1eb","modified":1471517820340},{"_id":"public/2013-06-11-read-spark-source-code-using-scala-ide/index.html","hash":"d3efe22860ca481ced68cf9ba17662e823dceb57","modified":1471517820340},{"_id":"public/2013-04-12-latex-distributions-and-editors/index.html","hash":"d7386c4ac47005f10655157c213aceac3108db4a","modified":1471517820340},{"_id":"public/2013-04-02-my-octopress-configuration/index.html","hash":"5b50b44b1bd224655f97dc7ce56b6588c288c6b7","modified":1471517820340},{"_id":"public/2013-04-01-using-github-and-octoperss-to-create-a-free-blog/index.html","hash":"bd1edb8c1f49be94ecc1aa72a5ce0a82d0b58e44","modified":1471517820340},{"_id":"public/2013-03-27-some-classical-machine-learning-tutorials/index.html","hash":"7c784cca7a9751ab3da0008878cdfb6e2e97f0fd","modified":1471517820341},{"_id":"public/2013-03-22-some-popular-programming-contest-websites/index.html","hash":"344a8ab9943ec1cea76fd782fd030a2ed3d598be","modified":1471517820341},{"_id":"public/2013-02-26-numerical-or-scientific-computation-library/index.html","hash":"a7a411d94f4846796d9d6f34a2f4eb3dfccbc4a6","modified":1471517820341},{"_id":"public/2013-02-25-differences-between-knn-and-kmeans/index.html","hash":"3362002f6fd3caa4d3630ea8dea604db96deb21c","modified":1471517820341},{"_id":"public/2012-08-11-configure-tomcat-jmx-to-allow-visualvm-connect-tomcat/index.html","hash":"d4faae351bbbdc7e258a8def545279c1a99d56c5","modified":1471517820341},{"_id":"public/2012-04-23-install-and-configure-a-centos-server-from-scratch/index.html","hash":"fc84ade228f2ddc87b42c14eb5f94d88e25efdfe","modified":1471517820341},{"_id":"public/2012-04-18-create-a-bootable-vmware-esxi-5-usb-stick/index.html","hash":"276ac288d0059bf6b946931c5293b4a78564e1e9","modified":1471517820341},{"_id":"public/2012-01-03-hadoop-installation-on-ubuntu/index.html","hash":"e19c7af7ba4a2f1722f3fbcd5857e5d1bb0954ae","modified":1471517820342},{"_id":"public/2012-01-02-ssh-passwordless-login-configuration/index.html","hash":"e3fcb9470d5eab63347b709431bb7b9d6178ba1f","modified":1471517820342},{"_id":"public/2011-06-23-using-javac-to-compile-multi-java-files/index.html","hash":"f886e74dfc676405e5c2556961ea4eb0eb08ad86","modified":1471517820342},{"_id":"public/2010-04-17-tex-resources-for-newbies/index.html","hash":"b9b28ce29ec82f179ade897330c524db36cc33a5","modified":1471517820342},{"_id":"public/archives/2010/02/index.html","hash":"e04fa940ea802b0650cfbce11d739d84efa8c6c0","modified":1471517820380},{"_id":"public/archives/2010/03/index.html","hash":"3108a37cd879e73d414f6e8338a0d04dcfc0e6db","modified":1471517820380},{"_id":"public/archives/2010/04/index.html","hash":"2a40b408911392660aadd705820240750707478a","modified":1471517820380},{"_id":"public/archives/2010/05/index.html","hash":"78faafb6b092474d88df206b59251d590de5741f","modified":1471517820380},{"_id":"public/archives/2011/index.html","hash":"011b6d692bc03210afd1c78cc211587e98bb950e","modified":1471517820381},{"_id":"public/archives/2011/04/index.html","hash":"16ba39d918ef25567367193dfa010a69099cf1b8","modified":1471517820381},{"_id":"public/archives/2011/06/index.html","hash":"214d1db8e12f4f25878093e3339f72ed3ce0622f","modified":1471517820381},{"_id":"public/archives/2012/01/index.html","hash":"3dce933564828aaa5c39d0b41147c93c8282f2c8","modified":1471517820381},{"_id":"public/archives/2012/04/index.html","hash":"1524c9a1818ee86f38ac53acfe8477e3b78964e1","modified":1471517820382},{"_id":"public/archives/2012/08/index.html","hash":"134f22853e15ad9c5d1c9910e39b1722b90fce8c","modified":1471517820382},{"_id":"public/archives/2013/02/index.html","hash":"8ee3b29b578b13a9660439221a724eeed0947966","modified":1471517820382},{"_id":"public/archives/2013/03/index.html","hash":"9ec863f4c1d4d7c113b3ed5b61ce068b405e5982","modified":1471517820382},{"_id":"public/archives/2013/04/index.html","hash":"72f675be109f54f2f706f0ad905ba7e94ba57421","modified":1471517820382},{"_id":"public/archives/2013/06/index.html","hash":"601ba6d409fd6826b936591de1c3da510844fd6e","modified":1471517820382},{"_id":"public/archives/2013/08/index.html","hash":"eb3f6969407d1af61e8e1f06a770ba2b581177a1","modified":1471517820382},{"_id":"public/archives/2013/12/index.html","hash":"2e8fba6b1f8a8fba80a2e588b4b506cb674f8813","modified":1471517820382},{"_id":"public/archives/2014/01/page/2/index.html","hash":"f6ccdeb66284e53564f2ff53ece7cfbd825e4b1a","modified":1471517820382},{"_id":"public/archives/2014/04/index.html","hash":"562d72a1b5fdc0292cbd4ff418469d0e5de55b76","modified":1471517820383},{"_id":"public/archives/2014/08/index.html","hash":"a73eb6b39e2d92e22f2e2d2c1cce52475f70d944","modified":1471517820383},{"_id":"public/archives/2016/index.html","hash":"f74f19b7702562263c919df83904da5023d808b0","modified":1471517820383},{"_id":"public/archives/2016/08/index.html","hash":"dd30c7035bfd35439c0151f0923eeea4d382d975","modified":1471517820383},{"_id":"public/categories/Tools/page/2/index.html","hash":"fdf8cbc0699a9de17af7b21039cb3733e4833e4d","modified":1471517820383},{"_id":"public/categories/Language/index.html","hash":"2800750951aae91c10c8492dc1106520a82bd0b9","modified":1471517820383},{"_id":"public/categories/Algorithm/index.html","hash":"3027364186c5face80c1e50a993e6c759e91f5dc","modified":1471517820383},{"_id":"public/categories/Docker/index.html","hash":"99320d3739006a1ebe008508b7e0b30de8c1d77b","modified":1471517820383},{"_id":"public/categories/Deep-Learning/index.html","hash":"5c58699f05ebb8bcd103e517c16556b262a3852b","modified":1471517820383},{"_id":"public/categories/Python/index.html","hash":"e6a931d125514efb3c25e7128c0a099f046c3035","modified":1471517820384},{"_id":"public/categories/深度学习/index.html","hash":"867b8e0eee6161e1e8e2686e1409e50c2e7af4a0","modified":1471517820385},{"_id":"public/tags/scala/index.html","hash":"ebea65d0156ddfb00128b779cbc8c10ec392cc59","modified":1471517820385},{"_id":"public/tags/spark/index.html","hash":"3a72ac44dd365487f8211fc497f55b3b70f4e55c","modified":1471517820385},{"_id":"public/tags/mahout/index.html","hash":"6a40986c4274cb6a79f872eee0fd682104fe0572","modified":1471517820385},{"_id":"public/tags/naive-bayes/index.html","hash":"88cb738530186c895300601f99ad23f15a8aee72","modified":1471517820385},{"_id":"public/tags/深度学习/index.html","hash":"d5816856a09d7bda7c14aac64b95923e6129b905","modified":1471517820385},{"_id":"public/2010-05-28-text-classification-algorithm-based-on-naive-bayes/index.html","hash":"a320a7bf3ab30c7932db47e4966c03f949773264","modified":1471517820386},{"_id":"public/2010-04-01-read-and-write-images-using-java-imageio/index.html","hash":"83662bed131cbbfc2be31d858eaa81dc8a2f6495","modified":1471517820386},{"_id":"public/2010-03-31-java-qa-tools/index.html","hash":"6b8512efa888d2d4ccec48fce3e2a64e9175ac77","modified":1471517820386},{"_id":"public/2010-03-28-extract-text-from-pdf-using-pdfbox/index.html","hash":"2e899adf239c0bc550d9e53f6408f518dfde2085","modified":1471517820386},{"_id":"public/2010-02-15-run-class-file-in-java-command-line/index.html","hash":"8f36b2d261f9f7485988278c82b21d20b28e2645","modified":1471517820386},{"_id":"public/archives/index.html","hash":"d8d8a7603aa89f3771bcfb0b106a7a899458e91c","modified":1471517820386},{"_id":"public/archives/page/2/index.html","hash":"136b5ebf98c98997266916b30cc1481c2f8e0c0f","modified":1471517820386},{"_id":"public/archives/page/5/index.html","hash":"ef8079d7a8570497019dc1d5670cfc513751ff9f","modified":1471517820386},{"_id":"public/archives/page/6/index.html","hash":"b159e348a5bd00e2655df539a0478f8bbf131ddc","modified":1471517820386},{"_id":"public/archives/2010/index.html","hash":"c4e780f0b47420c570a0c9628dc476f5f3c9d766","modified":1471517820387},{"_id":"public/archives/2012/index.html","hash":"98aaee9a98bc5cf619830754f388e32c1fe504a7","modified":1471517820387},{"_id":"public/archives/2013/index.html","hash":"4b092c7367a55fcb0fe6908949286c225439c8bc","modified":1471517820387},{"_id":"public/archives/2013/page/2/index.html","hash":"4a390ed2e3c6ef610119a55579206248a8c64461","modified":1471517820387},{"_id":"public/archives/2013/10/index.html","hash":"734e3999fd749f0df010860f7115aa45d9376c40","modified":1471517820387},{"_id":"public/archives/2014/index.html","hash":"cba9c39bb6de0e19785bdb8de18fd2165026379d","modified":1471517820387},{"_id":"public/archives/2014/page/2/index.html","hash":"c7896371984a7b40cd711859fbd880b6b8ebb0a1","modified":1471517820387},{"_id":"public/archives/2014/page/3/index.html","hash":"d0158d7cdfc7c3333edef64055f88102f03b1035","modified":1471517820387},{"_id":"public/archives/2014/01/index.html","hash":"16479a2f038d3afdca5fad0a2d9a05163ee2c850","modified":1471517820388},{"_id":"public/archives/2014/02/index.html","hash":"2fb808e8c8fdfddc339e7aba01045fd208467b12","modified":1471517820388},{"_id":"public/categories/Tools/index.html","hash":"49e5dbd55ef861451147981a2675483677506031","modified":1471517820388},{"_id":"public/categories/Machine-Learning/index.html","hash":"dd3bc781c7bec791f28ae86e806a19ab391b86ae","modified":1471517820388},{"_id":"public/categories/DevOps/index.html","hash":"e78c5ee0b488208f5bd65fdb1da71fd3acf5c5d5","modified":1471517820388},{"_id":"public/categories/Hadoop/index.html","hash":"d26f0740288bff37f8e4a8de5d2a9d3e4930ddf4","modified":1471517820388},{"_id":"public/categories/Spark/index.html","hash":"e843ab5aca5592a00d886ebfe589a8d91f7ed69f","modified":1471517820389},{"_id":"public/categories/Search-Engine/index.html","hash":"7cbfc5ee8a6724d05fbde08b97072049ceb5dba6","modified":1471517820389},{"_id":"public/index.html","hash":"895458811e932a5214855d98330c93f69b1f4c1d","modified":1471517820389},{"_id":"public/page/2/index.html","hash":"0cdccda50c56c164752c3ccad167e58f625ce930","modified":1471517820389},{"_id":"public/page/3/index.html","hash":"5fa65bb46c17619e43a148a53ceb1619b3b4c136","modified":1471517820389},{"_id":"public/page/4/index.html","hash":"2c71e2f348eb1d65729003724a30e53046ff6217","modified":1471517820390},{"_id":"public/page/5/index.html","hash":"c30c944e3e8cd2e7cf94466bbf4c72385a86bcb2","modified":1471517820390},{"_id":"public/page/6/index.html","hash":"55820ca924c665cbfcef0f1ce3f54d3ef8e42b09","modified":1471517820390},{"_id":"public/archives/page/3/index.html","hash":"7854b890e04358f87cce563cb7750ad32b332c4d","modified":1471517820390},{"_id":"public/archives/page/4/index.html","hash":"8b5e25caefab6347b93f1c155fc86c95ba16d54b","modified":1471517820390},{"_id":"public/CNAME","hash":"10cbd40f0de2ea1319192b1002535c600a5deedb","modified":1471517820390},{"_id":"public/images/cc-by-nd.svg","hash":"c563508ce9ced1e66948024ba1153400ac0e0621","modified":1471517820390},{"_id":"public/images/cc-by-nc.svg","hash":"8d39b39d88f8501c0d27f8df9aae47136ebc59b7","modified":1471517820390},{"_id":"public/images/cc-by.svg","hash":"28a0a4fe355a974a5e42f68031652b76798d4f7e","modified":1471517820391},{"_id":"public/images/cc-by-sa.svg","hash":"aa4742d733c8af8d38d4c183b8adbdcab045872e","modified":1471517820391},{"_id":"public/images/placeholder.gif","hash":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1471517820391},{"_id":"public/images/loading.gif","hash":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1471517820391},{"_id":"public/images/cc-zero.svg","hash":"87669bf8ac268a91d027a0a4802c92a1473e9030","modified":1471517820391},{"_id":"public/images/quote-l.svg","hash":"94e870b4c8c48da61d09522196d4dd40e277a98f","modified":1471517820391},{"_id":"public/images/searchicon.png","hash":"67727a6a969be0b2659b908518fa6706eed307b8","modified":1471517820391},{"_id":"public/images/quote-r.svg","hash":"e60ae504f9d99b712c793c3740c6b100d057d4ec","modified":1471517820392},{"_id":"public/vendors/font-awesome/HELP-US-OUT.txt","hash":"69a4c537d167b68a0ccf1c6febd138aeffca60d6","modified":1471517820392},{"_id":"public/vendors/fastclick/LICENSE","hash":"dcd5b6b43095d9e90353a28b09cb269de8d4838e","modified":1471517820392},{"_id":"public/images/cc-by-nc-nd.svg","hash":"c6524ece3f8039a5f612feaf865d21ec8a794564","modified":1471517820392},{"_id":"public/images/avatar.gif","hash":"264082bb3a1af70d5499c7d22b0902cb454b6d12","modified":1471517820392},{"_id":"public/vendors/fancybox/source/fancybox_loading@2x.gif","hash":"273b123496a42ba45c3416adb027cd99745058b0","modified":1471517820392},{"_id":"public/vendors/fancybox/source/fancybox_loading.gif","hash":"1a755fb2599f3a313cc6cfdb14df043f8c14a99c","modified":1471517820394},{"_id":"public/vendors/fancybox/source/blank.gif","hash":"2daeaa8b5f19f0bc209d976c02bd6acb51b00b0a","modified":1471517820394},{"_id":"public/vendors/fancybox/source/fancybox_overlay.png","hash":"b3a4ee645ba494f52840ef8412015ba0f465dbe0","modified":1471517820394},{"_id":"public/vendors/fancybox/source/fancybox_sprite.png","hash":"17df19f97628e77be09c352bf27425faea248251","modified":1471517820394},{"_id":"public/vendors/fancybox/source/fancybox_sprite@2x.png","hash":"30c58913f327e28f466a00f4c1ac8001b560aed8","modified":1471517820395},{"_id":"public/vendors/font-awesome/css/font-awesome.css.map","hash":"0189d278706509412bac4745f96c83984e1d59f4","modified":1471517820395},{"_id":"public/vendors/font-awesome/fonts/fontawesome-webfont.woff2","hash":"574ea2698c03ae9477db2ea3baf460ee32f1a7ea","modified":1471517820395},{"_id":"public/vendors/fancybox/source/helpers/fancybox_buttons.png","hash":"e385b139516c6813dcd64b8fc431c364ceafe5f3","modified":1471517820395},{"_id":"public/vendors/font-awesome/fonts/FontAwesome.otf","hash":"0112e96f327d413938d37c1693806f468ffdbace","modified":1471517822905},{"_id":"public/vendors/font-awesome/fonts/fontawesome-webfont.eot","hash":"b3c2f08e73320135b69c23a3908b87a12053a2f6","modified":1471517822918},{"_id":"public/vendors/font-awesome/fonts/fontawesome-webfont.woff","hash":"507970402e328b2baeb05bde73bf9ded4e2c3a2d","modified":1471517822920},{"_id":"public/images/cc-by-nc-sa.svg","hash":"3031be41e8753c70508aa88e84ed8f4f653f157e","modified":1471517822920},{"_id":"public/js/src/affix.js","hash":"978e0422b5bf1b560236d8d10ebc1adcf66392e3","modified":1471517822950},{"_id":"public/js/src/hook-duoshuo.js","hash":"a6119070c0119f33e08b29da7d2cce2635eb40a0","modified":1471517822950},{"_id":"public/js/src/bootstrap.js","hash":"39bf93769d9080fa01a9a875183b43198f79bc19","modified":1471517822950},{"_id":"public/js/src/motion.js","hash":"269414e84df544a4ccb88519f6abae4943db3c67","modified":1471517822951},{"_id":"public/js/src/scrollspy.js","hash":"fe4da1b9fe73518226446f5f27d2831e4426fc35","modified":1471517822951},{"_id":"public/js/src/post-details.js","hash":"2038f54e289b6da5def09689e69f623187147be5","modified":1471517822951},{"_id":"public/js/src/utils.js","hash":"e5cb720894c4bc28ca8f10b33df127fb394018d9","modified":1471517822951},{"_id":"public/vendors/font-awesome/bower.json","hash":"64394a2a9aa00f8e321d8daa5e51a420f0e96dad","modified":1471517822951},{"_id":"public/vendors/fastclick/bower.json","hash":"4dcecf83afddba148464d5339c93f6d0aa9f42e9","modified":1471517822951},{"_id":"public/vendors/fastclick/README.html","hash":"da3c74d484c73cc7df565e8abbfa4d6a5a18d4da","modified":1471517822951},{"_id":"public/vendors/jquery_lazyload/README.html","hash":"bde24335f6bc09d8801c0dcd7274f71b466552bd","modified":1471517822951},{"_id":"public/vendors/jquery_lazyload/jquery.lazyload.js","hash":"481fd478650e12b67c201a0ea41e92743f8b45a3","modified":1471517822951},{"_id":"public/vendors/jquery_lazyload/jquery.scrollstop.js","hash":"0e9a81785a011c98be5ea821a8ed7d411818cfd1","modified":1471517822952},{"_id":"public/vendors/velocity/bower.json","hash":"0ef14e7ccdfba5db6eb3f8fc6aa3b47282c36409","modified":1471517822952},{"_id":"public/vendors/velocity/velocity.ui.min.js","hash":"ed5e534cd680a25d8d14429af824f38a2c7d9908","modified":1471517822952},{"_id":"public/js/src/schemes/pisces.js","hash":"7506e7490c69a200831393c38d25e91c156bd471","modified":1471517822952},{"_id":"public/vendors/fancybox/source/jquery.fancybox.css","hash":"5f163444617b6cf267342f06ac166a237bb62df9","modified":1471517822952},{"_id":"public/vendors/fastclick/lib/fastclick.min.js","hash":"2cae0f5a6c5d6f3cb993015e6863f9483fc4de18","modified":1471517822952},{"_id":"public/vendors/ua-parser-js/dist/ua-parser.pack.js","hash":"214dad442a92d36af77ed0ca1d9092b16687f02f","modified":1471517822952},{"_id":"public/vendors/ua-parser-js/dist/ua-parser.min.js","hash":"38628e75e4412cc6f11074e03e1c6d257aae495b","modified":1471517822952},{"_id":"public/vendors/fancybox/source/helpers/jquery.fancybox-buttons.css","hash":"1a9d8e5c22b371fcc69d4dbbb823d9c39f04c0c8","modified":1471517822952},{"_id":"public/vendors/fancybox/source/helpers/jquery.fancybox-media.js","hash":"3bdf69ed2469e4fb57f5a95f17300eef891ff90d","modified":1471517822955},{"_id":"public/vendors/fancybox/source/helpers/jquery.fancybox-thumbs.css","hash":"4ac329c16a5277592fc12a37cca3d72ca4ec292f","modified":1471517822955},{"_id":"public/vendors/fancybox/source/helpers/jquery.fancybox-buttons.js","hash":"91e41741c2e93f732c82aaacec4cfc6e3f3ec876","modified":1471517822955},{"_id":"public/vendors/fancybox/source/helpers/jquery.fancybox-thumbs.js","hash":"53e194f4a72e649c04fb586dd57762b8c022800b","modified":1471517822955},{"_id":"public/css/main.css","hash":"d6a80cce9f349ae362118a1e0f506c8bb84928ee","modified":1471517822956},{"_id":"public/vendors/velocity/velocity.min.js","hash":"2f1afadc12e4cf59ef3b405308d21baa97e739c6","modified":1471517822956},{"_id":"public/vendors/velocity/velocity.ui.js","hash":"6a1d101eab3de87527bb54fcc8c7b36b79d8f0df","modified":1471517822956},{"_id":"public/vendors/jquery/index.js","hash":"41b4bfbaa96be6d1440db6e78004ade1c134e276","modified":1471517822956},{"_id":"public/vendors/fancybox/source/jquery.fancybox.pack.js","hash":"53360764b429c212f424399384417ccc233bb3be","modified":1471517822956},{"_id":"public/vendors/fancybox/source/jquery.fancybox.js","hash":"1cf3d47b5ccb7cb6e9019c64f2a88d03a64853e4","modified":1471517822956},{"_id":"public/vendors/font-awesome/css/font-awesome.min.css","hash":"05ea25bc9b3ac48993e1fee322d3bc94b49a6e22","modified":1471517822956},{"_id":"public/vendors/font-awesome/css/font-awesome.css","hash":"3b87c2560832748cd06f9bfd2fd6ea8edbdae8c7","modified":1471517822956},{"_id":"public/vendors/fastclick/lib/fastclick.js","hash":"06cef196733a710e77ad7e386ced6963f092dc55","modified":1471517822957},{"_id":"public/vendors/velocity/velocity.js","hash":"9f08181baea0cc0e906703b7e5df9111b9ef3373","modified":1471517822957},{"_id":"public/images/weibo-which-motherboard.png","hash":"467bfc39938c3cc0f7bee1b8983477a53ba182d0","modified":1471517822957},{"_id":"public/vendors/font-awesome/fonts/fontawesome-webfont.ttf","hash":"27cf1f2ec59aece6938c7bb2feb0e287ea778ff9","modified":1471517822957},{"_id":"public/vendors/jquery_lazyload/CONTRIBUTING.html","hash":"a6358170d346af13b1452ac157b60505bec7015c","modified":1471517822969},{"_id":"public/vendors/jquery_lazyload/bower.json","hash":"ae3c3b61e6e7f9e1d7e3585ad854380ecc04cf53","modified":1471517822969},{"_id":"public/vendors/font-awesome/fonts/fontawesome-webfont.svg","hash":"2b3c8ba7008cc014d8fb37abc6f9f49aeda83824","modified":1471517823046},{"_id":"public/images/weibo-cannot-boot.png","hash":"75ad836981d95618c913f357b43deb35447546a4","modified":1471517823200}],"Category":[{"name":"Tools","_id":"cis07peup000101pqouklpfo6"},{"name":"Language","_id":"cis07pf23000801pq08b0ttbv"},{"name":"Machine-Learning","_id":"cis07pf2g000i01pq8vda41tw"},{"name":"DevOps","_id":"cis07pf2l000m01pqsc5pm4zu"},{"name":"Hadoop","_id":"cis07pf2q000r01pqdvkmdjze"},{"name":"Algorithm","_id":"cis07pf2z000w01pqc1q9efel"},{"name":"algorithm","_id":"cis07pf35001301pqoxdytt9y"},{"name":"Spark","_id":"cis07pf3a001b01pq78kknjv4"},{"name":"mahout","_id":"cis07pf3j001o01pq4jmlr1kc"},{"name":"Docker","_id":"cis07pf3r002201pqyfwf5cwr"},{"name":"Search-Engine","_id":"cis07pf3w002701pqaeykd1qt"},{"name":"Deep-Learning","_id":"cis07pf4r003s01pqhthv3ali"},{"name":"Python","_id":"cis07pf4u003y01pqbuinyg41"},{"name":"深度学习","_id":"cis07pf4w004401pqewxnoaad"}],"Data":[],"Page":[],"Post":[{"layout":"post","title":"使用pdfbox 抽取PDF文件中的文本","date":"2010-03-28T16:41:00.000Z","comments":1,"_content":"``` java\npackage com.yanjiuyanjiu.search;\n\nimport java.io.File;\nimport java.io.IOException;\n\nimport org.apache.pdfbox.pdmodel.PDDocument;\nimport org.apache.pdfbox.util.PDFTextStripper;\n\n/**\n * 抽去PDF文件中的文本.\n * @author soulmachine\n *\n */\npublic final class PDFboxTest {\n /** 禁止创建对象. */\n private PDFboxTest() {\n }\n /**\n * 抽取PDF中的文本.\n * @param f PDF文件\n * @return PDF对应的文本字符串\n */\n public static String getText(final File f) {\n String text = \"\";\n try {\n PDDocument pdfdocument = PDDocument.load(f);\n PDFTextStripper stripper = new PDFTextStripper();\n stripper.setStartPage(1); // 只抽取第1页和第2页\n stripper.setEndPage(2);\n text = stripper.getText(pdfdocument);\n pdfdocument.close();\n\n } catch (IOException e) {\n e.printStackTrace();\n }\n\n return text;\n }\n\n /** 测试.\n *\n * @param args PDF文件路径\n */\n public static void main(final String[]  args) {\n File file = new File(args[0]);\n System.out.println(PDFboxTest.getText(file));\n }\n}\n```\n","source":"_posts/2010-03-28-extract-text-from-pdf-using-pdfbox.md","raw":"---\nlayout: post\ntitle: \"使用pdfbox 抽取PDF文件中的文本\"\ndate: 2010-03-28 16:41\ncomments: true\ncategories: Tools\n---\n``` java\npackage com.yanjiuyanjiu.search;\n\nimport java.io.File;\nimport java.io.IOException;\n\nimport org.apache.pdfbox.pdmodel.PDDocument;\nimport org.apache.pdfbox.util.PDFTextStripper;\n\n/**\n * 抽去PDF文件中的文本.\n * @author soulmachine\n *\n */\npublic final class PDFboxTest {\n /** 禁止创建对象. */\n private PDFboxTest() {\n }\n /**\n * 抽取PDF中的文本.\n * @param f PDF文件\n * @return PDF对应的文本字符串\n */\n public static String getText(final File f) {\n String text = \"\";\n try {\n PDDocument pdfdocument = PDDocument.load(f);\n PDFTextStripper stripper = new PDFTextStripper();\n stripper.setStartPage(1); // 只抽取第1页和第2页\n stripper.setEndPage(2);\n text = stripper.getText(pdfdocument);\n pdfdocument.close();\n\n } catch (IOException e) {\n e.printStackTrace();\n }\n\n return text;\n }\n\n /** 测试.\n *\n * @param args PDF文件路径\n */\n public static void main(final String[]  args) {\n File file = new File(args[0]);\n System.out.println(PDFboxTest.getText(file));\n }\n}\n```\n","slug":"2010-03-28-extract-text-from-pdf-using-pdfbox","published":1,"updated":"2016-08-18T09:21:04.000Z","photos":[],"link":"","_id":"cis07peu1000001pq47uvm9d9","content":"<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">package</span> com.yanjiuyanjiu.search;</div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">import</span> java.io.File;</div><div class=\"line\"><span class=\"keyword\">import</span> java.io.IOException;</div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">import</span> org.apache.pdfbox.pdmodel.PDDocument;</div><div class=\"line\"><span class=\"keyword\">import</span> org.apache.pdfbox.util.PDFTextStripper;</div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\">/**</span></div><div class=\"line\"> * 抽去PDF文件中的文本.</div><div class=\"line\"> * <span class=\"doctag\">@author</span> soulmachine</div><div class=\"line\"> *</div><div class=\"line\"> */</div><div class=\"line\"><span class=\"keyword\">public</span> <span class=\"keyword\">final</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">PDFboxTest</span> </span>&#123;</div><div class=\"line\"> <span class=\"comment\">/** 禁止创建对象. */</span></div><div class=\"line\"> <span class=\"function\"><span class=\"keyword\">private</span> <span class=\"title\">PDFboxTest</span><span class=\"params\">()</span> </span>&#123;</div><div class=\"line\"> &#125;</div><div class=\"line\"> <span class=\"comment\">/**</span></div><div class=\"line\"> * 抽取PDF中的文本.</div><div class=\"line\"> * <span class=\"doctag\">@param</span> f PDF文件</div><div class=\"line\"> * <span class=\"doctag\">@return</span> PDF对应的文本字符串</div><div class=\"line\"> */</div><div class=\"line\"> <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">static</span> String <span class=\"title\">getText</span><span class=\"params\">(<span class=\"keyword\">final</span> File f)</span> </span>&#123;</div><div class=\"line\"> String text = <span class=\"string\">\"\"</span>;</div><div class=\"line\"> <span class=\"keyword\">try</span> &#123;</div><div class=\"line\"> PDDocument pdfdocument = PDDocument.load(f);</div><div class=\"line\"> PDFTextStripper stripper = <span class=\"keyword\">new</span> PDFTextStripper();</div><div class=\"line\"> stripper.setStartPage(<span class=\"number\">1</span>); <span class=\"comment\">// 只抽取第1页和第2页</span></div><div class=\"line\"> stripper.setEndPage(<span class=\"number\">2</span>);</div><div class=\"line\"> text = stripper.getText(pdfdocument);</div><div class=\"line\"> pdfdocument.close();</div><div class=\"line\"></div><div class=\"line\"> &#125; <span class=\"keyword\">catch</span> (IOException e) &#123;</div><div class=\"line\"> e.printStackTrace();</div><div class=\"line\"> &#125;</div><div class=\"line\"></div><div class=\"line\"> <span class=\"keyword\">return</span> text;</div><div class=\"line\"> &#125;</div><div class=\"line\"></div><div class=\"line\"> <span class=\"comment\">/** 测试.</span></div><div class=\"line\"> *</div><div class=\"line\"> * <span class=\"doctag\">@param</span> args PDF文件路径</div><div class=\"line\"> */</div><div class=\"line\"> <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">static</span> <span class=\"keyword\">void</span> <span class=\"title\">main</span><span class=\"params\">(<span class=\"keyword\">final</span> String[]  args)</span> </span>&#123;</div><div class=\"line\"> File file = <span class=\"keyword\">new</span> File(args[<span class=\"number\">0</span>]);</div><div class=\"line\"> System.out.println(PDFboxTest.getText(file));</div><div class=\"line\"> &#125;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n","excerpt":"","more":"<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">package</span> com.yanjiuyanjiu.search;</div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">import</span> java.io.File;</div><div class=\"line\"><span class=\"keyword\">import</span> java.io.IOException;</div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">import</span> org.apache.pdfbox.pdmodel.PDDocument;</div><div class=\"line\"><span class=\"keyword\">import</span> org.apache.pdfbox.util.PDFTextStripper;</div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\">/**</div><div class=\"line\"> * 抽去PDF文件中的文本.</div><div class=\"line\"> * <span class=\"doctag\">@author</span> soulmachine</div><div class=\"line\"> *</div><div class=\"line\"> */</span></div><div class=\"line\"><span class=\"keyword\">public</span> <span class=\"keyword\">final</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">PDFboxTest</span> </span>&#123;</div><div class=\"line\"> <span class=\"comment\">/** 禁止创建对象. */</span></div><div class=\"line\"> <span class=\"function\"><span class=\"keyword\">private</span> <span class=\"title\">PDFboxTest</span><span class=\"params\">()</span> </span>&#123;</div><div class=\"line\"> &#125;</div><div class=\"line\"> <span class=\"comment\">/**</div><div class=\"line\"> * 抽取PDF中的文本.</div><div class=\"line\"> * <span class=\"doctag\">@param</span> f PDF文件</div><div class=\"line\"> * <span class=\"doctag\">@return</span> PDF对应的文本字符串</div><div class=\"line\"> */</span></div><div class=\"line\"> <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">static</span> String <span class=\"title\">getText</span><span class=\"params\">(<span class=\"keyword\">final</span> File f)</span> </span>&#123;</div><div class=\"line\"> String text = <span class=\"string\">\"\"</span>;</div><div class=\"line\"> <span class=\"keyword\">try</span> &#123;</div><div class=\"line\"> PDDocument pdfdocument = PDDocument.load(f);</div><div class=\"line\"> PDFTextStripper stripper = <span class=\"keyword\">new</span> PDFTextStripper();</div><div class=\"line\"> stripper.setStartPage(<span class=\"number\">1</span>); <span class=\"comment\">// 只抽取第1页和第2页</span></div><div class=\"line\"> stripper.setEndPage(<span class=\"number\">2</span>);</div><div class=\"line\"> text = stripper.getText(pdfdocument);</div><div class=\"line\"> pdfdocument.close();</div><div class=\"line\"></div><div class=\"line\"> &#125; <span class=\"keyword\">catch</span> (IOException e) &#123;</div><div class=\"line\"> e.printStackTrace();</div><div class=\"line\"> &#125;</div><div class=\"line\"></div><div class=\"line\"> <span class=\"keyword\">return</span> text;</div><div class=\"line\"> &#125;</div><div class=\"line\"></div><div class=\"line\"> <span class=\"comment\">/** 测试.</div><div class=\"line\"> *</div><div class=\"line\"> * <span class=\"doctag\">@param</span> args PDF文件路径</div><div class=\"line\"> */</span></div><div class=\"line\"> <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">static</span> <span class=\"keyword\">void</span> <span class=\"title\">main</span><span class=\"params\">(<span class=\"keyword\">final</span> String[]  args)</span> </span>&#123;</div><div class=\"line\"> File file = <span class=\"keyword\">new</span> File(args[<span class=\"number\">0</span>]);</div><div class=\"line\"> System.out.println(PDFboxTest.getText(file));</div><div class=\"line\"> &#125;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n"},{"layout":"post","title":"Java使用imageio 读写图像","date":"2010-04-01T16:53:00.000Z","comments":1,"_content":"Java中进行图像I/O（即读图片和写图片，不涉及到复杂图像处理）有三个方法：\n\n1. Java Image I/O API，支持常见图片，从Java 2 version 1.4.0开始就内置了。\n主页：[http://java.sun.com/javase/6/docs/technotes/guides/imageio/index.html](http://java.sun.com/javase/6/docs/technotes/guides/imageio/index.html)\n2. JAI 中的 Image I/O Tools，支持更多图片类型，例如JPEG-LS, JPEG2000, 和 TIFF。\n主页：[https://jai-imageio.dev.java.net/](https://jai-imageio.dev.java.net/)。JAI 是一个关于图像处理的框架，很庞大，\n其中仅仅jai-imageio是关于图像I/O的，其他的可以不看。\n3. JAI的com.sun.media.jai.codec 也有一定的图像解码能力\n\n当然，还有众多的java开源工具包可以读写图像，例如JIMI, JMagic等，但JDK目前本身能\n够读写图片，就用JDK的，开发和部署方便，不需要额外下载jar包。\n\n由于JAI是Java新加入的，很多组件不是正式规范，JDK不自带，因此开发和部署需要额外\n安装，安装文件在官网[https://jai.dev.java.net/](https://jai.dev.java.net/)下载得到。\n\n如果你仅仅想读取常见格式的图片，不需要用JAI这么高级这么庞大的东西，\n用Java Image I/O API即可。\n\n下面重点介绍 Java Image I/O API。\n\nJava Image I/O API 主要在 javax.imageio 下面。JDK已经内置了常见图片格式的插件，\n但它提供了插件体系结构，第三方也可以开发插件支持其他图片格式。\n\n<!--more-->\n\n下面这段代码可以展示，JDK内置支持的图片格式。\n\n``` java\nimport javax.imageio.*;\nimport java.util.Arrays;\n\npublic class HelloWorld {\npublic static void main(String args[]) {\nString readFormats[] = ImageIO.getReaderFormatNames();\nString writeFormats[] = ImageIO.getWriterFormatNames();\nSystem.out.println(“Readers:  ” + Arrays.asList(readFormats));\nSystem.out.println(“Writers:  ” + Arrays.asList(writeFormats));\n}\n}\n```\n\n主页上有一个文档，Java Image I/O API Guide，很通俗易懂，可以让你快速上手。以下\n内容主要来自这个文档的第3章。\n\n#第3章 编写图像I/O程序\n##3.1 读写图片\njavax.imageio.ImageIO类提供了一组静态方法进行最简单的图像I/O操作。\n读取一个标准格式(GIF, PNG, or JPEG)的图片很简单：\n\n``` java\nFile f = new File(“c:imagesmyimage.gif”);\nBufferedImage bi = ImageIO.read(f);\n```\n\nJava Image I/O API 会自动探测图片的格式并调用对应的插件进行解码，当安装了一个新\n插件，新的格式会被自动理解，程序代码不需要改变。\n\n写图片同样简单：\n\n``` java\nBufferedImage bi;\nFile f = new File(“c:imagesmyimage.png”);\nImageIO.write(im, “png”, f);\n```\n\n##3.2 更进一步\n上一节谈到的方法对于简单程序已经足够了。不过，Java Image I/O API 提供了为编写复\n杂程序的能力。为了利用API的高级特性，应用程序应当直接使用类ImageReader 和\nImageWriter。\n\n##3.3 ImageReader 类\n与其用ImageIO类来进行所有的解码操作，不如用ImageIO类去得到一个ImageReader对象，\n再用这个对象去进行读操作：\n\n``` java\nIterator readers = ImageIO.getImageReadersByFormatName(“gif”);\nImageReader reader = (ImageReader)readers.next();\n```\n\nImageReader对象也可以基于文件内容、文件后缀或MIME类型获得。这个用于查找和初始\n化ImageReader对象的机制用到了javax.imageio.spi.ImageReaderSpi类，它可以在不用初\n始化插件的情况下获得插件的信息。”service provider interfaces” (SPIs)将会在下一\n章详细讨论。一旦获得了一个ImageReader对象，必须给它是指一个输入源。大部分\nImageReader对象可以从ImageInputStream类输入源读取数据，ImageInputStream是Image\nI/O API定义的专用输入源。\n\n获得一个ImageInputStream 是简单的。给定一个File或InputStream，一个\nImageInputStream对象可以通过调用如下函数产生：\n\n``` java\nObject source; // File or InputStream\nImageInputStream iis = ImageIO.createImageInputStream(source);\n```\n一旦有了输入源，可以把它与一个ImageReader对象关联起来：\nreader.setInput(iis, true);\n\n如果输入源文件包含多张图片，而程序不保证按顺序读取时，第二个参数应该设置为\nfalse。对于那些只允许存储一张图片的文件格式，永远传递true是合理的。\n\n当ImageReader对象有了输入源后，我们就可以获取图片信息而不用把整张图片数据都读入\n内存。例如，调用reader.getImageWidth(0)可以让我们获得文件中第一张图片的宽度。一\n个好的插件会试图解码文件的必要部分，去获得图片的宽度，而不用读取任何一个像素。\n\n为读取图片，可以调用reader.read(imageIndex), imageIndex是文件（当包含多张图片时）\n中图片的索引。这与上一节调用ImageIO.read()产生的结果相同。\n\n###3.3.1 ImageReadParam\n如果需要更多的控制，可以向read()方法传递一个ImageReadParam类型的参数。一个\nImageReadParam对象可以让程序更好的利用内存。它不仅允许指定一个感兴趣的区域，还\n可以指定一个抽样因子，用于向下采样。\n\n例如，为了只解码图片的左上角的1/4，程序可以先获取一个合适的ImageReadParam对象：\n\n``` java\nImageReadParam param = reader.getDefaultReadParam();\n```\n\n接下来，指定图片区域：\n\n``` java\nimport java.awt.Rectangle;\nint imageIndex = 0;\nint half_width = reader.getImageWidth(imageIndex)/2;\nint half_height = reader.getImageHeight(imageIndex)/2;\nRectangle rect = new Rectangle(0, 0, half_width, half_height);\nparam.setSourceRegion(rect);\n```\n\n最后，读取图片：\n\n``` java\nBufferedImage bi = reader.read(imageIndex, param);\n```\n\n结果是一张新图片，宽和高都只有原图片的一半。\n\n另一个例子，为了读取每三个像素中的一个，产生一个原图片1/9大小的图片，可以用\nImageReadParam指定抽样因子：\n\n``` java\nparam = reader.getDefaultImageParam();\nparam.setSourceSubsampling(3, 3, 0, 0);\nBufferedImage bi3 = reader.read(0, param);\n```\n\n###3.3.2 IIOParamController\n插件有时会提供一个IIOParamController类，这是可选的。略。\n\n###3.3.3 读多图片文件\nImageReader 中所有与图片打交道的方法都有一个imageIndex 参数，这个参数用于读取多\n图片文件中的一张。\n\nImageReader.getNumImages()返回多图片文件中的图片个数。这个方法有一个boolean参数，\nallowSearch。有的图片格式，典型的GIF，没有提供任何获取文件中的图片个数方法，除\n非读取整个进行解析。这样代价很高，因此设置allowSearch为false可以让方法直接返回\n-1，而不是实际的图片个数。如果此参数是true，则该方法总会返回文件中实际的图片个\n数。\n\n即使在不知道文件中图片个数的情况下，仍可以调用read(imageIndex); 如果索引值过大，\n该方法会抛出IndexOutOfBoundsException异常。因此，程序可以递增索引去获取图片，\n直到异常。\n\n###3.3.4 读缩略图 \n有的图片格式允许一个（或多个）小的预览图，与主图片一起存储在文件中。这些\n“缩略图”对于快速识别图片很有用，不用解码整个图片。\n\n程序可以调用如下代码，探测一张图片有多少张缩略图：\nreader.getNumThumbnails(imageIndex);\n\n如果存在缩略图，可以调用如下代码获取：\n\n``` java\nint thumbailIndex = 0;\nBufferedImage bi;\nbi = reader.readThumbnail(imageIndex, thumbnailIndex);\n```\n\n##3.4 ImageWriter 类 \n就像我们可以用ImageIO 的一个方法获取某种图片格式的ImageReader对象一样，我们也可\n以获取ImageWriter对象：\n\n``` java\nIterator writers = ImageIO.getImageWritersByFormatName(“png”);\nImageWriter writer = (ImageWriter)writers.next();\n\n一旦获取了一个ImageWriter对象，必须给它设置一个输出源ImageOutputStream。\nFile f = new File(“c:imagesmyimage.png”);\nImageOutputStream ios = ImageIO.createImageOutputStream(f);\nwriter.setOutput(ios);\n```\n\n最后，可以把图片写入到输出源：\n\n``` java\nBufferedImage bi;\nwriter.write(bi);\n```\n\n###3.4.1 写多图片文件\nIIOImage类用于存储图片，缩略图或元信息的引用。下一节将讨论Metadata，目前，我们\n简单地给Metadata相关参数传递null。\nImageWriter 类有一个方法write()，用于从IIOImage创建一个新文件，还有一个方法\nwriteInsert()，用于向一个已存在文件添加一个IIOImage对象。通过调用这两者，可以创\n建一个多图片文件：\n\n``` java\nBufferedImage first_bi, second_bi;\nIIOImage first_IIOImage = new IIOImage(first_bi, null, null);\nIIOImage second_IIOImage = new IIOImage(second_bi, null, null);\nwriter.write(null, first_IIOImage, null);\nif (writer.canInsertImage(1)) {\nwriter.writeInsert(1, second_IIOImage, null);\n} else {\nSystem.err.println(“Writer can’t append a second image!”);\n}\n```\n\n##3.5  处理 Metadata \n所有与像素无关的信息，都属于在Metadata。javax.imageio.metadata 包含了用于访问\nMetadata的类和接口。\n\nImage I/O API 将stream metadata 和image metadata区别对待。stream metadata与一个\n文件中存储了多张图片有关，image metadata只与单个图片有关。如果一个文件只包含一张\n图片，那么就只存在image metadata。\n\n可以通过调用ImageReader.getStreamMetadata 和 getImageMetadata(int imageIndex)来\n获取metadata。这些方法会返回一个实现了IIOMetadata接口的对象，该对象会被向上转化\n为ImageReader类型，\n\n##3.6 编码转换\n略\n\n##3.7 事件监听\n略\n","source":"_posts/2010-04-01-read-and-write-images-using-java-imageio.md","raw":"---\nlayout: post\ntitle: \"Java使用imageio 读写图像\"\ndate: 2010-04-01 16:53\ncomments: true\ncategories: Tools\n---\nJava中进行图像I/O（即读图片和写图片，不涉及到复杂图像处理）有三个方法：\n\n1. Java Image I/O API，支持常见图片，从Java 2 version 1.4.0开始就内置了。\n主页：[http://java.sun.com/javase/6/docs/technotes/guides/imageio/index.html](http://java.sun.com/javase/6/docs/technotes/guides/imageio/index.html)\n2. JAI 中的 Image I/O Tools，支持更多图片类型，例如JPEG-LS, JPEG2000, 和 TIFF。\n主页：[https://jai-imageio.dev.java.net/](https://jai-imageio.dev.java.net/)。JAI 是一个关于图像处理的框架，很庞大，\n其中仅仅jai-imageio是关于图像I/O的，其他的可以不看。\n3. JAI的com.sun.media.jai.codec 也有一定的图像解码能力\n\n当然，还有众多的java开源工具包可以读写图像，例如JIMI, JMagic等，但JDK目前本身能\n够读写图片，就用JDK的，开发和部署方便，不需要额外下载jar包。\n\n由于JAI是Java新加入的，很多组件不是正式规范，JDK不自带，因此开发和部署需要额外\n安装，安装文件在官网[https://jai.dev.java.net/](https://jai.dev.java.net/)下载得到。\n\n如果你仅仅想读取常见格式的图片，不需要用JAI这么高级这么庞大的东西，\n用Java Image I/O API即可。\n\n下面重点介绍 Java Image I/O API。\n\nJava Image I/O API 主要在 javax.imageio 下面。JDK已经内置了常见图片格式的插件，\n但它提供了插件体系结构，第三方也可以开发插件支持其他图片格式。\n\n<!--more-->\n\n下面这段代码可以展示，JDK内置支持的图片格式。\n\n``` java\nimport javax.imageio.*;\nimport java.util.Arrays;\n\npublic class HelloWorld {\npublic static void main(String args[]) {\nString readFormats[] = ImageIO.getReaderFormatNames();\nString writeFormats[] = ImageIO.getWriterFormatNames();\nSystem.out.println(“Readers:  ” + Arrays.asList(readFormats));\nSystem.out.println(“Writers:  ” + Arrays.asList(writeFormats));\n}\n}\n```\n\n主页上有一个文档，Java Image I/O API Guide，很通俗易懂，可以让你快速上手。以下\n内容主要来自这个文档的第3章。\n\n#第3章 编写图像I/O程序\n##3.1 读写图片\njavax.imageio.ImageIO类提供了一组静态方法进行最简单的图像I/O操作。\n读取一个标准格式(GIF, PNG, or JPEG)的图片很简单：\n\n``` java\nFile f = new File(“c:imagesmyimage.gif”);\nBufferedImage bi = ImageIO.read(f);\n```\n\nJava Image I/O API 会自动探测图片的格式并调用对应的插件进行解码，当安装了一个新\n插件，新的格式会被自动理解，程序代码不需要改变。\n\n写图片同样简单：\n\n``` java\nBufferedImage bi;\nFile f = new File(“c:imagesmyimage.png”);\nImageIO.write(im, “png”, f);\n```\n\n##3.2 更进一步\n上一节谈到的方法对于简单程序已经足够了。不过，Java Image I/O API 提供了为编写复\n杂程序的能力。为了利用API的高级特性，应用程序应当直接使用类ImageReader 和\nImageWriter。\n\n##3.3 ImageReader 类\n与其用ImageIO类来进行所有的解码操作，不如用ImageIO类去得到一个ImageReader对象，\n再用这个对象去进行读操作：\n\n``` java\nIterator readers = ImageIO.getImageReadersByFormatName(“gif”);\nImageReader reader = (ImageReader)readers.next();\n```\n\nImageReader对象也可以基于文件内容、文件后缀或MIME类型获得。这个用于查找和初始\n化ImageReader对象的机制用到了javax.imageio.spi.ImageReaderSpi类，它可以在不用初\n始化插件的情况下获得插件的信息。”service provider interfaces” (SPIs)将会在下一\n章详细讨论。一旦获得了一个ImageReader对象，必须给它是指一个输入源。大部分\nImageReader对象可以从ImageInputStream类输入源读取数据，ImageInputStream是Image\nI/O API定义的专用输入源。\n\n获得一个ImageInputStream 是简单的。给定一个File或InputStream，一个\nImageInputStream对象可以通过调用如下函数产生：\n\n``` java\nObject source; // File or InputStream\nImageInputStream iis = ImageIO.createImageInputStream(source);\n```\n一旦有了输入源，可以把它与一个ImageReader对象关联起来：\nreader.setInput(iis, true);\n\n如果输入源文件包含多张图片，而程序不保证按顺序读取时，第二个参数应该设置为\nfalse。对于那些只允许存储一张图片的文件格式，永远传递true是合理的。\n\n当ImageReader对象有了输入源后，我们就可以获取图片信息而不用把整张图片数据都读入\n内存。例如，调用reader.getImageWidth(0)可以让我们获得文件中第一张图片的宽度。一\n个好的插件会试图解码文件的必要部分，去获得图片的宽度，而不用读取任何一个像素。\n\n为读取图片，可以调用reader.read(imageIndex), imageIndex是文件（当包含多张图片时）\n中图片的索引。这与上一节调用ImageIO.read()产生的结果相同。\n\n###3.3.1 ImageReadParam\n如果需要更多的控制，可以向read()方法传递一个ImageReadParam类型的参数。一个\nImageReadParam对象可以让程序更好的利用内存。它不仅允许指定一个感兴趣的区域，还\n可以指定一个抽样因子，用于向下采样。\n\n例如，为了只解码图片的左上角的1/4，程序可以先获取一个合适的ImageReadParam对象：\n\n``` java\nImageReadParam param = reader.getDefaultReadParam();\n```\n\n接下来，指定图片区域：\n\n``` java\nimport java.awt.Rectangle;\nint imageIndex = 0;\nint half_width = reader.getImageWidth(imageIndex)/2;\nint half_height = reader.getImageHeight(imageIndex)/2;\nRectangle rect = new Rectangle(0, 0, half_width, half_height);\nparam.setSourceRegion(rect);\n```\n\n最后，读取图片：\n\n``` java\nBufferedImage bi = reader.read(imageIndex, param);\n```\n\n结果是一张新图片，宽和高都只有原图片的一半。\n\n另一个例子，为了读取每三个像素中的一个，产生一个原图片1/9大小的图片，可以用\nImageReadParam指定抽样因子：\n\n``` java\nparam = reader.getDefaultImageParam();\nparam.setSourceSubsampling(3, 3, 0, 0);\nBufferedImage bi3 = reader.read(0, param);\n```\n\n###3.3.2 IIOParamController\n插件有时会提供一个IIOParamController类，这是可选的。略。\n\n###3.3.3 读多图片文件\nImageReader 中所有与图片打交道的方法都有一个imageIndex 参数，这个参数用于读取多\n图片文件中的一张。\n\nImageReader.getNumImages()返回多图片文件中的图片个数。这个方法有一个boolean参数，\nallowSearch。有的图片格式，典型的GIF，没有提供任何获取文件中的图片个数方法，除\n非读取整个进行解析。这样代价很高，因此设置allowSearch为false可以让方法直接返回\n-1，而不是实际的图片个数。如果此参数是true，则该方法总会返回文件中实际的图片个\n数。\n\n即使在不知道文件中图片个数的情况下，仍可以调用read(imageIndex); 如果索引值过大，\n该方法会抛出IndexOutOfBoundsException异常。因此，程序可以递增索引去获取图片，\n直到异常。\n\n###3.3.4 读缩略图 \n有的图片格式允许一个（或多个）小的预览图，与主图片一起存储在文件中。这些\n“缩略图”对于快速识别图片很有用，不用解码整个图片。\n\n程序可以调用如下代码，探测一张图片有多少张缩略图：\nreader.getNumThumbnails(imageIndex);\n\n如果存在缩略图，可以调用如下代码获取：\n\n``` java\nint thumbailIndex = 0;\nBufferedImage bi;\nbi = reader.readThumbnail(imageIndex, thumbnailIndex);\n```\n\n##3.4 ImageWriter 类 \n就像我们可以用ImageIO 的一个方法获取某种图片格式的ImageReader对象一样，我们也可\n以获取ImageWriter对象：\n\n``` java\nIterator writers = ImageIO.getImageWritersByFormatName(“png”);\nImageWriter writer = (ImageWriter)writers.next();\n\n一旦获取了一个ImageWriter对象，必须给它设置一个输出源ImageOutputStream。\nFile f = new File(“c:imagesmyimage.png”);\nImageOutputStream ios = ImageIO.createImageOutputStream(f);\nwriter.setOutput(ios);\n```\n\n最后，可以把图片写入到输出源：\n\n``` java\nBufferedImage bi;\nwriter.write(bi);\n```\n\n###3.4.1 写多图片文件\nIIOImage类用于存储图片，缩略图或元信息的引用。下一节将讨论Metadata，目前，我们\n简单地给Metadata相关参数传递null。\nImageWriter 类有一个方法write()，用于从IIOImage创建一个新文件，还有一个方法\nwriteInsert()，用于向一个已存在文件添加一个IIOImage对象。通过调用这两者，可以创\n建一个多图片文件：\n\n``` java\nBufferedImage first_bi, second_bi;\nIIOImage first_IIOImage = new IIOImage(first_bi, null, null);\nIIOImage second_IIOImage = new IIOImage(second_bi, null, null);\nwriter.write(null, first_IIOImage, null);\nif (writer.canInsertImage(1)) {\nwriter.writeInsert(1, second_IIOImage, null);\n} else {\nSystem.err.println(“Writer can’t append a second image!”);\n}\n```\n\n##3.5  处理 Metadata \n所有与像素无关的信息，都属于在Metadata。javax.imageio.metadata 包含了用于访问\nMetadata的类和接口。\n\nImage I/O API 将stream metadata 和image metadata区别对待。stream metadata与一个\n文件中存储了多张图片有关，image metadata只与单个图片有关。如果一个文件只包含一张\n图片，那么就只存在image metadata。\n\n可以通过调用ImageReader.getStreamMetadata 和 getImageMetadata(int imageIndex)来\n获取metadata。这些方法会返回一个实现了IIOMetadata接口的对象，该对象会被向上转化\n为ImageReader类型，\n\n##3.6 编码转换\n略\n\n##3.7 事件监听\n略\n","slug":"2010-04-01-read-and-write-images-using-java-imageio","published":1,"updated":"2016-08-18T09:21:04.000Z","photos":[],"link":"","_id":"cis07pf1g000301pqv3a7otwa","content":"<p>Java中进行图像I/O（即读图片和写图片，不涉及到复杂图像处理）有三个方法：</p>\n<ol>\n<li>Java Image I/O API，支持常见图片，从Java 2 version 1.4.0开始就内置了。<br>主页：<a href=\"http://java.sun.com/javase/6/docs/technotes/guides/imageio/index.html\" target=\"_blank\" rel=\"external\">http://java.sun.com/javase/6/docs/technotes/guides/imageio/index.html</a></li>\n<li>JAI 中的 Image I/O Tools，支持更多图片类型，例如JPEG-LS, JPEG2000, 和 TIFF。<br>主页：<a href=\"https://jai-imageio.dev.java.net/\" target=\"_blank\" rel=\"external\">https://jai-imageio.dev.java.net/</a>。JAI 是一个关于图像处理的框架，很庞大，<br>其中仅仅jai-imageio是关于图像I/O的，其他的可以不看。</li>\n<li>JAI的com.sun.media.jai.codec 也有一定的图像解码能力</li>\n</ol>\n<p>当然，还有众多的java开源工具包可以读写图像，例如JIMI, JMagic等，但JDK目前本身能<br>够读写图片，就用JDK的，开发和部署方便，不需要额外下载jar包。</p>\n<p>由于JAI是Java新加入的，很多组件不是正式规范，JDK不自带，因此开发和部署需要额外<br>安装，安装文件在官网<a href=\"https://jai.dev.java.net/\" target=\"_blank\" rel=\"external\">https://jai.dev.java.net/</a>下载得到。</p>\n<p>如果你仅仅想读取常见格式的图片，不需要用JAI这么高级这么庞大的东西，<br>用Java Image I/O API即可。</p>\n<p>下面重点介绍 Java Image I/O API。</p>\n<p>Java Image I/O API 主要在 javax.imageio 下面。JDK已经内置了常见图片格式的插件，<br>但它提供了插件体系结构，第三方也可以开发插件支持其他图片格式。</p>\n<a id=\"more\"></a>\n<p>下面这段代码可以展示，JDK内置支持的图片格式。</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">import</span> javax.imageio.*;</div><div class=\"line\"><span class=\"keyword\">import</span> java.util.Arrays;</div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">HelloWorld</span> </span>&#123;</div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">static</span> <span class=\"keyword\">void</span> <span class=\"title\">main</span><span class=\"params\">(String args[])</span> </span>&#123;</div><div class=\"line\">String readFormats[] = ImageIO.getReaderFormatNames();</div><div class=\"line\">String writeFormats[] = ImageIO.getWriterFormatNames();</div><div class=\"line\">System.out.println(“Readers:  ” + Arrays.asList(readFormats));</div><div class=\"line\">System.out.println(“Writers:  ” + Arrays.asList(writeFormats));</div><div class=\"line\">&#125;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<p>主页上有一个文档，Java Image I/O API Guide，很通俗易懂，可以让你快速上手。以下<br>内容主要来自这个文档的第3章。</p>\n<p>#第3章 编写图像I/O程序</p>\n<p>##3.1 读写图片<br>javax.imageio.ImageIO类提供了一组静态方法进行最简单的图像I/O操作。<br>读取一个标准格式(GIF, PNG, or JPEG)的图片很简单：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">File f = <span class=\"keyword\">new</span> File(“c:imagesmyimage.gif”);</div><div class=\"line\">BufferedImage bi = ImageIO.read(f);</div></pre></td></tr></table></figure>\n<p>Java Image I/O API 会自动探测图片的格式并调用对应的插件进行解码，当安装了一个新<br>插件，新的格式会被自动理解，程序代码不需要改变。</p>\n<p>写图片同样简单：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">BufferedImage bi;</div><div class=\"line\">File f = <span class=\"keyword\">new</span> File(“c:imagesmyimage.png”);</div><div class=\"line\">ImageIO.write(im, “png”, f);</div></pre></td></tr></table></figure>\n<p>##3.2 更进一步<br>上一节谈到的方法对于简单程序已经足够了。不过，Java Image I/O API 提供了为编写复<br>杂程序的能力。为了利用API的高级特性，应用程序应当直接使用类ImageReader 和<br>ImageWriter。</p>\n<p>##3.3 ImageReader 类<br>与其用ImageIO类来进行所有的解码操作，不如用ImageIO类去得到一个ImageReader对象，<br>再用这个对象去进行读操作：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">Iterator readers = ImageIO.getImageReadersByFormatName(“gif”);</div><div class=\"line\">ImageReader reader = (ImageReader)readers.next();</div></pre></td></tr></table></figure>\n<p>ImageReader对象也可以基于文件内容、文件后缀或MIME类型获得。这个用于查找和初始<br>化ImageReader对象的机制用到了javax.imageio.spi.ImageReaderSpi类，它可以在不用初<br>始化插件的情况下获得插件的信息。”service provider interfaces” (SPIs)将会在下一<br>章详细讨论。一旦获得了一个ImageReader对象，必须给它是指一个输入源。大部分<br>ImageReader对象可以从ImageInputStream类输入源读取数据，ImageInputStream是Image<br>I/O API定义的专用输入源。</p>\n<p>获得一个ImageInputStream 是简单的。给定一个File或InputStream，一个<br>ImageInputStream对象可以通过调用如下函数产生：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">Object source; <span class=\"comment\">// File or InputStream</span></div><div class=\"line\">ImageInputStream iis = ImageIO.createImageInputStream(source);</div></pre></td></tr></table></figure>\n<p>一旦有了输入源，可以把它与一个ImageReader对象关联起来：<br>reader.setInput(iis, true);</p>\n<p>如果输入源文件包含多张图片，而程序不保证按顺序读取时，第二个参数应该设置为<br>false。对于那些只允许存储一张图片的文件格式，永远传递true是合理的。</p>\n<p>当ImageReader对象有了输入源后，我们就可以获取图片信息而不用把整张图片数据都读入<br>内存。例如，调用reader.getImageWidth(0)可以让我们获得文件中第一张图片的宽度。一<br>个好的插件会试图解码文件的必要部分，去获得图片的宽度，而不用读取任何一个像素。</p>\n<p>为读取图片，可以调用reader.read(imageIndex), imageIndex是文件（当包含多张图片时）<br>中图片的索引。这与上一节调用ImageIO.read()产生的结果相同。</p>\n<p>###3.3.1 ImageReadParam<br>如果需要更多的控制，可以向read()方法传递一个ImageReadParam类型的参数。一个<br>ImageReadParam对象可以让程序更好的利用内存。它不仅允许指定一个感兴趣的区域，还<br>可以指定一个抽样因子，用于向下采样。</p>\n<p>例如，为了只解码图片的左上角的1/4，程序可以先获取一个合适的ImageReadParam对象：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">ImageReadParam param = reader.getDefaultReadParam();</div></pre></td></tr></table></figure>\n<p>接下来，指定图片区域：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">import</span> java.awt.Rectangle;</div><div class=\"line\"><span class=\"keyword\">int</span> imageIndex = <span class=\"number\">0</span>;</div><div class=\"line\"><span class=\"keyword\">int</span> half_width = reader.getImageWidth(imageIndex)/<span class=\"number\">2</span>;</div><div class=\"line\"><span class=\"keyword\">int</span> half_height = reader.getImageHeight(imageIndex)/<span class=\"number\">2</span>;</div><div class=\"line\">Rectangle rect = <span class=\"keyword\">new</span> Rectangle(<span class=\"number\">0</span>, <span class=\"number\">0</span>, half_width, half_height);</div><div class=\"line\">param.setSourceRegion(rect);</div></pre></td></tr></table></figure>\n<p>最后，读取图片：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">BufferedImage bi = reader.read(imageIndex, param);</div></pre></td></tr></table></figure>\n<p>结果是一张新图片，宽和高都只有原图片的一半。</p>\n<p>另一个例子，为了读取每三个像素中的一个，产生一个原图片1/9大小的图片，可以用<br>ImageReadParam指定抽样因子：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">param = reader.getDefaultImageParam();</div><div class=\"line\">param.setSourceSubsampling(<span class=\"number\">3</span>, <span class=\"number\">3</span>, <span class=\"number\">0</span>, <span class=\"number\">0</span>);</div><div class=\"line\">BufferedImage bi3 = reader.read(<span class=\"number\">0</span>, param);</div></pre></td></tr></table></figure>\n<p>###3.3.2 IIOParamController<br>插件有时会提供一个IIOParamController类，这是可选的。略。</p>\n<p>###3.3.3 读多图片文件<br>ImageReader 中所有与图片打交道的方法都有一个imageIndex 参数，这个参数用于读取多<br>图片文件中的一张。</p>\n<p>ImageReader.getNumImages()返回多图片文件中的图片个数。这个方法有一个boolean参数，<br>allowSearch。有的图片格式，典型的GIF，没有提供任何获取文件中的图片个数方法，除<br>非读取整个进行解析。这样代价很高，因此设置allowSearch为false可以让方法直接返回<br>-1，而不是实际的图片个数。如果此参数是true，则该方法总会返回文件中实际的图片个<br>数。</p>\n<p>即使在不知道文件中图片个数的情况下，仍可以调用read(imageIndex); 如果索引值过大，<br>该方法会抛出IndexOutOfBoundsException异常。因此，程序可以递增索引去获取图片，<br>直到异常。</p>\n<p>###3.3.4 读缩略图<br>有的图片格式允许一个（或多个）小的预览图，与主图片一起存储在文件中。这些<br>“缩略图”对于快速识别图片很有用，不用解码整个图片。</p>\n<p>程序可以调用如下代码，探测一张图片有多少张缩略图：<br>reader.getNumThumbnails(imageIndex);</p>\n<p>如果存在缩略图，可以调用如下代码获取：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">int</span> thumbailIndex = <span class=\"number\">0</span>;</div><div class=\"line\">BufferedImage bi;</div><div class=\"line\">bi = reader.readThumbnail(imageIndex, thumbnailIndex);</div></pre></td></tr></table></figure>\n<p>##3.4 ImageWriter 类<br>就像我们可以用ImageIO 的一个方法获取某种图片格式的ImageReader对象一样，我们也可<br>以获取ImageWriter对象：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div></pre></td><td class=\"code\"><pre><div class=\"line\">Iterator writers = ImageIO.getImageWritersByFormatName(“png”);</div><div class=\"line\">ImageWriter writer = (ImageWriter)writers.next();</div><div class=\"line\"></div><div class=\"line\">一旦获取了一个ImageWriter对象，必须给它设置一个输出源ImageOutputStream。</div><div class=\"line\">File f = <span class=\"keyword\">new</span> File(“c:imagesmyimage.png”);</div><div class=\"line\">ImageOutputStream ios = ImageIO.createImageOutputStream(f);</div><div class=\"line\">writer.setOutput(ios);</div></pre></td></tr></table></figure>\n<p>最后，可以把图片写入到输出源：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">BufferedImage bi;</div><div class=\"line\">writer.write(bi);</div></pre></td></tr></table></figure>\n<p>###3.4.1 写多图片文件<br>IIOImage类用于存储图片，缩略图或元信息的引用。下一节将讨论Metadata，目前，我们<br>简单地给Metadata相关参数传递null。<br>ImageWriter 类有一个方法write()，用于从IIOImage创建一个新文件，还有一个方法<br>writeInsert()，用于向一个已存在文件添加一个IIOImage对象。通过调用这两者，可以创<br>建一个多图片文件：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div></pre></td><td class=\"code\"><pre><div class=\"line\">BufferedImage first_bi, second_bi;</div><div class=\"line\">IIOImage first_IIOImage = <span class=\"keyword\">new</span> IIOImage(first_bi, <span class=\"keyword\">null</span>, <span class=\"keyword\">null</span>);</div><div class=\"line\">IIOImage second_IIOImage = <span class=\"keyword\">new</span> IIOImage(second_bi, <span class=\"keyword\">null</span>, <span class=\"keyword\">null</span>);</div><div class=\"line\">writer.write(<span class=\"keyword\">null</span>, first_IIOImage, <span class=\"keyword\">null</span>);</div><div class=\"line\"><span class=\"keyword\">if</span> (writer.canInsertImage(<span class=\"number\">1</span>)) &#123;</div><div class=\"line\">writer.writeInsert(<span class=\"number\">1</span>, second_IIOImage, <span class=\"keyword\">null</span>);</div><div class=\"line\">&#125; <span class=\"keyword\">else</span> &#123;</div><div class=\"line\">System.err.println(“Writer can’t append a second image!”);</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<p>##3.5  处理 Metadata<br>所有与像素无关的信息，都属于在Metadata。javax.imageio.metadata 包含了用于访问<br>Metadata的类和接口。</p>\n<p>Image I/O API 将stream metadata 和image metadata区别对待。stream metadata与一个<br>文件中存储了多张图片有关，image metadata只与单个图片有关。如果一个文件只包含一张<br>图片，那么就只存在image metadata。</p>\n<p>可以通过调用ImageReader.getStreamMetadata 和 getImageMetadata(int imageIndex)来<br>获取metadata。这些方法会返回一个实现了IIOMetadata接口的对象，该对象会被向上转化<br>为ImageReader类型，</p>\n<p>##3.6 编码转换<br>略</p>\n<p>##3.7 事件监听<br>略</p>\n","excerpt":"<p>Java中进行图像I/O（即读图片和写图片，不涉及到复杂图像处理）有三个方法：</p>\n<ol>\n<li>Java Image I/O API，支持常见图片，从Java 2 version 1.4.0开始就内置了。<br>主页：<a href=\"http://java.sun.com/javase/6/docs/technotes/guides/imageio/index.html\">http://java.sun.com/javase/6/docs/technotes/guides/imageio/index.html</a></li>\n<li>JAI 中的 Image I/O Tools，支持更多图片类型，例如JPEG-LS, JPEG2000, 和 TIFF。<br>主页：<a href=\"https://jai-imageio.dev.java.net/\">https://jai-imageio.dev.java.net/</a>。JAI 是一个关于图像处理的框架，很庞大，<br>其中仅仅jai-imageio是关于图像I/O的，其他的可以不看。</li>\n<li>JAI的com.sun.media.jai.codec 也有一定的图像解码能力</li>\n</ol>\n<p>当然，还有众多的java开源工具包可以读写图像，例如JIMI, JMagic等，但JDK目前本身能<br>够读写图片，就用JDK的，开发和部署方便，不需要额外下载jar包。</p>\n<p>由于JAI是Java新加入的，很多组件不是正式规范，JDK不自带，因此开发和部署需要额外<br>安装，安装文件在官网<a href=\"https://jai.dev.java.net/\">https://jai.dev.java.net/</a>下载得到。</p>\n<p>如果你仅仅想读取常见格式的图片，不需要用JAI这么高级这么庞大的东西，<br>用Java Image I/O API即可。</p>\n<p>下面重点介绍 Java Image I/O API。</p>\n<p>Java Image I/O API 主要在 javax.imageio 下面。JDK已经内置了常见图片格式的插件，<br>但它提供了插件体系结构，第三方也可以开发插件支持其他图片格式。</p>","more":"<p>下面这段代码可以展示，JDK内置支持的图片格式。</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">import</span> javax.imageio.*;</div><div class=\"line\"><span class=\"keyword\">import</span> java.util.Arrays;</div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">HelloWorld</span> </span>&#123;</div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">static</span> <span class=\"keyword\">void</span> <span class=\"title\">main</span><span class=\"params\">(String args[])</span> </span>&#123;</div><div class=\"line\">String readFormats[] = ImageIO.getReaderFormatNames();</div><div class=\"line\">String writeFormats[] = ImageIO.getWriterFormatNames();</div><div class=\"line\">System.out.println(“Readers:  ” + Arrays.asList(readFormats));</div><div class=\"line\">System.out.println(“Writers:  ” + Arrays.asList(writeFormats));</div><div class=\"line\">&#125;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<p>主页上有一个文档，Java Image I/O API Guide，很通俗易懂，可以让你快速上手。以下<br>内容主要来自这个文档的第3章。</p>\n<p>#第3章 编写图像I/O程序</p>\n<p>##3.1 读写图片<br>javax.imageio.ImageIO类提供了一组静态方法进行最简单的图像I/O操作。<br>读取一个标准格式(GIF, PNG, or JPEG)的图片很简单：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">File f = <span class=\"keyword\">new</span> File(“c:imagesmyimage.gif”);</div><div class=\"line\">BufferedImage bi = ImageIO.read(f);</div></pre></td></tr></table></figure>\n<p>Java Image I/O API 会自动探测图片的格式并调用对应的插件进行解码，当安装了一个新<br>插件，新的格式会被自动理解，程序代码不需要改变。</p>\n<p>写图片同样简单：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">BufferedImage bi;</div><div class=\"line\">File f = <span class=\"keyword\">new</span> File(“c:imagesmyimage.png”);</div><div class=\"line\">ImageIO.write(im, “png”, f);</div></pre></td></tr></table></figure>\n<p>##3.2 更进一步<br>上一节谈到的方法对于简单程序已经足够了。不过，Java Image I/O API 提供了为编写复<br>杂程序的能力。为了利用API的高级特性，应用程序应当直接使用类ImageReader 和<br>ImageWriter。</p>\n<p>##3.3 ImageReader 类<br>与其用ImageIO类来进行所有的解码操作，不如用ImageIO类去得到一个ImageReader对象，<br>再用这个对象去进行读操作：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">Iterator readers = ImageIO.getImageReadersByFormatName(“gif”);</div><div class=\"line\">ImageReader reader = (ImageReader)readers.next();</div></pre></td></tr></table></figure>\n<p>ImageReader对象也可以基于文件内容、文件后缀或MIME类型获得。这个用于查找和初始<br>化ImageReader对象的机制用到了javax.imageio.spi.ImageReaderSpi类，它可以在不用初<br>始化插件的情况下获得插件的信息。”service provider interfaces” (SPIs)将会在下一<br>章详细讨论。一旦获得了一个ImageReader对象，必须给它是指一个输入源。大部分<br>ImageReader对象可以从ImageInputStream类输入源读取数据，ImageInputStream是Image<br>I/O API定义的专用输入源。</p>\n<p>获得一个ImageInputStream 是简单的。给定一个File或InputStream，一个<br>ImageInputStream对象可以通过调用如下函数产生：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">Object source; <span class=\"comment\">// File or InputStream</span></div><div class=\"line\">ImageInputStream iis = ImageIO.createImageInputStream(source);</div></pre></td></tr></table></figure>\n<p>一旦有了输入源，可以把它与一个ImageReader对象关联起来：<br>reader.setInput(iis, true);</p>\n<p>如果输入源文件包含多张图片，而程序不保证按顺序读取时，第二个参数应该设置为<br>false。对于那些只允许存储一张图片的文件格式，永远传递true是合理的。</p>\n<p>当ImageReader对象有了输入源后，我们就可以获取图片信息而不用把整张图片数据都读入<br>内存。例如，调用reader.getImageWidth(0)可以让我们获得文件中第一张图片的宽度。一<br>个好的插件会试图解码文件的必要部分，去获得图片的宽度，而不用读取任何一个像素。</p>\n<p>为读取图片，可以调用reader.read(imageIndex), imageIndex是文件（当包含多张图片时）<br>中图片的索引。这与上一节调用ImageIO.read()产生的结果相同。</p>\n<p>###3.3.1 ImageReadParam<br>如果需要更多的控制，可以向read()方法传递一个ImageReadParam类型的参数。一个<br>ImageReadParam对象可以让程序更好的利用内存。它不仅允许指定一个感兴趣的区域，还<br>可以指定一个抽样因子，用于向下采样。</p>\n<p>例如，为了只解码图片的左上角的1/4，程序可以先获取一个合适的ImageReadParam对象：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">ImageReadParam param = reader.getDefaultReadParam();</div></pre></td></tr></table></figure>\n<p>接下来，指定图片区域：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">import</span> java.awt.Rectangle;</div><div class=\"line\"><span class=\"keyword\">int</span> imageIndex = <span class=\"number\">0</span>;</div><div class=\"line\"><span class=\"keyword\">int</span> half_width = reader.getImageWidth(imageIndex)/<span class=\"number\">2</span>;</div><div class=\"line\"><span class=\"keyword\">int</span> half_height = reader.getImageHeight(imageIndex)/<span class=\"number\">2</span>;</div><div class=\"line\">Rectangle rect = <span class=\"keyword\">new</span> Rectangle(<span class=\"number\">0</span>, <span class=\"number\">0</span>, half_width, half_height);</div><div class=\"line\">param.setSourceRegion(rect);</div></pre></td></tr></table></figure>\n<p>最后，读取图片：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">BufferedImage bi = reader.read(imageIndex, param);</div></pre></td></tr></table></figure>\n<p>结果是一张新图片，宽和高都只有原图片的一半。</p>\n<p>另一个例子，为了读取每三个像素中的一个，产生一个原图片1/9大小的图片，可以用<br>ImageReadParam指定抽样因子：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">param = reader.getDefaultImageParam();</div><div class=\"line\">param.setSourceSubsampling(<span class=\"number\">3</span>, <span class=\"number\">3</span>, <span class=\"number\">0</span>, <span class=\"number\">0</span>);</div><div class=\"line\">BufferedImage bi3 = reader.read(<span class=\"number\">0</span>, param);</div></pre></td></tr></table></figure>\n<p>###3.3.2 IIOParamController<br>插件有时会提供一个IIOParamController类，这是可选的。略。</p>\n<p>###3.3.3 读多图片文件<br>ImageReader 中所有与图片打交道的方法都有一个imageIndex 参数，这个参数用于读取多<br>图片文件中的一张。</p>\n<p>ImageReader.getNumImages()返回多图片文件中的图片个数。这个方法有一个boolean参数，<br>allowSearch。有的图片格式，典型的GIF，没有提供任何获取文件中的图片个数方法，除<br>非读取整个进行解析。这样代价很高，因此设置allowSearch为false可以让方法直接返回<br>-1，而不是实际的图片个数。如果此参数是true，则该方法总会返回文件中实际的图片个<br>数。</p>\n<p>即使在不知道文件中图片个数的情况下，仍可以调用read(imageIndex); 如果索引值过大，<br>该方法会抛出IndexOutOfBoundsException异常。因此，程序可以递增索引去获取图片，<br>直到异常。</p>\n<p>###3.3.4 读缩略图<br>有的图片格式允许一个（或多个）小的预览图，与主图片一起存储在文件中。这些<br>“缩略图”对于快速识别图片很有用，不用解码整个图片。</p>\n<p>程序可以调用如下代码，探测一张图片有多少张缩略图：<br>reader.getNumThumbnails(imageIndex);</p>\n<p>如果存在缩略图，可以调用如下代码获取：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">int</span> thumbailIndex = <span class=\"number\">0</span>;</div><div class=\"line\">BufferedImage bi;</div><div class=\"line\">bi = reader.readThumbnail(imageIndex, thumbnailIndex);</div></pre></td></tr></table></figure>\n<p>##3.4 ImageWriter 类<br>就像我们可以用ImageIO 的一个方法获取某种图片格式的ImageReader对象一样，我们也可<br>以获取ImageWriter对象：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div></pre></td><td class=\"code\"><pre><div class=\"line\">Iterator writers = ImageIO.getImageWritersByFormatName(“png”);</div><div class=\"line\">ImageWriter writer = (ImageWriter)writers.next();</div><div class=\"line\"></div><div class=\"line\">一旦获取了一个ImageWriter对象，必须给它设置一个输出源ImageOutputStream。</div><div class=\"line\">File f = <span class=\"keyword\">new</span> File(“c:imagesmyimage.png”);</div><div class=\"line\">ImageOutputStream ios = ImageIO.createImageOutputStream(f);</div><div class=\"line\">writer.setOutput(ios);</div></pre></td></tr></table></figure>\n<p>最后，可以把图片写入到输出源：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">BufferedImage bi;</div><div class=\"line\">writer.write(bi);</div></pre></td></tr></table></figure>\n<p>###3.4.1 写多图片文件<br>IIOImage类用于存储图片，缩略图或元信息的引用。下一节将讨论Metadata，目前，我们<br>简单地给Metadata相关参数传递null。<br>ImageWriter 类有一个方法write()，用于从IIOImage创建一个新文件，还有一个方法<br>writeInsert()，用于向一个已存在文件添加一个IIOImage对象。通过调用这两者，可以创<br>建一个多图片文件：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div></pre></td><td class=\"code\"><pre><div class=\"line\">BufferedImage first_bi, second_bi;</div><div class=\"line\">IIOImage first_IIOImage = <span class=\"keyword\">new</span> IIOImage(first_bi, <span class=\"keyword\">null</span>, <span class=\"keyword\">null</span>);</div><div class=\"line\">IIOImage second_IIOImage = <span class=\"keyword\">new</span> IIOImage(second_bi, <span class=\"keyword\">null</span>, <span class=\"keyword\">null</span>);</div><div class=\"line\">writer.write(<span class=\"keyword\">null</span>, first_IIOImage, <span class=\"keyword\">null</span>);</div><div class=\"line\"><span class=\"keyword\">if</span> (writer.canInsertImage(<span class=\"number\">1</span>)) &#123;</div><div class=\"line\">writer.writeInsert(<span class=\"number\">1</span>, second_IIOImage, <span class=\"keyword\">null</span>);</div><div class=\"line\">&#125; <span class=\"keyword\">else</span> &#123;</div><div class=\"line\">System.err.println(“Writer can’t append a second image!”);</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<p>##3.5  处理 Metadata<br>所有与像素无关的信息，都属于在Metadata。javax.imageio.metadata 包含了用于访问<br>Metadata的类和接口。</p>\n<p>Image I/O API 将stream metadata 和image metadata区别对待。stream metadata与一个<br>文件中存储了多张图片有关，image metadata只与单个图片有关。如果一个文件只包含一张<br>图片，那么就只存在image metadata。</p>\n<p>可以通过调用ImageReader.getStreamMetadata 和 getImageMetadata(int imageIndex)来<br>获取metadata。这些方法会返回一个实现了IIOMetadata接口的对象，该对象会被向上转化<br>为ImageReader类型，</p>\n<p>##3.6 编码转换<br>略</p>\n<p>##3.7 事件监听<br>略</p>"},{"layout":"post","title":"推荐给TeX新手的电子书和书籍","date":"2011-04-17T17:03:00.000Z","comments":1,"_content":"##CTEX自带的文档\n1. 安装好CTEX后，c:CTEXCTeXctexdoc下的两个文档，ctex-faq.pdf和lshort-cn.pdf（即93 分钟学会 LaTeX2e）\n2. [ftp://ftp.ctex.org/pub/tex/documents/bible/](ftp://ftp.ctex.org/pub/tex/documents/bible/) 下的 LaTeX_manual.zip\n对于初学者，上面3个文档足够了，在c:CTEXCTeXctexdoc目录下的其他几个文档也非常好。\n\n    如果想进一步学习，推荐下面一本书。\n3. [《LaTeX入门与提高》](http://www.amazon.cn/mn/detailApp/ref=sr_1_1?_encoding=UTF8&s=books&qid=1271499096&asin=B00114JYBU&sr=8-1)，陈志杰，2008，高等教育出版社，卓越上有卖的。[这里有个PDF扫描版](http://ishare.iask.sina.com.cn/f/7485622.html)。\n\n<!-- more -->\n\n##网上的免费电子书：\n* [A Guide to LaTeX](http://gigapedia.com/items/104415/a-guide-to-latex--document-preparation-for-beginners-and-advanced-users--3rd-edition-)\n* the latex companion，和第2个文档 LaTeX_manual 在同一个ftp目录下,还有[另一个下载地址](http://gigapedia.com/items/3842/the-latex-companion--tools-and-techniques-for-computer-typesetting-)。\n* [LaTeX2e使用手册](http://ftp.ctex.org/pub/tex/documents/texguru/homepage/guide.html)\n* [LaTeX2e插图指南](ftp://ftp.ctex.org/pub/tex/documents/bible/LaTeX_graphics.zip)\n\n##参考资料\n* [陈志杰老师的《latex入门与提高》这本书怎么样啊？](http://bbs.ctex.org/redirect.php?tid=31930&goto=lastpost)\n* [中国LaTeX 新用户，LaTeX中文必读教程](http://bbs.ctex.org/viewthread.php?&tid=1023)\n","source":"_posts/2010-04-17-tex-resources-for-newbies.md","raw":"---\nlayout: post\ntitle: \"推荐给TeX新手的电子书和书籍\"\ndate: 2011-04-17 17:03\ncomments: true\ncategories: Tools\n---\n##CTEX自带的文档\n1. 安装好CTEX后，c:CTEXCTeXctexdoc下的两个文档，ctex-faq.pdf和lshort-cn.pdf（即93 分钟学会 LaTeX2e）\n2. [ftp://ftp.ctex.org/pub/tex/documents/bible/](ftp://ftp.ctex.org/pub/tex/documents/bible/) 下的 LaTeX_manual.zip\n对于初学者，上面3个文档足够了，在c:CTEXCTeXctexdoc目录下的其他几个文档也非常好。\n\n    如果想进一步学习，推荐下面一本书。\n3. [《LaTeX入门与提高》](http://www.amazon.cn/mn/detailApp/ref=sr_1_1?_encoding=UTF8&s=books&qid=1271499096&asin=B00114JYBU&sr=8-1)，陈志杰，2008，高等教育出版社，卓越上有卖的。[这里有个PDF扫描版](http://ishare.iask.sina.com.cn/f/7485622.html)。\n\n<!-- more -->\n\n##网上的免费电子书：\n* [A Guide to LaTeX](http://gigapedia.com/items/104415/a-guide-to-latex--document-preparation-for-beginners-and-advanced-users--3rd-edition-)\n* the latex companion，和第2个文档 LaTeX_manual 在同一个ftp目录下,还有[另一个下载地址](http://gigapedia.com/items/3842/the-latex-companion--tools-and-techniques-for-computer-typesetting-)。\n* [LaTeX2e使用手册](http://ftp.ctex.org/pub/tex/documents/texguru/homepage/guide.html)\n* [LaTeX2e插图指南](ftp://ftp.ctex.org/pub/tex/documents/bible/LaTeX_graphics.zip)\n\n##参考资料\n* [陈志杰老师的《latex入门与提高》这本书怎么样啊？](http://bbs.ctex.org/redirect.php?tid=31930&goto=lastpost)\n* [中国LaTeX 新用户，LaTeX中文必读教程](http://bbs.ctex.org/viewthread.php?&tid=1023)\n","slug":"2010-04-17-tex-resources-for-newbies","published":1,"updated":"2016-08-18T09:21:04.000Z","photos":[],"link":"","_id":"cis07pf1k000401pqx4q6heub","content":"<p>##CTEX自带的文档</p>\n<ol>\n<li>安装好CTEX后，c:CTEXCTeXctexdoc下的两个文档，ctex-faq.pdf和lshort-cn.pdf（即93 分钟学会 LaTeX2e）</li>\n<li><p><a href=\"ftp://ftp.ctex.org/pub/tex/documents/bible/\" target=\"_blank\" rel=\"external\">ftp://ftp.ctex.org/pub/tex/documents/bible/</a> 下的 LaTeX_manual.zip<br>对于初学者，上面3个文档足够了，在c:CTEXCTeXctexdoc目录下的其他几个文档也非常好。</p>\n<p> 如果想进一步学习，推荐下面一本书。</p>\n</li>\n<li><a href=\"http://www.amazon.cn/mn/detailApp/ref=sr_1_1?_encoding=UTF8&amp;s=books&amp;qid=1271499096&amp;asin=B00114JYBU&amp;sr=8-1\" target=\"_blank\" rel=\"external\">《LaTeX入门与提高》</a>，陈志杰，2008，高等教育出版社，卓越上有卖的。<a href=\"http://ishare.iask.sina.com.cn/f/7485622.html\" target=\"_blank\" rel=\"external\">这里有个PDF扫描版</a>。</li>\n</ol>\n<a id=\"more\"></a>\n<p>##网上的免费电子书：</p>\n<ul>\n<li><a href=\"http://gigapedia.com/items/104415/a-guide-to-latex--document-preparation-for-beginners-and-advanced-users--3rd-edition-\" target=\"_blank\" rel=\"external\">A Guide to LaTeX</a></li>\n<li>the latex companion，和第2个文档 LaTeX_manual 在同一个ftp目录下,还有<a href=\"http://gigapedia.com/items/3842/the-latex-companion--tools-and-techniques-for-computer-typesetting-\" target=\"_blank\" rel=\"external\">另一个下载地址</a>。</li>\n<li><a href=\"http://ftp.ctex.org/pub/tex/documents/texguru/homepage/guide.html\" target=\"_blank\" rel=\"external\">LaTeX2e使用手册</a></li>\n<li><a href=\"ftp://ftp.ctex.org/pub/tex/documents/bible/LaTeX_graphics.zip\" target=\"_blank\" rel=\"external\">LaTeX2e插图指南</a></li>\n</ul>\n<p>##参考资料</p>\n<ul>\n<li><a href=\"http://bbs.ctex.org/redirect.php?tid=31930&amp;goto=lastpost\" target=\"_blank\" rel=\"external\">陈志杰老师的《latex入门与提高》这本书怎么样啊？</a></li>\n<li><a href=\"http://bbs.ctex.org/viewthread.php?&amp;tid=1023\" target=\"_blank\" rel=\"external\">中国LaTeX 新用户，LaTeX中文必读教程</a></li>\n</ul>\n","excerpt":"<p>##CTEX自带的文档</p>\n<ol>\n<li>安装好CTEX后，c:CTEXCTeXctexdoc下的两个文档，ctex-faq.pdf和lshort-cn.pdf（即93 分钟学会 LaTeX2e）</li>\n<li><p><a href=\"ftp://ftp.ctex.org/pub/tex/documents/bible/\">ftp://ftp.ctex.org/pub/tex/documents/bible/</a> 下的 LaTeX_manual.zip<br>对于初学者，上面3个文档足够了，在c:CTEXCTeXctexdoc目录下的其他几个文档也非常好。</p>\n<p> 如果想进一步学习，推荐下面一本书。</p>\n</li>\n<li><a href=\"http://www.amazon.cn/mn/detailApp/ref=sr_1_1?_encoding=UTF8&amp;s=books&amp;qid=1271499096&amp;asin=B00114JYBU&amp;sr=8-1\">《LaTeX入门与提高》</a>，陈志杰，2008，高等教育出版社，卓越上有卖的。<a href=\"http://ishare.iask.sina.com.cn/f/7485622.html\">这里有个PDF扫描版</a>。</li>\n</ol>","more":"<p>##网上的免费电子书：</p>\n<ul>\n<li><a href=\"http://gigapedia.com/items/104415/a-guide-to-latex--document-preparation-for-beginners-and-advanced-users--3rd-edition-\">A Guide to LaTeX</a></li>\n<li>the latex companion，和第2个文档 LaTeX_manual 在同一个ftp目录下,还有<a href=\"http://gigapedia.com/items/3842/the-latex-companion--tools-and-techniques-for-computer-typesetting-\">另一个下载地址</a>。</li>\n<li><a href=\"http://ftp.ctex.org/pub/tex/documents/texguru/homepage/guide.html\">LaTeX2e使用手册</a></li>\n<li><a href=\"ftp://ftp.ctex.org/pub/tex/documents/bible/LaTeX_graphics.zip\">LaTeX2e插图指南</a></li>\n</ul>\n<p>##参考资料</p>\n<ul>\n<li><a href=\"http://bbs.ctex.org/redirect.php?tid=31930&amp;goto=lastpost\">陈志杰老师的《latex入门与提高》这本书怎么样啊？</a></li>\n<li><a href=\"http://bbs.ctex.org/viewthread.php?&amp;tid=1023\">中国LaTeX 新用户，LaTeX中文必读教程</a></li>\n</ul>"},{"layout":"post","title":"java命令行下运行class文件","date":"2010-02-15T16:27:00.000Z","comments":1,"_content":"今天碰到了一个很变态的问题，写了一个很简单的HelloWord.java，内容如下：\n\n``` java\npackage com.yanjiuyanjiu;\n\npublic class HelloWorld {\npublic static void main(String args[]) {\nSystem.out.println(“Hello World!”);\n}\n}\n```\n在eclipse中运行是可以的，但是在命令行下运行总是失败。我的工程位置为 d:workspaceHelloWorld。\n\n尝试了很多次，如下：\n\n<!--more-->\n\n``` bash\nd:workspaceHelloWorldbincomyanjiuyanjiu>java HelloWorld\n\nException in thread “main” java.lang.NoClassDefFoundError: HelloWorld (wrong name: com/yanjiuyanjiu/HelloWorld)\nat java.lang.ClassLoader.defineClass1(Native Method)\nat java.lang.ClassLoader.defineClassCond(Unknown Source)\nat java.lang.ClassLoader.defineClass(Unknown Source)\nat java.security.SecureClassLoader.defineClass(Unknown Source)\nat java.net.URLClassLoader.defineClass(Unknown Source)\nat java.net.URLClassLoader.access$000(Unknown Source)\nat java.net.URLClassLoader$1.run(Unknown Source)\nat java.security.AccessController.doPrivileged(Native Method)\nat java.net.URLClassLoader.findClass(Unknown Source)\nat java.lang.ClassLoader.loadClass(Unknown Source)\nat sun.misc.Launcher$AppClassLoader.loadClass(Unknown Source)\nat java.lang.ClassLoader.loadClass(Unknown Source)\nCould not find the main class: HelloWorld.  Program will exit.\nException in thread “main”\n\nd:workspaceHelloWorldbincomyanjiuyanjiu>java -classpath .; HelloWorld\nException in thread “main” java.lang.NoClassDefFoundError: HelloWorld (wrong name: com/yanjiuyanjiu/HelloWorld)\nat java.lang.ClassLoader.defineClass1(Native Method)\nat java.lang.ClassLoader.defineClassCond(Unknown Source)\nat java.lang.ClassLoader.defineClass(Unknown Source)\nat java.security.SecureClassLoader.defineClass(Unknown Source)\nat java.net.URLClassLoader.defineClass(Unknown Source)\nat java.net.URLClassLoader.access$000(Unknown Source)\nat java.net.URLClassLoader$1.run(Unknown Source)\nat java.security.AccessController.doPrivileged(Native Method)\nat java.net.URLClassLoader.findClass(Unknown Source)\nat java.lang.ClassLoader.loadClass(Unknown Source)\nat sun.misc.Launcher$AppClassLoader.loadClass(Unknown Source)\nat java.lang.ClassLoader.loadClass(Unknown Source)\nCould not find the main class: HelloWorld.  Program will exit.\nException in thread “main”\n\nd:workspaceHelloWorldbincomyanjiuyanjiu>cd..\n\nd:workspaceHelloWorldbincom>cd..\n\nd:workspaceHelloWorldbin>java -classpath .; com/yanjiuyanjiu/HelloWorld    只有这个成功\n\nHello World!\n\nd:workspaceHelloWorldbin>java -classpath .; comyanjiuyanjiuHelloWorld    换了个斜杠就不行了\n\nException in thread “main” java.lang.NoClassDefFoundError: comyanjiuyanjiuHelloWorld (wrong name: com/yanjiuyanjiu/HelloWorld)\nat java.lang.ClassLoader.defineClass1(Native Method)\nat java.lang.ClassLoader.defineClassCond(Unknown Source)\nat java.lang.ClassLoader.defineClass(Unknown Source)\nat java.security.SecureClassLoader.defineClass(Unknown Source)\nat java.net.URLClassLoader.defineClass(Unknown Source)\nat java.net.URLClassLoader.access$000(Unknown Source)\nat java.net.URLClassLoader$1.run(Unknown Source)\nat java.security.AccessController.doPrivileged(Native Method)\nat java.net.URLClassLoader.findClass(Unknown Source)\nat java.lang.ClassLoader.loadClass(Unknown Source)\nat sun.misc.Launcher$AppClassLoader.loadClass(Unknown Source)\nat java.lang.ClassLoader.loadClass(Unknown Source)\nCould not find the main class: comyanjiuyanjiuHelloWorld.  Program will exit.\nException in thread “main”\n\nd:workspaceHelloWorldbin>java -classpath ./com/yanjiuyanjiu/; HelloWorld\n\nException in thread “main”java.lang.NoClassDefFoundError: HelloWorld (wrong name: com/yanjiuyanjiu/HelloWorld)\nat java.lang.ClassLoader.defineClass1(Native Method)\nat java.lang.ClassLoader.defineClassCond(Unknown Source)\nat java.lang.ClassLoader.defineClass(Unknown Source)\nat java.security.SecureClassLoader.defineClass(Unknown Source)\nat java.net.URLClassLoader.defineClass(Unknown Source)\nat java.net.URLClassLoader.access$000(Unknown Source)\nat java.net.URLClassLoader$1.run(Unknown Source)\nat java.security.AccessController.doPrivileged(Native Method)\nat java.net.URLClassLoader.findClass(Unknown Source)\nat java.lang.ClassLoader.loadClass(Unknown Source)\nat sun.misc.Launcher$AppClassLoader.loadClass(Unknown Source)\nat java.lang.ClassLoader.loadClass(Unknown Source)\nCould not find the main class: HelloWorld.  Program will exit.\nException in thread “main”\n```\n\n在网上搜索了大半天，大部分说是环境 变量，classpath或JDK 版本的问题，还有执行时文件名 class后缀不要。我一一试过，都没有解决。最后无意中换了一下命令符的位置，成功了。总结如下：\n\n1. 环境变量，CLASSPATH当然要设置好，执行时不要带class后缀；  \n1. 路径中的斜杠用“/”而不是“”；  \n1. 命令符的当前目录要在包的起点。比如这里应该在 d:workspaceHelloWorldbin>，如果在 d:workspaceHelloWorldbincomyanjiuyanjiu>，反而不行，有点“近水楼台不得月”的意思，不知 道为什么，还请高手解释一下。\n","source":"_posts/2010-02-15-run-class-file-in-java-command-line.md","raw":"---\nlayout: post\ntitle: \"java命令行下运行class文件\"\ndate: 2010-02-15 16:27\ncomments: true\ncategories: Language\n---\n今天碰到了一个很变态的问题，写了一个很简单的HelloWord.java，内容如下：\n\n``` java\npackage com.yanjiuyanjiu;\n\npublic class HelloWorld {\npublic static void main(String args[]) {\nSystem.out.println(“Hello World!”);\n}\n}\n```\n在eclipse中运行是可以的，但是在命令行下运行总是失败。我的工程位置为 d:workspaceHelloWorld。\n\n尝试了很多次，如下：\n\n<!--more-->\n\n``` bash\nd:workspaceHelloWorldbincomyanjiuyanjiu>java HelloWorld\n\nException in thread “main” java.lang.NoClassDefFoundError: HelloWorld (wrong name: com/yanjiuyanjiu/HelloWorld)\nat java.lang.ClassLoader.defineClass1(Native Method)\nat java.lang.ClassLoader.defineClassCond(Unknown Source)\nat java.lang.ClassLoader.defineClass(Unknown Source)\nat java.security.SecureClassLoader.defineClass(Unknown Source)\nat java.net.URLClassLoader.defineClass(Unknown Source)\nat java.net.URLClassLoader.access$000(Unknown Source)\nat java.net.URLClassLoader$1.run(Unknown Source)\nat java.security.AccessController.doPrivileged(Native Method)\nat java.net.URLClassLoader.findClass(Unknown Source)\nat java.lang.ClassLoader.loadClass(Unknown Source)\nat sun.misc.Launcher$AppClassLoader.loadClass(Unknown Source)\nat java.lang.ClassLoader.loadClass(Unknown Source)\nCould not find the main class: HelloWorld.  Program will exit.\nException in thread “main”\n\nd:workspaceHelloWorldbincomyanjiuyanjiu>java -classpath .; HelloWorld\nException in thread “main” java.lang.NoClassDefFoundError: HelloWorld (wrong name: com/yanjiuyanjiu/HelloWorld)\nat java.lang.ClassLoader.defineClass1(Native Method)\nat java.lang.ClassLoader.defineClassCond(Unknown Source)\nat java.lang.ClassLoader.defineClass(Unknown Source)\nat java.security.SecureClassLoader.defineClass(Unknown Source)\nat java.net.URLClassLoader.defineClass(Unknown Source)\nat java.net.URLClassLoader.access$000(Unknown Source)\nat java.net.URLClassLoader$1.run(Unknown Source)\nat java.security.AccessController.doPrivileged(Native Method)\nat java.net.URLClassLoader.findClass(Unknown Source)\nat java.lang.ClassLoader.loadClass(Unknown Source)\nat sun.misc.Launcher$AppClassLoader.loadClass(Unknown Source)\nat java.lang.ClassLoader.loadClass(Unknown Source)\nCould not find the main class: HelloWorld.  Program will exit.\nException in thread “main”\n\nd:workspaceHelloWorldbincomyanjiuyanjiu>cd..\n\nd:workspaceHelloWorldbincom>cd..\n\nd:workspaceHelloWorldbin>java -classpath .; com/yanjiuyanjiu/HelloWorld    只有这个成功\n\nHello World!\n\nd:workspaceHelloWorldbin>java -classpath .; comyanjiuyanjiuHelloWorld    换了个斜杠就不行了\n\nException in thread “main” java.lang.NoClassDefFoundError: comyanjiuyanjiuHelloWorld (wrong name: com/yanjiuyanjiu/HelloWorld)\nat java.lang.ClassLoader.defineClass1(Native Method)\nat java.lang.ClassLoader.defineClassCond(Unknown Source)\nat java.lang.ClassLoader.defineClass(Unknown Source)\nat java.security.SecureClassLoader.defineClass(Unknown Source)\nat java.net.URLClassLoader.defineClass(Unknown Source)\nat java.net.URLClassLoader.access$000(Unknown Source)\nat java.net.URLClassLoader$1.run(Unknown Source)\nat java.security.AccessController.doPrivileged(Native Method)\nat java.net.URLClassLoader.findClass(Unknown Source)\nat java.lang.ClassLoader.loadClass(Unknown Source)\nat sun.misc.Launcher$AppClassLoader.loadClass(Unknown Source)\nat java.lang.ClassLoader.loadClass(Unknown Source)\nCould not find the main class: comyanjiuyanjiuHelloWorld.  Program will exit.\nException in thread “main”\n\nd:workspaceHelloWorldbin>java -classpath ./com/yanjiuyanjiu/; HelloWorld\n\nException in thread “main”java.lang.NoClassDefFoundError: HelloWorld (wrong name: com/yanjiuyanjiu/HelloWorld)\nat java.lang.ClassLoader.defineClass1(Native Method)\nat java.lang.ClassLoader.defineClassCond(Unknown Source)\nat java.lang.ClassLoader.defineClass(Unknown Source)\nat java.security.SecureClassLoader.defineClass(Unknown Source)\nat java.net.URLClassLoader.defineClass(Unknown Source)\nat java.net.URLClassLoader.access$000(Unknown Source)\nat java.net.URLClassLoader$1.run(Unknown Source)\nat java.security.AccessController.doPrivileged(Native Method)\nat java.net.URLClassLoader.findClass(Unknown Source)\nat java.lang.ClassLoader.loadClass(Unknown Source)\nat sun.misc.Launcher$AppClassLoader.loadClass(Unknown Source)\nat java.lang.ClassLoader.loadClass(Unknown Source)\nCould not find the main class: HelloWorld.  Program will exit.\nException in thread “main”\n```\n\n在网上搜索了大半天，大部分说是环境 变量，classpath或JDK 版本的问题，还有执行时文件名 class后缀不要。我一一试过，都没有解决。最后无意中换了一下命令符的位置，成功了。总结如下：\n\n1. 环境变量，CLASSPATH当然要设置好，执行时不要带class后缀；  \n1. 路径中的斜杠用“/”而不是“”；  \n1. 命令符的当前目录要在包的起点。比如这里应该在 d:workspaceHelloWorldbin>，如果在 d:workspaceHelloWorldbincomyanjiuyanjiu>，反而不行，有点“近水楼台不得月”的意思，不知 道为什么，还请高手解释一下。\n","slug":"2010-02-15-run-class-file-in-java-command-line","published":1,"updated":"2016-08-18T09:21:04.000Z","photos":[],"link":"","_id":"cis07pf1q000501pqasii4xlw","content":"<p>今天碰到了一个很变态的问题，写了一个很简单的HelloWord.java，内容如下：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">package</span> com.yanjiuyanjiu;</div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">HelloWorld</span> </span>&#123;</div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">static</span> <span class=\"keyword\">void</span> <span class=\"title\">main</span><span class=\"params\">(String args[])</span> </span>&#123;</div><div class=\"line\">System.out.println(“Hello World!”);</div><div class=\"line\">&#125;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<p>在eclipse中运行是可以的，但是在命令行下运行总是失败。我的工程位置为 d:workspaceHelloWorld。</p>\n<p>尝试了很多次，如下：</p>\n<a id=\"more\"></a>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div><div class=\"line\">51</div><div class=\"line\">52</div><div class=\"line\">53</div><div class=\"line\">54</div><div class=\"line\">55</div><div class=\"line\">56</div><div class=\"line\">57</div><div class=\"line\">58</div><div class=\"line\">59</div><div class=\"line\">60</div><div class=\"line\">61</div><div class=\"line\">62</div><div class=\"line\">63</div><div class=\"line\">64</div><div class=\"line\">65</div><div class=\"line\">66</div><div class=\"line\">67</div><div class=\"line\">68</div><div class=\"line\">69</div><div class=\"line\">70</div><div class=\"line\">71</div><div class=\"line\">72</div><div class=\"line\">73</div><div class=\"line\">74</div><div class=\"line\">75</div><div class=\"line\">76</div><div class=\"line\">77</div><div class=\"line\">78</div></pre></td><td class=\"code\"><pre><div class=\"line\">d:workspaceHelloWorldbincomyanjiuyanjiu&gt;java HelloWorld</div><div class=\"line\"></div><div class=\"line\">Exception <span class=\"keyword\">in</span> thread “main” java.lang.NoClassDefFoundError: HelloWorld (wrong name: com/yanjiuyanjiu/HelloWorld)</div><div class=\"line\">at java.lang.ClassLoader.defineClass1(Native Method)</div><div class=\"line\">at java.lang.ClassLoader.defineClassCond(Unknown Source)</div><div class=\"line\">at java.lang.ClassLoader.defineClass(Unknown Source)</div><div class=\"line\">at java.security.SecureClassLoader.defineClass(Unknown Source)</div><div class=\"line\">at java.net.URLClassLoader.defineClass(Unknown Source)</div><div class=\"line\">at java.net.URLClassLoader.access<span class=\"variable\">$000</span>(Unknown Source)</div><div class=\"line\">at java.net.URLClassLoader<span class=\"variable\">$1</span>.run(Unknown Source)</div><div class=\"line\">at java.security.AccessController.doPrivileged(Native Method)</div><div class=\"line\">at java.net.URLClassLoader.findClass(Unknown Source)</div><div class=\"line\">at java.lang.ClassLoader.loadClass(Unknown Source)</div><div class=\"line\">at sun.misc.Launcher<span class=\"variable\">$AppClassLoader</span>.loadClass(Unknown Source)</div><div class=\"line\">at java.lang.ClassLoader.loadClass(Unknown Source)</div><div class=\"line\">Could not find the main class: HelloWorld.  Program will exit.</div><div class=\"line\">Exception <span class=\"keyword\">in</span> thread “main”</div><div class=\"line\"></div><div class=\"line\">d:workspaceHelloWorldbincomyanjiuyanjiu&gt;java -classpath .; HelloWorld</div><div class=\"line\">Exception <span class=\"keyword\">in</span> thread “main” java.lang.NoClassDefFoundError: HelloWorld (wrong name: com/yanjiuyanjiu/HelloWorld)</div><div class=\"line\">at java.lang.ClassLoader.defineClass1(Native Method)</div><div class=\"line\">at java.lang.ClassLoader.defineClassCond(Unknown Source)</div><div class=\"line\">at java.lang.ClassLoader.defineClass(Unknown Source)</div><div class=\"line\">at java.security.SecureClassLoader.defineClass(Unknown Source)</div><div class=\"line\">at java.net.URLClassLoader.defineClass(Unknown Source)</div><div class=\"line\">at java.net.URLClassLoader.access<span class=\"variable\">$000</span>(Unknown Source)</div><div class=\"line\">at java.net.URLClassLoader<span class=\"variable\">$1</span>.run(Unknown Source)</div><div class=\"line\">at java.security.AccessController.doPrivileged(Native Method)</div><div class=\"line\">at java.net.URLClassLoader.findClass(Unknown Source)</div><div class=\"line\">at java.lang.ClassLoader.loadClass(Unknown Source)</div><div class=\"line\">at sun.misc.Launcher<span class=\"variable\">$AppClassLoader</span>.loadClass(Unknown Source)</div><div class=\"line\">at java.lang.ClassLoader.loadClass(Unknown Source)</div><div class=\"line\">Could not find the main class: HelloWorld.  Program will exit.</div><div class=\"line\">Exception <span class=\"keyword\">in</span> thread “main”</div><div class=\"line\"></div><div class=\"line\">d:workspaceHelloWorldbincomyanjiuyanjiu&gt;cd..</div><div class=\"line\"></div><div class=\"line\">d:workspaceHelloWorldbincom&gt;cd..</div><div class=\"line\"></div><div class=\"line\">d:workspaceHelloWorldbin&gt;java -classpath .; com/yanjiuyanjiu/HelloWorld    只有这个成功</div><div class=\"line\"></div><div class=\"line\">Hello World!</div><div class=\"line\"></div><div class=\"line\">d:workspaceHelloWorldbin&gt;java -classpath .; comyanjiuyanjiuHelloWorld    换了个斜杠就不行了</div><div class=\"line\"></div><div class=\"line\">Exception <span class=\"keyword\">in</span> thread “main” java.lang.NoClassDefFoundError: comyanjiuyanjiuHelloWorld (wrong name: com/yanjiuyanjiu/HelloWorld)</div><div class=\"line\">at java.lang.ClassLoader.defineClass1(Native Method)</div><div class=\"line\">at java.lang.ClassLoader.defineClassCond(Unknown Source)</div><div class=\"line\">at java.lang.ClassLoader.defineClass(Unknown Source)</div><div class=\"line\">at java.security.SecureClassLoader.defineClass(Unknown Source)</div><div class=\"line\">at java.net.URLClassLoader.defineClass(Unknown Source)</div><div class=\"line\">at java.net.URLClassLoader.access<span class=\"variable\">$000</span>(Unknown Source)</div><div class=\"line\">at java.net.URLClassLoader<span class=\"variable\">$1</span>.run(Unknown Source)</div><div class=\"line\">at java.security.AccessController.doPrivileged(Native Method)</div><div class=\"line\">at java.net.URLClassLoader.findClass(Unknown Source)</div><div class=\"line\">at java.lang.ClassLoader.loadClass(Unknown Source)</div><div class=\"line\">at sun.misc.Launcher<span class=\"variable\">$AppClassLoader</span>.loadClass(Unknown Source)</div><div class=\"line\">at java.lang.ClassLoader.loadClass(Unknown Source)</div><div class=\"line\">Could not find the main class: comyanjiuyanjiuHelloWorld.  Program will exit.</div><div class=\"line\">Exception <span class=\"keyword\">in</span> thread “main”</div><div class=\"line\"></div><div class=\"line\">d:workspaceHelloWorldbin&gt;java -classpath ./com/yanjiuyanjiu/; HelloWorld</div><div class=\"line\"></div><div class=\"line\">Exception <span class=\"keyword\">in</span> thread “main”java.lang.NoClassDefFoundError: HelloWorld (wrong name: com/yanjiuyanjiu/HelloWorld)</div><div class=\"line\">at java.lang.ClassLoader.defineClass1(Native Method)</div><div class=\"line\">at java.lang.ClassLoader.defineClassCond(Unknown Source)</div><div class=\"line\">at java.lang.ClassLoader.defineClass(Unknown Source)</div><div class=\"line\">at java.security.SecureClassLoader.defineClass(Unknown Source)</div><div class=\"line\">at java.net.URLClassLoader.defineClass(Unknown Source)</div><div class=\"line\">at java.net.URLClassLoader.access<span class=\"variable\">$000</span>(Unknown Source)</div><div class=\"line\">at java.net.URLClassLoader<span class=\"variable\">$1</span>.run(Unknown Source)</div><div class=\"line\">at java.security.AccessController.doPrivileged(Native Method)</div><div class=\"line\">at java.net.URLClassLoader.findClass(Unknown Source)</div><div class=\"line\">at java.lang.ClassLoader.loadClass(Unknown Source)</div><div class=\"line\">at sun.misc.Launcher<span class=\"variable\">$AppClassLoader</span>.loadClass(Unknown Source)</div><div class=\"line\">at java.lang.ClassLoader.loadClass(Unknown Source)</div><div class=\"line\">Could not find the main class: HelloWorld.  Program will exit.</div><div class=\"line\">Exception <span class=\"keyword\">in</span> thread “main”</div></pre></td></tr></table></figure>\n<p>在网上搜索了大半天，大部分说是环境 变量，classpath或JDK 版本的问题，还有执行时文件名 class后缀不要。我一一试过，都没有解决。最后无意中换了一下命令符的位置，成功了。总结如下：</p>\n<ol>\n<li>环境变量，CLASSPATH当然要设置好，执行时不要带class后缀；  </li>\n<li>路径中的斜杠用“/”而不是“”；  </li>\n<li>命令符的当前目录要在包的起点。比如这里应该在 d:workspaceHelloWorldbin&gt;，如果在 d:workspaceHelloWorldbincomyanjiuyanjiu&gt;，反而不行，有点“近水楼台不得月”的意思，不知 道为什么，还请高手解释一下。</li>\n</ol>\n","excerpt":"<p>今天碰到了一个很变态的问题，写了一个很简单的HelloWord.java，内容如下：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">package</span> com.yanjiuyanjiu;</div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">HelloWorld</span> </span>&#123;</div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">static</span> <span class=\"keyword\">void</span> <span class=\"title\">main</span><span class=\"params\">(String args[])</span> </span>&#123;</div><div class=\"line\">System.out.println(“Hello World!”);</div><div class=\"line\">&#125;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<p>在eclipse中运行是可以的，但是在命令行下运行总是失败。我的工程位置为 d:workspaceHelloWorld。</p>\n<p>尝试了很多次，如下：</p>","more":"<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div><div class=\"line\">51</div><div class=\"line\">52</div><div class=\"line\">53</div><div class=\"line\">54</div><div class=\"line\">55</div><div class=\"line\">56</div><div class=\"line\">57</div><div class=\"line\">58</div><div class=\"line\">59</div><div class=\"line\">60</div><div class=\"line\">61</div><div class=\"line\">62</div><div class=\"line\">63</div><div class=\"line\">64</div><div class=\"line\">65</div><div class=\"line\">66</div><div class=\"line\">67</div><div class=\"line\">68</div><div class=\"line\">69</div><div class=\"line\">70</div><div class=\"line\">71</div><div class=\"line\">72</div><div class=\"line\">73</div><div class=\"line\">74</div><div class=\"line\">75</div><div class=\"line\">76</div><div class=\"line\">77</div><div class=\"line\">78</div></pre></td><td class=\"code\"><pre><div class=\"line\">d:workspaceHelloWorldbincomyanjiuyanjiu&gt;java HelloWorld</div><div class=\"line\"></div><div class=\"line\">Exception <span class=\"keyword\">in</span> thread “main” java.lang.NoClassDefFoundError: HelloWorld (wrong name: com/yanjiuyanjiu/HelloWorld)</div><div class=\"line\">at java.lang.ClassLoader.defineClass1(Native Method)</div><div class=\"line\">at java.lang.ClassLoader.defineClassCond(Unknown Source)</div><div class=\"line\">at java.lang.ClassLoader.defineClass(Unknown Source)</div><div class=\"line\">at java.security.SecureClassLoader.defineClass(Unknown Source)</div><div class=\"line\">at java.net.URLClassLoader.defineClass(Unknown Source)</div><div class=\"line\">at java.net.URLClassLoader.access<span class=\"variable\">$000</span>(Unknown Source)</div><div class=\"line\">at java.net.URLClassLoader<span class=\"variable\">$1</span>.run(Unknown Source)</div><div class=\"line\">at java.security.AccessController.doPrivileged(Native Method)</div><div class=\"line\">at java.net.URLClassLoader.findClass(Unknown Source)</div><div class=\"line\">at java.lang.ClassLoader.loadClass(Unknown Source)</div><div class=\"line\">at sun.misc.Launcher<span class=\"variable\">$AppClassLoader</span>.loadClass(Unknown Source)</div><div class=\"line\">at java.lang.ClassLoader.loadClass(Unknown Source)</div><div class=\"line\">Could not find the main class: HelloWorld.  Program will exit.</div><div class=\"line\">Exception <span class=\"keyword\">in</span> thread “main”</div><div class=\"line\"></div><div class=\"line\">d:workspaceHelloWorldbincomyanjiuyanjiu&gt;java -classpath .; HelloWorld</div><div class=\"line\">Exception <span class=\"keyword\">in</span> thread “main” java.lang.NoClassDefFoundError: HelloWorld (wrong name: com/yanjiuyanjiu/HelloWorld)</div><div class=\"line\">at java.lang.ClassLoader.defineClass1(Native Method)</div><div class=\"line\">at java.lang.ClassLoader.defineClassCond(Unknown Source)</div><div class=\"line\">at java.lang.ClassLoader.defineClass(Unknown Source)</div><div class=\"line\">at java.security.SecureClassLoader.defineClass(Unknown Source)</div><div class=\"line\">at java.net.URLClassLoader.defineClass(Unknown Source)</div><div class=\"line\">at java.net.URLClassLoader.access<span class=\"variable\">$000</span>(Unknown Source)</div><div class=\"line\">at java.net.URLClassLoader<span class=\"variable\">$1</span>.run(Unknown Source)</div><div class=\"line\">at java.security.AccessController.doPrivileged(Native Method)</div><div class=\"line\">at java.net.URLClassLoader.findClass(Unknown Source)</div><div class=\"line\">at java.lang.ClassLoader.loadClass(Unknown Source)</div><div class=\"line\">at sun.misc.Launcher<span class=\"variable\">$AppClassLoader</span>.loadClass(Unknown Source)</div><div class=\"line\">at java.lang.ClassLoader.loadClass(Unknown Source)</div><div class=\"line\">Could not find the main class: HelloWorld.  Program will exit.</div><div class=\"line\">Exception <span class=\"keyword\">in</span> thread “main”</div><div class=\"line\"></div><div class=\"line\">d:workspaceHelloWorldbincomyanjiuyanjiu&gt;cd..</div><div class=\"line\"></div><div class=\"line\">d:workspaceHelloWorldbincom&gt;cd..</div><div class=\"line\"></div><div class=\"line\">d:workspaceHelloWorldbin&gt;java -classpath .; com/yanjiuyanjiu/HelloWorld    只有这个成功</div><div class=\"line\"></div><div class=\"line\">Hello World!</div><div class=\"line\"></div><div class=\"line\">d:workspaceHelloWorldbin&gt;java -classpath .; comyanjiuyanjiuHelloWorld    换了个斜杠就不行了</div><div class=\"line\"></div><div class=\"line\">Exception <span class=\"keyword\">in</span> thread “main” java.lang.NoClassDefFoundError: comyanjiuyanjiuHelloWorld (wrong name: com/yanjiuyanjiu/HelloWorld)</div><div class=\"line\">at java.lang.ClassLoader.defineClass1(Native Method)</div><div class=\"line\">at java.lang.ClassLoader.defineClassCond(Unknown Source)</div><div class=\"line\">at java.lang.ClassLoader.defineClass(Unknown Source)</div><div class=\"line\">at java.security.SecureClassLoader.defineClass(Unknown Source)</div><div class=\"line\">at java.net.URLClassLoader.defineClass(Unknown Source)</div><div class=\"line\">at java.net.URLClassLoader.access<span class=\"variable\">$000</span>(Unknown Source)</div><div class=\"line\">at java.net.URLClassLoader<span class=\"variable\">$1</span>.run(Unknown Source)</div><div class=\"line\">at java.security.AccessController.doPrivileged(Native Method)</div><div class=\"line\">at java.net.URLClassLoader.findClass(Unknown Source)</div><div class=\"line\">at java.lang.ClassLoader.loadClass(Unknown Source)</div><div class=\"line\">at sun.misc.Launcher<span class=\"variable\">$AppClassLoader</span>.loadClass(Unknown Source)</div><div class=\"line\">at java.lang.ClassLoader.loadClass(Unknown Source)</div><div class=\"line\">Could not find the main class: comyanjiuyanjiuHelloWorld.  Program will exit.</div><div class=\"line\">Exception <span class=\"keyword\">in</span> thread “main”</div><div class=\"line\"></div><div class=\"line\">d:workspaceHelloWorldbin&gt;java -classpath ./com/yanjiuyanjiu/; HelloWorld</div><div class=\"line\"></div><div class=\"line\">Exception <span class=\"keyword\">in</span> thread “main”java.lang.NoClassDefFoundError: HelloWorld (wrong name: com/yanjiuyanjiu/HelloWorld)</div><div class=\"line\">at java.lang.ClassLoader.defineClass1(Native Method)</div><div class=\"line\">at java.lang.ClassLoader.defineClassCond(Unknown Source)</div><div class=\"line\">at java.lang.ClassLoader.defineClass(Unknown Source)</div><div class=\"line\">at java.security.SecureClassLoader.defineClass(Unknown Source)</div><div class=\"line\">at java.net.URLClassLoader.defineClass(Unknown Source)</div><div class=\"line\">at java.net.URLClassLoader.access<span class=\"variable\">$000</span>(Unknown Source)</div><div class=\"line\">at java.net.URLClassLoader<span class=\"variable\">$1</span>.run(Unknown Source)</div><div class=\"line\">at java.security.AccessController.doPrivileged(Native Method)</div><div class=\"line\">at java.net.URLClassLoader.findClass(Unknown Source)</div><div class=\"line\">at java.lang.ClassLoader.loadClass(Unknown Source)</div><div class=\"line\">at sun.misc.Launcher<span class=\"variable\">$AppClassLoader</span>.loadClass(Unknown Source)</div><div class=\"line\">at java.lang.ClassLoader.loadClass(Unknown Source)</div><div class=\"line\">Could not find the main class: HelloWorld.  Program will exit.</div><div class=\"line\">Exception <span class=\"keyword\">in</span> thread “main”</div></pre></td></tr></table></figure>\n<p>在网上搜索了大半天，大部分说是环境 变量，classpath或JDK 版本的问题，还有执行时文件名 class后缀不要。我一一试过，都没有解决。最后无意中换了一下命令符的位置，成功了。总结如下：</p>\n<ol>\n<li>环境变量，CLASSPATH当然要设置好，执行时不要带class后缀；  </li>\n<li>路径中的斜杠用“/”而不是“”；  </li>\n<li>命令符的当前目录要在包的起点。比如这里应该在 d:workspaceHelloWorldbin&gt;，如果在 d:workspaceHelloWorldbincomyanjiuyanjiu&gt;，反而不行，有点“近水楼台不得月”的意思，不知 道为什么，还请高手解释一下。</li>\n</ol>"},{"layout":"post","title":"Java质量检测评估工具","date":"2010-03-31T16:45:00.000Z","comments":1,"_content":"Java代码质量检测评估工具\n“五大” 代码分析领域：\n\n* 编码风格\n* 冗余代码\n* 代码覆盖率\n* 依赖项分析\n* 复杂度监控\n\n一下列举了一些目前比较流行的工具。网址后面列出了其PR值，可以反映此工具的流行度。\n\n##1. 编码风格\nCheckStyle\nHome page: <http://checkstyle.sourceforge.net/> (6)  \n对应的eclipse插件有多个，其中eclipsecs最常用  \nHome page: <http://eclipse-cs.sourceforge.net/> (6)  \neclipse插件URL：<http://eclipse-cs.sf.net/update/>\n\n##2. 冗余代码\nSimian <http://www.redhillconsulting.com.au/products/simian/> (5)  \nPMD 的 CPD <http://pmd.sourceforge.net/cpd.html> (5)\n\n##3. 代码覆盖率\nEMMA  <http://emma.sourceforge.net/> (6)  \nCobertura  <http://cobertura.sourceforge.net/> (6)  \nEclEmma <http://update.eclemma.org/> (5)  \nCoverlipse <http://coverlipse.sourceforge.net/> (3)\n\n##4. 依赖项分析\nJDepend <http://clarkware.com/software/JDepend.html> (6)\n\n##5. 复杂度监控\nMetrics <http://metrics.sourceforge.net/> (4)\n\n##6. 静态分析工具\n具有以上两项或两项以上的综合工具（也称为静态分析工具）： \n\n###6.1 PMD\nHome page: <http://pmd.sourceforge.net/> (6)  \neclipse插件URL：<http://sourceforge.net/projects/pmd/files/pmd-eclipse/update-site/>\n\n###6.2 FindBugs <http://findbugs.sourceforge.net/> (6)  \neclipse插件URL：<http://findbugs.cs.umd.edu/eclipse>\n\nFindBugs 检查程序生成的class文件，即分析字节码\nPMD 检查源码，分析源代码\n\n###6.3 Jtest\n<http://www.parasoft.com/jtest>\n\n###6.4 Jlint\n<http://artho.com/jlint/> (5)\n\n###6.5 Lint4j\n<http://www.jutils.com/> (4)\n\n我个人平时最常用的是Checkstyle，其次是PMD，大家可以参考一下。\n\n##参考资料\n<http://blog.csdn.net/cb_121/archive/2009/05/22/4208792.aspx>\n","source":"_posts/2010-03-31-java-qa-tools.md","raw":"---\nlayout: post\ntitle: \"Java质量检测评估工具\"\ndate: 2010-03-31 16:45\ncomments: true\ncategories: Tools\n---\nJava代码质量检测评估工具\n“五大” 代码分析领域：\n\n* 编码风格\n* 冗余代码\n* 代码覆盖率\n* 依赖项分析\n* 复杂度监控\n\n一下列举了一些目前比较流行的工具。网址后面列出了其PR值，可以反映此工具的流行度。\n\n##1. 编码风格\nCheckStyle\nHome page: <http://checkstyle.sourceforge.net/> (6)  \n对应的eclipse插件有多个，其中eclipsecs最常用  \nHome page: <http://eclipse-cs.sourceforge.net/> (6)  \neclipse插件URL：<http://eclipse-cs.sf.net/update/>\n\n##2. 冗余代码\nSimian <http://www.redhillconsulting.com.au/products/simian/> (5)  \nPMD 的 CPD <http://pmd.sourceforge.net/cpd.html> (5)\n\n##3. 代码覆盖率\nEMMA  <http://emma.sourceforge.net/> (6)  \nCobertura  <http://cobertura.sourceforge.net/> (6)  \nEclEmma <http://update.eclemma.org/> (5)  \nCoverlipse <http://coverlipse.sourceforge.net/> (3)\n\n##4. 依赖项分析\nJDepend <http://clarkware.com/software/JDepend.html> (6)\n\n##5. 复杂度监控\nMetrics <http://metrics.sourceforge.net/> (4)\n\n##6. 静态分析工具\n具有以上两项或两项以上的综合工具（也称为静态分析工具）： \n\n###6.1 PMD\nHome page: <http://pmd.sourceforge.net/> (6)  \neclipse插件URL：<http://sourceforge.net/projects/pmd/files/pmd-eclipse/update-site/>\n\n###6.2 FindBugs <http://findbugs.sourceforge.net/> (6)  \neclipse插件URL：<http://findbugs.cs.umd.edu/eclipse>\n\nFindBugs 检查程序生成的class文件，即分析字节码\nPMD 检查源码，分析源代码\n\n###6.3 Jtest\n<http://www.parasoft.com/jtest>\n\n###6.4 Jlint\n<http://artho.com/jlint/> (5)\n\n###6.5 Lint4j\n<http://www.jutils.com/> (4)\n\n我个人平时最常用的是Checkstyle，其次是PMD，大家可以参考一下。\n\n##参考资料\n<http://blog.csdn.net/cb_121/archive/2009/05/22/4208792.aspx>\n","slug":"2010-03-31-java-qa-tools","published":1,"updated":"2016-08-18T09:21:04.000Z","photos":[],"link":"","_id":"cis07pf1t000701pq0alsvk9a","content":"<p>Java代码质量检测评估工具<br>“五大” 代码分析领域：</p>\n<ul>\n<li>编码风格</li>\n<li>冗余代码</li>\n<li>代码覆盖率</li>\n<li>依赖项分析</li>\n<li>复杂度监控</li>\n</ul>\n<p>一下列举了一些目前比较流行的工具。网址后面列出了其PR值，可以反映此工具的流行度。</p>\n<p>##1. 编码风格<br>CheckStyle<br>Home page: <a href=\"http://checkstyle.sourceforge.net/\" target=\"_blank\" rel=\"external\">http://checkstyle.sourceforge.net/</a> (6)<br>对应的eclipse插件有多个，其中eclipsecs最常用<br>Home page: <a href=\"http://eclipse-cs.sourceforge.net/\" target=\"_blank\" rel=\"external\">http://eclipse-cs.sourceforge.net/</a> (6)<br>eclipse插件URL：<a href=\"http://eclipse-cs.sf.net/update/\" target=\"_blank\" rel=\"external\">http://eclipse-cs.sf.net/update/</a></p>\n<p>##2. 冗余代码<br>Simian <a href=\"http://www.redhillconsulting.com.au/products/simian/\" target=\"_blank\" rel=\"external\">http://www.redhillconsulting.com.au/products/simian/</a> (5)<br>PMD 的 CPD <a href=\"http://pmd.sourceforge.net/cpd.html\" target=\"_blank\" rel=\"external\">http://pmd.sourceforge.net/cpd.html</a> (5)</p>\n<p>##3. 代码覆盖率<br>EMMA  <a href=\"http://emma.sourceforge.net/\" target=\"_blank\" rel=\"external\">http://emma.sourceforge.net/</a> (6)<br>Cobertura  <a href=\"http://cobertura.sourceforge.net/\" target=\"_blank\" rel=\"external\">http://cobertura.sourceforge.net/</a> (6)<br>EclEmma <a href=\"http://update.eclemma.org/\" target=\"_blank\" rel=\"external\">http://update.eclemma.org/</a> (5)<br>Coverlipse <a href=\"http://coverlipse.sourceforge.net/\" target=\"_blank\" rel=\"external\">http://coverlipse.sourceforge.net/</a> (3)</p>\n<p>##4. 依赖项分析<br>JDepend <a href=\"http://clarkware.com/software/JDepend.html\" target=\"_blank\" rel=\"external\">http://clarkware.com/software/JDepend.html</a> (6)</p>\n<p>##5. 复杂度监控<br>Metrics <a href=\"http://metrics.sourceforge.net/\" target=\"_blank\" rel=\"external\">http://metrics.sourceforge.net/</a> (4)</p>\n<p>##6. 静态分析工具<br>具有以上两项或两项以上的综合工具（也称为静态分析工具）： </p>\n<p>###6.1 PMD<br>Home page: <a href=\"http://pmd.sourceforge.net/\" target=\"_blank\" rel=\"external\">http://pmd.sourceforge.net/</a> (6)<br>eclipse插件URL：<a href=\"http://sourceforge.net/projects/pmd/files/pmd-eclipse/update-site/\" target=\"_blank\" rel=\"external\">http://sourceforge.net/projects/pmd/files/pmd-eclipse/update-site/</a></p>\n<p>###6.2 FindBugs <a href=\"http://findbugs.sourceforge.net/\" target=\"_blank\" rel=\"external\">http://findbugs.sourceforge.net/</a> (6)<br>eclipse插件URL：<a href=\"http://findbugs.cs.umd.edu/eclipse\" target=\"_blank\" rel=\"external\">http://findbugs.cs.umd.edu/eclipse</a></p>\n<p>FindBugs 检查程序生成的class文件，即分析字节码<br>PMD 检查源码，分析源代码</p>\n<p>###6.3 Jtest<br><a href=\"http://www.parasoft.com/jtest\" target=\"_blank\" rel=\"external\">http://www.parasoft.com/jtest</a></p>\n<p>###6.4 Jlint<br><a href=\"http://artho.com/jlint/\" target=\"_blank\" rel=\"external\">http://artho.com/jlint/</a> (5)</p>\n<p>###6.5 Lint4j<br><a href=\"http://www.jutils.com/\" target=\"_blank\" rel=\"external\">http://www.jutils.com/</a> (4)</p>\n<p>我个人平时最常用的是Checkstyle，其次是PMD，大家可以参考一下。</p>\n<p>##参考资料<br><a href=\"http://blog.csdn.net/cb_121/archive/2009/05/22/4208792.aspx\" target=\"_blank\" rel=\"external\">http://blog.csdn.net/cb_121/archive/2009/05/22/4208792.aspx</a></p>\n","excerpt":"","more":"<p>Java代码质量检测评估工具<br>“五大” 代码分析领域：</p>\n<ul>\n<li>编码风格</li>\n<li>冗余代码</li>\n<li>代码覆盖率</li>\n<li>依赖项分析</li>\n<li>复杂度监控</li>\n</ul>\n<p>一下列举了一些目前比较流行的工具。网址后面列出了其PR值，可以反映此工具的流行度。</p>\n<p>##1. 编码风格<br>CheckStyle<br>Home page: <a href=\"http://checkstyle.sourceforge.net/\">http://checkstyle.sourceforge.net/</a> (6)<br>对应的eclipse插件有多个，其中eclipsecs最常用<br>Home page: <a href=\"http://eclipse-cs.sourceforge.net/\">http://eclipse-cs.sourceforge.net/</a> (6)<br>eclipse插件URL：<a href=\"http://eclipse-cs.sf.net/update/\">http://eclipse-cs.sf.net/update/</a></p>\n<p>##2. 冗余代码<br>Simian <a href=\"http://www.redhillconsulting.com.au/products/simian/\">http://www.redhillconsulting.com.au/products/simian/</a> (5)<br>PMD 的 CPD <a href=\"http://pmd.sourceforge.net/cpd.html\">http://pmd.sourceforge.net/cpd.html</a> (5)</p>\n<p>##3. 代码覆盖率<br>EMMA  <a href=\"http://emma.sourceforge.net/\">http://emma.sourceforge.net/</a> (6)<br>Cobertura  <a href=\"http://cobertura.sourceforge.net/\">http://cobertura.sourceforge.net/</a> (6)<br>EclEmma <a href=\"http://update.eclemma.org/\">http://update.eclemma.org/</a> (5)<br>Coverlipse <a href=\"http://coverlipse.sourceforge.net/\">http://coverlipse.sourceforge.net/</a> (3)</p>\n<p>##4. 依赖项分析<br>JDepend <a href=\"http://clarkware.com/software/JDepend.html\">http://clarkware.com/software/JDepend.html</a> (6)</p>\n<p>##5. 复杂度监控<br>Metrics <a href=\"http://metrics.sourceforge.net/\">http://metrics.sourceforge.net/</a> (4)</p>\n<p>##6. 静态分析工具<br>具有以上两项或两项以上的综合工具（也称为静态分析工具）： </p>\n<p>###6.1 PMD<br>Home page: <a href=\"http://pmd.sourceforge.net/\">http://pmd.sourceforge.net/</a> (6)<br>eclipse插件URL：<a href=\"http://sourceforge.net/projects/pmd/files/pmd-eclipse/update-site/\">http://sourceforge.net/projects/pmd/files/pmd-eclipse/update-site/</a></p>\n<p>###6.2 FindBugs <a href=\"http://findbugs.sourceforge.net/\">http://findbugs.sourceforge.net/</a> (6)<br>eclipse插件URL：<a href=\"http://findbugs.cs.umd.edu/eclipse\">http://findbugs.cs.umd.edu/eclipse</a></p>\n<p>FindBugs 检查程序生成的class文件，即分析字节码<br>PMD 检查源码，分析源代码</p>\n<p>###6.3 Jtest<br><a href=\"http://www.parasoft.com/jtest\">http://www.parasoft.com/jtest</a></p>\n<p>###6.4 Jlint<br><a href=\"http://artho.com/jlint/\">http://artho.com/jlint/</a> (5)</p>\n<p>###6.5 Lint4j<br><a href=\"http://www.jutils.com/\">http://www.jutils.com/</a> (4)</p>\n<p>我个人平时最常用的是Checkstyle，其次是PMD，大家可以参考一下。</p>\n<p>##参考资料<br><a href=\"http://blog.csdn.net/cb_121/archive/2009/05/22/4208792.aspx\">http://blog.csdn.net/cb_121/archive/2009/05/22/4208792.aspx</a></p>\n"},{"layout":"post","title":"用javac命令行编译多个java文件","date":"2011-06-23T17:22:00.000Z","comments":1,"_content":"1. CLASSPATH一定要具体到jar路径，例如\n\n``` bash\nexport CLASSPATH=/usr/lib/jvm/java-6-sun/lib/commons-codec.jar:/usr/lib/jvm/java-6-sun/lib/commons-httpclient-3.1.jar:/usr/lib/jvm/java-6-sun/lib/commons-logging-1.1.jar:/usr/lib/jvm/java-6-sun/lib/dt.jar:/usr/lib/jvm/java-6-sun/lib/htmlconverter.jar:/usr/lib/jvm/java-6-sun/lib/jconsole.jar:/usr/lib/jvm/java-6-sun/lib/junit-4.1.jar:/usr/lib/jvm/java-6-sun/lib/mysql-connector-java-5.1.16-bin.jar:/usr/lib/jvm/java-6-sun/lib/sa-jdi.jar:/usr/lib/jvm/java-6-sun/lib/tools.jar\n```\n\n2. 每个java文件给出路径，最常见的是用通配符*，不支持目录递归。\n\n3. 最好加上 -d，这样会在这个目录下生成class文件，而不会和java文件混在一起\n\n看我的一个具体的例子\n\n```\njavac -d /home/dfq/crawler/bin crawler/*.java weibo4j/*.java weibo4j/org/json/*.java weibo4j/*.java weibo4j/util/*.java weibo4j/http/*.java\n```\n\n运行时用如下命令：\n\n```\ncd /home/dfq/crawler/bin\njava -cp .:$CLASSPATH crawler.ManagerThread\n```\n","source":"_posts/2011-06-23-using-javac-to-compile-multi-java-files.md","raw":"---\nlayout: post\ntitle: \"用javac命令行编译多个java文件\"\ndate: 2011-06-23 17:22\ncomments: true\ncategories: Language\n---\n1. CLASSPATH一定要具体到jar路径，例如\n\n``` bash\nexport CLASSPATH=/usr/lib/jvm/java-6-sun/lib/commons-codec.jar:/usr/lib/jvm/java-6-sun/lib/commons-httpclient-3.1.jar:/usr/lib/jvm/java-6-sun/lib/commons-logging-1.1.jar:/usr/lib/jvm/java-6-sun/lib/dt.jar:/usr/lib/jvm/java-6-sun/lib/htmlconverter.jar:/usr/lib/jvm/java-6-sun/lib/jconsole.jar:/usr/lib/jvm/java-6-sun/lib/junit-4.1.jar:/usr/lib/jvm/java-6-sun/lib/mysql-connector-java-5.1.16-bin.jar:/usr/lib/jvm/java-6-sun/lib/sa-jdi.jar:/usr/lib/jvm/java-6-sun/lib/tools.jar\n```\n\n2. 每个java文件给出路径，最常见的是用通配符*，不支持目录递归。\n\n3. 最好加上 -d，这样会在这个目录下生成class文件，而不会和java文件混在一起\n\n看我的一个具体的例子\n\n```\njavac -d /home/dfq/crawler/bin crawler/*.java weibo4j/*.java weibo4j/org/json/*.java weibo4j/*.java weibo4j/util/*.java weibo4j/http/*.java\n```\n\n运行时用如下命令：\n\n```\ncd /home/dfq/crawler/bin\njava -cp .:$CLASSPATH crawler.ManagerThread\n```\n","slug":"2011-06-23-using-javac-to-compile-multi-java-files","published":1,"updated":"2016-08-18T09:21:04.000Z","photos":[],"link":"","_id":"cis07pf23000a01pqs6xv4xnv","content":"<ol>\n<li>CLASSPATH一定要具体到jar路径，例如</li>\n</ol>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"built_in\">export</span> CLASSPATH=/usr/lib/jvm/java-6-sun/lib/commons-codec.jar:/usr/lib/jvm/java-6-sun/lib/commons-httpclient-3.1.jar:/usr/lib/jvm/java-6-sun/lib/commons-logging-1.1.jar:/usr/lib/jvm/java-6-sun/lib/dt.jar:/usr/lib/jvm/java-6-sun/lib/htmlconverter.jar:/usr/lib/jvm/java-6-sun/lib/jconsole.jar:/usr/lib/jvm/java-6-sun/lib/junit-4.1.jar:/usr/lib/jvm/java-6-sun/lib/mysql-connector-java-5.1.16-bin.jar:/usr/lib/jvm/java-6-sun/lib/sa-jdi.jar:/usr/lib/jvm/java-6-sun/lib/tools.jar</div></pre></td></tr></table></figure>\n<ol>\n<li><p>每个java文件给出路径，最常见的是用通配符*，不支持目录递归。</p>\n</li>\n<li><p>最好加上 -d，这样会在这个目录下生成class文件，而不会和java文件混在一起</p>\n</li>\n</ol>\n<p>看我的一个具体的例子</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">javac -d /home/dfq/crawler/bin crawler/*.java weibo4j/*.java weibo4j/org/json/*.java weibo4j/*.java weibo4j/util/*.java weibo4j/http/*.java</div></pre></td></tr></table></figure>\n<p>运行时用如下命令：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">cd /home/dfq/crawler/bin</div><div class=\"line\">java -cp .:$CLASSPATH crawler.ManagerThread</div></pre></td></tr></table></figure>\n","excerpt":"","more":"<ol>\n<li>CLASSPATH一定要具体到jar路径，例如</li>\n</ol>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"built_in\">export</span> CLASSPATH=/usr/lib/jvm/java-6-sun/lib/commons-codec.jar:/usr/lib/jvm/java-6-sun/lib/commons-httpclient-3.1.jar:/usr/lib/jvm/java-6-sun/lib/commons-logging-1.1.jar:/usr/lib/jvm/java-6-sun/lib/dt.jar:/usr/lib/jvm/java-6-sun/lib/htmlconverter.jar:/usr/lib/jvm/java-6-sun/lib/jconsole.jar:/usr/lib/jvm/java-6-sun/lib/junit-4.1.jar:/usr/lib/jvm/java-6-sun/lib/mysql-connector-java-5.1.16-bin.jar:/usr/lib/jvm/java-6-sun/lib/sa-jdi.jar:/usr/lib/jvm/java-6-sun/lib/tools.jar</div></pre></td></tr></table></figure>\n<ol>\n<li><p>每个java文件给出路径，最常见的是用通配符*，不支持目录递归。</p>\n</li>\n<li><p>最好加上 -d，这样会在这个目录下生成class文件，而不会和java文件混在一起</p>\n</li>\n</ol>\n<p>看我的一个具体的例子</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">javac -d /home/dfq/crawler/bin crawler/*.java weibo4j/*.java weibo4j/org/json/*.java weibo4j/*.java weibo4j/util/*.java weibo4j/http/*.java</div></pre></td></tr></table></figure>\n<p>运行时用如下命令：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">cd /home/dfq/crawler/bin</div><div class=\"line\">java -cp .:$CLASSPATH crawler.ManagerThread</div></pre></td></tr></table></figure>\n"},{"layout":"post","title":"基于朴素贝叶斯的文本分类算法","date":"2010-05-28T17:15:00.000Z","comments":1,"_content":"作者: 灵魂机器  \n新浪博客：[www.weibo.com/soulmachine](www.weibo.com/soulmachine)  \n作者博客：[www.yanjiuyanjiu.com](www.yanjiuyanjiu.com)\n\n**摘要**：常用的文本分类方法有支持向量机、K-近邻算法和朴素贝叶斯。其中朴素贝叶斯具有容易实现，运行速度快的特点，被广泛使用。本文详细介绍了朴素贝叶斯的基本原理，讨论了两种常见模型：多项式模型（MM）和伯努利模型（BM），实现了可运行的代码，并进行了一些数据测试。\n\n**关键字**：朴素贝叶斯；文本分类\n\n**Text Classification Algorithm Based on Naive Bayes**  \n**Author**: soulmachine  \n**Email**：soulmachine@gmail.com  \n**Blog**：[www.yanjiuyanjiu.com](www.yanjiuyanjiu.com)\n\n**Abstract**:Usually there are three methods for text classification: SVM、KNN and Naïve Bayes. Naïve Bayes is easy to implement and fast, so it is widely used. This article introduced the theory of Naïve Bayes and discussed two popular models: multinomial model(MM) and Bernoulli model(BM) in details, implemented runnable code and performed some data tests.\n\n**Keywords**: naïve bayes; text classification\n\n##1 贝叶斯原理\n\n###1.1 贝叶斯公式\n\n设A、B是两个事件，且P(A)>0，称 $$P(Y \\vert X)=\\dfrac {P(XY)}{P(X)}$$ 为事件A发生的条件下事件B发生的**条件概率**。\n\n**乘法公式** $$P(XYZ)=P(Z \\vert XY)P(Y \\vert X)P(X)$$  \n**全概率公式**  $$P(X)=P(X \\vert Y_1)+ P(X \\vert Y_2)+…+ P(X \\vert Y_n)$$  \n**贝叶斯公式**  $$P(Y_i \\vert X)=\\dfrac{P(XY_i)}{P(X)}=\\dfrac{P(X \\vert Y_i)P(Y_i)}{P(X)}=\\dfrac{P(X \\vert Y_i)P(Y_i)}{\\sum\\limits _{j=1} ^{n} P(X \\vert Y_j)}$$  \n\n在此处，贝叶斯公式，我们要用到的是 $$P(Y_i \\vert X)=\\dfrac{P(X \\vert Y_i)P(Y_i)}{P(X)}$$\n\n以上公式，请读者参考[《概率论与数理统计（第五版）》](http://book.douban.com/subject/1231189/)的1.4节“条件概率”（这里将原书中的A换成了X，B换成了Y），获得更深的理解。\n\n<!-- more -->\n\n###1.2 贝叶斯定理在分类中的应用\n在分类（classification）问题中，常常需要把一个事物分到某个类别。一个事物具有很多属性，把它的众多属性看做一个向量，即$$x=(x_1,x_2,x_3,…,x_n)$$，用x这个向量来代表这个事物。类别也是有很多种，用集合$$Y={y_1,y_2,…y_m}$$表示。如果x属于$$y_1$$类别，就可以给x打上$$y_1$$标签，意思是说x属于$$y_1$$类别。这就是所谓的**分类(Classification)**。\n\nx的集合记为X，称为属性集。一般X和Y的关系是不确定的，你只能在某种程度上说x有多大可能性属于类$$y_1$$，比如说x有80%的可能性属于类$$y_1$$，这时可以把X和Y看做是随机变量，$$P(Y \\vert X)$$称为Y的**后验概率**（posterior probability），与之相对的，P(Y)称为Y的**先验概率**（prior probability）[^2]。\n\n在训练阶段，我们要根据从训练数据中收集的信息，**对X和Y的每一种组合学习后验概率$$P(Y \\vert X)$$。**分类时，来了一个实例x，在刚才训练得到的一堆后验概率中找出所有的$$P(Y \\vert x)$$， 其中最大的那个y，即为x所属分类。根据贝叶斯公式，后验概率为$$P(Y \\vert X)=\\dfrac{P(X \\vert Y)P(Y)}{P(X)}$$\n \n在比较不同Y值的后验概率时，分母P(X)总是常数，**因此可以忽略**。先验概率P(Y)可以通过计算训练集中属于每一个类的训练样本所占的比例容易地估计。\n\n我们来举个简单的例子，让读者对上述思路有个形象的认识[^3]。  \n考虑一个医疗诊断问题，有两种可能的假设：（1）病人有癌症。（2）病人无癌症。样本数据来自某化验测试，它也有两种可能的结果：阳性和阴性。假设我们已经有先验知识：在所有人口中只有0.008的人患病。此外，化验测试对有病的患者有98%的可能返回阳性结果，对无病患者有97%的可能返回阴性结果。\n\n上面的数据可以用以下概率式子表示：  \nP(cancer)=0.008,P(无cancer)=0.992  \nP(阳性|cancer)=0.98,P(阴性|cancer)=0.02  \nP(阳性|无cancer)=0.03，P(阴性|无cancer)=0.97  \n假设现在有一个新病人，化验测试返回阳性，是否将病人断定为有癌症呢？\n\n在这里，Y={cancer，无cancer}，共两个类别，这个新病人是一个样本，他有一个属性阳性，可以令x=(阳性)。我们可以来计算各个类别的后验概率：  \nP(cancer | 阳性) = P(阳性 | cancer)p(cancer)=0.98\\* 0.008 = 0.0078  \nP(无cancer | 阳性) =P(阳性 | 无cancer)\\* p(无cancer)=0.03\\* 0.992 = 0.0298   \n因此，应该判断为无癌症。\n\n在这个例子中，类条件概率，P(cancer|阳性)和P(无cancer|阳性)直接告诉了我们。\n\n一般地，对**类条件概率$$P(X \\vert Y)$$**的估计，有朴素贝叶斯分类器和贝叶斯信念网络两种方法，这里介绍朴素贝叶斯分类器。\n\n###1.3 朴素贝叶斯分类器\n**1、条件独立性**  \n给定类标号y，朴素贝叶斯分类器在估计类条件概率时假设属性之间条件独立。条件独立假设可以形式化的表达如下：  \n$$\n\\prod\\limits_{i=1}^{n} P(x_i  \\vert Y=y)\n$$\n其中每个训练样本可用一个属性向量$$X=(x_1,x_2,x_3,…,x_n)$$表示，各个属性之间条件独立。\n\n比如，对于一篇文章，\n \n> Good good study,Day day up.\n\n可以用一个文本特征向量来表示，`x=(Good, good, study, Day, day , up)`。一般各个词语之间肯定不是相互独立的，有一定的上下文联系。但在朴素贝叶斯文本分类时，我们假设个单词之间没有联系，可以用一个文本特征向量来表示这篇文章，这就是“朴素”的来历。\n\n**2、朴素贝叶斯如何工作**  \n**有了条件独立假设，就不必计算X和Y的每一种组合的类条件概率**，只需对给定的Y，计算每个$$x_i$$的条件概率。后一种方法更实用，因为它不需要很大的训练集就能获得较好的概率估计。\n\n**3、估计分类属性的条件概率**  \n$$P(x_i \\vert Y=y)$$怎么计算呢？它一般根据类别y下包含属性$$x_i$$的实例的比例来估计。以文本分类为例，xi表示一个单词，$$P(x_i \\vert Y=y)=$$包含该类别下包含单词的xi的文章总数/ 该类别下的文章总数。\n\n**4、贝叶斯分类器举例**\n假设给定了如下训练样本数据，我们学习的目标是根据给定的天气状况判断你对PlayTennis这个请求的回答是Yes还是No。\n\n<table border=\"1\" cellspacing=\"0\" cellpadding=\"0\">\n<tbody>\n<tr>\n<td valign=\"top\" width=\"95\">Day</td>\n<td valign=\"top\" width=\"95\">Outlook</td>\n<td valign=\"top\" width=\"95\">Temperature</td>\n<td valign=\"top\" width=\"95\">Humidity</td>\n<td valign=\"top\" width=\"95\">Wind</td>\n<td valign=\"top\" width=\"95\">PlayTennis</td>\n</tr>\n<tr>\n<td valign=\"top\" width=\"95\">D1</td>\n<td valign=\"top\" width=\"95\">Sunny</td>\n<td valign=\"top\" width=\"95\">Hot</td>\n<td valign=\"top\" width=\"95\">High</td>\n<td valign=\"top\" width=\"95\">Weak</td>\n<td valign=\"top\" width=\"95\">No</td>\n</tr>\n<tr>\n<td valign=\"top\" width=\"95\">D2</td>\n<td valign=\"top\" width=\"95\">Sunny</td>\n<td valign=\"top\" width=\"95\">Hot</td>\n<td valign=\"top\" width=\"95\">High</td>\n<td valign=\"top\" width=\"95\">Strong</td>\n<td valign=\"top\" width=\"95\">No</td>\n</tr>\n<tr>\n<td valign=\"top\" width=\"95\">D3</td>\n<td valign=\"top\" width=\"95\">Overcast</td>\n<td valign=\"top\" width=\"95\">Hot</td>\n<td valign=\"top\" width=\"95\">High</td>\n<td valign=\"top\" width=\"95\">Weak</td>\n<td valign=\"top\" width=\"95\">Yes</td>\n</tr>\n<tr>\n<td valign=\"top\" width=\"95\">D4</td>\n<td valign=\"top\" width=\"95\">Rain</td>\n<td valign=\"top\" width=\"95\">Mild</td>\n<td valign=\"top\" width=\"95\">High</td>\n<td valign=\"top\" width=\"95\">Weak</td>\n<td valign=\"top\" width=\"95\">Yes</td>\n</tr>\n<tr>\n<td valign=\"top\" width=\"95\">D5</td>\n<td valign=\"top\" width=\"95\">Rain</td>\n<td valign=\"top\" width=\"95\">Cool</td>\n<td valign=\"top\" width=\"95\">Normal</td>\n<td valign=\"top\" width=\"95\">Weak</td>\n<td valign=\"top\" width=\"95\">Yes</td>\n</tr>\n<tr>\n<td valign=\"top\" width=\"95\">D6</td>\n<td valign=\"top\" width=\"95\">Rain</td>\n<td valign=\"top\" width=\"95\">Cool</td>\n<td valign=\"top\" width=\"95\">Normal</td>\n<td valign=\"top\" width=\"95\">Strong</td>\n<td valign=\"top\" width=\"95\">No</td>\n</tr>\n<tr>\n<td valign=\"top\" width=\"95\">D7</td>\n<td valign=\"top\" width=\"95\">Overcast</td>\n<td valign=\"top\" width=\"95\">Cool</td>\n<td valign=\"top\" width=\"95\">Normal</td>\n<td valign=\"top\" width=\"95\">Strong</td>\n<td valign=\"top\" width=\"95\">Yes</td>\n</tr>\n<tr>\n<td valign=\"top\" width=\"95\">D8</td>\n<td valign=\"top\" width=\"95\">Sunny</td>\n<td valign=\"top\" width=\"95\">Mild</td>\n<td valign=\"top\" width=\"95\">High</td>\n<td valign=\"top\" width=\"95\">Weak</td>\n<td valign=\"top\" width=\"95\">No</td>\n</tr>\n<tr>\n<td valign=\"top\" width=\"95\">D9</td>\n<td valign=\"top\" width=\"95\">Sunny</td>\n<td valign=\"top\" width=\"95\">Cool</td>\n<td valign=\"top\" width=\"95\">Normal</td>\n<td valign=\"top\" width=\"95\">Weak</td>\n<td valign=\"top\" width=\"95\">Yes</td>\n</tr>\n<tr>\n<td valign=\"top\" width=\"95\">D10</td>\n<td valign=\"top\" width=\"95\">Rain</td>\n<td valign=\"top\" width=\"95\">Mild</td>\n<td valign=\"top\" width=\"95\">Normal</td>\n<td valign=\"top\" width=\"95\">Weak</td>\n<td valign=\"top\" width=\"95\">Yes</td>\n</tr>\n<tr>\n<td valign=\"top\" width=\"95\">D11</td>\n<td valign=\"top\" width=\"95\">Sunny</td>\n<td valign=\"top\" width=\"95\">Mild</td>\n<td valign=\"top\" width=\"95\">Normal</td>\n<td valign=\"top\" width=\"95\">Strong</td>\n<td valign=\"top\" width=\"95\">Yes</td>\n</tr>\n<tr>\n<td valign=\"top\" width=\"95\">D12</td>\n<td valign=\"top\" width=\"95\">Overcast</td>\n<td valign=\"top\" width=\"95\">Mild</td>\n<td valign=\"top\" width=\"95\">High</td>\n<td valign=\"top\" width=\"95\">Strong</td>\n<td valign=\"top\" width=\"95\">Yes</td>\n</tr>\n<tr>\n<td valign=\"top\" width=\"95\">D13</td>\n<td valign=\"top\" width=\"95\">Overcast</td>\n<td valign=\"top\" width=\"95\">Hot</td>\n<td valign=\"top\" width=\"95\">Normal</td>\n<td valign=\"top\" width=\"95\">Weak</td>\n<td valign=\"top\" width=\"95\">Yes</td>\n</tr>\n<tr>\n<td valign=\"top\" width=\"95\">D14</td>\n<td valign=\"top\" width=\"95\">Rain</td>\n<td valign=\"top\" width=\"95\">Mild</td>\n<td valign=\"top\" width=\"95\">High</td>\n<td valign=\"top\" width=\"95\">Strong</td>\n<td valign=\"top\" width=\"95\">No</td>\n</tr>\n</tbody>\n</table> \n可以看到这里样本数据集提供了14个训练样本，我们将使用此表的数据，并结合朴素贝叶斯分类器来分类下面的新实例：  \nx = (Outlook = Sunny,Temprature = Cool,Humidity = High,Wind = Strong)\n\n在这个例子中，属性向量X=(Outlook, Temperature, Humidity, Wind)，类集合Y={Yes, No}。我们需要利用训练数据计算后验概率$$P(Yes \\vert x)$$和$$P(No \\vert x)$$，如果$$P(Yes \\vert x)>P(No \\vert x)$$，那么新实例分类为Yes，否则为No。\n\n为了计算后验概率，我们需要计算先验概率P(Yes)和P(No)和类条件概率$$P(x_i \\vert Y)$$。\n\n因为有9个样本属于Yes，5个样本属于No，所以$$P(Yes)=\\dfrac{9}{14}$$, $$P(No)=\\dfrac{5}{14}$$。类条件概率计算如下：  \n$$P(Outlook = Sunny \\vert Yes)=\\dfrac{2}{9}　　　P(Outlook = Sunny \\vert No)=\\dfrac{3}{5}$$  \n$$P(Temprature = Cool  \\vert Yes) =\\dfrac{3}{9}　　　P(Temprature = Cool  \\vert No) =\\dfrac{1}{5}$$  \n$$P(Humidity = High  \\vert Yes) =\\dfrac{3}{9}　　　P(Humidity = High  \\vert No) =\\dfrac{4}{5}$$\n$$P(Wind = Strong  \\vert Yes) =\\dfrac{3}{9}　　　P(Wind = Strong  \\vert No) =\\dfrac{3}{5}$$    \n\n后验概率计算如下：\n$$\n\\begin{aligned}\nP(Yes  \\vert  x) & = P(Outlook = Sunny \\vert Yes) \\times P(Temprature = Cool  \\vert Yes) \\newline\n& \\times P(Humidity = High  \\vert Yes) \\times P(Wind = Strong  \\vert Yes) \\times P(Yes) \\newline\n& =\\dfrac{2}{9} \\times \\dfrac{3}{9} \\times \\dfrac{3}{9} \\times \\dfrac{3}{9} \\times \\dfrac{3}{9} \\times \\dfrac{9}{14}=\\dfrac{2}{243}=\\dfrac{9}{1701} \\approx 0.00529\n\\end{aligned}\n$$\n$$\n\\begin{aligned}\nP(No  \\vert  x)&= P(Outlook = Sunny \\vert No) \\times P(Temprature = Cool  \\vert No) \\newline\n& \\times P(Humidity = High  \\vert No) \\times P(Wind = Strong  \\vert No) \\times P(No) \\newline\n& =\\dfrac{3}{5}\\times \\dfrac{1}{5} \\times \\dfrac{4}{5} \\times \\dfrac{3}{5} \\times  \\dfrac{5}{14}=\\dfrac{18}{875} \\approx 0.02057\n\\end{aligned}\n$$\n通过计算得出$$P(No  \\vert  x)> P(Yes  \\vert  x)$$，所以该样本分类为No[^3]。\n\n**5、条件概率的m估计**  \n假设有来了一个新样本 $$x_1= (Outlook = Cloudy,Temprature = Cool,Humidity = High,Wind = Strong)$$，要求对其分类。我们来开始计算，  \n$$P(Outlook = Cloudy \\vert Yes)=\\dfrac{0}{9}=0  P(Outlook = Cloudy  \\vert No)=\\dfrac{0}{5}=0$$  \n计算到这里，大家就会意识到，这里出现了一个新的属性值，在训练样本中所没有的。如果有一个属性的类条件概率为0，则整个类的后验概率就等于0，我们可以直接得到后验概率$$P(Yes  \\vert  x_1)= P(No  \\vert  x_1)=0$$，这时二者相等，无法分类。\n\n当训练样本不能覆盖那么多的属性值时，都会出现上述的窘境。简单的使用样本比例来估计类条件概率的方法太脆弱了，尤其是当训练样本少而属性数目又很大时。\n\n解决方法是使用m估计(m-estimate)方法来估计条件概率：\n$$\nP(x_i \\vert y_i)=\\dfrac{n_c+mp}{n+m}\n$$\nn是类$$y_j$$中的样本总数，$$n_c$$是类$$y_j$$中取值$$x_i$$的样本数，m是称为等价样本大小的参数，而p是用户指定的参数。如果没有训练集（即n=0），则$$P(x_i \\vert y_i)=p$$, 因此p可以看作是在类$$y_j$$的样本中观察属性值$$x_i$$的先验概率。等价样本大小决定先验概率和观测概率$$\\dfrac{n_c}{n}$$之间的平衡[^2]。\n\n##2 朴素贝叶斯文本分类算法\n现在开始进入本文的主旨部分：如何将贝叶斯分类器应用到文本分类上来。\n\n###2.1文本分类问题\n在文本分类中，假设我们有一个文档d∈X，X是文档向量空间(document space)，和一个固定的类集合C={c1,c2,…,cj}，类别又称为标签。显然，文档向量空间是一个高维度空间。我们把一堆打了标签的文档集合<d,c>作为训练样本，<d,c>∈X×C。例如：  \n<d,c>={Beijing joins the World Trade Organization, China}  \n对于这个只有一句话的文档，我们把它归类到 China，即打上china标签。\n\n我们期望用某种训练算法，训练出一个函数γ，能够将文档映射到某一个类别：\nγ:X→C\n\n这种类型的学习方法叫做有监督学习，因为事先有一个监督者（我们事先给出了一堆打好标签的文档）像个老师一样监督着整个学习过程。\n\n朴素贝叶斯分类器是一种有监督学习，常见有两种模型，多项式模型(multinomial model)和伯努利模型(Bernoulli model)[^4]。\n\n###2.2 多项式模型\n\n####2.2.1 基本原理\n在多项式模型中， 设某文档$$d=(t_1,t_2,…,t_k)$$，tk是该文档中出现过的单词，允许重复，则  \n先验概率$$P(c)=$$ 类c下单词总数/整个训练样本的单词总数  \n类条件概率$$P(t_k \\vert c)=$$(类c下单词tk在各个文档中出现过的次数之和+1)/(类c下单词总数+|V|)\n\nV是训练样本的单词表（即抽取单词，单词出现多次，只算一个），`|V|`则表示训练样本包含多少种单词。在这里，`m=|V|, p=1/|V|`。\n\n$$P(t_k \\vert c)=$$可以看作是单词tk在证明d属于类c上提供了多大的证据，而P(c)则可以认为是类别c在整体上占多大比例(有多大可能性)。\n\n####2.2.2 伪代码[^1]\n``` java\n//C，类别集合，D，用于训练的文本文件集合\nTrainMultiNomialNB(C,D) {\n    // 单词出现多次，只算一个\n    V←ExtractVocabulary(D)\n    // 单词可重复计算\n    N←CountTokens(D)\n    for each c∈C\n        // 计算类别c下的单词总数\n        // N和Nc的计算方法和Introduction to Information Retrieval上的不同，个人认为\n        //该书是错误的，先验概率和类条件概率的计算方法应当保持一致\n        Nc←CountTokensInClass(D,c)\n        prior[c]←Nc/N\n        // 将类别c下的文档连接成一个大字符串\n        textc←ConcatenateTextOfAllDocsInClass(D,c)\n        for each t∈V\n            // 计算类c下单词t的出现次数\n            Tct←CountTokensOfTerm(textc,t)\n        for each t∈V\n            //计算P(t|c)\n            condprob[t][c]← \n    return V,prior,condprob\n}\n\nApplyMultiNomialNB(C,V,prior,condprob,d) {\n    // 将文档d中的单词抽取出来，允许重复，如果单词是全新的，在全局单词表V中都\n    // 没出现过，则忽略掉\n    W←ExtractTokensFromDoc(V,d)\n    for each c∈C\n        score[c]←prior[c]\n        for each t∈W\n            if t∈Vd\n                score[c] *= condprob[t][c]\n    return max(score[c])\n}\n```\n\n####2.2.3 举例\n给定一组分类好了的文本训练数据，如下：  \n\n<table border=\"1\" cellspacing=\"0\" cellpadding=\"0\">\n<tbody>\n<tr>\n<td valign=\"top\" width=\"64\">docId</td>\n<td valign=\"top\" width=\"236\">doc</td>\n<td valign=\"top\" width=\"126\">类别In c=China?</td>\n</tr>\n<tr>\n<td valign=\"top\" width=\"64\">1</td>\n<td valign=\"top\" width=\"236\">Chinese Beijing Chinese</td>\n<td valign=\"top\" width=\"126\">yes</td>\n</tr>\n<tr>\n<td valign=\"top\" width=\"64\">2</td>\n<td valign=\"top\" width=\"236\">Chinese Chinese Shanghai</td>\n<td valign=\"top\" width=\"126\">yes</td>\n</tr>\n<tr>\n<td valign=\"top\" width=\"64\">3</td>\n<td valign=\"top\" width=\"236\">Chinese Macao</td>\n<td valign=\"top\" width=\"126\">yes</td>\n</tr>\n<tr>\n<td valign=\"top\" width=\"64\">4</td>\n<td valign=\"top\" width=\"236\">Tokyo Japan Chinese</td>\n<td valign=\"top\" width=\"126\">no</td>\n</tr>\n</tbody>\n</table>\n\n给定一个新样本\n> Chinese Chinese Chinese Tokyo Japan\n\n对其进行分类。该文本用属性向量表示为`d=(Chinese, Chinese, Chinese, Tokyo, Japan)`，类别集合为`Y={yes, no}`。\n\n类yes下总共有8个单词，类no下总共有3个单词，训练样本单词总数为11，因此$$P(yes)=\\dfrac{8}{11}, P(no)=\\dfrac{3}{11}$$。类条件概率计算如下：  \n$$P(Chinese  \\vert  yes)=\\dfrac{5+1}{8+6}=\\dfrac{6}{14}=\\dfrac{3}{7}$$  \n$$P(Japan  \\vert  yes)=P(Tokyo  \\vert  yes)= \\dfrac{0+1}{8+6}=\\dfrac{1}{14}$$  \n$$P(Chinese \\vert no)=\\dfrac{1+1}{3+6}=\\dfrac{2}{9}$$  \n$$P(Japan \\vert no)=P(Tokyo \\vert  no) =\\dfrac{1+1}{3+6}=\\dfrac{2}{9}$$  \n分母中的8，是指yes类别下textc的长度，也即训练样本的单词总数，6是指训练样本有Chinese,Beijing,Shanghai, Macao, Tokyo, Japan 共6个单词，3是指no类下共有3个单词。\n\n有了以上类条件概率，开始计算后验概率，  \n$$P(yes  \\vert  d)=\\left(\\dfrac{3}{7}\\right)^3 \\times \\dfrac{1}{14} \\times \\dfrac{1}{14} \\times \\dfrac{8}{11}=\\dfrac{108}{184877} \\approx 0.00058417$$  \n$$P(no  \\vert  d)= \\left(\\dfrac{2}{9}\\right)^3 \\times \\dfrac{2}{9} \\times \\dfrac{2}{9} \\times \\dfrac{3}{11}=\\dfrac{32}{216513} \\approx 0.00014780$$  \n因此，这个文档属于类别china。\n\n###2.3 伯努利模型\n\n####2.3.1 基本原理\n$$P(c)=$$ 类c下文件总数/整个训练样本的文件总数  \n$$P(t_k \\vert c)=$$(类c下包含单词tk的文件数+1)/(类c下单词总数+2)  \n在这里，$$m=2, p=\\dfrac{1}{2}$$。\n\n后验概率的计算，也有点变化，见下面的伪代码。\n\n####2.3.2 伪代码\n``` java\n//C，类别集合，D，用于训练的文本文件集合\nTrainBernoulliNB(C, D) {\n    // 单词出现多次，只算一个\nV←ExtractVocabulary(D)\n    // 计算文件总数\n    N←CountDocs(D)\n    for each c∈C\n        // 计算类别c下的文件总数\n        Nc←CountDocsInClass(D,c)\n        prior[c]←Nc/N\n        for each t∈V\n            // 计算类c下包含单词t的文件数\n            Nct←CountDocsInClassContainingTerm(D,c,t)\n            //计算P(t|c)\n            condprob[t][c]←(Nct+1)/(Nct+2)\n    return V,prior,condprob\n}\n\nApplyBernoulliNB(C,V,prior,condprob,d) {\n    // 将文档d中单词表抽取出来，如果单词是全新的，在全局单词表V中都没出现过，\n    // 则舍弃\n    Vd←ExtractTermsFromDoc(V,d)\n    for each c∈C\n        score[c]←prior[c]\n        for each t∈V\n            if t∈Vd\n                score[c] *= condprob[t][c]\n            else\n                score[c] *= (1-condprob[t][c])\n    return max(score[c])\n}\n```\n\n####2.3.3 举例\n还是使用前面例子中的数据，不过模型换成了使用伯努利模型。\n\n类yes下总共有3个文件，类no下有1个文件，训练样本文件总数为11，因此$$P(yes)=\\dfrac{3}{4}, P(Chinese  \\vert  yes)=\\dfrac{3+1}{3+2}=\\dfrac{4}{5}$$  \n$$P(Japan  \\vert  yes)=P(Tokyo  \\vert  yes)=\\dfrac{0+1}{3+2}=\\dfrac{1}{5}$$  \n$$P(Beijing  \\vert  yes)= P(Macao \\vert yes)= P(Shanghai  \\vert yes)=\\dfrac{1+1}{3+2}=\\dfrac{2}{5}$$  \n$$P(Chinese \\vert no)=\\dfrac{1+1}{1+2}=\\dfrac{2}{3}$$  \n$$P(Japan \\vert no)=P(Tokyo \\vert  no) =\\dfrac{1+1}{1+2}=\\dfrac{2}{3}$$  \n$$P(Beijing \\vert  no)= P(Macao \\vert  no)= P(Shanghai  \\vert  no)=\\dfrac{0+1}{1+2}=\\dfrac{1}{3}$$  \n\n有了以上类条件概率，开始计算后验概率，  \n$$\n\\begin{aligned}\nP(yes  \\vert  d)&=P(yes) \\times P(Chinese \\vert yes) \\times P(Japan \\vert yes) \\times P(Tokyo \\vert yes) \\newline\n&\\times (1-P(Beijing \\vert yes)) \\times (1-P(Shanghai \\vert yes))\\newline\n&\\times (1-P(Macao \\vert yes)) \\newline\n&=\\dfrac{3}{4} \\times \\dfrac{4}{5} \\times \\dfrac{1}{5} \\times \\dfrac{1}{5} \\times (1-\\dfrac{2}{5} \\times (1-\\dfrac{2}{5}) \\times (1-\\dfrac{2}{5})=\\dfrac{81}{15625} \\approx 0.005\n\\end{aligned}\n$$\n$$P(no   \\vert   d)= \\dfrac{1}{4} \\times \\dfrac{2}{3} \\times \\dfrac{2}{5} \\times \\dfrac{2}{5} \\times (1-\\dfrac{1}{3}) \\times (1-\\dfrac{1}{3}) \\times (1-\\dfrac{1}{3})=\\dfrac{16}{729} \\approx 0.022$$  \n因此，这个文档不属于类别china。\n\n###2.4 两个模型的区别\n二者的计算粒度不一样，多项式模型以单词为粒度，伯努利模型以文件为粒度，因此二者的先验概率和类条件概率的计算方法都不同。\n\n计算后验概率时，对于一个文档d，多项式模型中，只有在d中出现过的单词，才会参与后验概率计算，伯努利模型中，没有在d中出现，但是在全局单词表中出现的单词，也会参与计算，不过是作为“反方”参与的。\n\n##3 代码详解\n本文附带了一个eclipse工程，有完整的源代码，以及一个微型文本训练库。\n\nChineseSpliter用于中文分词，StopWordsHandler用于判断一个单词是否是停止词，ClassifyResult用于保存结果，IntermediateData用于预处理文本语料库，TrainnedModel用于保存训练后得到的数据，NaiveBayesClassifier是基础类，包含了贝叶斯分类器的主要代码，MultiNomialNB是多项式模型，类似的，BernoulliNB是伯努利模型，二者都继承自NaiveBayesClassifier，都只重写了父类的计算先验概率，类条件概率和后验概率这3个函数。\n\n###3.1 中文分词\n中文分词不是本文的重点，这里我们直接使用第三方工具，本源码使用的是[极易中文分词组件](http://www.jesoft.cn/)，你还可以使用[MMSEG](http://chtsai.org/)，中科院的[ICTCLAS](http://ictclas.org/)等等。\n\n``` java\n/**\n     * 对给定的文本进行中文分词.\n     * \n     * @param text\n     *            给定的文本\n     * @param splitToken\n     *            用于分割的标记,如\"|\"\n     * @return 分词完毕的文本\n     */\n    public String split(final String text, final String splitToken) {\n        String result = null;\n        \n        try {\n            result = analyzer.segment(text, splitToken);\n        } catch (IOException e) {\n            e.printStackTrace();\n        }\n        return result;\n}\n```\n\n###3.2 停止词处理\n停止词(Stop Word)是指那些无意义的字或词，如“的”、“在”等。去掉文档中的停止词也是必须的一项工作,这里简单的定义了一些常见的停止词，并根据这些常用停止词在分词时进行判断。\n\n``` java\n/** 常用停用词. */\n    private static String[] stopWordsList = {\n            // 来自 c:\\Windows\\System32\\NOISE.CHS\n            \"的\", \"一\", \"不\", \"在\", \"人\", \"有\", \"是\", \"为\", \"以\", \"于\", \"上\", \"他\", \"而\",\n            \"后\", \"之\", \"来\", \"及\", \"了\", \"因\", \"下\", \"可\", \"到\", \"由\", \"这\", \"与\", \"也\",\n            \"此\", \"但\", \"并\", \"个\", \"其\", \"已\", \"无\", \"小\", \"我\", \"们\", \"起\", \"最\", \"再\",\n            \"今\", \"去\", \"好\", \"只\", \"又\", \"或\", \"很\", \"亦\", \"某\", \"把\", \"那\", \"你\", \"乃\",\n            \"它\",\n            // 来自网络\n            \"要\", \"将\", \"应\", \"位\", \"新\", \"两\", \"中\", \"更\", \"我们\", \"自己\", \"没有\", \"“\", \"”\",\n            \"，\", \"（\", \"）\", \"\" };\n\n    /**\n     * 判断一个词是否是停止词.\n     * \n     * @param word\n     *            要判断的词\n     * @return 是停止词，返回true，否则返回false\n     */\n    public static boolean isStopWord(final String word) {\n        for (int i = 0; i < stopWordsList.length; ++i) {\n            if (word.equalsIgnoreCase(stopWordsList[i])) {\n                return true;\n            }\n        }\n        return false;\n    }\n```\n\n###3.3 预处理数据\n我们这里使用[搜狗的文本分类语料库](http://www.sogou.com/labs/dl/c.html)作为训练样本，把SogouC.reduced.20061102.tar.gz解压到D盘，目录结构为\n\n``` bash\nD:\\Reduced\n         |-- C000008\n         |-- C000010\n         |-- C000013\n         |-- C000014\n         |-- C000016\n         |-- C000020\n         |-- C000022\n         |-- C000023\n         |-- C000024\n```\nIntermediateData.java主要用于处理文本数据，将所需要的信息计算好，存放到数据库文件中。\n\n中间数据文件主要保存了如下信息，\n\n``` java\n/** 单词X在类别C下出现的总数. */\n\tpublic HashMap[] filesOfXC;\n\t/** 给定分类下的文件数目. */\n    public int[] filesOfC;\n    /** 根目录下的文件总数. */\n    public int files;\n    \n\t/** 单词X在类别C下出现的总数 */\n\tpublic HashMap[] tokensOfXC;\n    /** 类别C下所有单词的总数. */\n    public int[] tokensOfC;\n    /** 整个语料库中单词的总数. */\n    public int tokens;\n    /** 整个训练语料所出现的单词. */\n    public HashSet<String> vocabulary;\n```\n我们使用命令\n\n``` bash\nIntermediateData d:\\Reduced\\ gbk d:\\reduced.db\n```\n将文本训练库的信息计算好，保存到中间文件中。以后的阶段，我们都不再需要文本语料库了，只需要reduced.db。\n\n\n###3.3 训练\n基本的框架代码都在NaiveBayesClassifier中，MultiNomialNB和BernoulliNB都只是重新实现(override)了这三个函数。\n\n``` java\n/** 计算先验概率P(c). */\n    protected void calculatePc() {\n    }\n    \n    /** 计算类条件概率P(x|c). */\n    protected void calculatePxc() {\n    }\n    \n    \n    /**\n     * 计算文本属性向量X在类Cj下的后验概率P(Cj|X).\n     * \n     * @param x\n     *            文本属性向量\n     * @param cj\n     *            给定的类别\n     * @return 后验概率\n     */\n    protected double calcProd(final String[] x, final int cj) {\n        return 0;\n    }\n```\n\n训练函数如下：\n\n```\npublic final void train(String intermediateData, String modelFile) {\n    \t// 加载中间数据文件\n    \tloadData(intermediateData);\n    \t\n    \tmodel = new TrainnedModel(db.classifications.length);\n    \t\n    \tmodel.classifications = db.classifications;\n    \tmodel.vocabulary = db.vocabulary;\n    \t// 开始训练\n    \tcalculatePc();\n    \tcalculatePxc();\n    \tdb = null;\n    \t\n    \ttry {\n    \t\t// 用序列化，将训练得到的结果存放到模型文件中\n            ObjectOutputStream out = new ObjectOutputStream(\n                    new FileOutputStream(modelFile));\n            out.writeObject(model);\n            out.close();\n        } catch (IOException e) {\n            e.printStackTrace();\n        }\n}\n```\n我们使用命令：\n\n``` bash\nMultiNomialNB –t d:\\reduced.db d:\\reduced.mdl\n```\n开始训练，得到的模型文件保存在reduced.mdl中。\n\n###3.4 分类\n有了模型文件，就可以用它来进行分类了。\n\n可以使用命令\n\n``` bash\nMultiNomialNB d:\\reduced.mdl d:\\temp.txt gbk\n```\n对文本文件temp.txt进行分类。\n\n还可以将当初训练出这个模型文件的文本库，进行分类，看看正确率有多少，即“吃自己的狗食”，命令行如下\n\n``` bash\nMultiNomialNB -r d:\\reduced\\ gbk d:\\reduced.mdl\n```\n\n分类函数如下：\n\n``` java\n/**\n * 对给定的文本进行分类.\n * \n * @param text\n *            给定的文本\n * @return 分类结果\n */\npublic final String classify(final String text) {\n    String[] terms = null;\n    // 中文分词处理(分词后结果可能还包含有停用词）\nterms = textSpliter.split(text, \" \").split(\" \");\n    // 去掉停用词，以免影响分类\n    terms = ChineseSpliter.dropStopWords(terms); \n        \ndouble probility = 0.0;\n    // 分类结果\n    List<ClassifyResult> crs = new ArrayList<ClassifyResult>(); \n    for (int i = 0; i < model.classifications.length; i++) {\n        // 计算给定的文本属性向量terms在给定的分类Ci中的分类条件概率\n        probility = calcProd(terms, i);\n        // 保存分类结果\n        ClassifyResult cr = new ClassifyResult();\n         cr.classification = model.classifications[i]; // 分类\n        cr.probility = probility; // 关键字在分类的条件概率\n        System.out.println(\"In process....\");\n        System.out.println(model.classifications[i] + \"：\" + probility);\n        crs.add(cr);\n    }\n        \n    // 找出最大的元素\n    ClassifyResult maxElem = (ClassifyResult) java.util.Collections.max(\n            crs, new Comparator() {\n                public int compare(final Object o1, final Object o2) {\n                    final ClassifyResult m1 = (ClassifyResult) o1;\n                    final ClassifyResult m2 = (ClassifyResult) o2;\n                    final double ret = m1.probility - m2.probility;\n                    if (ret < 0) {\n                        return -1;\n                    } else {\n                        return 1;\n                    }\n                }\n            });\n\n    return maxElem.classification;\n}\n```\n测试正确率的函数getCorrectRate()，核心代码就是对每个文本文件调用classify()，将得到的类别和原始的类别比较，经过统计后就可以得到百分比。\n\n更多细节请读者阅读[源代码](http://yanjiuyanjiu-wordpress.stor.sinaapp.com/uploads/2010/05/NaiveBayesClassifier.zip)。\n\n##参考文献\n\n[^1]: Christopher D. Manning, Prabhakar Raghavan, Hinrich Schütze, [Introduction to Information Retrieval](http://nlp.stanford.edu/IR-book/), Cambridge University Press, 2008, chapter 13, Text classification and Naive Bayes.\n\n[^2]: Pang-Ning Tan, Michael Steinbach, Vipin Kumar, 《[数据挖掘导论](http://book.douban.com/subject/1786120/)》，北京：人民邮电出版社，2007，第140~145页。\n\n[^3]: 石志伟, 吴功宜, “[基于朴素贝叶斯分类器的文本分类算法](http://d.wanfangdata.com.cn/Conference_5615512.aspx)”, 第一届全国信息检索与内容安全学术会议，2004\n\n[^4]: 洞庭散人，“[基于朴素贝叶斯分类器的文本分类算法（上）](http://www.cnblogs.com/phinecos/archive/2008/10/21/1315948.html)”，“[基于朴素贝叶斯分类器的文本分类算法（下）](http://www.cnblogs.com/phinecos/archive/2008/10/21/1316044.html)”，2008\n\n[^5]: DL88250, “[朴素贝叶斯中文文本分类器的研究与实现（1）](http://blog.csdn.net/DL88250/archive/2008/02/20/2108164.aspx)”，“[朴素贝叶斯中文文本分类器的研究与实现（2）](http://blog.csdn.net/DL88250/archive/2008/03/27/2224126.aspx)”，2008\n","source":"_posts/2010-05-28-text-classification-algorithm-based-on-naive-bayes.md","raw":"---\nlayout: post\ntitle: \"基于朴素贝叶斯的文本分类算法\"\ndate: 2010-05-28 17:15\ncomments: true\ncategories: \"Machine-Learning\"\n---\n作者: 灵魂机器  \n新浪博客：[www.weibo.com/soulmachine](www.weibo.com/soulmachine)  \n作者博客：[www.yanjiuyanjiu.com](www.yanjiuyanjiu.com)\n\n**摘要**：常用的文本分类方法有支持向量机、K-近邻算法和朴素贝叶斯。其中朴素贝叶斯具有容易实现，运行速度快的特点，被广泛使用。本文详细介绍了朴素贝叶斯的基本原理，讨论了两种常见模型：多项式模型（MM）和伯努利模型（BM），实现了可运行的代码，并进行了一些数据测试。\n\n**关键字**：朴素贝叶斯；文本分类\n\n**Text Classification Algorithm Based on Naive Bayes**  \n**Author**: soulmachine  \n**Email**：soulmachine@gmail.com  \n**Blog**：[www.yanjiuyanjiu.com](www.yanjiuyanjiu.com)\n\n**Abstract**:Usually there are three methods for text classification: SVM、KNN and Naïve Bayes. Naïve Bayes is easy to implement and fast, so it is widely used. This article introduced the theory of Naïve Bayes and discussed two popular models: multinomial model(MM) and Bernoulli model(BM) in details, implemented runnable code and performed some data tests.\n\n**Keywords**: naïve bayes; text classification\n\n##1 贝叶斯原理\n\n###1.1 贝叶斯公式\n\n设A、B是两个事件，且P(A)>0，称 $$P(Y \\vert X)=\\dfrac {P(XY)}{P(X)}$$ 为事件A发生的条件下事件B发生的**条件概率**。\n\n**乘法公式** $$P(XYZ)=P(Z \\vert XY)P(Y \\vert X)P(X)$$  \n**全概率公式**  $$P(X)=P(X \\vert Y_1)+ P(X \\vert Y_2)+…+ P(X \\vert Y_n)$$  \n**贝叶斯公式**  $$P(Y_i \\vert X)=\\dfrac{P(XY_i)}{P(X)}=\\dfrac{P(X \\vert Y_i)P(Y_i)}{P(X)}=\\dfrac{P(X \\vert Y_i)P(Y_i)}{\\sum\\limits _{j=1} ^{n} P(X \\vert Y_j)}$$  \n\n在此处，贝叶斯公式，我们要用到的是 $$P(Y_i \\vert X)=\\dfrac{P(X \\vert Y_i)P(Y_i)}{P(X)}$$\n\n以上公式，请读者参考[《概率论与数理统计（第五版）》](http://book.douban.com/subject/1231189/)的1.4节“条件概率”（这里将原书中的A换成了X，B换成了Y），获得更深的理解。\n\n<!-- more -->\n\n###1.2 贝叶斯定理在分类中的应用\n在分类（classification）问题中，常常需要把一个事物分到某个类别。一个事物具有很多属性，把它的众多属性看做一个向量，即$$x=(x_1,x_2,x_3,…,x_n)$$，用x这个向量来代表这个事物。类别也是有很多种，用集合$$Y={y_1,y_2,…y_m}$$表示。如果x属于$$y_1$$类别，就可以给x打上$$y_1$$标签，意思是说x属于$$y_1$$类别。这就是所谓的**分类(Classification)**。\n\nx的集合记为X，称为属性集。一般X和Y的关系是不确定的，你只能在某种程度上说x有多大可能性属于类$$y_1$$，比如说x有80%的可能性属于类$$y_1$$，这时可以把X和Y看做是随机变量，$$P(Y \\vert X)$$称为Y的**后验概率**（posterior probability），与之相对的，P(Y)称为Y的**先验概率**（prior probability）[^2]。\n\n在训练阶段，我们要根据从训练数据中收集的信息，**对X和Y的每一种组合学习后验概率$$P(Y \\vert X)$$。**分类时，来了一个实例x，在刚才训练得到的一堆后验概率中找出所有的$$P(Y \\vert x)$$， 其中最大的那个y，即为x所属分类。根据贝叶斯公式，后验概率为$$P(Y \\vert X)=\\dfrac{P(X \\vert Y)P(Y)}{P(X)}$$\n \n在比较不同Y值的后验概率时，分母P(X)总是常数，**因此可以忽略**。先验概率P(Y)可以通过计算训练集中属于每一个类的训练样本所占的比例容易地估计。\n\n我们来举个简单的例子，让读者对上述思路有个形象的认识[^3]。  \n考虑一个医疗诊断问题，有两种可能的假设：（1）病人有癌症。（2）病人无癌症。样本数据来自某化验测试，它也有两种可能的结果：阳性和阴性。假设我们已经有先验知识：在所有人口中只有0.008的人患病。此外，化验测试对有病的患者有98%的可能返回阳性结果，对无病患者有97%的可能返回阴性结果。\n\n上面的数据可以用以下概率式子表示：  \nP(cancer)=0.008,P(无cancer)=0.992  \nP(阳性|cancer)=0.98,P(阴性|cancer)=0.02  \nP(阳性|无cancer)=0.03，P(阴性|无cancer)=0.97  \n假设现在有一个新病人，化验测试返回阳性，是否将病人断定为有癌症呢？\n\n在这里，Y={cancer，无cancer}，共两个类别，这个新病人是一个样本，他有一个属性阳性，可以令x=(阳性)。我们可以来计算各个类别的后验概率：  \nP(cancer | 阳性) = P(阳性 | cancer)p(cancer)=0.98\\* 0.008 = 0.0078  \nP(无cancer | 阳性) =P(阳性 | 无cancer)\\* p(无cancer)=0.03\\* 0.992 = 0.0298   \n因此，应该判断为无癌症。\n\n在这个例子中，类条件概率，P(cancer|阳性)和P(无cancer|阳性)直接告诉了我们。\n\n一般地，对**类条件概率$$P(X \\vert Y)$$**的估计，有朴素贝叶斯分类器和贝叶斯信念网络两种方法，这里介绍朴素贝叶斯分类器。\n\n###1.3 朴素贝叶斯分类器\n**1、条件独立性**  \n给定类标号y，朴素贝叶斯分类器在估计类条件概率时假设属性之间条件独立。条件独立假设可以形式化的表达如下：  \n$$\n\\prod\\limits_{i=1}^{n} P(x_i  \\vert Y=y)\n$$\n其中每个训练样本可用一个属性向量$$X=(x_1,x_2,x_3,…,x_n)$$表示，各个属性之间条件独立。\n\n比如，对于一篇文章，\n \n> Good good study,Day day up.\n\n可以用一个文本特征向量来表示，`x=(Good, good, study, Day, day , up)`。一般各个词语之间肯定不是相互独立的，有一定的上下文联系。但在朴素贝叶斯文本分类时，我们假设个单词之间没有联系，可以用一个文本特征向量来表示这篇文章，这就是“朴素”的来历。\n\n**2、朴素贝叶斯如何工作**  \n**有了条件独立假设，就不必计算X和Y的每一种组合的类条件概率**，只需对给定的Y，计算每个$$x_i$$的条件概率。后一种方法更实用，因为它不需要很大的训练集就能获得较好的概率估计。\n\n**3、估计分类属性的条件概率**  \n$$P(x_i \\vert Y=y)$$怎么计算呢？它一般根据类别y下包含属性$$x_i$$的实例的比例来估计。以文本分类为例，xi表示一个单词，$$P(x_i \\vert Y=y)=$$包含该类别下包含单词的xi的文章总数/ 该类别下的文章总数。\n\n**4、贝叶斯分类器举例**\n假设给定了如下训练样本数据，我们学习的目标是根据给定的天气状况判断你对PlayTennis这个请求的回答是Yes还是No。\n\n<table border=\"1\" cellspacing=\"0\" cellpadding=\"0\">\n<tbody>\n<tr>\n<td valign=\"top\" width=\"95\">Day</td>\n<td valign=\"top\" width=\"95\">Outlook</td>\n<td valign=\"top\" width=\"95\">Temperature</td>\n<td valign=\"top\" width=\"95\">Humidity</td>\n<td valign=\"top\" width=\"95\">Wind</td>\n<td valign=\"top\" width=\"95\">PlayTennis</td>\n</tr>\n<tr>\n<td valign=\"top\" width=\"95\">D1</td>\n<td valign=\"top\" width=\"95\">Sunny</td>\n<td valign=\"top\" width=\"95\">Hot</td>\n<td valign=\"top\" width=\"95\">High</td>\n<td valign=\"top\" width=\"95\">Weak</td>\n<td valign=\"top\" width=\"95\">No</td>\n</tr>\n<tr>\n<td valign=\"top\" width=\"95\">D2</td>\n<td valign=\"top\" width=\"95\">Sunny</td>\n<td valign=\"top\" width=\"95\">Hot</td>\n<td valign=\"top\" width=\"95\">High</td>\n<td valign=\"top\" width=\"95\">Strong</td>\n<td valign=\"top\" width=\"95\">No</td>\n</tr>\n<tr>\n<td valign=\"top\" width=\"95\">D3</td>\n<td valign=\"top\" width=\"95\">Overcast</td>\n<td valign=\"top\" width=\"95\">Hot</td>\n<td valign=\"top\" width=\"95\">High</td>\n<td valign=\"top\" width=\"95\">Weak</td>\n<td valign=\"top\" width=\"95\">Yes</td>\n</tr>\n<tr>\n<td valign=\"top\" width=\"95\">D4</td>\n<td valign=\"top\" width=\"95\">Rain</td>\n<td valign=\"top\" width=\"95\">Mild</td>\n<td valign=\"top\" width=\"95\">High</td>\n<td valign=\"top\" width=\"95\">Weak</td>\n<td valign=\"top\" width=\"95\">Yes</td>\n</tr>\n<tr>\n<td valign=\"top\" width=\"95\">D5</td>\n<td valign=\"top\" width=\"95\">Rain</td>\n<td valign=\"top\" width=\"95\">Cool</td>\n<td valign=\"top\" width=\"95\">Normal</td>\n<td valign=\"top\" width=\"95\">Weak</td>\n<td valign=\"top\" width=\"95\">Yes</td>\n</tr>\n<tr>\n<td valign=\"top\" width=\"95\">D6</td>\n<td valign=\"top\" width=\"95\">Rain</td>\n<td valign=\"top\" width=\"95\">Cool</td>\n<td valign=\"top\" width=\"95\">Normal</td>\n<td valign=\"top\" width=\"95\">Strong</td>\n<td valign=\"top\" width=\"95\">No</td>\n</tr>\n<tr>\n<td valign=\"top\" width=\"95\">D7</td>\n<td valign=\"top\" width=\"95\">Overcast</td>\n<td valign=\"top\" width=\"95\">Cool</td>\n<td valign=\"top\" width=\"95\">Normal</td>\n<td valign=\"top\" width=\"95\">Strong</td>\n<td valign=\"top\" width=\"95\">Yes</td>\n</tr>\n<tr>\n<td valign=\"top\" width=\"95\">D8</td>\n<td valign=\"top\" width=\"95\">Sunny</td>\n<td valign=\"top\" width=\"95\">Mild</td>\n<td valign=\"top\" width=\"95\">High</td>\n<td valign=\"top\" width=\"95\">Weak</td>\n<td valign=\"top\" width=\"95\">No</td>\n</tr>\n<tr>\n<td valign=\"top\" width=\"95\">D9</td>\n<td valign=\"top\" width=\"95\">Sunny</td>\n<td valign=\"top\" width=\"95\">Cool</td>\n<td valign=\"top\" width=\"95\">Normal</td>\n<td valign=\"top\" width=\"95\">Weak</td>\n<td valign=\"top\" width=\"95\">Yes</td>\n</tr>\n<tr>\n<td valign=\"top\" width=\"95\">D10</td>\n<td valign=\"top\" width=\"95\">Rain</td>\n<td valign=\"top\" width=\"95\">Mild</td>\n<td valign=\"top\" width=\"95\">Normal</td>\n<td valign=\"top\" width=\"95\">Weak</td>\n<td valign=\"top\" width=\"95\">Yes</td>\n</tr>\n<tr>\n<td valign=\"top\" width=\"95\">D11</td>\n<td valign=\"top\" width=\"95\">Sunny</td>\n<td valign=\"top\" width=\"95\">Mild</td>\n<td valign=\"top\" width=\"95\">Normal</td>\n<td valign=\"top\" width=\"95\">Strong</td>\n<td valign=\"top\" width=\"95\">Yes</td>\n</tr>\n<tr>\n<td valign=\"top\" width=\"95\">D12</td>\n<td valign=\"top\" width=\"95\">Overcast</td>\n<td valign=\"top\" width=\"95\">Mild</td>\n<td valign=\"top\" width=\"95\">High</td>\n<td valign=\"top\" width=\"95\">Strong</td>\n<td valign=\"top\" width=\"95\">Yes</td>\n</tr>\n<tr>\n<td valign=\"top\" width=\"95\">D13</td>\n<td valign=\"top\" width=\"95\">Overcast</td>\n<td valign=\"top\" width=\"95\">Hot</td>\n<td valign=\"top\" width=\"95\">Normal</td>\n<td valign=\"top\" width=\"95\">Weak</td>\n<td valign=\"top\" width=\"95\">Yes</td>\n</tr>\n<tr>\n<td valign=\"top\" width=\"95\">D14</td>\n<td valign=\"top\" width=\"95\">Rain</td>\n<td valign=\"top\" width=\"95\">Mild</td>\n<td valign=\"top\" width=\"95\">High</td>\n<td valign=\"top\" width=\"95\">Strong</td>\n<td valign=\"top\" width=\"95\">No</td>\n</tr>\n</tbody>\n</table> \n可以看到这里样本数据集提供了14个训练样本，我们将使用此表的数据，并结合朴素贝叶斯分类器来分类下面的新实例：  \nx = (Outlook = Sunny,Temprature = Cool,Humidity = High,Wind = Strong)\n\n在这个例子中，属性向量X=(Outlook, Temperature, Humidity, Wind)，类集合Y={Yes, No}。我们需要利用训练数据计算后验概率$$P(Yes \\vert x)$$和$$P(No \\vert x)$$，如果$$P(Yes \\vert x)>P(No \\vert x)$$，那么新实例分类为Yes，否则为No。\n\n为了计算后验概率，我们需要计算先验概率P(Yes)和P(No)和类条件概率$$P(x_i \\vert Y)$$。\n\n因为有9个样本属于Yes，5个样本属于No，所以$$P(Yes)=\\dfrac{9}{14}$$, $$P(No)=\\dfrac{5}{14}$$。类条件概率计算如下：  \n$$P(Outlook = Sunny \\vert Yes)=\\dfrac{2}{9}　　　P(Outlook = Sunny \\vert No)=\\dfrac{3}{5}$$  \n$$P(Temprature = Cool  \\vert Yes) =\\dfrac{3}{9}　　　P(Temprature = Cool  \\vert No) =\\dfrac{1}{5}$$  \n$$P(Humidity = High  \\vert Yes) =\\dfrac{3}{9}　　　P(Humidity = High  \\vert No) =\\dfrac{4}{5}$$\n$$P(Wind = Strong  \\vert Yes) =\\dfrac{3}{9}　　　P(Wind = Strong  \\vert No) =\\dfrac{3}{5}$$    \n\n后验概率计算如下：\n$$\n\\begin{aligned}\nP(Yes  \\vert  x) & = P(Outlook = Sunny \\vert Yes) \\times P(Temprature = Cool  \\vert Yes) \\newline\n& \\times P(Humidity = High  \\vert Yes) \\times P(Wind = Strong  \\vert Yes) \\times P(Yes) \\newline\n& =\\dfrac{2}{9} \\times \\dfrac{3}{9} \\times \\dfrac{3}{9} \\times \\dfrac{3}{9} \\times \\dfrac{3}{9} \\times \\dfrac{9}{14}=\\dfrac{2}{243}=\\dfrac{9}{1701} \\approx 0.00529\n\\end{aligned}\n$$\n$$\n\\begin{aligned}\nP(No  \\vert  x)&= P(Outlook = Sunny \\vert No) \\times P(Temprature = Cool  \\vert No) \\newline\n& \\times P(Humidity = High  \\vert No) \\times P(Wind = Strong  \\vert No) \\times P(No) \\newline\n& =\\dfrac{3}{5}\\times \\dfrac{1}{5} \\times \\dfrac{4}{5} \\times \\dfrac{3}{5} \\times  \\dfrac{5}{14}=\\dfrac{18}{875} \\approx 0.02057\n\\end{aligned}\n$$\n通过计算得出$$P(No  \\vert  x)> P(Yes  \\vert  x)$$，所以该样本分类为No[^3]。\n\n**5、条件概率的m估计**  \n假设有来了一个新样本 $$x_1= (Outlook = Cloudy,Temprature = Cool,Humidity = High,Wind = Strong)$$，要求对其分类。我们来开始计算，  \n$$P(Outlook = Cloudy \\vert Yes)=\\dfrac{0}{9}=0  P(Outlook = Cloudy  \\vert No)=\\dfrac{0}{5}=0$$  \n计算到这里，大家就会意识到，这里出现了一个新的属性值，在训练样本中所没有的。如果有一个属性的类条件概率为0，则整个类的后验概率就等于0，我们可以直接得到后验概率$$P(Yes  \\vert  x_1)= P(No  \\vert  x_1)=0$$，这时二者相等，无法分类。\n\n当训练样本不能覆盖那么多的属性值时，都会出现上述的窘境。简单的使用样本比例来估计类条件概率的方法太脆弱了，尤其是当训练样本少而属性数目又很大时。\n\n解决方法是使用m估计(m-estimate)方法来估计条件概率：\n$$\nP(x_i \\vert y_i)=\\dfrac{n_c+mp}{n+m}\n$$\nn是类$$y_j$$中的样本总数，$$n_c$$是类$$y_j$$中取值$$x_i$$的样本数，m是称为等价样本大小的参数，而p是用户指定的参数。如果没有训练集（即n=0），则$$P(x_i \\vert y_i)=p$$, 因此p可以看作是在类$$y_j$$的样本中观察属性值$$x_i$$的先验概率。等价样本大小决定先验概率和观测概率$$\\dfrac{n_c}{n}$$之间的平衡[^2]。\n\n##2 朴素贝叶斯文本分类算法\n现在开始进入本文的主旨部分：如何将贝叶斯分类器应用到文本分类上来。\n\n###2.1文本分类问题\n在文本分类中，假设我们有一个文档d∈X，X是文档向量空间(document space)，和一个固定的类集合C={c1,c2,…,cj}，类别又称为标签。显然，文档向量空间是一个高维度空间。我们把一堆打了标签的文档集合<d,c>作为训练样本，<d,c>∈X×C。例如：  \n<d,c>={Beijing joins the World Trade Organization, China}  \n对于这个只有一句话的文档，我们把它归类到 China，即打上china标签。\n\n我们期望用某种训练算法，训练出一个函数γ，能够将文档映射到某一个类别：\nγ:X→C\n\n这种类型的学习方法叫做有监督学习，因为事先有一个监督者（我们事先给出了一堆打好标签的文档）像个老师一样监督着整个学习过程。\n\n朴素贝叶斯分类器是一种有监督学习，常见有两种模型，多项式模型(multinomial model)和伯努利模型(Bernoulli model)[^4]。\n\n###2.2 多项式模型\n\n####2.2.1 基本原理\n在多项式模型中， 设某文档$$d=(t_1,t_2,…,t_k)$$，tk是该文档中出现过的单词，允许重复，则  \n先验概率$$P(c)=$$ 类c下单词总数/整个训练样本的单词总数  \n类条件概率$$P(t_k \\vert c)=$$(类c下单词tk在各个文档中出现过的次数之和+1)/(类c下单词总数+|V|)\n\nV是训练样本的单词表（即抽取单词，单词出现多次，只算一个），`|V|`则表示训练样本包含多少种单词。在这里，`m=|V|, p=1/|V|`。\n\n$$P(t_k \\vert c)=$$可以看作是单词tk在证明d属于类c上提供了多大的证据，而P(c)则可以认为是类别c在整体上占多大比例(有多大可能性)。\n\n####2.2.2 伪代码[^1]\n``` java\n//C，类别集合，D，用于训练的文本文件集合\nTrainMultiNomialNB(C,D) {\n    // 单词出现多次，只算一个\n    V←ExtractVocabulary(D)\n    // 单词可重复计算\n    N←CountTokens(D)\n    for each c∈C\n        // 计算类别c下的单词总数\n        // N和Nc的计算方法和Introduction to Information Retrieval上的不同，个人认为\n        //该书是错误的，先验概率和类条件概率的计算方法应当保持一致\n        Nc←CountTokensInClass(D,c)\n        prior[c]←Nc/N\n        // 将类别c下的文档连接成一个大字符串\n        textc←ConcatenateTextOfAllDocsInClass(D,c)\n        for each t∈V\n            // 计算类c下单词t的出现次数\n            Tct←CountTokensOfTerm(textc,t)\n        for each t∈V\n            //计算P(t|c)\n            condprob[t][c]← \n    return V,prior,condprob\n}\n\nApplyMultiNomialNB(C,V,prior,condprob,d) {\n    // 将文档d中的单词抽取出来，允许重复，如果单词是全新的，在全局单词表V中都\n    // 没出现过，则忽略掉\n    W←ExtractTokensFromDoc(V,d)\n    for each c∈C\n        score[c]←prior[c]\n        for each t∈W\n            if t∈Vd\n                score[c] *= condprob[t][c]\n    return max(score[c])\n}\n```\n\n####2.2.3 举例\n给定一组分类好了的文本训练数据，如下：  \n\n<table border=\"1\" cellspacing=\"0\" cellpadding=\"0\">\n<tbody>\n<tr>\n<td valign=\"top\" width=\"64\">docId</td>\n<td valign=\"top\" width=\"236\">doc</td>\n<td valign=\"top\" width=\"126\">类别In c=China?</td>\n</tr>\n<tr>\n<td valign=\"top\" width=\"64\">1</td>\n<td valign=\"top\" width=\"236\">Chinese Beijing Chinese</td>\n<td valign=\"top\" width=\"126\">yes</td>\n</tr>\n<tr>\n<td valign=\"top\" width=\"64\">2</td>\n<td valign=\"top\" width=\"236\">Chinese Chinese Shanghai</td>\n<td valign=\"top\" width=\"126\">yes</td>\n</tr>\n<tr>\n<td valign=\"top\" width=\"64\">3</td>\n<td valign=\"top\" width=\"236\">Chinese Macao</td>\n<td valign=\"top\" width=\"126\">yes</td>\n</tr>\n<tr>\n<td valign=\"top\" width=\"64\">4</td>\n<td valign=\"top\" width=\"236\">Tokyo Japan Chinese</td>\n<td valign=\"top\" width=\"126\">no</td>\n</tr>\n</tbody>\n</table>\n\n给定一个新样本\n> Chinese Chinese Chinese Tokyo Japan\n\n对其进行分类。该文本用属性向量表示为`d=(Chinese, Chinese, Chinese, Tokyo, Japan)`，类别集合为`Y={yes, no}`。\n\n类yes下总共有8个单词，类no下总共有3个单词，训练样本单词总数为11，因此$$P(yes)=\\dfrac{8}{11}, P(no)=\\dfrac{3}{11}$$。类条件概率计算如下：  \n$$P(Chinese  \\vert  yes)=\\dfrac{5+1}{8+6}=\\dfrac{6}{14}=\\dfrac{3}{7}$$  \n$$P(Japan  \\vert  yes)=P(Tokyo  \\vert  yes)= \\dfrac{0+1}{8+6}=\\dfrac{1}{14}$$  \n$$P(Chinese \\vert no)=\\dfrac{1+1}{3+6}=\\dfrac{2}{9}$$  \n$$P(Japan \\vert no)=P(Tokyo \\vert  no) =\\dfrac{1+1}{3+6}=\\dfrac{2}{9}$$  \n分母中的8，是指yes类别下textc的长度，也即训练样本的单词总数，6是指训练样本有Chinese,Beijing,Shanghai, Macao, Tokyo, Japan 共6个单词，3是指no类下共有3个单词。\n\n有了以上类条件概率，开始计算后验概率，  \n$$P(yes  \\vert  d)=\\left(\\dfrac{3}{7}\\right)^3 \\times \\dfrac{1}{14} \\times \\dfrac{1}{14} \\times \\dfrac{8}{11}=\\dfrac{108}{184877} \\approx 0.00058417$$  \n$$P(no  \\vert  d)= \\left(\\dfrac{2}{9}\\right)^3 \\times \\dfrac{2}{9} \\times \\dfrac{2}{9} \\times \\dfrac{3}{11}=\\dfrac{32}{216513} \\approx 0.00014780$$  \n因此，这个文档属于类别china。\n\n###2.3 伯努利模型\n\n####2.3.1 基本原理\n$$P(c)=$$ 类c下文件总数/整个训练样本的文件总数  \n$$P(t_k \\vert c)=$$(类c下包含单词tk的文件数+1)/(类c下单词总数+2)  \n在这里，$$m=2, p=\\dfrac{1}{2}$$。\n\n后验概率的计算，也有点变化，见下面的伪代码。\n\n####2.3.2 伪代码\n``` java\n//C，类别集合，D，用于训练的文本文件集合\nTrainBernoulliNB(C, D) {\n    // 单词出现多次，只算一个\nV←ExtractVocabulary(D)\n    // 计算文件总数\n    N←CountDocs(D)\n    for each c∈C\n        // 计算类别c下的文件总数\n        Nc←CountDocsInClass(D,c)\n        prior[c]←Nc/N\n        for each t∈V\n            // 计算类c下包含单词t的文件数\n            Nct←CountDocsInClassContainingTerm(D,c,t)\n            //计算P(t|c)\n            condprob[t][c]←(Nct+1)/(Nct+2)\n    return V,prior,condprob\n}\n\nApplyBernoulliNB(C,V,prior,condprob,d) {\n    // 将文档d中单词表抽取出来，如果单词是全新的，在全局单词表V中都没出现过，\n    // 则舍弃\n    Vd←ExtractTermsFromDoc(V,d)\n    for each c∈C\n        score[c]←prior[c]\n        for each t∈V\n            if t∈Vd\n                score[c] *= condprob[t][c]\n            else\n                score[c] *= (1-condprob[t][c])\n    return max(score[c])\n}\n```\n\n####2.3.3 举例\n还是使用前面例子中的数据，不过模型换成了使用伯努利模型。\n\n类yes下总共有3个文件，类no下有1个文件，训练样本文件总数为11，因此$$P(yes)=\\dfrac{3}{4}, P(Chinese  \\vert  yes)=\\dfrac{3+1}{3+2}=\\dfrac{4}{5}$$  \n$$P(Japan  \\vert  yes)=P(Tokyo  \\vert  yes)=\\dfrac{0+1}{3+2}=\\dfrac{1}{5}$$  \n$$P(Beijing  \\vert  yes)= P(Macao \\vert yes)= P(Shanghai  \\vert yes)=\\dfrac{1+1}{3+2}=\\dfrac{2}{5}$$  \n$$P(Chinese \\vert no)=\\dfrac{1+1}{1+2}=\\dfrac{2}{3}$$  \n$$P(Japan \\vert no)=P(Tokyo \\vert  no) =\\dfrac{1+1}{1+2}=\\dfrac{2}{3}$$  \n$$P(Beijing \\vert  no)= P(Macao \\vert  no)= P(Shanghai  \\vert  no)=\\dfrac{0+1}{1+2}=\\dfrac{1}{3}$$  \n\n有了以上类条件概率，开始计算后验概率，  \n$$\n\\begin{aligned}\nP(yes  \\vert  d)&=P(yes) \\times P(Chinese \\vert yes) \\times P(Japan \\vert yes) \\times P(Tokyo \\vert yes) \\newline\n&\\times (1-P(Beijing \\vert yes)) \\times (1-P(Shanghai \\vert yes))\\newline\n&\\times (1-P(Macao \\vert yes)) \\newline\n&=\\dfrac{3}{4} \\times \\dfrac{4}{5} \\times \\dfrac{1}{5} \\times \\dfrac{1}{5} \\times (1-\\dfrac{2}{5} \\times (1-\\dfrac{2}{5}) \\times (1-\\dfrac{2}{5})=\\dfrac{81}{15625} \\approx 0.005\n\\end{aligned}\n$$\n$$P(no   \\vert   d)= \\dfrac{1}{4} \\times \\dfrac{2}{3} \\times \\dfrac{2}{5} \\times \\dfrac{2}{5} \\times (1-\\dfrac{1}{3}) \\times (1-\\dfrac{1}{3}) \\times (1-\\dfrac{1}{3})=\\dfrac{16}{729} \\approx 0.022$$  \n因此，这个文档不属于类别china。\n\n###2.4 两个模型的区别\n二者的计算粒度不一样，多项式模型以单词为粒度，伯努利模型以文件为粒度，因此二者的先验概率和类条件概率的计算方法都不同。\n\n计算后验概率时，对于一个文档d，多项式模型中，只有在d中出现过的单词，才会参与后验概率计算，伯努利模型中，没有在d中出现，但是在全局单词表中出现的单词，也会参与计算，不过是作为“反方”参与的。\n\n##3 代码详解\n本文附带了一个eclipse工程，有完整的源代码，以及一个微型文本训练库。\n\nChineseSpliter用于中文分词，StopWordsHandler用于判断一个单词是否是停止词，ClassifyResult用于保存结果，IntermediateData用于预处理文本语料库，TrainnedModel用于保存训练后得到的数据，NaiveBayesClassifier是基础类，包含了贝叶斯分类器的主要代码，MultiNomialNB是多项式模型，类似的，BernoulliNB是伯努利模型，二者都继承自NaiveBayesClassifier，都只重写了父类的计算先验概率，类条件概率和后验概率这3个函数。\n\n###3.1 中文分词\n中文分词不是本文的重点，这里我们直接使用第三方工具，本源码使用的是[极易中文分词组件](http://www.jesoft.cn/)，你还可以使用[MMSEG](http://chtsai.org/)，中科院的[ICTCLAS](http://ictclas.org/)等等。\n\n``` java\n/**\n     * 对给定的文本进行中文分词.\n     * \n     * @param text\n     *            给定的文本\n     * @param splitToken\n     *            用于分割的标记,如\"|\"\n     * @return 分词完毕的文本\n     */\n    public String split(final String text, final String splitToken) {\n        String result = null;\n        \n        try {\n            result = analyzer.segment(text, splitToken);\n        } catch (IOException e) {\n            e.printStackTrace();\n        }\n        return result;\n}\n```\n\n###3.2 停止词处理\n停止词(Stop Word)是指那些无意义的字或词，如“的”、“在”等。去掉文档中的停止词也是必须的一项工作,这里简单的定义了一些常见的停止词，并根据这些常用停止词在分词时进行判断。\n\n``` java\n/** 常用停用词. */\n    private static String[] stopWordsList = {\n            // 来自 c:\\Windows\\System32\\NOISE.CHS\n            \"的\", \"一\", \"不\", \"在\", \"人\", \"有\", \"是\", \"为\", \"以\", \"于\", \"上\", \"他\", \"而\",\n            \"后\", \"之\", \"来\", \"及\", \"了\", \"因\", \"下\", \"可\", \"到\", \"由\", \"这\", \"与\", \"也\",\n            \"此\", \"但\", \"并\", \"个\", \"其\", \"已\", \"无\", \"小\", \"我\", \"们\", \"起\", \"最\", \"再\",\n            \"今\", \"去\", \"好\", \"只\", \"又\", \"或\", \"很\", \"亦\", \"某\", \"把\", \"那\", \"你\", \"乃\",\n            \"它\",\n            // 来自网络\n            \"要\", \"将\", \"应\", \"位\", \"新\", \"两\", \"中\", \"更\", \"我们\", \"自己\", \"没有\", \"“\", \"”\",\n            \"，\", \"（\", \"）\", \"\" };\n\n    /**\n     * 判断一个词是否是停止词.\n     * \n     * @param word\n     *            要判断的词\n     * @return 是停止词，返回true，否则返回false\n     */\n    public static boolean isStopWord(final String word) {\n        for (int i = 0; i < stopWordsList.length; ++i) {\n            if (word.equalsIgnoreCase(stopWordsList[i])) {\n                return true;\n            }\n        }\n        return false;\n    }\n```\n\n###3.3 预处理数据\n我们这里使用[搜狗的文本分类语料库](http://www.sogou.com/labs/dl/c.html)作为训练样本，把SogouC.reduced.20061102.tar.gz解压到D盘，目录结构为\n\n``` bash\nD:\\Reduced\n         |-- C000008\n         |-- C000010\n         |-- C000013\n         |-- C000014\n         |-- C000016\n         |-- C000020\n         |-- C000022\n         |-- C000023\n         |-- C000024\n```\nIntermediateData.java主要用于处理文本数据，将所需要的信息计算好，存放到数据库文件中。\n\n中间数据文件主要保存了如下信息，\n\n``` java\n/** 单词X在类别C下出现的总数. */\n\tpublic HashMap[] filesOfXC;\n\t/** 给定分类下的文件数目. */\n    public int[] filesOfC;\n    /** 根目录下的文件总数. */\n    public int files;\n    \n\t/** 单词X在类别C下出现的总数 */\n\tpublic HashMap[] tokensOfXC;\n    /** 类别C下所有单词的总数. */\n    public int[] tokensOfC;\n    /** 整个语料库中单词的总数. */\n    public int tokens;\n    /** 整个训练语料所出现的单词. */\n    public HashSet<String> vocabulary;\n```\n我们使用命令\n\n``` bash\nIntermediateData d:\\Reduced\\ gbk d:\\reduced.db\n```\n将文本训练库的信息计算好，保存到中间文件中。以后的阶段，我们都不再需要文本语料库了，只需要reduced.db。\n\n\n###3.3 训练\n基本的框架代码都在NaiveBayesClassifier中，MultiNomialNB和BernoulliNB都只是重新实现(override)了这三个函数。\n\n``` java\n/** 计算先验概率P(c). */\n    protected void calculatePc() {\n    }\n    \n    /** 计算类条件概率P(x|c). */\n    protected void calculatePxc() {\n    }\n    \n    \n    /**\n     * 计算文本属性向量X在类Cj下的后验概率P(Cj|X).\n     * \n     * @param x\n     *            文本属性向量\n     * @param cj\n     *            给定的类别\n     * @return 后验概率\n     */\n    protected double calcProd(final String[] x, final int cj) {\n        return 0;\n    }\n```\n\n训练函数如下：\n\n```\npublic final void train(String intermediateData, String modelFile) {\n    \t// 加载中间数据文件\n    \tloadData(intermediateData);\n    \t\n    \tmodel = new TrainnedModel(db.classifications.length);\n    \t\n    \tmodel.classifications = db.classifications;\n    \tmodel.vocabulary = db.vocabulary;\n    \t// 开始训练\n    \tcalculatePc();\n    \tcalculatePxc();\n    \tdb = null;\n    \t\n    \ttry {\n    \t\t// 用序列化，将训练得到的结果存放到模型文件中\n            ObjectOutputStream out = new ObjectOutputStream(\n                    new FileOutputStream(modelFile));\n            out.writeObject(model);\n            out.close();\n        } catch (IOException e) {\n            e.printStackTrace();\n        }\n}\n```\n我们使用命令：\n\n``` bash\nMultiNomialNB –t d:\\reduced.db d:\\reduced.mdl\n```\n开始训练，得到的模型文件保存在reduced.mdl中。\n\n###3.4 分类\n有了模型文件，就可以用它来进行分类了。\n\n可以使用命令\n\n``` bash\nMultiNomialNB d:\\reduced.mdl d:\\temp.txt gbk\n```\n对文本文件temp.txt进行分类。\n\n还可以将当初训练出这个模型文件的文本库，进行分类，看看正确率有多少，即“吃自己的狗食”，命令行如下\n\n``` bash\nMultiNomialNB -r d:\\reduced\\ gbk d:\\reduced.mdl\n```\n\n分类函数如下：\n\n``` java\n/**\n * 对给定的文本进行分类.\n * \n * @param text\n *            给定的文本\n * @return 分类结果\n */\npublic final String classify(final String text) {\n    String[] terms = null;\n    // 中文分词处理(分词后结果可能还包含有停用词）\nterms = textSpliter.split(text, \" \").split(\" \");\n    // 去掉停用词，以免影响分类\n    terms = ChineseSpliter.dropStopWords(terms); \n        \ndouble probility = 0.0;\n    // 分类结果\n    List<ClassifyResult> crs = new ArrayList<ClassifyResult>(); \n    for (int i = 0; i < model.classifications.length; i++) {\n        // 计算给定的文本属性向量terms在给定的分类Ci中的分类条件概率\n        probility = calcProd(terms, i);\n        // 保存分类结果\n        ClassifyResult cr = new ClassifyResult();\n         cr.classification = model.classifications[i]; // 分类\n        cr.probility = probility; // 关键字在分类的条件概率\n        System.out.println(\"In process....\");\n        System.out.println(model.classifications[i] + \"：\" + probility);\n        crs.add(cr);\n    }\n        \n    // 找出最大的元素\n    ClassifyResult maxElem = (ClassifyResult) java.util.Collections.max(\n            crs, new Comparator() {\n                public int compare(final Object o1, final Object o2) {\n                    final ClassifyResult m1 = (ClassifyResult) o1;\n                    final ClassifyResult m2 = (ClassifyResult) o2;\n                    final double ret = m1.probility - m2.probility;\n                    if (ret < 0) {\n                        return -1;\n                    } else {\n                        return 1;\n                    }\n                }\n            });\n\n    return maxElem.classification;\n}\n```\n测试正确率的函数getCorrectRate()，核心代码就是对每个文本文件调用classify()，将得到的类别和原始的类别比较，经过统计后就可以得到百分比。\n\n更多细节请读者阅读[源代码](http://yanjiuyanjiu-wordpress.stor.sinaapp.com/uploads/2010/05/NaiveBayesClassifier.zip)。\n\n##参考文献\n\n[^1]: Christopher D. Manning, Prabhakar Raghavan, Hinrich Schütze, [Introduction to Information Retrieval](http://nlp.stanford.edu/IR-book/), Cambridge University Press, 2008, chapter 13, Text classification and Naive Bayes.\n\n[^2]: Pang-Ning Tan, Michael Steinbach, Vipin Kumar, 《[数据挖掘导论](http://book.douban.com/subject/1786120/)》，北京：人民邮电出版社，2007，第140~145页。\n\n[^3]: 石志伟, 吴功宜, “[基于朴素贝叶斯分类器的文本分类算法](http://d.wanfangdata.com.cn/Conference_5615512.aspx)”, 第一届全国信息检索与内容安全学术会议，2004\n\n[^4]: 洞庭散人，“[基于朴素贝叶斯分类器的文本分类算法（上）](http://www.cnblogs.com/phinecos/archive/2008/10/21/1315948.html)”，“[基于朴素贝叶斯分类器的文本分类算法（下）](http://www.cnblogs.com/phinecos/archive/2008/10/21/1316044.html)”，2008\n\n[^5]: DL88250, “[朴素贝叶斯中文文本分类器的研究与实现（1）](http://blog.csdn.net/DL88250/archive/2008/02/20/2108164.aspx)”，“[朴素贝叶斯中文文本分类器的研究与实现（2）](http://blog.csdn.net/DL88250/archive/2008/03/27/2224126.aspx)”，2008\n","slug":"2010-05-28-text-classification-algorithm-based-on-naive-bayes","published":1,"updated":"2016-08-18T09:21:04.000Z","photos":[],"link":"","_id":"cis07pf26000b01pqunhuxk3z","content":"<p>作者: 灵魂机器<br>新浪博客：<a href=\"www.weibo.com/soulmachine\">www.weibo.com/soulmachine</a><br>作者博客：<a href=\"www.yanjiuyanjiu.com\">www.yanjiuyanjiu.com</a></p>\n<p><strong>摘要</strong>：常用的文本分类方法有支持向量机、K-近邻算法和朴素贝叶斯。其中朴素贝叶斯具有容易实现，运行速度快的特点，被广泛使用。本文详细介绍了朴素贝叶斯的基本原理，讨论了两种常见模型：多项式模型（MM）和伯努利模型（BM），实现了可运行的代码，并进行了一些数据测试。</p>\n<p><strong>关键字</strong>：朴素贝叶斯；文本分类</p>\n<p><strong>Text Classification Algorithm Based on Naive Bayes</strong><br><strong>Author</strong>: soulmachine<br><strong>Email</strong>：soulmachine@gmail.com<br><strong>Blog</strong>：<a href=\"www.yanjiuyanjiu.com\">www.yanjiuyanjiu.com</a></p>\n<p><strong>Abstract</strong>:Usually there are three methods for text classification: SVM、KNN and Naïve Bayes. Naïve Bayes is easy to implement and fast, so it is widely used. This article introduced the theory of Naïve Bayes and discussed two popular models: multinomial model(MM) and Bernoulli model(BM) in details, implemented runnable code and performed some data tests.</p>\n<p><strong>Keywords</strong>: naïve bayes; text classification</p>\n<p>##1 贝叶斯原理</p>\n<p>###1.1 贝叶斯公式</p>\n<p>设A、B是两个事件，且P(A)&gt;0，称 $$P(Y \\vert X)=\\dfrac {P(XY)}{P(X)}$$ 为事件A发生的条件下事件B发生的<strong>条件概率</strong>。</p>\n<p><strong>乘法公式</strong> $$P(XYZ)=P(Z \\vert XY)P(Y \\vert X)P(X)$$<br><strong>全概率公式</strong>  $$P(X)=P(X \\vert Y_1)+ P(X \\vert Y_2)+…+ P(X \\vert Y_n)$$<br><strong>贝叶斯公式</strong>  $$P(Y_i \\vert X)=\\dfrac{P(XY_i)}{P(X)}=\\dfrac{P(X \\vert Y_i)P(Y_i)}{P(X)}=\\dfrac{P(X \\vert Y_i)P(Y<em>i)}{\\sum\\limits </em>{j=1} ^{n} P(X \\vert Y_j)}$$  </p>\n<p>在此处，贝叶斯公式，我们要用到的是 $$P(Y_i \\vert X)=\\dfrac{P(X \\vert Y_i)P(Y_i)}{P(X)}$$</p>\n<p>以上公式，请读者参考<a href=\"http://book.douban.com/subject/1231189/\" target=\"_blank\" rel=\"external\">《概率论与数理统计（第五版）》</a>的1.4节“条件概率”（这里将原书中的A换成了X，B换成了Y），获得更深的理解。</p>\n<a id=\"more\"></a>\n<p>###1.2 贝叶斯定理在分类中的应用<br>在分类（classification）问题中，常常需要把一个事物分到某个类别。一个事物具有很多属性，把它的众多属性看做一个向量，即$$x=(x_1,x_2,x_3,…,x_n)$$，用x这个向量来代表这个事物。类别也是有很多种，用集合$$Y={y_1,y_2,…y_m}$$表示。如果x属于$$y_1$$类别，就可以给x打上$$y_1$$标签，意思是说x属于$$y_1$$类别。这就是所谓的<strong>分类(Classification)</strong>。</p>\n<p>x的集合记为X，称为属性集。一般X和Y的关系是不确定的，你只能在某种程度上说x有多大可能性属于类$$y_1$$，比如说x有80%的可能性属于类$$y_1$$，这时可以把X和Y看做是随机变量，$$P(Y \\vert X)$$称为Y的<strong>后验概率</strong>（posterior probability），与之相对的，P(Y)称为Y的<strong>先验概率</strong>（prior probability）[^2]。</p>\n<p>在训练阶段，我们要根据从训练数据中收集的信息，<strong>对X和Y的每一种组合学习后验概率$$P(Y \\vert X)$$。</strong>分类时，来了一个实例x，在刚才训练得到的一堆后验概率中找出所有的$$P(Y \\vert x)$$， 其中最大的那个y，即为x所属分类。根据贝叶斯公式，后验概率为$$P(Y \\vert X)=\\dfrac{P(X \\vert Y)P(Y)}{P(X)}$$</p>\n<p>在比较不同Y值的后验概率时，分母P(X)总是常数，<strong>因此可以忽略</strong>。先验概率P(Y)可以通过计算训练集中属于每一个类的训练样本所占的比例容易地估计。</p>\n<p>我们来举个简单的例子，让读者对上述思路有个形象的认识[^3]。<br>考虑一个医疗诊断问题，有两种可能的假设：（1）病人有癌症。（2）病人无癌症。样本数据来自某化验测试，它也有两种可能的结果：阳性和阴性。假设我们已经有先验知识：在所有人口中只有0.008的人患病。此外，化验测试对有病的患者有98%的可能返回阳性结果，对无病患者有97%的可能返回阴性结果。</p>\n<p>上面的数据可以用以下概率式子表示：<br>P(cancer)=0.008,P(无cancer)=0.992<br>P(阳性|cancer)=0.98,P(阴性|cancer)=0.02<br>P(阳性|无cancer)=0.03，P(阴性|无cancer)=0.97<br>假设现在有一个新病人，化验测试返回阳性，是否将病人断定为有癌症呢？</p>\n<p>在这里，Y={cancer，无cancer}，共两个类别，这个新病人是一个样本，他有一个属性阳性，可以令x=(阳性)。我们可以来计算各个类别的后验概率：<br>P(cancer | 阳性) = P(阳性 | cancer)p(cancer)=0.98* 0.008 = 0.0078<br>P(无cancer | 阳性) =P(阳性 | 无cancer)* p(无cancer)=0.03* 0.992 = 0.0298<br>因此，应该判断为无癌症。</p>\n<p>在这个例子中，类条件概率，P(cancer|阳性)和P(无cancer|阳性)直接告诉了我们。</p>\n<p>一般地，对<strong>类条件概率$$P(X \\vert Y)$$</strong>的估计，有朴素贝叶斯分类器和贝叶斯信念网络两种方法，这里介绍朴素贝叶斯分类器。</p>\n<p>###1.3 朴素贝叶斯分类器<br><strong>1、条件独立性</strong><br>给定类标号y，朴素贝叶斯分类器在估计类条件概率时假设属性之间条件独立。条件独立假设可以形式化的表达如下：<br>$$<br>\\prod\\limits_{i=1}^{n} P(x_i  \\vert Y=y)<br>$$<br>其中每个训练样本可用一个属性向量$$X=(x_1,x_2,x_3,…,x_n)$$表示，各个属性之间条件独立。</p>\n<p>比如，对于一篇文章，</p>\n<blockquote>\n<p>Good good study,Day day up.</p>\n</blockquote>\n<p>可以用一个文本特征向量来表示，<code>x=(Good, good, study, Day, day , up)</code>。一般各个词语之间肯定不是相互独立的，有一定的上下文联系。但在朴素贝叶斯文本分类时，我们假设个单词之间没有联系，可以用一个文本特征向量来表示这篇文章，这就是“朴素”的来历。</p>\n<p><strong>2、朴素贝叶斯如何工作</strong><br><strong>有了条件独立假设，就不必计算X和Y的每一种组合的类条件概率</strong>，只需对给定的Y，计算每个$$x_i$$的条件概率。后一种方法更实用，因为它不需要很大的训练集就能获得较好的概率估计。</p>\n<p><strong>3、估计分类属性的条件概率</strong><br>$$P(x_i \\vert Y=y)$$怎么计算呢？它一般根据类别y下包含属性$$x_i$$的实例的比例来估计。以文本分类为例，xi表示一个单词，$$P(x_i \\vert Y=y)=$$包含该类别下包含单词的xi的文章总数/ 该类别下的文章总数。</p>\n<p><strong>4、贝叶斯分类器举例</strong><br>假设给定了如下训练样本数据，我们学习的目标是根据给定的天气状况判断你对PlayTennis这个请求的回答是Yes还是No。</p>\n<table border=\"1\" cellspacing=\"0\" cellpadding=\"0\"><br><tbody><br><tr><br><td valign=\"top\" width=\"95\">Day</td><br><td valign=\"top\" width=\"95\">Outlook</td><br><td valign=\"top\" width=\"95\">Temperature</td><br><td valign=\"top\" width=\"95\">Humidity</td><br><td valign=\"top\" width=\"95\">Wind</td><br><td valign=\"top\" width=\"95\">PlayTennis</td><br></tr><br><tr><br><td valign=\"top\" width=\"95\">D1</td><br><td valign=\"top\" width=\"95\">Sunny</td><br><td valign=\"top\" width=\"95\">Hot</td><br><td valign=\"top\" width=\"95\">High</td><br><td valign=\"top\" width=\"95\">Weak</td><br><td valign=\"top\" width=\"95\">No</td><br></tr><br><tr><br><td valign=\"top\" width=\"95\">D2</td><br><td valign=\"top\" width=\"95\">Sunny</td><br><td valign=\"top\" width=\"95\">Hot</td><br><td valign=\"top\" width=\"95\">High</td><br><td valign=\"top\" width=\"95\">Strong</td><br><td valign=\"top\" width=\"95\">No</td><br></tr><br><tr><br><td valign=\"top\" width=\"95\">D3</td><br><td valign=\"top\" width=\"95\">Overcast</td><br><td valign=\"top\" width=\"95\">Hot</td><br><td valign=\"top\" width=\"95\">High</td><br><td valign=\"top\" width=\"95\">Weak</td><br><td valign=\"top\" width=\"95\">Yes</td><br></tr><br><tr><br><td valign=\"top\" width=\"95\">D4</td><br><td valign=\"top\" width=\"95\">Rain</td><br><td valign=\"top\" width=\"95\">Mild</td><br><td valign=\"top\" width=\"95\">High</td><br><td valign=\"top\" width=\"95\">Weak</td><br><td valign=\"top\" width=\"95\">Yes</td><br></tr><br><tr><br><td valign=\"top\" width=\"95\">D5</td><br><td valign=\"top\" width=\"95\">Rain</td><br><td valign=\"top\" width=\"95\">Cool</td><br><td valign=\"top\" width=\"95\">Normal</td><br><td valign=\"top\" width=\"95\">Weak</td><br><td valign=\"top\" width=\"95\">Yes</td><br></tr><br><tr><br><td valign=\"top\" width=\"95\">D6</td><br><td valign=\"top\" width=\"95\">Rain</td><br><td valign=\"top\" width=\"95\">Cool</td><br><td valign=\"top\" width=\"95\">Normal</td><br><td valign=\"top\" width=\"95\">Strong</td><br><td valign=\"top\" width=\"95\">No</td><br></tr><br><tr><br><td valign=\"top\" width=\"95\">D7</td><br><td valign=\"top\" width=\"95\">Overcast</td><br><td valign=\"top\" width=\"95\">Cool</td><br><td valign=\"top\" width=\"95\">Normal</td><br><td valign=\"top\" width=\"95\">Strong</td><br><td valign=\"top\" width=\"95\">Yes</td><br></tr><br><tr><br><td valign=\"top\" width=\"95\">D8</td><br><td valign=\"top\" width=\"95\">Sunny</td><br><td valign=\"top\" width=\"95\">Mild</td><br><td valign=\"top\" width=\"95\">High</td><br><td valign=\"top\" width=\"95\">Weak</td><br><td valign=\"top\" width=\"95\">No</td><br></tr><br><tr><br><td valign=\"top\" width=\"95\">D9</td><br><td valign=\"top\" width=\"95\">Sunny</td><br><td valign=\"top\" width=\"95\">Cool</td><br><td valign=\"top\" width=\"95\">Normal</td><br><td valign=\"top\" width=\"95\">Weak</td><br><td valign=\"top\" width=\"95\">Yes</td><br></tr><br><tr><br><td valign=\"top\" width=\"95\">D10</td><br><td valign=\"top\" width=\"95\">Rain</td><br><td valign=\"top\" width=\"95\">Mild</td><br><td valign=\"top\" width=\"95\">Normal</td><br><td valign=\"top\" width=\"95\">Weak</td><br><td valign=\"top\" width=\"95\">Yes</td><br></tr><br><tr><br><td valign=\"top\" width=\"95\">D11</td><br><td valign=\"top\" width=\"95\">Sunny</td><br><td valign=\"top\" width=\"95\">Mild</td><br><td valign=\"top\" width=\"95\">Normal</td><br><td valign=\"top\" width=\"95\">Strong</td><br><td valign=\"top\" width=\"95\">Yes</td><br></tr><br><tr><br><td valign=\"top\" width=\"95\">D12</td><br><td valign=\"top\" width=\"95\">Overcast</td><br><td valign=\"top\" width=\"95\">Mild</td><br><td valign=\"top\" width=\"95\">High</td><br><td valign=\"top\" width=\"95\">Strong</td><br><td valign=\"top\" width=\"95\">Yes</td><br></tr><br><tr><br><td valign=\"top\" width=\"95\">D13</td><br><td valign=\"top\" width=\"95\">Overcast</td><br><td valign=\"top\" width=\"95\">Hot</td><br><td valign=\"top\" width=\"95\">Normal</td><br><td valign=\"top\" width=\"95\">Weak</td><br><td valign=\"top\" width=\"95\">Yes</td><br></tr><br><tr><br><td valign=\"top\" width=\"95\">D14</td><br><td valign=\"top\" width=\"95\">Rain</td><br><td valign=\"top\" width=\"95\">Mild</td><br><td valign=\"top\" width=\"95\">High</td><br><td valign=\"top\" width=\"95\">Strong</td><br><td valign=\"top\" width=\"95\">No</td><br></tr><br></tbody><br></table><br>可以看到这里样本数据集提供了14个训练样本，我们将使用此表的数据，并结合朴素贝叶斯分类器来分类下面的新实例：<br>x = (Outlook = Sunny,Temprature = Cool,Humidity = High,Wind = Strong)<br><br>在这个例子中，属性向量X=(Outlook, Temperature, Humidity, Wind)，类集合Y={Yes, No}。我们需要利用训练数据计算后验概率$$P(Yes \\vert x)$$和$$P(No \\vert x)$$，如果$$P(Yes \\vert x)&gt;P(No \\vert x)$$，那么新实例分类为Yes，否则为No。<br><br>为了计算后验概率，我们需要计算先验概率P(Yes)和P(No)和类条件概率$$P(x_i \\vert Y)$$。<br><br>因为有9个样本属于Yes，5个样本属于No，所以$$P(Yes)=\\dfrac{9}{14}$$, $$P(No)=\\dfrac{5}{14}$$。类条件概率计算如下：<br>$$P(Outlook = Sunny \\vert Yes)=\\dfrac{2}{9}　　　P(Outlook = Sunny \\vert No)=\\dfrac{3}{5}$$<br>$$P(Temprature = Cool  \\vert Yes) =\\dfrac{3}{9}　　　P(Temprature = Cool  \\vert No) =\\dfrac{1}{5}$$<br>$$P(Humidity = High  \\vert Yes) =\\dfrac{3}{9}　　　P(Humidity = High  \\vert No) =\\dfrac{4}{5}$$<br>$$P(Wind = Strong  \\vert Yes) =\\dfrac{3}{9}　　　P(Wind = Strong  \\vert No) =\\dfrac{3}{5}$$<br><br>后验概率计算如下：<br>$$<br>\\begin{aligned}<br>P(Yes  \\vert  x) &amp; = P(Outlook = Sunny \\vert Yes) \\times P(Temprature = Cool  \\vert Yes) \\newline<br>&amp; \\times P(Humidity = High  \\vert Yes) \\times P(Wind = Strong  \\vert Yes) \\times P(Yes) \\newline<br>&amp; =\\dfrac{2}{9} \\times \\dfrac{3}{9} \\times \\dfrac{3}{9} \\times \\dfrac{3}{9} \\times \\dfrac{3}{9} \\times \\dfrac{9}{14}=\\dfrac{2}{243}=\\dfrac{9}{1701} \\approx 0.00529<br>\\end{aligned}<br>$$<br>$$<br>\\begin{aligned}<br>P(No  \\vert  x)&amp;= P(Outlook = Sunny \\vert No) \\times P(Temprature = Cool  \\vert No) \\newline<br>&amp; \\times P(Humidity = High  \\vert No) \\times P(Wind = Strong  \\vert No) \\times P(No) \\newline<br>&amp; =\\dfrac{3}{5}\\times \\dfrac{1}{5} \\times \\dfrac{4}{5} \\times \\dfrac{3}{5} \\times  \\dfrac{5}{14}=\\dfrac{18}{875} \\approx 0.02057<br>\\end{aligned}<br>$$<br>通过计算得出$$P(No  \\vert  x)&gt; P(Yes  \\vert  x)$$，所以该样本分类为No[^3]。<br><br><strong>5、条件概率的m估计</strong><br>假设有来了一个新样本 $$x_1= (Outlook = Cloudy,Temprature = Cool,Humidity = High,Wind = Strong)$$，要求对其分类。我们来开始计算，<br>$$P(Outlook = Cloudy \\vert Yes)=\\dfrac{0}{9}=0  P(Outlook = Cloudy  \\vert No)=\\dfrac{0}{5}=0$$<br>计算到这里，大家就会意识到，这里出现了一个新的属性值，在训练样本中所没有的。如果有一个属性的类条件概率为0，则整个类的后验概率就等于0，我们可以直接得到后验概率$$P(Yes  \\vert  x_1)= P(No  \\vert  x_1)=0$$，这时二者相等，无法分类。<br><br>当训练样本不能覆盖那么多的属性值时，都会出现上述的窘境。简单的使用样本比例来估计类条件概率的方法太脆弱了，尤其是当训练样本少而属性数目又很大时。<br><br>解决方法是使用m估计(m-estimate)方法来估计条件概率：<br>$$<br>P(x_i \\vert y_i)=\\dfrac{n_c+mp}{n+m}<br>$$<br>n是类$$y_j$$中的样本总数，$$n_c$$是类$$y_j$$中取值$$x_i$$的样本数，m是称为等价样本大小的参数，而p是用户指定的参数。如果没有训练集（即n=0），则$$P(x_i \\vert y_i)=p$$, 因此p可以看作是在类$$y_j$$的样本中观察属性值$$x_i$$的先验概率。等价样本大小决定先验概率和观测概率$$\\dfrac{n_c}{n}$$之间的平衡[^2]。<br><br>##2 朴素贝叶斯文本分类算法<br>现在开始进入本文的主旨部分：如何将贝叶斯分类器应用到文本分类上来。<br><br>###2.1文本分类问题<br>在文本分类中，假设我们有一个文档d∈X，X是文档向量空间(document space)，和一个固定的类集合C={c1,c2,…,cj}，类别又称为标签。显然，文档向量空间是一个高维度空间。我们把一堆打了标签的文档集合<d,c>作为训练样本，<d,c>∈X×C。例如：<br><d,c>={Beijing joins the World Trade Organization, China}<br>对于这个只有一句话的文档，我们把它归类到 China，即打上china标签。<br><br>我们期望用某种训练算法，训练出一个函数γ，能够将文档映射到某一个类别：<br>γ:X→C<br><br>这种类型的学习方法叫做有监督学习，因为事先有一个监督者（我们事先给出了一堆打好标签的文档）像个老师一样监督着整个学习过程。<br><br>朴素贝叶斯分类器是一种有监督学习，常见有两种模型，多项式模型(multinomial model)和伯努利模型(Bernoulli model)<a href=\"洞庭散人，“[基于朴素贝叶斯分类器的文本分类算法（上）](http://www.cnblogs.com/phinecos/archive/2008/10/21/1315948.html)”，“[基于朴素贝叶斯分类器的文本分类算法（下）](http://www.cnblogs.com/phinecos/archive/2008/10/21/1316044.html)”，2008\">^4</a>。<br><br>###2.2 多项式模型<br><br>####2.2.1 基本原理<br>在多项式模型中， 设某文档$$d=(t_1,t_2,…,t_k)$$，tk是该文档中出现过的单词，允许重复，则<br>先验概率$$P(c)=$$ 类c下单词总数/整个训练样本的单词总数<br>类条件概率$$P(t_k \\vert c)=$$(类c下单词tk在各个文档中出现过的次数之和+1)/(类c下单词总数+|V|)<br><br>V是训练样本的单词表（即抽取单词，单词出现多次，只算一个），<code>|V|</code>则表示训练样本包含多少种单词。在这里，<code>m=|V|, p=1/|V|</code>。<br><br>$$P(t_k \\vert c)=$$可以看作是单词tk在证明d属于类c上提供了多大的证据，而P(c)则可以认为是类别c在整体上占多大比例(有多大可能性)。<br><br>####2.2.2 伪代码[^1]<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">//C，类别集合，D，用于训练的文本文件集合</span></div><div class=\"line\">TrainMultiNomialNB(C,D) &#123;</div><div class=\"line\">    <span class=\"comment\">// 单词出现多次，只算一个</span></div><div class=\"line\">    V←ExtractVocabulary(D)</div><div class=\"line\">    <span class=\"comment\">// 单词可重复计算</span></div><div class=\"line\">    N←CountTokens(D)</div><div class=\"line\">    <span class=\"keyword\">for</span> each c∈C</div><div class=\"line\">        <span class=\"comment\">// 计算类别c下的单词总数</span></div><div class=\"line\">        <span class=\"comment\">// N和Nc的计算方法和Introduction to Information Retrieval上的不同，个人认为</span></div><div class=\"line\">        <span class=\"comment\">//该书是错误的，先验概率和类条件概率的计算方法应当保持一致</span></div><div class=\"line\">        Nc←CountTokensInClass(D,c)</div><div class=\"line\">        prior[c]←Nc/N</div><div class=\"line\">        <span class=\"comment\">// 将类别c下的文档连接成一个大字符串</span></div><div class=\"line\">        textc←ConcatenateTextOfAllDocsInClass(D,c)</div><div class=\"line\">        <span class=\"keyword\">for</span> each t∈V</div><div class=\"line\">            <span class=\"comment\">// 计算类c下单词t的出现次数</span></div><div class=\"line\">            Tct←CountTokensOfTerm(textc,t)</div><div class=\"line\">        <span class=\"keyword\">for</span> each t∈V</div><div class=\"line\">            <span class=\"comment\">//计算P(t|c)</span></div><div class=\"line\">            condprob[t][c]← </div><div class=\"line\">    <span class=\"keyword\">return</span> V,prior,condprob</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">ApplyMultiNomialNB(C,V,prior,condprob,d) &#123;</div><div class=\"line\">    <span class=\"comment\">// 将文档d中的单词抽取出来，允许重复，如果单词是全新的，在全局单词表V中都</span></div><div class=\"line\">    <span class=\"comment\">// 没出现过，则忽略掉</span></div><div class=\"line\">    W←ExtractTokensFromDoc(V,d)</div><div class=\"line\">    <span class=\"keyword\">for</span> each c∈C</div><div class=\"line\">        score[c]←prior[c]</div><div class=\"line\">        <span class=\"keyword\">for</span> each t∈W</div><div class=\"line\">            <span class=\"keyword\">if</span> t∈Vd</div><div class=\"line\">                score[c] *= condprob[t][c]</div><div class=\"line\">    <span class=\"keyword\">return</span> max(score[c])</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure><br><br>####2.2.3 举例<br>给定一组分类好了的文本训练数据，如下：<br><br><table border=\"1\" cellspacing=\"0\" cellpadding=\"0\"><br><tbody><br><tr><br><td valign=\"top\" width=\"64\">docId</td><br><td valign=\"top\" width=\"236\">doc</td><br><td valign=\"top\" width=\"126\">类别In c=China?</td><br></tr><br><tr><br><td valign=\"top\" width=\"64\">1</td><br><td valign=\"top\" width=\"236\">Chinese Beijing Chinese</td><br><td valign=\"top\" width=\"126\">yes</td><br></tr><br><tr><br><td valign=\"top\" width=\"64\">2</td><br><td valign=\"top\" width=\"236\">Chinese Chinese Shanghai</td><br><td valign=\"top\" width=\"126\">yes</td><br></tr><br><tr><br><td valign=\"top\" width=\"64\">3</td><br><td valign=\"top\" width=\"236\">Chinese Macao</td><br><td valign=\"top\" width=\"126\">yes</td><br></tr><br><tr><br><td valign=\"top\" width=\"64\">4</td><br><td valign=\"top\" width=\"236\">Tokyo Japan Chinese</td><br><td valign=\"top\" width=\"126\">no</td><br></tr><br></tbody><br></table>\n\n<p>给定一个新样本</p>\n<blockquote>\n<p>Chinese Chinese Chinese Tokyo Japan</p>\n</blockquote>\n<p>对其进行分类。该文本用属性向量表示为<code>d=(Chinese, Chinese, Chinese, Tokyo, Japan)</code>，类别集合为<code>Y={yes, no}</code>。</p>\n<p>类yes下总共有8个单词，类no下总共有3个单词，训练样本单词总数为11，因此$$P(yes)=\\dfrac{8}{11}, P(no)=\\dfrac{3}{11}$$。类条件概率计算如下：<br>$$P(Chinese  \\vert  yes)=\\dfrac{5+1}{8+6}=\\dfrac{6}{14}=\\dfrac{3}{7}$$<br>$$P(Japan  \\vert  yes)=P(Tokyo  \\vert  yes)= \\dfrac{0+1}{8+6}=\\dfrac{1}{14}$$<br>$$P(Chinese \\vert no)=\\dfrac{1+1}{3+6}=\\dfrac{2}{9}$$<br>$$P(Japan \\vert no)=P(Tokyo \\vert  no) =\\dfrac{1+1}{3+6}=\\dfrac{2}{9}$$<br>分母中的8，是指yes类别下textc的长度，也即训练样本的单词总数，6是指训练样本有Chinese,Beijing,Shanghai, Macao, Tokyo, Japan 共6个单词，3是指no类下共有3个单词。</p>\n<p>有了以上类条件概率，开始计算后验概率，<br>$$P(yes  \\vert  d)=\\left(\\dfrac{3}{7}\\right)^3 \\times \\dfrac{1}{14} \\times \\dfrac{1}{14} \\times \\dfrac{8}{11}=\\dfrac{108}{184877} \\approx 0.00058417$$<br>$$P(no  \\vert  d)= \\left(\\dfrac{2}{9}\\right)^3 \\times \\dfrac{2}{9} \\times \\dfrac{2}{9} \\times \\dfrac{3}{11}=\\dfrac{32}{216513} \\approx 0.00014780$$<br>因此，这个文档属于类别china。</p>\n<p>###2.3 伯努利模型</p>\n<p>####2.3.1 基本原理<br>$$P(c)=$$ 类c下文件总数/整个训练样本的文件总数<br>$$P(t_k \\vert c)=$$(类c下包含单词tk的文件数+1)/(类c下单词总数+2)<br>在这里，$$m=2, p=\\dfrac{1}{2}$$。</p>\n<p>后验概率的计算，也有点变化，见下面的伪代码。</p>\n<p>####2.3.2 伪代码<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">//C，类别集合，D，用于训练的文本文件集合</span></div><div class=\"line\">TrainBernoulliNB(C, D) &#123;</div><div class=\"line\">    <span class=\"comment\">// 单词出现多次，只算一个</span></div><div class=\"line\">V←ExtractVocabulary(D)</div><div class=\"line\">    <span class=\"comment\">// 计算文件总数</span></div><div class=\"line\">    N←CountDocs(D)</div><div class=\"line\">    <span class=\"keyword\">for</span> each c∈C</div><div class=\"line\">        <span class=\"comment\">// 计算类别c下的文件总数</span></div><div class=\"line\">        Nc←CountDocsInClass(D,c)</div><div class=\"line\">        prior[c]←Nc/N</div><div class=\"line\">        <span class=\"keyword\">for</span> each t∈V</div><div class=\"line\">            <span class=\"comment\">// 计算类c下包含单词t的文件数</span></div><div class=\"line\">            Nct←CountDocsInClassContainingTerm(D,c,t)</div><div class=\"line\">            <span class=\"comment\">//计算P(t|c)</span></div><div class=\"line\">            condprob[t][c]←(Nct+<span class=\"number\">1</span>)/(Nct+<span class=\"number\">2</span>)</div><div class=\"line\">    <span class=\"keyword\">return</span> V,prior,condprob</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">ApplyBernoulliNB(C,V,prior,condprob,d) &#123;</div><div class=\"line\">    <span class=\"comment\">// 将文档d中单词表抽取出来，如果单词是全新的，在全局单词表V中都没出现过，</span></div><div class=\"line\">    <span class=\"comment\">// 则舍弃</span></div><div class=\"line\">    Vd←ExtractTermsFromDoc(V,d)</div><div class=\"line\">    <span class=\"keyword\">for</span> each c∈C</div><div class=\"line\">        score[c]←prior[c]</div><div class=\"line\">        <span class=\"keyword\">for</span> each t∈V</div><div class=\"line\">            <span class=\"keyword\">if</span> t∈Vd</div><div class=\"line\">                score[c] *= condprob[t][c]</div><div class=\"line\">            <span class=\"keyword\">else</span></div><div class=\"line\">                score[c] *= (<span class=\"number\">1</span>-condprob[t][c])</div><div class=\"line\">    <span class=\"keyword\">return</span> max(score[c])</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure></p>\n<p>####2.3.3 举例<br>还是使用前面例子中的数据，不过模型换成了使用伯努利模型。</p>\n<p>类yes下总共有3个文件，类no下有1个文件，训练样本文件总数为11，因此$$P(yes)=\\dfrac{3}{4}, P(Chinese  \\vert  yes)=\\dfrac{3+1}{3+2}=\\dfrac{4}{5}$$<br>$$P(Japan  \\vert  yes)=P(Tokyo  \\vert  yes)=\\dfrac{0+1}{3+2}=\\dfrac{1}{5}$$<br>$$P(Beijing  \\vert  yes)= P(Macao \\vert yes)= P(Shanghai  \\vert yes)=\\dfrac{1+1}{3+2}=\\dfrac{2}{5}$$<br>$$P(Chinese \\vert no)=\\dfrac{1+1}{1+2}=\\dfrac{2}{3}$$<br>$$P(Japan \\vert no)=P(Tokyo \\vert  no) =\\dfrac{1+1}{1+2}=\\dfrac{2}{3}$$<br>$$P(Beijing \\vert  no)= P(Macao \\vert  no)= P(Shanghai  \\vert  no)=\\dfrac{0+1}{1+2}=\\dfrac{1}{3}$$  </p>\n<p>有了以上类条件概率，开始计算后验概率，<br>$$<br>\\begin{aligned}<br>P(yes  \\vert  d)&amp;=P(yes) \\times P(Chinese \\vert yes) \\times P(Japan \\vert yes) \\times P(Tokyo \\vert yes) \\newline<br>&amp;\\times (1-P(Beijing \\vert yes)) \\times (1-P(Shanghai \\vert yes))\\newline<br>&amp;\\times (1-P(Macao \\vert yes)) \\newline<br>&amp;=\\dfrac{3}{4} \\times \\dfrac{4}{5} \\times \\dfrac{1}{5} \\times \\dfrac{1}{5} \\times (1-\\dfrac{2}{5} \\times (1-\\dfrac{2}{5}) \\times (1-\\dfrac{2}{5})=\\dfrac{81}{15625} \\approx 0.005<br>\\end{aligned}<br>$$<br>$$P(no   \\vert   d)= \\dfrac{1}{4} \\times \\dfrac{2}{3} \\times \\dfrac{2}{5} \\times \\dfrac{2}{5} \\times (1-\\dfrac{1}{3}) \\times (1-\\dfrac{1}{3}) \\times (1-\\dfrac{1}{3})=\\dfrac{16}{729} \\approx 0.022$$<br>因此，这个文档不属于类别china。</p>\n<p>###2.4 两个模型的区别<br>二者的计算粒度不一样，多项式模型以单词为粒度，伯努利模型以文件为粒度，因此二者的先验概率和类条件概率的计算方法都不同。</p>\n<p>计算后验概率时，对于一个文档d，多项式模型中，只有在d中出现过的单词，才会参与后验概率计算，伯努利模型中，没有在d中出现，但是在全局单词表中出现的单词，也会参与计算，不过是作为“反方”参与的。</p>\n<p>##3 代码详解<br>本文附带了一个eclipse工程，有完整的源代码，以及一个微型文本训练库。</p>\n<p>ChineseSpliter用于中文分词，StopWordsHandler用于判断一个单词是否是停止词，ClassifyResult用于保存结果，IntermediateData用于预处理文本语料库，TrainnedModel用于保存训练后得到的数据，NaiveBayesClassifier是基础类，包含了贝叶斯分类器的主要代码，MultiNomialNB是多项式模型，类似的，BernoulliNB是伯努利模型，二者都继承自NaiveBayesClassifier，都只重写了父类的计算先验概率，类条件概率和后验概率这3个函数。</p>\n<p>###3.1 中文分词<br>中文分词不是本文的重点，这里我们直接使用第三方工具，本源码使用的是<a href=\"http://www.jesoft.cn/\" target=\"_blank\" rel=\"external\">极易中文分词组件</a>，你还可以使用<a href=\"http://chtsai.org/\" target=\"_blank\" rel=\"external\">MMSEG</a>，中科院的<a href=\"http://ictclas.org/\" target=\"_blank\" rel=\"external\">ICTCLAS</a>等等。</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">/**</span></div><div class=\"line\">     * 对给定的文本进行中文分词.</div><div class=\"line\">     * </div><div class=\"line\">     * <span class=\"doctag\">@param</span> text</div><div class=\"line\">     *            给定的文本</div><div class=\"line\">     * <span class=\"doctag\">@param</span> splitToken</div><div class=\"line\">     *            用于分割的标记,如\"|\"</div><div class=\"line\">     * <span class=\"doctag\">@return</span> 分词完毕的文本</div><div class=\"line\">     */</div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> String <span class=\"title\">split</span><span class=\"params\">(<span class=\"keyword\">final</span> String text, <span class=\"keyword\">final</span> String splitToken)</span> </span>&#123;</div><div class=\"line\">        String result = <span class=\"keyword\">null</span>;</div><div class=\"line\">        </div><div class=\"line\">        <span class=\"keyword\">try</span> &#123;</div><div class=\"line\">            result = analyzer.segment(text, splitToken);</div><div class=\"line\">        &#125; <span class=\"keyword\">catch</span> (IOException e) &#123;</div><div class=\"line\">            e.printStackTrace();</div><div class=\"line\">        &#125;</div><div class=\"line\">        <span class=\"keyword\">return</span> result;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<p>###3.2 停止词处理<br>停止词(Stop Word)是指那些无意义的字或词，如“的”、“在”等。去掉文档中的停止词也是必须的一项工作,这里简单的定义了一些常见的停止词，并根据这些常用停止词在分词时进行判断。</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">/** 常用停用词. */</span></div><div class=\"line\">    <span class=\"keyword\">private</span> <span class=\"keyword\">static</span> String[] stopWordsList = &#123;</div><div class=\"line\">            <span class=\"comment\">// 来自 c:\\Windows\\System32\\NOISE.CHS</span></div><div class=\"line\">            <span class=\"string\">\"的\"</span>, <span class=\"string\">\"一\"</span>, <span class=\"string\">\"不\"</span>, <span class=\"string\">\"在\"</span>, <span class=\"string\">\"人\"</span>, <span class=\"string\">\"有\"</span>, <span class=\"string\">\"是\"</span>, <span class=\"string\">\"为\"</span>, <span class=\"string\">\"以\"</span>, <span class=\"string\">\"于\"</span>, <span class=\"string\">\"上\"</span>, <span class=\"string\">\"他\"</span>, <span class=\"string\">\"而\"</span>,</div><div class=\"line\">            <span class=\"string\">\"后\"</span>, <span class=\"string\">\"之\"</span>, <span class=\"string\">\"来\"</span>, <span class=\"string\">\"及\"</span>, <span class=\"string\">\"了\"</span>, <span class=\"string\">\"因\"</span>, <span class=\"string\">\"下\"</span>, <span class=\"string\">\"可\"</span>, <span class=\"string\">\"到\"</span>, <span class=\"string\">\"由\"</span>, <span class=\"string\">\"这\"</span>, <span class=\"string\">\"与\"</span>, <span class=\"string\">\"也\"</span>,</div><div class=\"line\">            <span class=\"string\">\"此\"</span>, <span class=\"string\">\"但\"</span>, <span class=\"string\">\"并\"</span>, <span class=\"string\">\"个\"</span>, <span class=\"string\">\"其\"</span>, <span class=\"string\">\"已\"</span>, <span class=\"string\">\"无\"</span>, <span class=\"string\">\"小\"</span>, <span class=\"string\">\"我\"</span>, <span class=\"string\">\"们\"</span>, <span class=\"string\">\"起\"</span>, <span class=\"string\">\"最\"</span>, <span class=\"string\">\"再\"</span>,</div><div class=\"line\">            <span class=\"string\">\"今\"</span>, <span class=\"string\">\"去\"</span>, <span class=\"string\">\"好\"</span>, <span class=\"string\">\"只\"</span>, <span class=\"string\">\"又\"</span>, <span class=\"string\">\"或\"</span>, <span class=\"string\">\"很\"</span>, <span class=\"string\">\"亦\"</span>, <span class=\"string\">\"某\"</span>, <span class=\"string\">\"把\"</span>, <span class=\"string\">\"那\"</span>, <span class=\"string\">\"你\"</span>, <span class=\"string\">\"乃\"</span>,</div><div class=\"line\">            <span class=\"string\">\"它\"</span>,</div><div class=\"line\">            <span class=\"comment\">// 来自网络</span></div><div class=\"line\">            <span class=\"string\">\"要\"</span>, <span class=\"string\">\"将\"</span>, <span class=\"string\">\"应\"</span>, <span class=\"string\">\"位\"</span>, <span class=\"string\">\"新\"</span>, <span class=\"string\">\"两\"</span>, <span class=\"string\">\"中\"</span>, <span class=\"string\">\"更\"</span>, <span class=\"string\">\"我们\"</span>, <span class=\"string\">\"自己\"</span>, <span class=\"string\">\"没有\"</span>, <span class=\"string\">\"“\"</span>, <span class=\"string\">\"”\"</span>,</div><div class=\"line\">            <span class=\"string\">\"，\"</span>, <span class=\"string\">\"（\"</span>, <span class=\"string\">\"）\"</span>, <span class=\"string\">\"\"</span> &#125;;</div><div class=\"line\"></div><div class=\"line\">    <span class=\"comment\">/**</span></div><div class=\"line\">     * 判断一个词是否是停止词.</div><div class=\"line\">     * </div><div class=\"line\">     * <span class=\"doctag\">@param</span> word</div><div class=\"line\">     *            要判断的词</div><div class=\"line\">     * <span class=\"doctag\">@return</span> 是停止词，返回true，否则返回false</div><div class=\"line\">     */</div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">static</span> <span class=\"keyword\">boolean</span> <span class=\"title\">isStopWord</span><span class=\"params\">(<span class=\"keyword\">final</span> String word)</span> </span>&#123;</div><div class=\"line\">        <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>; i &lt; stopWordsList.length; ++i) &#123;</div><div class=\"line\">            <span class=\"keyword\">if</span> (word.equalsIgnoreCase(stopWordsList[i])) &#123;</div><div class=\"line\">                <span class=\"keyword\">return</span> <span class=\"keyword\">true</span>;</div><div class=\"line\">            &#125;</div><div class=\"line\">        &#125;</div><div class=\"line\">        <span class=\"keyword\">return</span> <span class=\"keyword\">false</span>;</div><div class=\"line\">    &#125;</div></pre></td></tr></table></figure>\n<p>###3.3 预处理数据<br>我们这里使用<a href=\"http://www.sogou.com/labs/dl/c.html\" target=\"_blank\" rel=\"external\">搜狗的文本分类语料库</a>作为训练样本，把SogouC.reduced.20061102.tar.gz解压到D盘，目录结构为</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div></pre></td><td class=\"code\"><pre><div class=\"line\">D:\\Reduced</div><div class=\"line\">         |-- C000008</div><div class=\"line\">         |-- C000010</div><div class=\"line\">         |-- C000013</div><div class=\"line\">         |-- C000014</div><div class=\"line\">         |-- C000016</div><div class=\"line\">         |-- C000020</div><div class=\"line\">         |-- C000022</div><div class=\"line\">         |-- C000023</div><div class=\"line\">         |-- C000024</div></pre></td></tr></table></figure>\n<p>IntermediateData.java主要用于处理文本数据，将所需要的信息计算好，存放到数据库文件中。</p>\n<p>中间数据文件主要保存了如下信息，</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">/** 单词X在类别C下出现的总数. */</span></div><div class=\"line\">\t<span class=\"keyword\">public</span> HashMap[] filesOfXC;</div><div class=\"line\">\t<span class=\"comment\">/** 给定分类下的文件数目. */</span></div><div class=\"line\">    <span class=\"keyword\">public</span> <span class=\"keyword\">int</span>[] filesOfC;</div><div class=\"line\">    <span class=\"comment\">/** 根目录下的文件总数. */</span></div><div class=\"line\">    <span class=\"keyword\">public</span> <span class=\"keyword\">int</span> files;</div><div class=\"line\">    </div><div class=\"line\">\t<span class=\"comment\">/** 单词X在类别C下出现的总数 */</span></div><div class=\"line\">\t<span class=\"keyword\">public</span> HashMap[] tokensOfXC;</div><div class=\"line\">    <span class=\"comment\">/** 类别C下所有单词的总数. */</span></div><div class=\"line\">    <span class=\"keyword\">public</span> <span class=\"keyword\">int</span>[] tokensOfC;</div><div class=\"line\">    <span class=\"comment\">/** 整个语料库中单词的总数. */</span></div><div class=\"line\">    <span class=\"keyword\">public</span> <span class=\"keyword\">int</span> tokens;</div><div class=\"line\">    <span class=\"comment\">/** 整个训练语料所出现的单词. */</span></div><div class=\"line\">    <span class=\"keyword\">public</span> HashSet&lt;String&gt; vocabulary;</div></pre></td></tr></table></figure>\n<p>我们使用命令</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">IntermediateData d:\\Reduced\\ gbk d:\\reduced.db</div></pre></td></tr></table></figure>\n<p>将文本训练库的信息计算好，保存到中间文件中。以后的阶段，我们都不再需要文本语料库了，只需要reduced.db。</p>\n<p>###3.3 训练<br>基本的框架代码都在NaiveBayesClassifier中，MultiNomialNB和BernoulliNB都只是重新实现(override)了这三个函数。</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">/** 计算先验概率P(c). */</span></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">protected</span> <span class=\"keyword\">void</span> <span class=\"title\">calculatePc</span><span class=\"params\">()</span> </span>&#123;</div><div class=\"line\">    &#125;</div><div class=\"line\">    </div><div class=\"line\">    <span class=\"comment\">/** 计算类条件概率P(x|c). */</span></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">protected</span> <span class=\"keyword\">void</span> <span class=\"title\">calculatePxc</span><span class=\"params\">()</span> </span>&#123;</div><div class=\"line\">    &#125;</div><div class=\"line\">    </div><div class=\"line\">    </div><div class=\"line\">    <span class=\"comment\">/**</span></div><div class=\"line\">     * 计算文本属性向量X在类Cj下的后验概率P(Cj|X).</div><div class=\"line\">     * </div><div class=\"line\">     * <span class=\"doctag\">@param</span> x</div><div class=\"line\">     *            文本属性向量</div><div class=\"line\">     * <span class=\"doctag\">@param</span> cj</div><div class=\"line\">     *            给定的类别</div><div class=\"line\">     * <span class=\"doctag\">@return</span> 后验概率</div><div class=\"line\">     */</div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">protected</span> <span class=\"keyword\">double</span> <span class=\"title\">calcProd</span><span class=\"params\">(<span class=\"keyword\">final</span> String[] x, <span class=\"keyword\">final</span> <span class=\"keyword\">int</span> cj)</span> </span>&#123;</div><div class=\"line\">        <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</div><div class=\"line\">    &#125;</div></pre></td></tr></table></figure>\n<p>训练函数如下：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div></pre></td><td class=\"code\"><pre><div class=\"line\">public final void train(String intermediateData, String modelFile) &#123;</div><div class=\"line\">    \t// 加载中间数据文件</div><div class=\"line\">    \tloadData(intermediateData);</div><div class=\"line\">    \t</div><div class=\"line\">    \tmodel = new TrainnedModel(db.classifications.length);</div><div class=\"line\">    \t</div><div class=\"line\">    \tmodel.classifications = db.classifications;</div><div class=\"line\">    \tmodel.vocabulary = db.vocabulary;</div><div class=\"line\">    \t// 开始训练</div><div class=\"line\">    \tcalculatePc();</div><div class=\"line\">    \tcalculatePxc();</div><div class=\"line\">    \tdb = null;</div><div class=\"line\">    \t</div><div class=\"line\">    \ttry &#123;</div><div class=\"line\">    \t\t// 用序列化，将训练得到的结果存放到模型文件中</div><div class=\"line\">            ObjectOutputStream out = new ObjectOutputStream(</div><div class=\"line\">                    new FileOutputStream(modelFile));</div><div class=\"line\">            out.writeObject(model);</div><div class=\"line\">            out.close();</div><div class=\"line\">        &#125; catch (IOException e) &#123;</div><div class=\"line\">            e.printStackTrace();</div><div class=\"line\">        &#125;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<p>我们使用命令：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">MultiNomialNB –t d:\\reduced.db d:\\reduced.mdl</div></pre></td></tr></table></figure>\n<p>开始训练，得到的模型文件保存在reduced.mdl中。</p>\n<p>###3.4 分类<br>有了模型文件，就可以用它来进行分类了。</p>\n<p>可以使用命令</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">MultiNomialNB d:\\reduced.mdl d:\\temp.txt gbk</div></pre></td></tr></table></figure>\n<p>对文本文件temp.txt进行分类。</p>\n<p>还可以将当初训练出这个模型文件的文本库，进行分类，看看正确率有多少，即“吃自己的狗食”，命令行如下</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">MultiNomialNB -r d:\\reduced\\ gbk d:\\reduced.mdl</div></pre></td></tr></table></figure>\n<p>分类函数如下：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">/**</span></div><div class=\"line\"> * 对给定的文本进行分类.</div><div class=\"line\"> * </div><div class=\"line\"> * <span class=\"doctag\">@param</span> text</div><div class=\"line\"> *            给定的文本</div><div class=\"line\"> * <span class=\"doctag\">@return</span> 分类结果</div><div class=\"line\"> */</div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">final</span> String <span class=\"title\">classify</span><span class=\"params\">(<span class=\"keyword\">final</span> String text)</span> </span>&#123;</div><div class=\"line\">    String[] terms = <span class=\"keyword\">null</span>;</div><div class=\"line\">    <span class=\"comment\">// 中文分词处理(分词后结果可能还包含有停用词）</span></div><div class=\"line\">terms = textSpliter.split(text, <span class=\"string\">\" \"</span>).split(<span class=\"string\">\" \"</span>);</div><div class=\"line\">    <span class=\"comment\">// 去掉停用词，以免影响分类</span></div><div class=\"line\">    terms = ChineseSpliter.dropStopWords(terms); </div><div class=\"line\">        </div><div class=\"line\"><span class=\"keyword\">double</span> probility = <span class=\"number\">0.0</span>;</div><div class=\"line\">    <span class=\"comment\">// 分类结果</span></div><div class=\"line\">    List&lt;ClassifyResult&gt; crs = <span class=\"keyword\">new</span> ArrayList&lt;ClassifyResult&gt;(); </div><div class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>; i &lt; model.classifications.length; i++) &#123;</div><div class=\"line\">        <span class=\"comment\">// 计算给定的文本属性向量terms在给定的分类Ci中的分类条件概率</span></div><div class=\"line\">        probility = calcProd(terms, i);</div><div class=\"line\">        <span class=\"comment\">// 保存分类结果</span></div><div class=\"line\">        ClassifyResult cr = <span class=\"keyword\">new</span> ClassifyResult();</div><div class=\"line\">         cr.classification = model.classifications[i]; <span class=\"comment\">// 分类</span></div><div class=\"line\">        cr.probility = probility; <span class=\"comment\">// 关键字在分类的条件概率</span></div><div class=\"line\">        System.out.println(<span class=\"string\">\"In process....\"</span>);</div><div class=\"line\">        System.out.println(model.classifications[i] + <span class=\"string\">\"：\"</span> + probility);</div><div class=\"line\">        crs.add(cr);</div><div class=\"line\">    &#125;</div><div class=\"line\">        </div><div class=\"line\">    <span class=\"comment\">// 找出最大的元素</span></div><div class=\"line\">    ClassifyResult maxElem = (ClassifyResult) java.util.Collections.max(</div><div class=\"line\">            crs, <span class=\"keyword\">new</span> Comparator() &#123;</div><div class=\"line\">                <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">int</span> <span class=\"title\">compare</span><span class=\"params\">(<span class=\"keyword\">final</span> Object o1, <span class=\"keyword\">final</span> Object o2)</span> </span>&#123;</div><div class=\"line\">                    <span class=\"keyword\">final</span> ClassifyResult m1 = (ClassifyResult) o1;</div><div class=\"line\">                    <span class=\"keyword\">final</span> ClassifyResult m2 = (ClassifyResult) o2;</div><div class=\"line\">                    <span class=\"keyword\">final</span> <span class=\"keyword\">double</span> ret = m1.probility - m2.probility;</div><div class=\"line\">                    <span class=\"keyword\">if</span> (ret &lt; <span class=\"number\">0</span>) &#123;</div><div class=\"line\">                        <span class=\"keyword\">return</span> -<span class=\"number\">1</span>;</div><div class=\"line\">                    &#125; <span class=\"keyword\">else</span> &#123;</div><div class=\"line\">                        <span class=\"keyword\">return</span> <span class=\"number\">1</span>;</div><div class=\"line\">                    &#125;</div><div class=\"line\">                &#125;</div><div class=\"line\">            &#125;);</div><div class=\"line\"></div><div class=\"line\">    <span class=\"keyword\">return</span> maxElem.classification;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<p>测试正确率的函数getCorrectRate()，核心代码就是对每个文本文件调用classify()，将得到的类别和原始的类别比较，经过统计后就可以得到百分比。</p>\n<p>更多细节请读者阅读<a href=\"http://yanjiuyanjiu-wordpress.stor.sinaapp.com/uploads/2010/05/NaiveBayesClassifier.zip\" target=\"_blank\" rel=\"external\">源代码</a>。</p>\n<p>##参考文献</p>\n<p>[^1]: Christopher D. Manning, Prabhakar Raghavan, Hinrich Schütze, <a href=\"http://nlp.stanford.edu/IR-book/\" target=\"_blank\" rel=\"external\">Introduction to Information Retrieval</a>, Cambridge University Press, 2008, chapter 13, Text classification and Naive Bayes.</p>\n<p>[^2]: Pang-Ning Tan, Michael Steinbach, Vipin Kumar, 《<a href=\"http://book.douban.com/subject/1786120/\" target=\"_blank\" rel=\"external\">数据挖掘导论</a>》，北京：人民邮电出版社，2007，第140~145页。</p>\n<p>[^3]: 石志伟, 吴功宜, “<a href=\"http://d.wanfangdata.com.cn/Conference_5615512.aspx\" target=\"_blank\" rel=\"external\">基于朴素贝叶斯分类器的文本分类算法</a>”, 第一届全国信息检索与内容安全学术会议，2004</p>\n<p>[^5]: DL88250, “<a href=\"http://blog.csdn.net/DL88250/archive/2008/02/20/2108164.aspx\" target=\"_blank\" rel=\"external\">朴素贝叶斯中文文本分类器的研究与实现（1）</a>”，“<a href=\"http://blog.csdn.net/DL88250/archive/2008/03/27/2224126.aspx\" target=\"_blank\" rel=\"external\">朴素贝叶斯中文文本分类器的研究与实现（2）</a>”，2008</p>\n</d,c></d,c></d,c>","excerpt":"<p>作者: 灵魂机器<br>新浪博客：<a href=\"www.weibo.com/soulmachine\">www.weibo.com/soulmachine</a><br>作者博客：<a href=\"www.yanjiuyanjiu.com\">www.yanjiuyanjiu.com</a></p>\n<p><strong>摘要</strong>：常用的文本分类方法有支持向量机、K-近邻算法和朴素贝叶斯。其中朴素贝叶斯具有容易实现，运行速度快的特点，被广泛使用。本文详细介绍了朴素贝叶斯的基本原理，讨论了两种常见模型：多项式模型（MM）和伯努利模型（BM），实现了可运行的代码，并进行了一些数据测试。</p>\n<p><strong>关键字</strong>：朴素贝叶斯；文本分类</p>\n<p><strong>Text Classification Algorithm Based on Naive Bayes</strong><br><strong>Author</strong>: soulmachine<br><strong>Email</strong>：soulmachine@gmail.com<br><strong>Blog</strong>：<a href=\"www.yanjiuyanjiu.com\">www.yanjiuyanjiu.com</a></p>\n<p><strong>Abstract</strong>:Usually there are three methods for text classification: SVM、KNN and Naïve Bayes. Naïve Bayes is easy to implement and fast, so it is widely used. This article introduced the theory of Naïve Bayes and discussed two popular models: multinomial model(MM) and Bernoulli model(BM) in details, implemented runnable code and performed some data tests.</p>\n<p><strong>Keywords</strong>: naïve bayes; text classification</p>\n<p>##1 贝叶斯原理</p>\n<p>###1.1 贝叶斯公式</p>\n<p>设A、B是两个事件，且P(A)&gt;0，称 $$P(Y \\vert X)=\\dfrac {P(XY)}{P(X)}$$ 为事件A发生的条件下事件B发生的<strong>条件概率</strong>。</p>\n<p><strong>乘法公式</strong> $$P(XYZ)=P(Z \\vert XY)P(Y \\vert X)P(X)$$<br><strong>全概率公式</strong>  $$P(X)=P(X \\vert Y_1)+ P(X \\vert Y_2)+…+ P(X \\vert Y_n)$$<br><strong>贝叶斯公式</strong>  $$P(Y_i \\vert X)=\\dfrac{P(XY_i)}{P(X)}=\\dfrac{P(X \\vert Y_i)P(Y_i)}{P(X)}=\\dfrac{P(X \\vert Y_i)P(Y<em>i)}{\\sum\\limits </em>{j=1} ^{n} P(X \\vert Y_j)}$$  </p>\n<p>在此处，贝叶斯公式，我们要用到的是 $$P(Y_i \\vert X)=\\dfrac{P(X \\vert Y_i)P(Y_i)}{P(X)}$$</p>\n<p>以上公式，请读者参考<a href=\"http://book.douban.com/subject/1231189/\">《概率论与数理统计（第五版）》</a>的1.4节“条件概率”（这里将原书中的A换成了X，B换成了Y），获得更深的理解。</p>","more":"<p>###1.2 贝叶斯定理在分类中的应用<br>在分类（classification）问题中，常常需要把一个事物分到某个类别。一个事物具有很多属性，把它的众多属性看做一个向量，即$$x=(x_1,x_2,x_3,…,x_n)$$，用x这个向量来代表这个事物。类别也是有很多种，用集合$$Y={y_1,y_2,…y_m}$$表示。如果x属于$$y_1$$类别，就可以给x打上$$y_1$$标签，意思是说x属于$$y_1$$类别。这就是所谓的<strong>分类(Classification)</strong>。</p>\n<p>x的集合记为X，称为属性集。一般X和Y的关系是不确定的，你只能在某种程度上说x有多大可能性属于类$$y_1$$，比如说x有80%的可能性属于类$$y_1$$，这时可以把X和Y看做是随机变量，$$P(Y \\vert X)$$称为Y的<strong>后验概率</strong>（posterior probability），与之相对的，P(Y)称为Y的<strong>先验概率</strong>（prior probability）[^2]。</p>\n<p>在训练阶段，我们要根据从训练数据中收集的信息，<strong>对X和Y的每一种组合学习后验概率$$P(Y \\vert X)$$。</strong>分类时，来了一个实例x，在刚才训练得到的一堆后验概率中找出所有的$$P(Y \\vert x)$$， 其中最大的那个y，即为x所属分类。根据贝叶斯公式，后验概率为$$P(Y \\vert X)=\\dfrac{P(X \\vert Y)P(Y)}{P(X)}$$</p>\n<p>在比较不同Y值的后验概率时，分母P(X)总是常数，<strong>因此可以忽略</strong>。先验概率P(Y)可以通过计算训练集中属于每一个类的训练样本所占的比例容易地估计。</p>\n<p>我们来举个简单的例子，让读者对上述思路有个形象的认识[^3]。<br>考虑一个医疗诊断问题，有两种可能的假设：（1）病人有癌症。（2）病人无癌症。样本数据来自某化验测试，它也有两种可能的结果：阳性和阴性。假设我们已经有先验知识：在所有人口中只有0.008的人患病。此外，化验测试对有病的患者有98%的可能返回阳性结果，对无病患者有97%的可能返回阴性结果。</p>\n<p>上面的数据可以用以下概率式子表示：<br>P(cancer)=0.008,P(无cancer)=0.992<br>P(阳性|cancer)=0.98,P(阴性|cancer)=0.02<br>P(阳性|无cancer)=0.03，P(阴性|无cancer)=0.97<br>假设现在有一个新病人，化验测试返回阳性，是否将病人断定为有癌症呢？</p>\n<p>在这里，Y={cancer，无cancer}，共两个类别，这个新病人是一个样本，他有一个属性阳性，可以令x=(阳性)。我们可以来计算各个类别的后验概率：<br>P(cancer | 阳性) = P(阳性 | cancer)p(cancer)=0.98* 0.008 = 0.0078<br>P(无cancer | 阳性) =P(阳性 | 无cancer)* p(无cancer)=0.03* 0.992 = 0.0298<br>因此，应该判断为无癌症。</p>\n<p>在这个例子中，类条件概率，P(cancer|阳性)和P(无cancer|阳性)直接告诉了我们。</p>\n<p>一般地，对<strong>类条件概率$$P(X \\vert Y)$$</strong>的估计，有朴素贝叶斯分类器和贝叶斯信念网络两种方法，这里介绍朴素贝叶斯分类器。</p>\n<p>###1.3 朴素贝叶斯分类器<br><strong>1、条件独立性</strong><br>给定类标号y，朴素贝叶斯分类器在估计类条件概率时假设属性之间条件独立。条件独立假设可以形式化的表达如下：<br>$$<br>\\prod\\limits_{i=1}^{n} P(x_i  \\vert Y=y)<br>$$<br>其中每个训练样本可用一个属性向量$$X=(x_1,x_2,x_3,…,x_n)$$表示，各个属性之间条件独立。</p>\n<p>比如，对于一篇文章，</p>\n<blockquote>\n<p>Good good study,Day day up.</p>\n</blockquote>\n<p>可以用一个文本特征向量来表示，<code>x=(Good, good, study, Day, day , up)</code>。一般各个词语之间肯定不是相互独立的，有一定的上下文联系。但在朴素贝叶斯文本分类时，我们假设个单词之间没有联系，可以用一个文本特征向量来表示这篇文章，这就是“朴素”的来历。</p>\n<p><strong>2、朴素贝叶斯如何工作</strong><br><strong>有了条件独立假设，就不必计算X和Y的每一种组合的类条件概率</strong>，只需对给定的Y，计算每个$$x_i$$的条件概率。后一种方法更实用，因为它不需要很大的训练集就能获得较好的概率估计。</p>\n<p><strong>3、估计分类属性的条件概率</strong><br>$$P(x_i \\vert Y=y)$$怎么计算呢？它一般根据类别y下包含属性$$x_i$$的实例的比例来估计。以文本分类为例，xi表示一个单词，$$P(x_i \\vert Y=y)=$$包含该类别下包含单词的xi的文章总数/ 该类别下的文章总数。</p>\n<p><strong>4、贝叶斯分类器举例</strong><br>假设给定了如下训练样本数据，我们学习的目标是根据给定的天气状况判断你对PlayTennis这个请求的回答是Yes还是No。</p>\n<table border=\"1\" cellspacing=\"0\" cellpadding=\"0\"><br><tbody><br><tr><br><td valign=\"top\" width=\"95\">Day</td><br><td valign=\"top\" width=\"95\">Outlook</td><br><td valign=\"top\" width=\"95\">Temperature</td><br><td valign=\"top\" width=\"95\">Humidity</td><br><td valign=\"top\" width=\"95\">Wind</td><br><td valign=\"top\" width=\"95\">PlayTennis</td><br></tr><br><tr><br><td valign=\"top\" width=\"95\">D1</td><br><td valign=\"top\" width=\"95\">Sunny</td><br><td valign=\"top\" width=\"95\">Hot</td><br><td valign=\"top\" width=\"95\">High</td><br><td valign=\"top\" width=\"95\">Weak</td><br><td valign=\"top\" width=\"95\">No</td><br></tr><br><tr><br><td valign=\"top\" width=\"95\">D2</td><br><td valign=\"top\" width=\"95\">Sunny</td><br><td valign=\"top\" width=\"95\">Hot</td><br><td valign=\"top\" width=\"95\">High</td><br><td valign=\"top\" width=\"95\">Strong</td><br><td valign=\"top\" width=\"95\">No</td><br></tr><br><tr><br><td valign=\"top\" width=\"95\">D3</td><br><td valign=\"top\" width=\"95\">Overcast</td><br><td valign=\"top\" width=\"95\">Hot</td><br><td valign=\"top\" width=\"95\">High</td><br><td valign=\"top\" width=\"95\">Weak</td><br><td valign=\"top\" width=\"95\">Yes</td><br></tr><br><tr><br><td valign=\"top\" width=\"95\">D4</td><br><td valign=\"top\" width=\"95\">Rain</td><br><td valign=\"top\" width=\"95\">Mild</td><br><td valign=\"top\" width=\"95\">High</td><br><td valign=\"top\" width=\"95\">Weak</td><br><td valign=\"top\" width=\"95\">Yes</td><br></tr><br><tr><br><td valign=\"top\" width=\"95\">D5</td><br><td valign=\"top\" width=\"95\">Rain</td><br><td valign=\"top\" width=\"95\">Cool</td><br><td valign=\"top\" width=\"95\">Normal</td><br><td valign=\"top\" width=\"95\">Weak</td><br><td valign=\"top\" width=\"95\">Yes</td><br></tr><br><tr><br><td valign=\"top\" width=\"95\">D6</td><br><td valign=\"top\" width=\"95\">Rain</td><br><td valign=\"top\" width=\"95\">Cool</td><br><td valign=\"top\" width=\"95\">Normal</td><br><td valign=\"top\" width=\"95\">Strong</td><br><td valign=\"top\" width=\"95\">No</td><br></tr><br><tr><br><td valign=\"top\" width=\"95\">D7</td><br><td valign=\"top\" width=\"95\">Overcast</td><br><td valign=\"top\" width=\"95\">Cool</td><br><td valign=\"top\" width=\"95\">Normal</td><br><td valign=\"top\" width=\"95\">Strong</td><br><td valign=\"top\" width=\"95\">Yes</td><br></tr><br><tr><br><td valign=\"top\" width=\"95\">D8</td><br><td valign=\"top\" width=\"95\">Sunny</td><br><td valign=\"top\" width=\"95\">Mild</td><br><td valign=\"top\" width=\"95\">High</td><br><td valign=\"top\" width=\"95\">Weak</td><br><td valign=\"top\" width=\"95\">No</td><br></tr><br><tr><br><td valign=\"top\" width=\"95\">D9</td><br><td valign=\"top\" width=\"95\">Sunny</td><br><td valign=\"top\" width=\"95\">Cool</td><br><td valign=\"top\" width=\"95\">Normal</td><br><td valign=\"top\" width=\"95\">Weak</td><br><td valign=\"top\" width=\"95\">Yes</td><br></tr><br><tr><br><td valign=\"top\" width=\"95\">D10</td><br><td valign=\"top\" width=\"95\">Rain</td><br><td valign=\"top\" width=\"95\">Mild</td><br><td valign=\"top\" width=\"95\">Normal</td><br><td valign=\"top\" width=\"95\">Weak</td><br><td valign=\"top\" width=\"95\">Yes</td><br></tr><br><tr><br><td valign=\"top\" width=\"95\">D11</td><br><td valign=\"top\" width=\"95\">Sunny</td><br><td valign=\"top\" width=\"95\">Mild</td><br><td valign=\"top\" width=\"95\">Normal</td><br><td valign=\"top\" width=\"95\">Strong</td><br><td valign=\"top\" width=\"95\">Yes</td><br></tr><br><tr><br><td valign=\"top\" width=\"95\">D12</td><br><td valign=\"top\" width=\"95\">Overcast</td><br><td valign=\"top\" width=\"95\">Mild</td><br><td valign=\"top\" width=\"95\">High</td><br><td valign=\"top\" width=\"95\">Strong</td><br><td valign=\"top\" width=\"95\">Yes</td><br></tr><br><tr><br><td valign=\"top\" width=\"95\">D13</td><br><td valign=\"top\" width=\"95\">Overcast</td><br><td valign=\"top\" width=\"95\">Hot</td><br><td valign=\"top\" width=\"95\">Normal</td><br><td valign=\"top\" width=\"95\">Weak</td><br><td valign=\"top\" width=\"95\">Yes</td><br></tr><br><tr><br><td valign=\"top\" width=\"95\">D14</td><br><td valign=\"top\" width=\"95\">Rain</td><br><td valign=\"top\" width=\"95\">Mild</td><br><td valign=\"top\" width=\"95\">High</td><br><td valign=\"top\" width=\"95\">Strong</td><br><td valign=\"top\" width=\"95\">No</td><br></tr><br></tbody><br></table><br>可以看到这里样本数据集提供了14个训练样本，我们将使用此表的数据，并结合朴素贝叶斯分类器来分类下面的新实例：<br>x = (Outlook = Sunny,Temprature = Cool,Humidity = High,Wind = Strong)<br><br>在这个例子中，属性向量X=(Outlook, Temperature, Humidity, Wind)，类集合Y={Yes, No}。我们需要利用训练数据计算后验概率$$P(Yes \\vert x)$$和$$P(No \\vert x)$$，如果$$P(Yes \\vert x)&gt;P(No \\vert x)$$，那么新实例分类为Yes，否则为No。<br><br>为了计算后验概率，我们需要计算先验概率P(Yes)和P(No)和类条件概率$$P(x_i \\vert Y)$$。<br><br>因为有9个样本属于Yes，5个样本属于No，所以$$P(Yes)=\\dfrac{9}{14}$$, $$P(No)=\\dfrac{5}{14}$$。类条件概率计算如下：<br>$$P(Outlook = Sunny \\vert Yes)=\\dfrac{2}{9}　　　P(Outlook = Sunny \\vert No)=\\dfrac{3}{5}$$<br>$$P(Temprature = Cool  \\vert Yes) =\\dfrac{3}{9}　　　P(Temprature = Cool  \\vert No) =\\dfrac{1}{5}$$<br>$$P(Humidity = High  \\vert Yes) =\\dfrac{3}{9}　　　P(Humidity = High  \\vert No) =\\dfrac{4}{5}$$<br>$$P(Wind = Strong  \\vert Yes) =\\dfrac{3}{9}　　　P(Wind = Strong  \\vert No) =\\dfrac{3}{5}$$<br><br>后验概率计算如下：<br>$$<br>\\begin{aligned}<br>P(Yes  \\vert  x) &amp; = P(Outlook = Sunny \\vert Yes) \\times P(Temprature = Cool  \\vert Yes) \\newline<br>&amp; \\times P(Humidity = High  \\vert Yes) \\times P(Wind = Strong  \\vert Yes) \\times P(Yes) \\newline<br>&amp; =\\dfrac{2}{9} \\times \\dfrac{3}{9} \\times \\dfrac{3}{9} \\times \\dfrac{3}{9} \\times \\dfrac{3}{9} \\times \\dfrac{9}{14}=\\dfrac{2}{243}=\\dfrac{9}{1701} \\approx 0.00529<br>\\end{aligned}<br>$$<br>$$<br>\\begin{aligned}<br>P(No  \\vert  x)&amp;= P(Outlook = Sunny \\vert No) \\times P(Temprature = Cool  \\vert No) \\newline<br>&amp; \\times P(Humidity = High  \\vert No) \\times P(Wind = Strong  \\vert No) \\times P(No) \\newline<br>&amp; =\\dfrac{3}{5}\\times \\dfrac{1}{5} \\times \\dfrac{4}{5} \\times \\dfrac{3}{5} \\times  \\dfrac{5}{14}=\\dfrac{18}{875} \\approx 0.02057<br>\\end{aligned}<br>$$<br>通过计算得出$$P(No  \\vert  x)&gt; P(Yes  \\vert  x)$$，所以该样本分类为No[^3]。<br><br><strong>5、条件概率的m估计</strong><br>假设有来了一个新样本 $$x_1= (Outlook = Cloudy,Temprature = Cool,Humidity = High,Wind = Strong)$$，要求对其分类。我们来开始计算，<br>$$P(Outlook = Cloudy \\vert Yes)=\\dfrac{0}{9}=0  P(Outlook = Cloudy  \\vert No)=\\dfrac{0}{5}=0$$<br>计算到这里，大家就会意识到，这里出现了一个新的属性值，在训练样本中所没有的。如果有一个属性的类条件概率为0，则整个类的后验概率就等于0，我们可以直接得到后验概率$$P(Yes  \\vert  x_1)= P(No  \\vert  x_1)=0$$，这时二者相等，无法分类。<br><br>当训练样本不能覆盖那么多的属性值时，都会出现上述的窘境。简单的使用样本比例来估计类条件概率的方法太脆弱了，尤其是当训练样本少而属性数目又很大时。<br><br>解决方法是使用m估计(m-estimate)方法来估计条件概率：<br>$$<br>P(x_i \\vert y_i)=\\dfrac{n_c+mp}{n+m}<br>$$<br>n是类$$y_j$$中的样本总数，$$n_c$$是类$$y_j$$中取值$$x_i$$的样本数，m是称为等价样本大小的参数，而p是用户指定的参数。如果没有训练集（即n=0），则$$P(x_i \\vert y_i)=p$$, 因此p可以看作是在类$$y_j$$的样本中观察属性值$$x_i$$的先验概率。等价样本大小决定先验概率和观测概率$$\\dfrac{n_c}{n}$$之间的平衡[^2]。<br><br>##2 朴素贝叶斯文本分类算法<br>现在开始进入本文的主旨部分：如何将贝叶斯分类器应用到文本分类上来。<br><br>###2.1文本分类问题<br>在文本分类中，假设我们有一个文档d∈X，X是文档向量空间(document space)，和一个固定的类集合C={c1,c2,…,cj}，类别又称为标签。显然，文档向量空间是一个高维度空间。我们把一堆打了标签的文档集合<d,c>作为训练样本，<d,c>∈X×C。例如：<br><d,c>={Beijing joins the World Trade Organization, China}<br>对于这个只有一句话的文档，我们把它归类到 China，即打上china标签。<br><br>我们期望用某种训练算法，训练出一个函数γ，能够将文档映射到某一个类别：<br>γ:X→C<br><br>这种类型的学习方法叫做有监督学习，因为事先有一个监督者（我们事先给出了一堆打好标签的文档）像个老师一样监督着整个学习过程。<br><br>朴素贝叶斯分类器是一种有监督学习，常见有两种模型，多项式模型(multinomial model)和伯努利模型(Bernoulli model)<a href=\"洞庭散人，“[基于朴素贝叶斯分类器的文本分类算法（上）](http://www.cnblogs.com/phinecos/archive/2008/10/21/1315948.html)”，“[基于朴素贝叶斯分类器的文本分类算法（下）](http://www.cnblogs.com/phinecos/archive/2008/10/21/1316044.html)”，2008\">^4</a>。<br><br>###2.2 多项式模型<br><br>####2.2.1 基本原理<br>在多项式模型中， 设某文档$$d=(t_1,t_2,…,t_k)$$，tk是该文档中出现过的单词，允许重复，则<br>先验概率$$P(c)=$$ 类c下单词总数/整个训练样本的单词总数<br>类条件概率$$P(t_k \\vert c)=$$(类c下单词tk在各个文档中出现过的次数之和+1)/(类c下单词总数+|V|)<br><br>V是训练样本的单词表（即抽取单词，单词出现多次，只算一个），<code>|V|</code>则表示训练样本包含多少种单词。在这里，<code>m=|V|, p=1/|V|</code>。<br><br>$$P(t_k \\vert c)=$$可以看作是单词tk在证明d属于类c上提供了多大的证据，而P(c)则可以认为是类别c在整体上占多大比例(有多大可能性)。<br><br>####2.2.2 伪代码[^1]<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">//C，类别集合，D，用于训练的文本文件集合</span></div><div class=\"line\">TrainMultiNomialNB(C,D) &#123;</div><div class=\"line\">    <span class=\"comment\">// 单词出现多次，只算一个</span></div><div class=\"line\">    V←ExtractVocabulary(D)</div><div class=\"line\">    <span class=\"comment\">// 单词可重复计算</span></div><div class=\"line\">    N←CountTokens(D)</div><div class=\"line\">    <span class=\"keyword\">for</span> each c∈C</div><div class=\"line\">        <span class=\"comment\">// 计算类别c下的单词总数</span></div><div class=\"line\">        <span class=\"comment\">// N和Nc的计算方法和Introduction to Information Retrieval上的不同，个人认为</span></div><div class=\"line\">        <span class=\"comment\">//该书是错误的，先验概率和类条件概率的计算方法应当保持一致</span></div><div class=\"line\">        Nc←CountTokensInClass(D,c)</div><div class=\"line\">        prior[c]←Nc/N</div><div class=\"line\">        <span class=\"comment\">// 将类别c下的文档连接成一个大字符串</span></div><div class=\"line\">        textc←ConcatenateTextOfAllDocsInClass(D,c)</div><div class=\"line\">        <span class=\"keyword\">for</span> each t∈V</div><div class=\"line\">            <span class=\"comment\">// 计算类c下单词t的出现次数</span></div><div class=\"line\">            Tct←CountTokensOfTerm(textc,t)</div><div class=\"line\">        <span class=\"keyword\">for</span> each t∈V</div><div class=\"line\">            <span class=\"comment\">//计算P(t|c)</span></div><div class=\"line\">            condprob[t][c]← </div><div class=\"line\">    <span class=\"keyword\">return</span> V,prior,condprob</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">ApplyMultiNomialNB(C,V,prior,condprob,d) &#123;</div><div class=\"line\">    <span class=\"comment\">// 将文档d中的单词抽取出来，允许重复，如果单词是全新的，在全局单词表V中都</span></div><div class=\"line\">    <span class=\"comment\">// 没出现过，则忽略掉</span></div><div class=\"line\">    W←ExtractTokensFromDoc(V,d)</div><div class=\"line\">    <span class=\"keyword\">for</span> each c∈C</div><div class=\"line\">        score[c]←prior[c]</div><div class=\"line\">        <span class=\"keyword\">for</span> each t∈W</div><div class=\"line\">            <span class=\"keyword\">if</span> t∈Vd</div><div class=\"line\">                score[c] *= condprob[t][c]</div><div class=\"line\">    <span class=\"keyword\">return</span> max(score[c])</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure><br><br>####2.2.3 举例<br>给定一组分类好了的文本训练数据，如下：<br><br><table border=\"1\" cellspacing=\"0\" cellpadding=\"0\"><br><tbody><br><tr><br><td valign=\"top\" width=\"64\">docId</td><br><td valign=\"top\" width=\"236\">doc</td><br><td valign=\"top\" width=\"126\">类别In c=China?</td><br></tr><br><tr><br><td valign=\"top\" width=\"64\">1</td><br><td valign=\"top\" width=\"236\">Chinese Beijing Chinese</td><br><td valign=\"top\" width=\"126\">yes</td><br></tr><br><tr><br><td valign=\"top\" width=\"64\">2</td><br><td valign=\"top\" width=\"236\">Chinese Chinese Shanghai</td><br><td valign=\"top\" width=\"126\">yes</td><br></tr><br><tr><br><td valign=\"top\" width=\"64\">3</td><br><td valign=\"top\" width=\"236\">Chinese Macao</td><br><td valign=\"top\" width=\"126\">yes</td><br></tr><br><tr><br><td valign=\"top\" width=\"64\">4</td><br><td valign=\"top\" width=\"236\">Tokyo Japan Chinese</td><br><td valign=\"top\" width=\"126\">no</td><br></tr><br></tbody><br></table>\n\n<p>给定一个新样本</p>\n<blockquote>\n<p>Chinese Chinese Chinese Tokyo Japan</p>\n</blockquote>\n<p>对其进行分类。该文本用属性向量表示为<code>d=(Chinese, Chinese, Chinese, Tokyo, Japan)</code>，类别集合为<code>Y={yes, no}</code>。</p>\n<p>类yes下总共有8个单词，类no下总共有3个单词，训练样本单词总数为11，因此$$P(yes)=\\dfrac{8}{11}, P(no)=\\dfrac{3}{11}$$。类条件概率计算如下：<br>$$P(Chinese  \\vert  yes)=\\dfrac{5+1}{8+6}=\\dfrac{6}{14}=\\dfrac{3}{7}$$<br>$$P(Japan  \\vert  yes)=P(Tokyo  \\vert  yes)= \\dfrac{0+1}{8+6}=\\dfrac{1}{14}$$<br>$$P(Chinese \\vert no)=\\dfrac{1+1}{3+6}=\\dfrac{2}{9}$$<br>$$P(Japan \\vert no)=P(Tokyo \\vert  no) =\\dfrac{1+1}{3+6}=\\dfrac{2}{9}$$<br>分母中的8，是指yes类别下textc的长度，也即训练样本的单词总数，6是指训练样本有Chinese,Beijing,Shanghai, Macao, Tokyo, Japan 共6个单词，3是指no类下共有3个单词。</p>\n<p>有了以上类条件概率，开始计算后验概率，<br>$$P(yes  \\vert  d)=\\left(\\dfrac{3}{7}\\right)^3 \\times \\dfrac{1}{14} \\times \\dfrac{1}{14} \\times \\dfrac{8}{11}=\\dfrac{108}{184877} \\approx 0.00058417$$<br>$$P(no  \\vert  d)= \\left(\\dfrac{2}{9}\\right)^3 \\times \\dfrac{2}{9} \\times \\dfrac{2}{9} \\times \\dfrac{3}{11}=\\dfrac{32}{216513} \\approx 0.00014780$$<br>因此，这个文档属于类别china。</p>\n<p>###2.3 伯努利模型</p>\n<p>####2.3.1 基本原理<br>$$P(c)=$$ 类c下文件总数/整个训练样本的文件总数<br>$$P(t_k \\vert c)=$$(类c下包含单词tk的文件数+1)/(类c下单词总数+2)<br>在这里，$$m=2, p=\\dfrac{1}{2}$$。</p>\n<p>后验概率的计算，也有点变化，见下面的伪代码。</p>\n<p>####2.3.2 伪代码<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">//C，类别集合，D，用于训练的文本文件集合</span></div><div class=\"line\">TrainBernoulliNB(C, D) &#123;</div><div class=\"line\">    <span class=\"comment\">// 单词出现多次，只算一个</span></div><div class=\"line\">V←ExtractVocabulary(D)</div><div class=\"line\">    <span class=\"comment\">// 计算文件总数</span></div><div class=\"line\">    N←CountDocs(D)</div><div class=\"line\">    <span class=\"keyword\">for</span> each c∈C</div><div class=\"line\">        <span class=\"comment\">// 计算类别c下的文件总数</span></div><div class=\"line\">        Nc←CountDocsInClass(D,c)</div><div class=\"line\">        prior[c]←Nc/N</div><div class=\"line\">        <span class=\"keyword\">for</span> each t∈V</div><div class=\"line\">            <span class=\"comment\">// 计算类c下包含单词t的文件数</span></div><div class=\"line\">            Nct←CountDocsInClassContainingTerm(D,c,t)</div><div class=\"line\">            <span class=\"comment\">//计算P(t|c)</span></div><div class=\"line\">            condprob[t][c]←(Nct+<span class=\"number\">1</span>)/(Nct+<span class=\"number\">2</span>)</div><div class=\"line\">    <span class=\"keyword\">return</span> V,prior,condprob</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">ApplyBernoulliNB(C,V,prior,condprob,d) &#123;</div><div class=\"line\">    <span class=\"comment\">// 将文档d中单词表抽取出来，如果单词是全新的，在全局单词表V中都没出现过，</span></div><div class=\"line\">    <span class=\"comment\">// 则舍弃</span></div><div class=\"line\">    Vd←ExtractTermsFromDoc(V,d)</div><div class=\"line\">    <span class=\"keyword\">for</span> each c∈C</div><div class=\"line\">        score[c]←prior[c]</div><div class=\"line\">        <span class=\"keyword\">for</span> each t∈V</div><div class=\"line\">            <span class=\"keyword\">if</span> t∈Vd</div><div class=\"line\">                score[c] *= condprob[t][c]</div><div class=\"line\">            <span class=\"keyword\">else</span></div><div class=\"line\">                score[c] *= (<span class=\"number\">1</span>-condprob[t][c])</div><div class=\"line\">    <span class=\"keyword\">return</span> max(score[c])</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure></p>\n<p>####2.3.3 举例<br>还是使用前面例子中的数据，不过模型换成了使用伯努利模型。</p>\n<p>类yes下总共有3个文件，类no下有1个文件，训练样本文件总数为11，因此$$P(yes)=\\dfrac{3}{4}, P(Chinese  \\vert  yes)=\\dfrac{3+1}{3+2}=\\dfrac{4}{5}$$<br>$$P(Japan  \\vert  yes)=P(Tokyo  \\vert  yes)=\\dfrac{0+1}{3+2}=\\dfrac{1}{5}$$<br>$$P(Beijing  \\vert  yes)= P(Macao \\vert yes)= P(Shanghai  \\vert yes)=\\dfrac{1+1}{3+2}=\\dfrac{2}{5}$$<br>$$P(Chinese \\vert no)=\\dfrac{1+1}{1+2}=\\dfrac{2}{3}$$<br>$$P(Japan \\vert no)=P(Tokyo \\vert  no) =\\dfrac{1+1}{1+2}=\\dfrac{2}{3}$$<br>$$P(Beijing \\vert  no)= P(Macao \\vert  no)= P(Shanghai  \\vert  no)=\\dfrac{0+1}{1+2}=\\dfrac{1}{3}$$  </p>\n<p>有了以上类条件概率，开始计算后验概率，<br>$$<br>\\begin{aligned}<br>P(yes  \\vert  d)&amp;=P(yes) \\times P(Chinese \\vert yes) \\times P(Japan \\vert yes) \\times P(Tokyo \\vert yes) \\newline<br>&amp;\\times (1-P(Beijing \\vert yes)) \\times (1-P(Shanghai \\vert yes))\\newline<br>&amp;\\times (1-P(Macao \\vert yes)) \\newline<br>&amp;=\\dfrac{3}{4} \\times \\dfrac{4}{5} \\times \\dfrac{1}{5} \\times \\dfrac{1}{5} \\times (1-\\dfrac{2}{5} \\times (1-\\dfrac{2}{5}) \\times (1-\\dfrac{2}{5})=\\dfrac{81}{15625} \\approx 0.005<br>\\end{aligned}<br>$$<br>$$P(no   \\vert   d)= \\dfrac{1}{4} \\times \\dfrac{2}{3} \\times \\dfrac{2}{5} \\times \\dfrac{2}{5} \\times (1-\\dfrac{1}{3}) \\times (1-\\dfrac{1}{3}) \\times (1-\\dfrac{1}{3})=\\dfrac{16}{729} \\approx 0.022$$<br>因此，这个文档不属于类别china。</p>\n<p>###2.4 两个模型的区别<br>二者的计算粒度不一样，多项式模型以单词为粒度，伯努利模型以文件为粒度，因此二者的先验概率和类条件概率的计算方法都不同。</p>\n<p>计算后验概率时，对于一个文档d，多项式模型中，只有在d中出现过的单词，才会参与后验概率计算，伯努利模型中，没有在d中出现，但是在全局单词表中出现的单词，也会参与计算，不过是作为“反方”参与的。</p>\n<p>##3 代码详解<br>本文附带了一个eclipse工程，有完整的源代码，以及一个微型文本训练库。</p>\n<p>ChineseSpliter用于中文分词，StopWordsHandler用于判断一个单词是否是停止词，ClassifyResult用于保存结果，IntermediateData用于预处理文本语料库，TrainnedModel用于保存训练后得到的数据，NaiveBayesClassifier是基础类，包含了贝叶斯分类器的主要代码，MultiNomialNB是多项式模型，类似的，BernoulliNB是伯努利模型，二者都继承自NaiveBayesClassifier，都只重写了父类的计算先验概率，类条件概率和后验概率这3个函数。</p>\n<p>###3.1 中文分词<br>中文分词不是本文的重点，这里我们直接使用第三方工具，本源码使用的是<a href=\"http://www.jesoft.cn/\">极易中文分词组件</a>，你还可以使用<a href=\"http://chtsai.org/\">MMSEG</a>，中科院的<a href=\"http://ictclas.org/\">ICTCLAS</a>等等。</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">/**</div><div class=\"line\">     * 对给定的文本进行中文分词.</div><div class=\"line\">     * </div><div class=\"line\">     * <span class=\"doctag\">@param</span> text</div><div class=\"line\">     *            给定的文本</div><div class=\"line\">     * <span class=\"doctag\">@param</span> splitToken</div><div class=\"line\">     *            用于分割的标记,如\"|\"</div><div class=\"line\">     * <span class=\"doctag\">@return</span> 分词完毕的文本</div><div class=\"line\">     */</span></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> String <span class=\"title\">split</span><span class=\"params\">(<span class=\"keyword\">final</span> String text, <span class=\"keyword\">final</span> String splitToken)</span> </span>&#123;</div><div class=\"line\">        String result = <span class=\"keyword\">null</span>;</div><div class=\"line\">        </div><div class=\"line\">        <span class=\"keyword\">try</span> &#123;</div><div class=\"line\">            result = analyzer.segment(text, splitToken);</div><div class=\"line\">        &#125; <span class=\"keyword\">catch</span> (IOException e) &#123;</div><div class=\"line\">            e.printStackTrace();</div><div class=\"line\">        &#125;</div><div class=\"line\">        <span class=\"keyword\">return</span> result;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<p>###3.2 停止词处理<br>停止词(Stop Word)是指那些无意义的字或词，如“的”、“在”等。去掉文档中的停止词也是必须的一项工作,这里简单的定义了一些常见的停止词，并根据这些常用停止词在分词时进行判断。</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">/** 常用停用词. */</span></div><div class=\"line\">    <span class=\"keyword\">private</span> <span class=\"keyword\">static</span> String[] stopWordsList = &#123;</div><div class=\"line\">            <span class=\"comment\">// 来自 c:\\Windows\\System32\\NOISE.CHS</span></div><div class=\"line\">            <span class=\"string\">\"的\"</span>, <span class=\"string\">\"一\"</span>, <span class=\"string\">\"不\"</span>, <span class=\"string\">\"在\"</span>, <span class=\"string\">\"人\"</span>, <span class=\"string\">\"有\"</span>, <span class=\"string\">\"是\"</span>, <span class=\"string\">\"为\"</span>, <span class=\"string\">\"以\"</span>, <span class=\"string\">\"于\"</span>, <span class=\"string\">\"上\"</span>, <span class=\"string\">\"他\"</span>, <span class=\"string\">\"而\"</span>,</div><div class=\"line\">            <span class=\"string\">\"后\"</span>, <span class=\"string\">\"之\"</span>, <span class=\"string\">\"来\"</span>, <span class=\"string\">\"及\"</span>, <span class=\"string\">\"了\"</span>, <span class=\"string\">\"因\"</span>, <span class=\"string\">\"下\"</span>, <span class=\"string\">\"可\"</span>, <span class=\"string\">\"到\"</span>, <span class=\"string\">\"由\"</span>, <span class=\"string\">\"这\"</span>, <span class=\"string\">\"与\"</span>, <span class=\"string\">\"也\"</span>,</div><div class=\"line\">            <span class=\"string\">\"此\"</span>, <span class=\"string\">\"但\"</span>, <span class=\"string\">\"并\"</span>, <span class=\"string\">\"个\"</span>, <span class=\"string\">\"其\"</span>, <span class=\"string\">\"已\"</span>, <span class=\"string\">\"无\"</span>, <span class=\"string\">\"小\"</span>, <span class=\"string\">\"我\"</span>, <span class=\"string\">\"们\"</span>, <span class=\"string\">\"起\"</span>, <span class=\"string\">\"最\"</span>, <span class=\"string\">\"再\"</span>,</div><div class=\"line\">            <span class=\"string\">\"今\"</span>, <span class=\"string\">\"去\"</span>, <span class=\"string\">\"好\"</span>, <span class=\"string\">\"只\"</span>, <span class=\"string\">\"又\"</span>, <span class=\"string\">\"或\"</span>, <span class=\"string\">\"很\"</span>, <span class=\"string\">\"亦\"</span>, <span class=\"string\">\"某\"</span>, <span class=\"string\">\"把\"</span>, <span class=\"string\">\"那\"</span>, <span class=\"string\">\"你\"</span>, <span class=\"string\">\"乃\"</span>,</div><div class=\"line\">            <span class=\"string\">\"它\"</span>,</div><div class=\"line\">            <span class=\"comment\">// 来自网络</span></div><div class=\"line\">            <span class=\"string\">\"要\"</span>, <span class=\"string\">\"将\"</span>, <span class=\"string\">\"应\"</span>, <span class=\"string\">\"位\"</span>, <span class=\"string\">\"新\"</span>, <span class=\"string\">\"两\"</span>, <span class=\"string\">\"中\"</span>, <span class=\"string\">\"更\"</span>, <span class=\"string\">\"我们\"</span>, <span class=\"string\">\"自己\"</span>, <span class=\"string\">\"没有\"</span>, <span class=\"string\">\"“\"</span>, <span class=\"string\">\"”\"</span>,</div><div class=\"line\">            <span class=\"string\">\"，\"</span>, <span class=\"string\">\"（\"</span>, <span class=\"string\">\"）\"</span>, <span class=\"string\">\"\"</span> &#125;;</div><div class=\"line\"></div><div class=\"line\">    <span class=\"comment\">/**</div><div class=\"line\">     * 判断一个词是否是停止词.</div><div class=\"line\">     * </div><div class=\"line\">     * <span class=\"doctag\">@param</span> word</div><div class=\"line\">     *            要判断的词</div><div class=\"line\">     * <span class=\"doctag\">@return</span> 是停止词，返回true，否则返回false</div><div class=\"line\">     */</span></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">static</span> <span class=\"keyword\">boolean</span> <span class=\"title\">isStopWord</span><span class=\"params\">(<span class=\"keyword\">final</span> String word)</span> </span>&#123;</div><div class=\"line\">        <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>; i &lt; stopWordsList.length; ++i) &#123;</div><div class=\"line\">            <span class=\"keyword\">if</span> (word.equalsIgnoreCase(stopWordsList[i])) &#123;</div><div class=\"line\">                <span class=\"keyword\">return</span> <span class=\"keyword\">true</span>;</div><div class=\"line\">            &#125;</div><div class=\"line\">        &#125;</div><div class=\"line\">        <span class=\"keyword\">return</span> <span class=\"keyword\">false</span>;</div><div class=\"line\">    &#125;</div></pre></td></tr></table></figure>\n<p>###3.3 预处理数据<br>我们这里使用<a href=\"http://www.sogou.com/labs/dl/c.html\">搜狗的文本分类语料库</a>作为训练样本，把SogouC.reduced.20061102.tar.gz解压到D盘，目录结构为</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div></pre></td><td class=\"code\"><pre><div class=\"line\">D:\\Reduced</div><div class=\"line\">         |-- C000008</div><div class=\"line\">         |-- C000010</div><div class=\"line\">         |-- C000013</div><div class=\"line\">         |-- C000014</div><div class=\"line\">         |-- C000016</div><div class=\"line\">         |-- C000020</div><div class=\"line\">         |-- C000022</div><div class=\"line\">         |-- C000023</div><div class=\"line\">         |-- C000024</div></pre></td></tr></table></figure>\n<p>IntermediateData.java主要用于处理文本数据，将所需要的信息计算好，存放到数据库文件中。</p>\n<p>中间数据文件主要保存了如下信息，</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">/** 单词X在类别C下出现的总数. */</span></div><div class=\"line\">\t<span class=\"keyword\">public</span> HashMap[] filesOfXC;</div><div class=\"line\">\t<span class=\"comment\">/** 给定分类下的文件数目. */</span></div><div class=\"line\">    <span class=\"keyword\">public</span> <span class=\"keyword\">int</span>[] filesOfC;</div><div class=\"line\">    <span class=\"comment\">/** 根目录下的文件总数. */</span></div><div class=\"line\">    <span class=\"keyword\">public</span> <span class=\"keyword\">int</span> files;</div><div class=\"line\">    </div><div class=\"line\">\t<span class=\"comment\">/** 单词X在类别C下出现的总数 */</span></div><div class=\"line\">\t<span class=\"keyword\">public</span> HashMap[] tokensOfXC;</div><div class=\"line\">    <span class=\"comment\">/** 类别C下所有单词的总数. */</span></div><div class=\"line\">    <span class=\"keyword\">public</span> <span class=\"keyword\">int</span>[] tokensOfC;</div><div class=\"line\">    <span class=\"comment\">/** 整个语料库中单词的总数. */</span></div><div class=\"line\">    <span class=\"keyword\">public</span> <span class=\"keyword\">int</span> tokens;</div><div class=\"line\">    <span class=\"comment\">/** 整个训练语料所出现的单词. */</span></div><div class=\"line\">    <span class=\"keyword\">public</span> HashSet&lt;String&gt; vocabulary;</div></pre></td></tr></table></figure>\n<p>我们使用命令</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">IntermediateData d:\\Reduced\\ gbk d:\\reduced.db</div></pre></td></tr></table></figure>\n<p>将文本训练库的信息计算好，保存到中间文件中。以后的阶段，我们都不再需要文本语料库了，只需要reduced.db。</p>\n<p>###3.3 训练<br>基本的框架代码都在NaiveBayesClassifier中，MultiNomialNB和BernoulliNB都只是重新实现(override)了这三个函数。</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">/** 计算先验概率P(c). */</span></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">protected</span> <span class=\"keyword\">void</span> <span class=\"title\">calculatePc</span><span class=\"params\">()</span> </span>&#123;</div><div class=\"line\">    &#125;</div><div class=\"line\">    </div><div class=\"line\">    <span class=\"comment\">/** 计算类条件概率P(x|c). */</span></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">protected</span> <span class=\"keyword\">void</span> <span class=\"title\">calculatePxc</span><span class=\"params\">()</span> </span>&#123;</div><div class=\"line\">    &#125;</div><div class=\"line\">    </div><div class=\"line\">    </div><div class=\"line\">    <span class=\"comment\">/**</div><div class=\"line\">     * 计算文本属性向量X在类Cj下的后验概率P(Cj|X).</div><div class=\"line\">     * </div><div class=\"line\">     * <span class=\"doctag\">@param</span> x</div><div class=\"line\">     *            文本属性向量</div><div class=\"line\">     * <span class=\"doctag\">@param</span> cj</div><div class=\"line\">     *            给定的类别</div><div class=\"line\">     * <span class=\"doctag\">@return</span> 后验概率</div><div class=\"line\">     */</span></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">protected</span> <span class=\"keyword\">double</span> <span class=\"title\">calcProd</span><span class=\"params\">(<span class=\"keyword\">final</span> String[] x, <span class=\"keyword\">final</span> <span class=\"keyword\">int</span> cj)</span> </span>&#123;</div><div class=\"line\">        <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</div><div class=\"line\">    &#125;</div></pre></td></tr></table></figure>\n<p>训练函数如下：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div></pre></td><td class=\"code\"><pre><div class=\"line\">public final void train(String intermediateData, String modelFile) &#123;</div><div class=\"line\">    \t// 加载中间数据文件</div><div class=\"line\">    \tloadData(intermediateData);</div><div class=\"line\">    \t</div><div class=\"line\">    \tmodel = new TrainnedModel(db.classifications.length);</div><div class=\"line\">    \t</div><div class=\"line\">    \tmodel.classifications = db.classifications;</div><div class=\"line\">    \tmodel.vocabulary = db.vocabulary;</div><div class=\"line\">    \t// 开始训练</div><div class=\"line\">    \tcalculatePc();</div><div class=\"line\">    \tcalculatePxc();</div><div class=\"line\">    \tdb = null;</div><div class=\"line\">    \t</div><div class=\"line\">    \ttry &#123;</div><div class=\"line\">    \t\t// 用序列化，将训练得到的结果存放到模型文件中</div><div class=\"line\">            ObjectOutputStream out = new ObjectOutputStream(</div><div class=\"line\">                    new FileOutputStream(modelFile));</div><div class=\"line\">            out.writeObject(model);</div><div class=\"line\">            out.close();</div><div class=\"line\">        &#125; catch (IOException e) &#123;</div><div class=\"line\">            e.printStackTrace();</div><div class=\"line\">        &#125;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<p>我们使用命令：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">MultiNomialNB –t d:\\reduced.db d:\\reduced.mdl</div></pre></td></tr></table></figure>\n<p>开始训练，得到的模型文件保存在reduced.mdl中。</p>\n<p>###3.4 分类<br>有了模型文件，就可以用它来进行分类了。</p>\n<p>可以使用命令</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">MultiNomialNB d:\\reduced.mdl d:\\temp.txt gbk</div></pre></td></tr></table></figure>\n<p>对文本文件temp.txt进行分类。</p>\n<p>还可以将当初训练出这个模型文件的文本库，进行分类，看看正确率有多少，即“吃自己的狗食”，命令行如下</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">MultiNomialNB -r d:\\reduced\\ gbk d:\\reduced.mdl</div></pre></td></tr></table></figure>\n<p>分类函数如下：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">/**</div><div class=\"line\"> * 对给定的文本进行分类.</div><div class=\"line\"> * </div><div class=\"line\"> * <span class=\"doctag\">@param</span> text</div><div class=\"line\"> *            给定的文本</div><div class=\"line\"> * <span class=\"doctag\">@return</span> 分类结果</div><div class=\"line\"> */</span></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">final</span> String <span class=\"title\">classify</span><span class=\"params\">(<span class=\"keyword\">final</span> String text)</span> </span>&#123;</div><div class=\"line\">    String[] terms = <span class=\"keyword\">null</span>;</div><div class=\"line\">    <span class=\"comment\">// 中文分词处理(分词后结果可能还包含有停用词）</span></div><div class=\"line\">terms = textSpliter.split(text, <span class=\"string\">\" \"</span>).split(<span class=\"string\">\" \"</span>);</div><div class=\"line\">    <span class=\"comment\">// 去掉停用词，以免影响分类</span></div><div class=\"line\">    terms = ChineseSpliter.dropStopWords(terms); </div><div class=\"line\">        </div><div class=\"line\"><span class=\"keyword\">double</span> probility = <span class=\"number\">0.0</span>;</div><div class=\"line\">    <span class=\"comment\">// 分类结果</span></div><div class=\"line\">    List&lt;ClassifyResult&gt; crs = <span class=\"keyword\">new</span> ArrayList&lt;ClassifyResult&gt;(); </div><div class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>; i &lt; model.classifications.length; i++) &#123;</div><div class=\"line\">        <span class=\"comment\">// 计算给定的文本属性向量terms在给定的分类Ci中的分类条件概率</span></div><div class=\"line\">        probility = calcProd(terms, i);</div><div class=\"line\">        <span class=\"comment\">// 保存分类结果</span></div><div class=\"line\">        ClassifyResult cr = <span class=\"keyword\">new</span> ClassifyResult();</div><div class=\"line\">         cr.classification = model.classifications[i]; <span class=\"comment\">// 分类</span></div><div class=\"line\">        cr.probility = probility; <span class=\"comment\">// 关键字在分类的条件概率</span></div><div class=\"line\">        System.out.println(<span class=\"string\">\"In process....\"</span>);</div><div class=\"line\">        System.out.println(model.classifications[i] + <span class=\"string\">\"：\"</span> + probility);</div><div class=\"line\">        crs.add(cr);</div><div class=\"line\">    &#125;</div><div class=\"line\">        </div><div class=\"line\">    <span class=\"comment\">// 找出最大的元素</span></div><div class=\"line\">    ClassifyResult maxElem = (ClassifyResult) java.util.Collections.max(</div><div class=\"line\">            crs, <span class=\"keyword\">new</span> Comparator() &#123;</div><div class=\"line\">                <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">int</span> <span class=\"title\">compare</span><span class=\"params\">(<span class=\"keyword\">final</span> Object o1, <span class=\"keyword\">final</span> Object o2)</span> </span>&#123;</div><div class=\"line\">                    <span class=\"keyword\">final</span> ClassifyResult m1 = (ClassifyResult) o1;</div><div class=\"line\">                    <span class=\"keyword\">final</span> ClassifyResult m2 = (ClassifyResult) o2;</div><div class=\"line\">                    <span class=\"keyword\">final</span> <span class=\"keyword\">double</span> ret = m1.probility - m2.probility;</div><div class=\"line\">                    <span class=\"keyword\">if</span> (ret &lt; <span class=\"number\">0</span>) &#123;</div><div class=\"line\">                        <span class=\"keyword\">return</span> -<span class=\"number\">1</span>;</div><div class=\"line\">                    &#125; <span class=\"keyword\">else</span> &#123;</div><div class=\"line\">                        <span class=\"keyword\">return</span> <span class=\"number\">1</span>;</div><div class=\"line\">                    &#125;</div><div class=\"line\">                &#125;</div><div class=\"line\">            &#125;);</div><div class=\"line\"></div><div class=\"line\">    <span class=\"keyword\">return</span> maxElem.classification;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<p>测试正确率的函数getCorrectRate()，核心代码就是对每个文本文件调用classify()，将得到的类别和原始的类别比较，经过统计后就可以得到百分比。</p>\n<p>更多细节请读者阅读<a href=\"http://yanjiuyanjiu-wordpress.stor.sinaapp.com/uploads/2010/05/NaiveBayesClassifier.zip\">源代码</a>。</p>\n<p>##参考文献</p>\n<p>[^1]: Christopher D. Manning, Prabhakar Raghavan, Hinrich Schütze, <a href=\"http://nlp.stanford.edu/IR-book/\">Introduction to Information Retrieval</a>, Cambridge University Press, 2008, chapter 13, Text classification and Naive Bayes.</p>\n<p>[^2]: Pang-Ning Tan, Michael Steinbach, Vipin Kumar, 《<a href=\"http://book.douban.com/subject/1786120/\">数据挖掘导论</a>》，北京：人民邮电出版社，2007，第140~145页。</p>\n<p>[^3]: 石志伟, 吴功宜, “<a href=\"http://d.wanfangdata.com.cn/Conference_5615512.aspx\">基于朴素贝叶斯分类器的文本分类算法</a>”, 第一届全国信息检索与内容安全学术会议，2004</p>\n<p>[^5]: DL88250, “<a href=\"http://blog.csdn.net/DL88250/archive/2008/02/20/2108164.aspx\">朴素贝叶斯中文文本分类器的研究与实现（1）</a>”，“<a href=\"http://blog.csdn.net/DL88250/archive/2008/03/27/2224126.aspx\">朴素贝叶斯中文文本分类器的研究与实现（2）</a>”，2008</p>"},{"layout":"post","title":"SSH无密码登录的配置","date":"2012-01-02T02:16:00.000Z","comments":1,"_content":"\n根据公钥加密的思想，如果机器A想无密码登录其他N台机器，只需要在自己机器上生成一对公钥和密钥，然后把密钥给这N台机器，这样，这N台机器，有了A的公钥，就可以解密A的数据包，跟A正常通信了。\n\n通常在一个集群中，我们会选择一台机器作为跳板机，在这台机器上登录其他机器，因此，无名需要在跳板机上生成一对公钥和密钥。一般的，我们也会把跳板板机作为整个集群的master，例如Hadoop的NameNode，因此最好选一台内存比较大的机器作为跳板机。\n\n下面详细讲解如何配置从跳板机SSH无密码登录到所有机器（包括自己）。\n\n根据公钥加密的思想，如果机器A想无密码登录其他N台机器，只需要在自己机器上生成一对公钥和密钥，然后把密钥给这N台机器，这样，这N台机器，有了A的公钥，就可以解密A的数据包，跟A正常通信了。\n\n通常在一个集群中，我们会选择一台机器作为跳板机，在这台机器上登录其他机器，因此，无名需要在跳板机上生成一对公钥和密钥。一般的，我们也会把跳板板机作为整个集群的master，例如Hadoop的NameNode，因此最好选一台内存比较大的机器作为跳板机。\n\n下面详细讲解如何配置从跳板机SSH无密码登录到所有机器（包括自己）。\n\n##前提： 修改hosts文件\n假设有三台机器，`192.168.1.131, 192.168.1.132, 192.168.1.133`，hostname分别是master, slave01, slave02\n\n##1.在master上生成一对公钥和密钥\n\n    dev@master:~$ ssh-keygen -t dsa -P '' -f ~/.ssh/id_dsa\n    \n##2. 将公钥拷贝到自己\n\n    dev@master:~$ cat ~/.ssh/id_dsa.pub >> ~/.ssh/authorized_keys\n\n##3. 将公钥拷贝到其他机器\n\n    dev@master:~$ scp ~/.ssh/id_dsa.pub dev@slave01:~\n    dev@master:~$ scp ~/.ssh/id_dsa.pub dev@slave02:~\n    #追加到authorized_keys\n    dev@master:~$ ssh slave01\n    dev@slave01:~$ mkdir .ssh\n    dev@slave01:~$ cat id_dsa.pub >> .ssh/authorized_keys\n    dev@slave01:~$ exit\n    dev@master:~$ ssh slave02\n    dev@slave02:~$ mkdir .ssh\n    dev@slave02:~$ cat id_dsa.pub >> .ssh/authorized_keys\n    dev@slave02:~$ exit\n\n##4. 设置.ssh目录和authorized_keys文件的权限\n在被登录的每台机器上，执行如下命令：\n\n    chmod 755 .ssh\n    chmod 600 ~/.ssh/authorized_keys\n\n##5. 测试一下\n\n    #在 master执行\n    dev@master:~$ ssh slave01\n\n第一次还是需要密码的，`exit`退出再试一次，就不需要密码了。\n\n如果登陆不上，试试先关闭所有机器的防火墙，例如Ubuntu的命令是：\n\n\tdev@slave01:~$ sudo ufw disable\n\n##参考资料\n[Howto Linux / UNIX setup SSH with DSA public key authentication (password less login)](http://www.cyberciti.biz/faq/ssh-password-less-login-with-dsa-publickey-authentication/)\n\n[HOWTO: Generating SSH Keys for Passwordless Login](http://hortonworks.com/kb/generating-ssh-keys-for-passwordless-login/)\n","source":"_posts/2012-01-02-ssh-passwordless-login-configuration.md","raw":"---\nlayout: post\ntitle: \"SSH无密码登录的配置\"\ndate: 2012-01-02 02:16\ncomments: true\ncategories: DevOps\n---\n\n根据公钥加密的思想，如果机器A想无密码登录其他N台机器，只需要在自己机器上生成一对公钥和密钥，然后把密钥给这N台机器，这样，这N台机器，有了A的公钥，就可以解密A的数据包，跟A正常通信了。\n\n通常在一个集群中，我们会选择一台机器作为跳板机，在这台机器上登录其他机器，因此，无名需要在跳板机上生成一对公钥和密钥。一般的，我们也会把跳板板机作为整个集群的master，例如Hadoop的NameNode，因此最好选一台内存比较大的机器作为跳板机。\n\n下面详细讲解如何配置从跳板机SSH无密码登录到所有机器（包括自己）。\n\n根据公钥加密的思想，如果机器A想无密码登录其他N台机器，只需要在自己机器上生成一对公钥和密钥，然后把密钥给这N台机器，这样，这N台机器，有了A的公钥，就可以解密A的数据包，跟A正常通信了。\n\n通常在一个集群中，我们会选择一台机器作为跳板机，在这台机器上登录其他机器，因此，无名需要在跳板机上生成一对公钥和密钥。一般的，我们也会把跳板板机作为整个集群的master，例如Hadoop的NameNode，因此最好选一台内存比较大的机器作为跳板机。\n\n下面详细讲解如何配置从跳板机SSH无密码登录到所有机器（包括自己）。\n\n##前提： 修改hosts文件\n假设有三台机器，`192.168.1.131, 192.168.1.132, 192.168.1.133`，hostname分别是master, slave01, slave02\n\n##1.在master上生成一对公钥和密钥\n\n    dev@master:~$ ssh-keygen -t dsa -P '' -f ~/.ssh/id_dsa\n    \n##2. 将公钥拷贝到自己\n\n    dev@master:~$ cat ~/.ssh/id_dsa.pub >> ~/.ssh/authorized_keys\n\n##3. 将公钥拷贝到其他机器\n\n    dev@master:~$ scp ~/.ssh/id_dsa.pub dev@slave01:~\n    dev@master:~$ scp ~/.ssh/id_dsa.pub dev@slave02:~\n    #追加到authorized_keys\n    dev@master:~$ ssh slave01\n    dev@slave01:~$ mkdir .ssh\n    dev@slave01:~$ cat id_dsa.pub >> .ssh/authorized_keys\n    dev@slave01:~$ exit\n    dev@master:~$ ssh slave02\n    dev@slave02:~$ mkdir .ssh\n    dev@slave02:~$ cat id_dsa.pub >> .ssh/authorized_keys\n    dev@slave02:~$ exit\n\n##4. 设置.ssh目录和authorized_keys文件的权限\n在被登录的每台机器上，执行如下命令：\n\n    chmod 755 .ssh\n    chmod 600 ~/.ssh/authorized_keys\n\n##5. 测试一下\n\n    #在 master执行\n    dev@master:~$ ssh slave01\n\n第一次还是需要密码的，`exit`退出再试一次，就不需要密码了。\n\n如果登陆不上，试试先关闭所有机器的防火墙，例如Ubuntu的命令是：\n\n\tdev@slave01:~$ sudo ufw disable\n\n##参考资料\n[Howto Linux / UNIX setup SSH with DSA public key authentication (password less login)](http://www.cyberciti.biz/faq/ssh-password-less-login-with-dsa-publickey-authentication/)\n\n[HOWTO: Generating SSH Keys for Passwordless Login](http://hortonworks.com/kb/generating-ssh-keys-for-passwordless-login/)\n","slug":"2012-01-02-ssh-passwordless-login-configuration","published":1,"updated":"2016-08-18T09:21:04.000Z","photos":[],"link":"","_id":"cis07pf27000d01pqt2w98y24","content":"<p>根据公钥加密的思想，如果机器A想无密码登录其他N台机器，只需要在自己机器上生成一对公钥和密钥，然后把密钥给这N台机器，这样，这N台机器，有了A的公钥，就可以解密A的数据包，跟A正常通信了。</p>\n<p>通常在一个集群中，我们会选择一台机器作为跳板机，在这台机器上登录其他机器，因此，无名需要在跳板机上生成一对公钥和密钥。一般的，我们也会把跳板板机作为整个集群的master，例如Hadoop的NameNode，因此最好选一台内存比较大的机器作为跳板机。</p>\n<p>下面详细讲解如何配置从跳板机SSH无密码登录到所有机器（包括自己）。</p>\n<p>根据公钥加密的思想，如果机器A想无密码登录其他N台机器，只需要在自己机器上生成一对公钥和密钥，然后把密钥给这N台机器，这样，这N台机器，有了A的公钥，就可以解密A的数据包，跟A正常通信了。</p>\n<p>通常在一个集群中，我们会选择一台机器作为跳板机，在这台机器上登录其他机器，因此，无名需要在跳板机上生成一对公钥和密钥。一般的，我们也会把跳板板机作为整个集群的master，例如Hadoop的NameNode，因此最好选一台内存比较大的机器作为跳板机。</p>\n<p>下面详细讲解如何配置从跳板机SSH无密码登录到所有机器（包括自己）。</p>\n<p>##前提： 修改hosts文件<br>假设有三台机器，<code>192.168.1.131, 192.168.1.132, 192.168.1.133</code>，hostname分别是master, slave01, slave02</p>\n<p>##1.在master上生成一对公钥和密钥</p>\n<pre><code>dev@master:~$ ssh-keygen -t dsa -P &apos;&apos; -f ~/.ssh/id_dsa\n</code></pre><p>##2. 将公钥拷贝到自己</p>\n<pre><code>dev@master:~$ cat ~/.ssh/id_dsa.pub &gt;&gt; ~/.ssh/authorized_keys\n</code></pre><p>##3. 将公钥拷贝到其他机器</p>\n<pre><code>dev@master:~$ scp ~/.ssh/id_dsa.pub dev@slave01:~\ndev@master:~$ scp ~/.ssh/id_dsa.pub dev@slave02:~\n#追加到authorized_keys\ndev@master:~$ ssh slave01\ndev@slave01:~$ mkdir .ssh\ndev@slave01:~$ cat id_dsa.pub &gt;&gt; .ssh/authorized_keys\ndev@slave01:~$ exit\ndev@master:~$ ssh slave02\ndev@slave02:~$ mkdir .ssh\ndev@slave02:~$ cat id_dsa.pub &gt;&gt; .ssh/authorized_keys\ndev@slave02:~$ exit\n</code></pre><p>##4. 设置.ssh目录和authorized_keys文件的权限<br>在被登录的每台机器上，执行如下命令：</p>\n<pre><code>chmod 755 .ssh\nchmod 600 ~/.ssh/authorized_keys\n</code></pre><p>##5. 测试一下</p>\n<pre><code>#在 master执行\ndev@master:~$ ssh slave01\n</code></pre><p>第一次还是需要密码的，<code>exit</code>退出再试一次，就不需要密码了。</p>\n<p>如果登陆不上，试试先关闭所有机器的防火墙，例如Ubuntu的命令是：</p>\n<pre><code>dev@slave01:~$ sudo ufw disable\n</code></pre><p>##参考资料<br><a href=\"http://www.cyberciti.biz/faq/ssh-password-less-login-with-dsa-publickey-authentication/\" target=\"_blank\" rel=\"external\">Howto Linux / UNIX setup SSH with DSA public key authentication (password less login)</a></p>\n<p><a href=\"http://hortonworks.com/kb/generating-ssh-keys-for-passwordless-login/\" target=\"_blank\" rel=\"external\">HOWTO: Generating SSH Keys for Passwordless Login</a></p>\n","excerpt":"","more":"<p>根据公钥加密的思想，如果机器A想无密码登录其他N台机器，只需要在自己机器上生成一对公钥和密钥，然后把密钥给这N台机器，这样，这N台机器，有了A的公钥，就可以解密A的数据包，跟A正常通信了。</p>\n<p>通常在一个集群中，我们会选择一台机器作为跳板机，在这台机器上登录其他机器，因此，无名需要在跳板机上生成一对公钥和密钥。一般的，我们也会把跳板板机作为整个集群的master，例如Hadoop的NameNode，因此最好选一台内存比较大的机器作为跳板机。</p>\n<p>下面详细讲解如何配置从跳板机SSH无密码登录到所有机器（包括自己）。</p>\n<p>根据公钥加密的思想，如果机器A想无密码登录其他N台机器，只需要在自己机器上生成一对公钥和密钥，然后把密钥给这N台机器，这样，这N台机器，有了A的公钥，就可以解密A的数据包，跟A正常通信了。</p>\n<p>通常在一个集群中，我们会选择一台机器作为跳板机，在这台机器上登录其他机器，因此，无名需要在跳板机上生成一对公钥和密钥。一般的，我们也会把跳板板机作为整个集群的master，例如Hadoop的NameNode，因此最好选一台内存比较大的机器作为跳板机。</p>\n<p>下面详细讲解如何配置从跳板机SSH无密码登录到所有机器（包括自己）。</p>\n<p>##前提： 修改hosts文件<br>假设有三台机器，<code>192.168.1.131, 192.168.1.132, 192.168.1.133</code>，hostname分别是master, slave01, slave02</p>\n<p>##1.在master上生成一对公钥和密钥</p>\n<pre><code>dev@master:~$ ssh-keygen -t dsa -P &apos;&apos; -f ~/.ssh/id_dsa\n</code></pre><p>##2. 将公钥拷贝到自己</p>\n<pre><code>dev@master:~$ cat ~/.ssh/id_dsa.pub &gt;&gt; ~/.ssh/authorized_keys\n</code></pre><p>##3. 将公钥拷贝到其他机器</p>\n<pre><code>dev@master:~$ scp ~/.ssh/id_dsa.pub dev@slave01:~\ndev@master:~$ scp ~/.ssh/id_dsa.pub dev@slave02:~\n#追加到authorized_keys\ndev@master:~$ ssh slave01\ndev@slave01:~$ mkdir .ssh\ndev@slave01:~$ cat id_dsa.pub &gt;&gt; .ssh/authorized_keys\ndev@slave01:~$ exit\ndev@master:~$ ssh slave02\ndev@slave02:~$ mkdir .ssh\ndev@slave02:~$ cat id_dsa.pub &gt;&gt; .ssh/authorized_keys\ndev@slave02:~$ exit\n</code></pre><p>##4. 设置.ssh目录和authorized_keys文件的权限<br>在被登录的每台机器上，执行如下命令：</p>\n<pre><code>chmod 755 .ssh\nchmod 600 ~/.ssh/authorized_keys\n</code></pre><p>##5. 测试一下</p>\n<pre><code>#在 master执行\ndev@master:~$ ssh slave01\n</code></pre><p>第一次还是需要密码的，<code>exit</code>退出再试一次，就不需要密码了。</p>\n<p>如果登陆不上，试试先关闭所有机器的防火墙，例如Ubuntu的命令是：</p>\n<pre><code>dev@slave01:~$ sudo ufw disable\n</code></pre><p>##参考资料<br><a href=\"http://www.cyberciti.biz/faq/ssh-password-less-login-with-dsa-publickey-authentication/\">Howto Linux / UNIX setup SSH with DSA public key authentication (password less login)</a></p>\n<p><a href=\"http://hortonworks.com/kb/generating-ssh-keys-for-passwordless-login/\">HOWTO: Generating SSH Keys for Passwordless Login</a></p>\n"},{"layout":"post","title":"在Ubuntu上安装Hadoop","date":"2012-01-03T18:54:00.000Z","comments":1,"_content":"本文所使用的版本是 hadoop 1.0.0，即 [2011年12月27日发布的1.0正式版](http://www.iteye.com/news/23874)。\n\n详细安装步骤如下，有大步骤，每个步骤里面有小步骤，绝大部分是必选，只有2步是可选的，粗体表示要特别注意的地方。\n\n##1. 用vmware workstation 新建三台虚拟机\n首先用vmware workstation 新建一台ubuntu server，装好操作系统，安装各种必须的软件，包括安装好hadoop。安装好后然后用浅拷贝`Create a linked clone` 克隆出两台作为slave，这样有了三台ubuntu机器。启动三台机器，假设IP分别为`192.168.1.131, 192.168.1.132, 192.168.1.133`, 131做为master 和 SecondaryNameNode, 身兼两职，132为 slave01, 133为slave02。\n\n##2. 修改机器名\n这一步看起来貌似不必要，其实是必须的，否则最后运行wordcount等例子时，会出现“Too many fetch-failures”。因为HDFS用hostname而不是IP，来相互之间进行通信（见后面的注意1）。\n\n* 192.168.1.131上执行\n\n\t\tdev@bogon:~$ sudo vi /etc/hostname\n\n输入`master`，重启，会发现命令提示符变为了 `dev@master:~$`\n\n用同样的方法，将`192.168.1.132`改为slave01，`192.168.1.133`改为slave02。\n\n<!-- more -->\n\n##3. 修改master的hosts文件，并拷贝到每台slave上\n\n\tdev@master:~$ sudo vi /etc/hosts\n\n添加三行内容\n\n\t192.168.1.131 master  \n\t192.168.1.132 slave01  \n\t192.168.1.133 slave02  \n\n**注意一定要注释掉**\n\n\t# 127.0.1.1      bogon.localdomain       bogon\n\n\n最后hosts文件内容如下：\n\t\n\t127.0.0.1       localhost\n\t# 127.0.1.1      bogon.localdomain       bogon\n\t192.168.1.131 master\n\t192.168.1.132 slave01\n\t192.168.1.133 slave02\n\t# The following lines are desirable for IPv6 capable hosts\n\t::1     ip6-localhost ip6-loopback\n\tfe00::0 ip6-localnet\n\tff00::0 ip6-mcastprefix\n\tff02::1 ip6-allnodes\n\tff02::2 ip6-allrouters\n\n* 将hosts文件拷贝到另外两台台机器上，覆盖原来的hosts文件\n\n\t\tdev@master:~$ scp /etc/hosts dev@192.168.1.132:~\n\t\tdev@master:~$ scp /etc/hosts dev@192.168.1.133:~\n\n* 在192.168.1.132上执行\n\n\t\tdev@slave01:~$ sudo mv hosts /etc/hosts\n\n* 在192.168.1.133上执行\n\n\t\tdev@slave02:~$ sudo mv hosts /etc/hosts\n\n##4. 配置 master 无密码登陆到所有机器（包括本机）\n参考我的另一篇博客，[SSH无密码登录的配置](http://www.yanjiuyanjiu.com/blog/20120102/)\n\n\n##5. 复制hadoop安装包到所有机器\n从hadoop.apache.org下载 hadoop-1.0.0-bin.tar.gz，上传到master中，解压，然后复制到其他机器，解压。\n\n\tdev@master:~$ tar -zxvf hadoop-1.0.0-bin.tar.gz\n\t\n\tdev@master:~$ scp hadoop-1.0.0-bin.tar.gz dev@192.168.1.132:~\n\t\n\tdev@master:~$ scp hadoop-1.0.0-bin.tar.gz dev@192.168.1.133:~\n\t\n\tdev@slave01:~$ tar -zxvf hadoop-1.0.0-bin.tar.gz\n\t\n\tdev@slave02:~$ tar -zxvf hadoop-1.0.0-bin.tar.gz\n\n##6. 编辑配置文件\n\n\tdev@master:~$ cd hadoop-1.0.0/etc/hadoop\n\t\n\tdev@master:~/hadoop-1.0.0/etc/hadoop$  vi hadoop-env.sh\n\n仅需要设置JAVA_HOME，\n\n\texport JAVA_HOME=/usr/lib/jvm/java-7-openjdk-i386\n\t\ncore-site.xml:\n\n\t<configuration>\n\t\t<property>\n\t\t\t<name>fs.default.name</name>\n\t\t\t<value>hdfs://master:9000</value>\n\t\t</property>\n\t\t<property>\n\t\t\t<name>hadoop.tmp.dir</name>\n\t\t\t<value>/home/dev/hadoop_tmp/</value>\n\t\t</property>\n\t</configuration>\n\nmapred-site.xml:\n\n\t<configuration>\n\t\t<property>\n\t\t\t<name>mapred.job.tracker</name>\n\t\t\t<value>master:9001</value>\n\t\t</property>\n\t</configuration>\n\n\nhdfs-site.xml:\n\n\t<configuration>\n\t\t<property>\n\t\t\t<name>dfs.replication</name>\n\t\t\t<value>3</value>\n\t\t</property>\n\t</configuration>\n\n\nmasters:\n\n\tmaster\n\nslaves:\n\n\tslave01\n\tslave02\n\n\n##7. 将配置文件拷贝到各台slave\n\n\tdev@master:~/hadoop-1.0.0/etc/hadoop$ scp hadoop-env.sh core-site.xml hdfs-site.xml mapred-site.xml masters slaves dev@192.168.1.132:~/hadoop-1.0.0/etc/hadoop\n\t\n\tdev@master:~/hadoop-1.0.0/etc/hadoop$ scp hadoop-env.sh core-site.xml hdfs-site.xml mapred-site.xml masters slaves dev@192.168.1.133:~/hadoop-1.0.0/etc/hadoop\n\n##8. 设置环境变量HADOOP\\_HOME，并将`$HADOOP_HOME/bin`加入PATH\n所有机器都要设置环境变量HADOOP\\_HOME，并将`$HADOOP_HOME/bin`加入PATH，因为master登陆到slave后，要执行`$HADOOP_HOME/bin` 下的一些命令。\n\n\t$ vi .bashrc\n\t\t\n\texport JAVA_HOME=/usr/lib/jvm/java-7-openjdk-i386\n\texport CLASSPATH=$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar\n\texport PATH=$PATH:$JAVA_HOME/bin\n\texport HADOOP_HOME=~/hadoop-1.0.0\n\texport PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin\n\texport CLASSPATH=$CLASSPATH:$HADOOP_HOME/share/hadoop/hadoop-core-1.0.0.jar\n\t\t\n\texport HADOOP_HOME=~/hadoop-1.0.0\n\t\t\n\texport PATH=$PATH:$HADOOP_HOME/bin\n\t\t\n\t$ source .bashrc\n\n##9. 运行 hadoop\n\n\t#只需一次，下次启动不再需要格式化，只需 start-all.sh\n\tdev@master:~$ hadoop  namenode -format）\n\t\n\tdev@master:~$ start-all.sh\n\n\n##10. 检查是否运行成功\n\n\tdev@master:~$ jps\n\t\n\t2615 NameNode\n\t2767 JobTracker\n\t2874 Jps\n\t\n\tdev@slave01:~$ jps\n\t\n\t3415 DataNode\n\t3582 TaskTracker\n\t3499 SecondaryNameNode\n\t3619 Jps\n\t\n\tdev@slave02:~$ jps\n\t\n\t3741 Jps\n\t3618 DataNode\n\t3702 TaskTracker\n\n\n##11. 停止 hadoop集群\n\n\tdev@master:~$ stop-all.sh\n让 slave 节点也 可以启动 整个hadoop集群\n\n\n##注意\n1. 所有配置文件只能用hostname，不能用IP。两年前我不懂，还为此[在stackoverflow上发了帖子](http://stackoverflow.com/questions/8702637/hadoop-conf-fs-default-name-cant-be-setted-ipport-format-directly)。hadoop会反向解析hostname，即使是用了IP，也会使用hostname 来启动TaskTracker。参考[hdfs LAN ip address hostname resolution](http://stackoverflow.com/questions/15230946/hdfs-lan-ip-address-hostname-resolution)，[hadoop入门经验总结- 杨贵堂的博客](http://www.makenotes.net/?p=337004)，[hadoop集群配置](http://51mst.iteye.com/blog/1152439)。\n2. stat-all.sh 启动后，刚刚开始，namenode的日志里有些异常，是正常的，过一两分钟就好了，如果两分钟后，还有异常不断在打印，就有问题了。datanode的日志，从一开始，正常情况下，就没有异常，如果报了异常，说明有异常，要去排除。\n\n3. masters文件，这个文件很容易被误解，它实际上存放的是secondarynamenode，而不是namenode。\n\n\t> An HDFS instance is started on a cluster by logging in to the NameNode machine and running$HADOOP_HOME/bin/start-dfs.sh (orstart-all.sh ). This script. starts a local instance of the NameNode process, logs into every machine listed in theconf/slaves file and starts an instance of the DataNode process, and logs into every machine listed in theconf/masters file and starts an instance of the SecondaryNameNode process. Themasters file does not govern which nodes become NameNodes or JobTrackers; those are started on the machine(s) wherebin/start-dfs.sh andbin/start-mapred.sh are executed. A more accurate filename might be “secondaries,” but that’s not currently the case.\n\n\t参考以下三篇文章：\n\t[Multi-host SecondaryNameNode Configuration](http://www.cloudera.com/blog/2009/02/multi-host-secondarynamenode-configuration/)  \n\t[SecondaryNamenode应用摘记](http://blog.csdn.net/dajuezhao/article/details/5987580)\n\t[hadoop下运行多个SecondaryNameNode的配置](http://blog.csdn.net/AE86_FC/article/details/5284181)\n\n4. 一定要注释掉 hosts里面的 `#127.0.1.1      bogon.localdomain       bogon`，参考 [Hadoop集群机器命名机制](http://blog.sina.com.cn/s/blog_631ffec50100w700.html)，[hadoop集群环境安装中的hosts 配置问题](http://blog.csdn.net/singno116/article/details/6298995)。\n\n5. 当测试ssh是否能连通时，如果连接不上，先记得要关闭防火墙，`sudo ufw disable`，参考[hadoop集群安装步骤](http://blog.csdn.net/make19830723/article/details/6230074)。\n\n\n##更新记录\n2012-01-03 针对 Ubuntu 13.04, Hadoop 1.1.2  \n2012-01-03 针对 Ubuntu 10.04, Hadoop 1.0.0","source":"_posts/2012-01-03-hadoop-installation-on-ubuntu.md","raw":"---\nlayout: post\ntitle: \"在Ubuntu上安装Hadoop\"\ndate: 2012-01-03 18:54\ncomments: true\ncategories: Hadoop\n---\n本文所使用的版本是 hadoop 1.0.0，即 [2011年12月27日发布的1.0正式版](http://www.iteye.com/news/23874)。\n\n详细安装步骤如下，有大步骤，每个步骤里面有小步骤，绝大部分是必选，只有2步是可选的，粗体表示要特别注意的地方。\n\n##1. 用vmware workstation 新建三台虚拟机\n首先用vmware workstation 新建一台ubuntu server，装好操作系统，安装各种必须的软件，包括安装好hadoop。安装好后然后用浅拷贝`Create a linked clone` 克隆出两台作为slave，这样有了三台ubuntu机器。启动三台机器，假设IP分别为`192.168.1.131, 192.168.1.132, 192.168.1.133`, 131做为master 和 SecondaryNameNode, 身兼两职，132为 slave01, 133为slave02。\n\n##2. 修改机器名\n这一步看起来貌似不必要，其实是必须的，否则最后运行wordcount等例子时，会出现“Too many fetch-failures”。因为HDFS用hostname而不是IP，来相互之间进行通信（见后面的注意1）。\n\n* 192.168.1.131上执行\n\n\t\tdev@bogon:~$ sudo vi /etc/hostname\n\n输入`master`，重启，会发现命令提示符变为了 `dev@master:~$`\n\n用同样的方法，将`192.168.1.132`改为slave01，`192.168.1.133`改为slave02。\n\n<!-- more -->\n\n##3. 修改master的hosts文件，并拷贝到每台slave上\n\n\tdev@master:~$ sudo vi /etc/hosts\n\n添加三行内容\n\n\t192.168.1.131 master  \n\t192.168.1.132 slave01  \n\t192.168.1.133 slave02  \n\n**注意一定要注释掉**\n\n\t# 127.0.1.1      bogon.localdomain       bogon\n\n\n最后hosts文件内容如下：\n\t\n\t127.0.0.1       localhost\n\t# 127.0.1.1      bogon.localdomain       bogon\n\t192.168.1.131 master\n\t192.168.1.132 slave01\n\t192.168.1.133 slave02\n\t# The following lines are desirable for IPv6 capable hosts\n\t::1     ip6-localhost ip6-loopback\n\tfe00::0 ip6-localnet\n\tff00::0 ip6-mcastprefix\n\tff02::1 ip6-allnodes\n\tff02::2 ip6-allrouters\n\n* 将hosts文件拷贝到另外两台台机器上，覆盖原来的hosts文件\n\n\t\tdev@master:~$ scp /etc/hosts dev@192.168.1.132:~\n\t\tdev@master:~$ scp /etc/hosts dev@192.168.1.133:~\n\n* 在192.168.1.132上执行\n\n\t\tdev@slave01:~$ sudo mv hosts /etc/hosts\n\n* 在192.168.1.133上执行\n\n\t\tdev@slave02:~$ sudo mv hosts /etc/hosts\n\n##4. 配置 master 无密码登陆到所有机器（包括本机）\n参考我的另一篇博客，[SSH无密码登录的配置](http://www.yanjiuyanjiu.com/blog/20120102/)\n\n\n##5. 复制hadoop安装包到所有机器\n从hadoop.apache.org下载 hadoop-1.0.0-bin.tar.gz，上传到master中，解压，然后复制到其他机器，解压。\n\n\tdev@master:~$ tar -zxvf hadoop-1.0.0-bin.tar.gz\n\t\n\tdev@master:~$ scp hadoop-1.0.0-bin.tar.gz dev@192.168.1.132:~\n\t\n\tdev@master:~$ scp hadoop-1.0.0-bin.tar.gz dev@192.168.1.133:~\n\t\n\tdev@slave01:~$ tar -zxvf hadoop-1.0.0-bin.tar.gz\n\t\n\tdev@slave02:~$ tar -zxvf hadoop-1.0.0-bin.tar.gz\n\n##6. 编辑配置文件\n\n\tdev@master:~$ cd hadoop-1.0.0/etc/hadoop\n\t\n\tdev@master:~/hadoop-1.0.0/etc/hadoop$  vi hadoop-env.sh\n\n仅需要设置JAVA_HOME，\n\n\texport JAVA_HOME=/usr/lib/jvm/java-7-openjdk-i386\n\t\ncore-site.xml:\n\n\t<configuration>\n\t\t<property>\n\t\t\t<name>fs.default.name</name>\n\t\t\t<value>hdfs://master:9000</value>\n\t\t</property>\n\t\t<property>\n\t\t\t<name>hadoop.tmp.dir</name>\n\t\t\t<value>/home/dev/hadoop_tmp/</value>\n\t\t</property>\n\t</configuration>\n\nmapred-site.xml:\n\n\t<configuration>\n\t\t<property>\n\t\t\t<name>mapred.job.tracker</name>\n\t\t\t<value>master:9001</value>\n\t\t</property>\n\t</configuration>\n\n\nhdfs-site.xml:\n\n\t<configuration>\n\t\t<property>\n\t\t\t<name>dfs.replication</name>\n\t\t\t<value>3</value>\n\t\t</property>\n\t</configuration>\n\n\nmasters:\n\n\tmaster\n\nslaves:\n\n\tslave01\n\tslave02\n\n\n##7. 将配置文件拷贝到各台slave\n\n\tdev@master:~/hadoop-1.0.0/etc/hadoop$ scp hadoop-env.sh core-site.xml hdfs-site.xml mapred-site.xml masters slaves dev@192.168.1.132:~/hadoop-1.0.0/etc/hadoop\n\t\n\tdev@master:~/hadoop-1.0.0/etc/hadoop$ scp hadoop-env.sh core-site.xml hdfs-site.xml mapred-site.xml masters slaves dev@192.168.1.133:~/hadoop-1.0.0/etc/hadoop\n\n##8. 设置环境变量HADOOP\\_HOME，并将`$HADOOP_HOME/bin`加入PATH\n所有机器都要设置环境变量HADOOP\\_HOME，并将`$HADOOP_HOME/bin`加入PATH，因为master登陆到slave后，要执行`$HADOOP_HOME/bin` 下的一些命令。\n\n\t$ vi .bashrc\n\t\t\n\texport JAVA_HOME=/usr/lib/jvm/java-7-openjdk-i386\n\texport CLASSPATH=$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar\n\texport PATH=$PATH:$JAVA_HOME/bin\n\texport HADOOP_HOME=~/hadoop-1.0.0\n\texport PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin\n\texport CLASSPATH=$CLASSPATH:$HADOOP_HOME/share/hadoop/hadoop-core-1.0.0.jar\n\t\t\n\texport HADOOP_HOME=~/hadoop-1.0.0\n\t\t\n\texport PATH=$PATH:$HADOOP_HOME/bin\n\t\t\n\t$ source .bashrc\n\n##9. 运行 hadoop\n\n\t#只需一次，下次启动不再需要格式化，只需 start-all.sh\n\tdev@master:~$ hadoop  namenode -format）\n\t\n\tdev@master:~$ start-all.sh\n\n\n##10. 检查是否运行成功\n\n\tdev@master:~$ jps\n\t\n\t2615 NameNode\n\t2767 JobTracker\n\t2874 Jps\n\t\n\tdev@slave01:~$ jps\n\t\n\t3415 DataNode\n\t3582 TaskTracker\n\t3499 SecondaryNameNode\n\t3619 Jps\n\t\n\tdev@slave02:~$ jps\n\t\n\t3741 Jps\n\t3618 DataNode\n\t3702 TaskTracker\n\n\n##11. 停止 hadoop集群\n\n\tdev@master:~$ stop-all.sh\n让 slave 节点也 可以启动 整个hadoop集群\n\n\n##注意\n1. 所有配置文件只能用hostname，不能用IP。两年前我不懂，还为此[在stackoverflow上发了帖子](http://stackoverflow.com/questions/8702637/hadoop-conf-fs-default-name-cant-be-setted-ipport-format-directly)。hadoop会反向解析hostname，即使是用了IP，也会使用hostname 来启动TaskTracker。参考[hdfs LAN ip address hostname resolution](http://stackoverflow.com/questions/15230946/hdfs-lan-ip-address-hostname-resolution)，[hadoop入门经验总结- 杨贵堂的博客](http://www.makenotes.net/?p=337004)，[hadoop集群配置](http://51mst.iteye.com/blog/1152439)。\n2. stat-all.sh 启动后，刚刚开始，namenode的日志里有些异常，是正常的，过一两分钟就好了，如果两分钟后，还有异常不断在打印，就有问题了。datanode的日志，从一开始，正常情况下，就没有异常，如果报了异常，说明有异常，要去排除。\n\n3. masters文件，这个文件很容易被误解，它实际上存放的是secondarynamenode，而不是namenode。\n\n\t> An HDFS instance is started on a cluster by logging in to the NameNode machine and running$HADOOP_HOME/bin/start-dfs.sh (orstart-all.sh ). This script. starts a local instance of the NameNode process, logs into every machine listed in theconf/slaves file and starts an instance of the DataNode process, and logs into every machine listed in theconf/masters file and starts an instance of the SecondaryNameNode process. Themasters file does not govern which nodes become NameNodes or JobTrackers; those are started on the machine(s) wherebin/start-dfs.sh andbin/start-mapred.sh are executed. A more accurate filename might be “secondaries,” but that’s not currently the case.\n\n\t参考以下三篇文章：\n\t[Multi-host SecondaryNameNode Configuration](http://www.cloudera.com/blog/2009/02/multi-host-secondarynamenode-configuration/)  \n\t[SecondaryNamenode应用摘记](http://blog.csdn.net/dajuezhao/article/details/5987580)\n\t[hadoop下运行多个SecondaryNameNode的配置](http://blog.csdn.net/AE86_FC/article/details/5284181)\n\n4. 一定要注释掉 hosts里面的 `#127.0.1.1      bogon.localdomain       bogon`，参考 [Hadoop集群机器命名机制](http://blog.sina.com.cn/s/blog_631ffec50100w700.html)，[hadoop集群环境安装中的hosts 配置问题](http://blog.csdn.net/singno116/article/details/6298995)。\n\n5. 当测试ssh是否能连通时，如果连接不上，先记得要关闭防火墙，`sudo ufw disable`，参考[hadoop集群安装步骤](http://blog.csdn.net/make19830723/article/details/6230074)。\n\n\n##更新记录\n2012-01-03 针对 Ubuntu 13.04, Hadoop 1.1.2  \n2012-01-03 针对 Ubuntu 10.04, Hadoop 1.0.0","slug":"2012-01-03-hadoop-installation-on-ubuntu","published":1,"updated":"2016-08-18T09:21:04.000Z","photos":[],"link":"","_id":"cis07pf2f000f01pqcuzjmhg0","content":"<p>本文所使用的版本是 hadoop 1.0.0，即 <a href=\"http://www.iteye.com/news/23874\" target=\"_blank\" rel=\"external\">2011年12月27日发布的1.0正式版</a>。</p>\n<p>详细安装步骤如下，有大步骤，每个步骤里面有小步骤，绝大部分是必选，只有2步是可选的，粗体表示要特别注意的地方。</p>\n<p>##1. 用vmware workstation 新建三台虚拟机<br>首先用vmware workstation 新建一台ubuntu server，装好操作系统，安装各种必须的软件，包括安装好hadoop。安装好后然后用浅拷贝<code>Create a linked clone</code> 克隆出两台作为slave，这样有了三台ubuntu机器。启动三台机器，假设IP分别为<code>192.168.1.131, 192.168.1.132, 192.168.1.133</code>, 131做为master 和 SecondaryNameNode, 身兼两职，132为 slave01, 133为slave02。</p>\n<p>##2. 修改机器名<br>这一步看起来貌似不必要，其实是必须的，否则最后运行wordcount等例子时，会出现“Too many fetch-failures”。因为HDFS用hostname而不是IP，来相互之间进行通信（见后面的注意1）。</p>\n<ul>\n<li><p>192.168.1.131上执行</p>\n<pre><code>dev@bogon:~$ sudo vi /etc/hostname\n</code></pre></li>\n</ul>\n<p>输入<code>master</code>，重启，会发现命令提示符变为了 <code>dev@master:~$</code></p>\n<p>用同样的方法，将<code>192.168.1.132</code>改为slave01，<code>192.168.1.133</code>改为slave02。</p>\n<a id=\"more\"></a>\n<p>##3. 修改master的hosts文件，并拷贝到每台slave上</p>\n<pre><code>dev@master:~$ sudo vi /etc/hosts\n</code></pre><p>添加三行内容</p>\n<pre><code>192.168.1.131 master  \n192.168.1.132 slave01  \n192.168.1.133 slave02  \n</code></pre><p><strong>注意一定要注释掉</strong></p>\n<pre><code># 127.0.1.1      bogon.localdomain       bogon\n</code></pre><p>最后hosts文件内容如下：</p>\n<pre><code>127.0.0.1       localhost\n# 127.0.1.1      bogon.localdomain       bogon\n192.168.1.131 master\n192.168.1.132 slave01\n192.168.1.133 slave02\n# The following lines are desirable for IPv6 capable hosts\n::1     ip6-localhost ip6-loopback\nfe00::0 ip6-localnet\nff00::0 ip6-mcastprefix\nff02::1 ip6-allnodes\nff02::2 ip6-allrouters\n</code></pre><ul>\n<li><p>将hosts文件拷贝到另外两台台机器上，覆盖原来的hosts文件</p>\n<pre><code>dev@master:~$ scp /etc/hosts dev@192.168.1.132:~\ndev@master:~$ scp /etc/hosts dev@192.168.1.133:~\n</code></pre></li>\n<li><p>在192.168.1.132上执行</p>\n<pre><code>dev@slave01:~$ sudo mv hosts /etc/hosts\n</code></pre></li>\n<li><p>在192.168.1.133上执行</p>\n<pre><code>dev@slave02:~$ sudo mv hosts /etc/hosts\n</code></pre></li>\n</ul>\n<p>##4. 配置 master 无密码登陆到所有机器（包括本机）<br>参考我的另一篇博客，<a href=\"http://www.yanjiuyanjiu.com/blog/20120102/\" target=\"_blank\" rel=\"external\">SSH无密码登录的配置</a></p>\n<p>##5. 复制hadoop安装包到所有机器<br>从hadoop.apache.org下载 hadoop-1.0.0-bin.tar.gz，上传到master中，解压，然后复制到其他机器，解压。</p>\n<pre><code>dev@master:~$ tar -zxvf hadoop-1.0.0-bin.tar.gz\n\ndev@master:~$ scp hadoop-1.0.0-bin.tar.gz dev@192.168.1.132:~\n\ndev@master:~$ scp hadoop-1.0.0-bin.tar.gz dev@192.168.1.133:~\n\ndev@slave01:~$ tar -zxvf hadoop-1.0.0-bin.tar.gz\n\ndev@slave02:~$ tar -zxvf hadoop-1.0.0-bin.tar.gz\n</code></pre><p>##6. 编辑配置文件</p>\n<pre><code>dev@master:~$ cd hadoop-1.0.0/etc/hadoop\n\ndev@master:~/hadoop-1.0.0/etc/hadoop$  vi hadoop-env.sh\n</code></pre><p>仅需要设置JAVA_HOME，</p>\n<pre><code>export JAVA_HOME=/usr/lib/jvm/java-7-openjdk-i386\n</code></pre><p>core-site.xml:</p>\n<pre><code>&lt;configuration&gt;\n    &lt;property&gt;\n        &lt;name&gt;fs.default.name&lt;/name&gt;\n        &lt;value&gt;hdfs://master:9000&lt;/value&gt;\n    &lt;/property&gt;\n    &lt;property&gt;\n        &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;\n        &lt;value&gt;/home/dev/hadoop_tmp/&lt;/value&gt;\n    &lt;/property&gt;\n&lt;/configuration&gt;\n</code></pre><p>mapred-site.xml:</p>\n<pre><code>&lt;configuration&gt;\n    &lt;property&gt;\n        &lt;name&gt;mapred.job.tracker&lt;/name&gt;\n        &lt;value&gt;master:9001&lt;/value&gt;\n    &lt;/property&gt;\n&lt;/configuration&gt;\n</code></pre><p>hdfs-site.xml:</p>\n<pre><code>&lt;configuration&gt;\n    &lt;property&gt;\n        &lt;name&gt;dfs.replication&lt;/name&gt;\n        &lt;value&gt;3&lt;/value&gt;\n    &lt;/property&gt;\n&lt;/configuration&gt;\n</code></pre><p>masters:</p>\n<pre><code>master\n</code></pre><p>slaves:</p>\n<pre><code>slave01\nslave02\n</code></pre><p>##7. 将配置文件拷贝到各台slave</p>\n<pre><code>dev@master:~/hadoop-1.0.0/etc/hadoop$ scp hadoop-env.sh core-site.xml hdfs-site.xml mapred-site.xml masters slaves dev@192.168.1.132:~/hadoop-1.0.0/etc/hadoop\n\ndev@master:~/hadoop-1.0.0/etc/hadoop$ scp hadoop-env.sh core-site.xml hdfs-site.xml mapred-site.xml masters slaves dev@192.168.1.133:~/hadoop-1.0.0/etc/hadoop\n</code></pre><p>##8. 设置环境变量HADOOP_HOME，并将<code>$HADOOP_HOME/bin</code>加入PATH<br>所有机器都要设置环境变量HADOOP_HOME，并将<code>$HADOOP_HOME/bin</code>加入PATH，因为master登陆到slave后，要执行<code>$HADOOP_HOME/bin</code> 下的一些命令。</p>\n<pre><code>$ vi .bashrc\n\nexport JAVA_HOME=/usr/lib/jvm/java-7-openjdk-i386\nexport CLASSPATH=$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar\nexport PATH=$PATH:$JAVA_HOME/bin\nexport HADOOP_HOME=~/hadoop-1.0.0\nexport PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin\nexport CLASSPATH=$CLASSPATH:$HADOOP_HOME/share/hadoop/hadoop-core-1.0.0.jar\n\nexport HADOOP_HOME=~/hadoop-1.0.0\n\nexport PATH=$PATH:$HADOOP_HOME/bin\n\n$ source .bashrc\n</code></pre><p>##9. 运行 hadoop</p>\n<pre><code>#只需一次，下次启动不再需要格式化，只需 start-all.sh\ndev@master:~$ hadoop  namenode -format）\n\ndev@master:~$ start-all.sh\n</code></pre><p>##10. 检查是否运行成功</p>\n<pre><code>dev@master:~$ jps\n\n2615 NameNode\n2767 JobTracker\n2874 Jps\n\ndev@slave01:~$ jps\n\n3415 DataNode\n3582 TaskTracker\n3499 SecondaryNameNode\n3619 Jps\n\ndev@slave02:~$ jps\n\n3741 Jps\n3618 DataNode\n3702 TaskTracker\n</code></pre><p>##11. 停止 hadoop集群</p>\n<pre><code>dev@master:~$ stop-all.sh\n</code></pre><p>让 slave 节点也 可以启动 整个hadoop集群</p>\n<p>##注意</p>\n<ol>\n<li>所有配置文件只能用hostname，不能用IP。两年前我不懂，还为此<a href=\"http://stackoverflow.com/questions/8702637/hadoop-conf-fs-default-name-cant-be-setted-ipport-format-directly\" target=\"_blank\" rel=\"external\">在stackoverflow上发了帖子</a>。hadoop会反向解析hostname，即使是用了IP，也会使用hostname 来启动TaskTracker。参考<a href=\"http://stackoverflow.com/questions/15230946/hdfs-lan-ip-address-hostname-resolution\" target=\"_blank\" rel=\"external\">hdfs LAN ip address hostname resolution</a>，<a href=\"http://www.makenotes.net/?p=337004\" target=\"_blank\" rel=\"external\">hadoop入门经验总结- 杨贵堂的博客</a>，<a href=\"http://51mst.iteye.com/blog/1152439\" target=\"_blank\" rel=\"external\">hadoop集群配置</a>。</li>\n<li><p>stat-all.sh 启动后，刚刚开始，namenode的日志里有些异常，是正常的，过一两分钟就好了，如果两分钟后，还有异常不断在打印，就有问题了。datanode的日志，从一开始，正常情况下，就没有异常，如果报了异常，说明有异常，要去排除。</p>\n</li>\n<li><p>masters文件，这个文件很容易被误解，它实际上存放的是secondarynamenode，而不是namenode。</p>\n<blockquote>\n<p>An HDFS instance is started on a cluster by logging in to the NameNode machine and running$HADOOP_HOME/bin/start-dfs.sh (orstart-all.sh ). This script. starts a local instance of the NameNode process, logs into every machine listed in theconf/slaves file and starts an instance of the DataNode process, and logs into every machine listed in theconf/masters file and starts an instance of the SecondaryNameNode process. Themasters file does not govern which nodes become NameNodes or JobTrackers; those are started on the machine(s) wherebin/start-dfs.sh andbin/start-mapred.sh are executed. A more accurate filename might be “secondaries,” but that’s not currently the case.</p>\n</blockquote>\n<p> 参考以下三篇文章：<br> <a href=\"http://www.cloudera.com/blog/2009/02/multi-host-secondarynamenode-configuration/\" target=\"_blank\" rel=\"external\">Multi-host SecondaryNameNode Configuration</a><br> <a href=\"http://blog.csdn.net/dajuezhao/article/details/5987580\" target=\"_blank\" rel=\"external\">SecondaryNamenode应用摘记</a><br> <a href=\"http://blog.csdn.net/AE86_FC/article/details/5284181\" target=\"_blank\" rel=\"external\">hadoop下运行多个SecondaryNameNode的配置</a></p>\n</li>\n<li><p>一定要注释掉 hosts里面的 <code>#127.0.1.1      bogon.localdomain       bogon</code>，参考 <a href=\"http://blog.sina.com.cn/s/blog_631ffec50100w700.html\" target=\"_blank\" rel=\"external\">Hadoop集群机器命名机制</a>，<a href=\"http://blog.csdn.net/singno116/article/details/6298995\" target=\"_blank\" rel=\"external\">hadoop集群环境安装中的hosts 配置问题</a>。</p>\n</li>\n<li><p>当测试ssh是否能连通时，如果连接不上，先记得要关闭防火墙，<code>sudo ufw disable</code>，参考<a href=\"http://blog.csdn.net/make19830723/article/details/6230074\" target=\"_blank\" rel=\"external\">hadoop集群安装步骤</a>。</p>\n</li>\n</ol>\n<p>##更新记录<br>2012-01-03 针对 Ubuntu 13.04, Hadoop 1.1.2<br>2012-01-03 针对 Ubuntu 10.04, Hadoop 1.0.0</p>\n","excerpt":"<p>本文所使用的版本是 hadoop 1.0.0，即 <a href=\"http://www.iteye.com/news/23874\">2011年12月27日发布的1.0正式版</a>。</p>\n<p>详细安装步骤如下，有大步骤，每个步骤里面有小步骤，绝大部分是必选，只有2步是可选的，粗体表示要特别注意的地方。</p>\n<p>##1. 用vmware workstation 新建三台虚拟机<br>首先用vmware workstation 新建一台ubuntu server，装好操作系统，安装各种必须的软件，包括安装好hadoop。安装好后然后用浅拷贝<code>Create a linked clone</code> 克隆出两台作为slave，这样有了三台ubuntu机器。启动三台机器，假设IP分别为<code>192.168.1.131, 192.168.1.132, 192.168.1.133</code>, 131做为master 和 SecondaryNameNode, 身兼两职，132为 slave01, 133为slave02。</p>\n<p>##2. 修改机器名<br>这一步看起来貌似不必要，其实是必须的，否则最后运行wordcount等例子时，会出现“Too many fetch-failures”。因为HDFS用hostname而不是IP，来相互之间进行通信（见后面的注意1）。</p>\n<ul>\n<li><p>192.168.1.131上执行</p>\n<pre><code>dev@bogon:~$ sudo vi /etc/hostname\n</code></pre></li>\n</ul>\n<p>输入<code>master</code>，重启，会发现命令提示符变为了 <code>dev@master:~$</code></p>\n<p>用同样的方法，将<code>192.168.1.132</code>改为slave01，<code>192.168.1.133</code>改为slave02。</p>","more":"<p>##3. 修改master的hosts文件，并拷贝到每台slave上</p>\n<pre><code>dev@master:~$ sudo vi /etc/hosts\n</code></pre><p>添加三行内容</p>\n<pre><code>192.168.1.131 master  \n192.168.1.132 slave01  \n192.168.1.133 slave02  \n</code></pre><p><strong>注意一定要注释掉</strong></p>\n<pre><code># 127.0.1.1      bogon.localdomain       bogon\n</code></pre><p>最后hosts文件内容如下：</p>\n<pre><code>127.0.0.1       localhost\n# 127.0.1.1      bogon.localdomain       bogon\n192.168.1.131 master\n192.168.1.132 slave01\n192.168.1.133 slave02\n# The following lines are desirable for IPv6 capable hosts\n::1     ip6-localhost ip6-loopback\nfe00::0 ip6-localnet\nff00::0 ip6-mcastprefix\nff02::1 ip6-allnodes\nff02::2 ip6-allrouters\n</code></pre><ul>\n<li><p>将hosts文件拷贝到另外两台台机器上，覆盖原来的hosts文件</p>\n<pre><code>dev@master:~$ scp /etc/hosts dev@192.168.1.132:~\ndev@master:~$ scp /etc/hosts dev@192.168.1.133:~\n</code></pre></li>\n<li><p>在192.168.1.132上执行</p>\n<pre><code>dev@slave01:~$ sudo mv hosts /etc/hosts\n</code></pre></li>\n<li><p>在192.168.1.133上执行</p>\n<pre><code>dev@slave02:~$ sudo mv hosts /etc/hosts\n</code></pre></li>\n</ul>\n<p>##4. 配置 master 无密码登陆到所有机器（包括本机）<br>参考我的另一篇博客，<a href=\"http://www.yanjiuyanjiu.com/blog/20120102/\">SSH无密码登录的配置</a></p>\n<p>##5. 复制hadoop安装包到所有机器<br>从hadoop.apache.org下载 hadoop-1.0.0-bin.tar.gz，上传到master中，解压，然后复制到其他机器，解压。</p>\n<pre><code>dev@master:~$ tar -zxvf hadoop-1.0.0-bin.tar.gz\n\ndev@master:~$ scp hadoop-1.0.0-bin.tar.gz dev@192.168.1.132:~\n\ndev@master:~$ scp hadoop-1.0.0-bin.tar.gz dev@192.168.1.133:~\n\ndev@slave01:~$ tar -zxvf hadoop-1.0.0-bin.tar.gz\n\ndev@slave02:~$ tar -zxvf hadoop-1.0.0-bin.tar.gz\n</code></pre><p>##6. 编辑配置文件</p>\n<pre><code>dev@master:~$ cd hadoop-1.0.0/etc/hadoop\n\ndev@master:~/hadoop-1.0.0/etc/hadoop$  vi hadoop-env.sh\n</code></pre><p>仅需要设置JAVA_HOME，</p>\n<pre><code>export JAVA_HOME=/usr/lib/jvm/java-7-openjdk-i386\n</code></pre><p>core-site.xml:</p>\n<pre><code>&lt;configuration&gt;\n    &lt;property&gt;\n        &lt;name&gt;fs.default.name&lt;/name&gt;\n        &lt;value&gt;hdfs://master:9000&lt;/value&gt;\n    &lt;/property&gt;\n    &lt;property&gt;\n        &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;\n        &lt;value&gt;/home/dev/hadoop_tmp/&lt;/value&gt;\n    &lt;/property&gt;\n&lt;/configuration&gt;\n</code></pre><p>mapred-site.xml:</p>\n<pre><code>&lt;configuration&gt;\n    &lt;property&gt;\n        &lt;name&gt;mapred.job.tracker&lt;/name&gt;\n        &lt;value&gt;master:9001&lt;/value&gt;\n    &lt;/property&gt;\n&lt;/configuration&gt;\n</code></pre><p>hdfs-site.xml:</p>\n<pre><code>&lt;configuration&gt;\n    &lt;property&gt;\n        &lt;name&gt;dfs.replication&lt;/name&gt;\n        &lt;value&gt;3&lt;/value&gt;\n    &lt;/property&gt;\n&lt;/configuration&gt;\n</code></pre><p>masters:</p>\n<pre><code>master\n</code></pre><p>slaves:</p>\n<pre><code>slave01\nslave02\n</code></pre><p>##7. 将配置文件拷贝到各台slave</p>\n<pre><code>dev@master:~/hadoop-1.0.0/etc/hadoop$ scp hadoop-env.sh core-site.xml hdfs-site.xml mapred-site.xml masters slaves dev@192.168.1.132:~/hadoop-1.0.0/etc/hadoop\n\ndev@master:~/hadoop-1.0.0/etc/hadoop$ scp hadoop-env.sh core-site.xml hdfs-site.xml mapred-site.xml masters slaves dev@192.168.1.133:~/hadoop-1.0.0/etc/hadoop\n</code></pre><p>##8. 设置环境变量HADOOP_HOME，并将<code>$HADOOP_HOME/bin</code>加入PATH<br>所有机器都要设置环境变量HADOOP_HOME，并将<code>$HADOOP_HOME/bin</code>加入PATH，因为master登陆到slave后，要执行<code>$HADOOP_HOME/bin</code> 下的一些命令。</p>\n<pre><code>$ vi .bashrc\n\nexport JAVA_HOME=/usr/lib/jvm/java-7-openjdk-i386\nexport CLASSPATH=$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar\nexport PATH=$PATH:$JAVA_HOME/bin\nexport HADOOP_HOME=~/hadoop-1.0.0\nexport PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin\nexport CLASSPATH=$CLASSPATH:$HADOOP_HOME/share/hadoop/hadoop-core-1.0.0.jar\n\nexport HADOOP_HOME=~/hadoop-1.0.0\n\nexport PATH=$PATH:$HADOOP_HOME/bin\n\n$ source .bashrc\n</code></pre><p>##9. 运行 hadoop</p>\n<pre><code>#只需一次，下次启动不再需要格式化，只需 start-all.sh\ndev@master:~$ hadoop  namenode -format）\n\ndev@master:~$ start-all.sh\n</code></pre><p>##10. 检查是否运行成功</p>\n<pre><code>dev@master:~$ jps\n\n2615 NameNode\n2767 JobTracker\n2874 Jps\n\ndev@slave01:~$ jps\n\n3415 DataNode\n3582 TaskTracker\n3499 SecondaryNameNode\n3619 Jps\n\ndev@slave02:~$ jps\n\n3741 Jps\n3618 DataNode\n3702 TaskTracker\n</code></pre><p>##11. 停止 hadoop集群</p>\n<pre><code>dev@master:~$ stop-all.sh\n</code></pre><p>让 slave 节点也 可以启动 整个hadoop集群</p>\n<p>##注意</p>\n<ol>\n<li>所有配置文件只能用hostname，不能用IP。两年前我不懂，还为此<a href=\"http://stackoverflow.com/questions/8702637/hadoop-conf-fs-default-name-cant-be-setted-ipport-format-directly\">在stackoverflow上发了帖子</a>。hadoop会反向解析hostname，即使是用了IP，也会使用hostname 来启动TaskTracker。参考<a href=\"http://stackoverflow.com/questions/15230946/hdfs-lan-ip-address-hostname-resolution\">hdfs LAN ip address hostname resolution</a>，<a href=\"http://www.makenotes.net/?p=337004\">hadoop入门经验总结- 杨贵堂的博客</a>，<a href=\"http://51mst.iteye.com/blog/1152439\">hadoop集群配置</a>。</li>\n<li><p>stat-all.sh 启动后，刚刚开始，namenode的日志里有些异常，是正常的，过一两分钟就好了，如果两分钟后，还有异常不断在打印，就有问题了。datanode的日志，从一开始，正常情况下，就没有异常，如果报了异常，说明有异常，要去排除。</p>\n</li>\n<li><p>masters文件，这个文件很容易被误解，它实际上存放的是secondarynamenode，而不是namenode。</p>\n<blockquote>\n<p>An HDFS instance is started on a cluster by logging in to the NameNode machine and running$HADOOP_HOME/bin/start-dfs.sh (orstart-all.sh ). This script. starts a local instance of the NameNode process, logs into every machine listed in theconf/slaves file and starts an instance of the DataNode process, and logs into every machine listed in theconf/masters file and starts an instance of the SecondaryNameNode process. Themasters file does not govern which nodes become NameNodes or JobTrackers; those are started on the machine(s) wherebin/start-dfs.sh andbin/start-mapred.sh are executed. A more accurate filename might be “secondaries,” but that’s not currently the case.</p>\n</blockquote>\n<p> 参考以下三篇文章：<br> <a href=\"http://www.cloudera.com/blog/2009/02/multi-host-secondarynamenode-configuration/\">Multi-host SecondaryNameNode Configuration</a><br> <a href=\"http://blog.csdn.net/dajuezhao/article/details/5987580\">SecondaryNamenode应用摘记</a><br> <a href=\"http://blog.csdn.net/AE86_FC/article/details/5284181\">hadoop下运行多个SecondaryNameNode的配置</a></p>\n</li>\n<li><p>一定要注释掉 hosts里面的 <code>#127.0.1.1      bogon.localdomain       bogon</code>，参考 <a href=\"http://blog.sina.com.cn/s/blog_631ffec50100w700.html\">Hadoop集群机器命名机制</a>，<a href=\"http://blog.csdn.net/singno116/article/details/6298995\">hadoop集群环境安装中的hosts 配置问题</a>。</p>\n</li>\n<li><p>当测试ssh是否能连通时，如果连接不上，先记得要关闭防火墙，<code>sudo ufw disable</code>，参考<a href=\"http://blog.csdn.net/make19830723/article/details/6230074\">hadoop集群安装步骤</a>。</p>\n</li>\n</ol>\n<p>##更新记录<br>2012-01-03 针对 Ubuntu 13.04, Hadoop 1.1.2<br>2012-01-03 针对 Ubuntu 10.04, Hadoop 1.0.0</p>"},{"layout":"post","title":"安装和配置CentOS服务器的详细步骤","date":"2012-04-23T20:43:00.000Z","comments":1,"_content":"\n这是我安装CentOS服务器的过程，记录下来，与大家一起分享。Ubuntu请见[安装和配置Ubuntu服务器的详细步骤](http://cn.soulmachine.me/blog/20140417/)。\n\n##安装操作系统\nCentOS 6.2 ，CentOS-6.2-i386-bin-DVD1.iso（32位） ，CentOS-6.2-x86_64-bin-DVD1.iso（64位）\n\n安装 CentOS时，选择 \"Basic Server\"  \nroot密码：root123  \nCentOS 自带了ssh  \n \n安装完操作系统后，添加一个用户 manong\n\n``` bash\n[root@localhost ~]$ useradd manong\n\n```\n然后密码设为 manong123\n\n``` bash\n[root@localhost ~]$ passwd manong\n```\n\n给予 sudo 权限\n\n``` bash\n[root@localhost ~]$ chmod u+w /etc/sudoers\n[root@localhost ~]$ vim /etc/sudoers\n# 在root ALL=(ALL) ALL 下 添加manong ALL=(ALL) ALL\n[root@localhost ~]$ chmod u-w /etc/sudoers \n```\n\n##设置上网\n安装完操作系统后，还不能上网，配置DHCP方式上网：\n\n``` bash\nvim /etc/sysconfig/network-scripts/ifcfg-eth0\nDEVICE=\"eth0\"\nHWADDR=\"00:0C:29:BD:E1:19\"\nNM_CONTROLLED=\"yes\"\nONBOOT=\"yes\"\nBOOTPROTO=dhcp\nUSECTL=no\nTYPE=Ethernet\nPEERDNS=yes\n#保存退出\nsudo service network restart\n```\n\n<!-- more -->\n\n或者，配置静态IP\n\n``` bash\nDEVICE=\"eth0\"\nHWADDR=\"00:0C:29:10:F4:4C\"\nONBOOT=\"yes\"\nBOOTPROTO=static\nTYPE=Ethernet\nIPADDR=192.168.0.162\nNETMASK=255.255.255.0\nBROADCAST=192.168.0.255\nNETWORK=192.168.0.0\n#保存退出  \n#修改/etc/sysconfig/network\nsudo vim /etc/sysconfig/network\nNETWORKING=yes\nHOSTNAME=localhost.localdomain\nGATEWAY=192.168.0.1\n#保存退出，重启网络\nsudo service network restart\n```\n如果失败，比如IP已被占用，换一个IP试试\n\n修改DNS，即时生效\n\n``` bash\nsudo vim /etc/resolv.conf\nnameserver 192.168.0.1\n# google提供的域名服务器\nnameserver 8.8.8.8\nsearch localhost\n```\n\n##安装常用软件\n有两种方式，方法一，去官网下载已经编译好的二进制文件，或源代码，编译安装\n方法二，用yum 命令安装，安装官方yum源里已经编译好的程序包。  \n第一种方式要敲很多命令，比yum麻烦，但是可以预先下载好文件，省略了下载的时间，整体速度比yum安装方式快很多，而且可以安装最新版。推荐第一种方式\n\n第二种方式操作简单，敲打的命令少，但是往往yum源的更新速度跟不上各个软件的官网速度，用Yum安装的版本经常比较旧。\n\nyum的命令形式一般是如下：`yum [options] [command] [package ...]`，其中的[options]是可选的，选项包括-h（帮助），-y（当安装过程提示选择全部为\"yes\"），-q（不显示安装的过程）等等。[command]为所要进行的操作，[package ...]是操作的对象。\n\n``` bash\n#yum search package-name # 在线搜索包 \n#yum list installed # 列出所有已经安装的包\n#\n#sudo yum install package-name # 安装程序包 \n#sudo yum groupinsall group-name 安装程序组\n#\n#sudo yum remove package-name 删除程序包\n#sudo yum groupremove group-name 删除程序组\n#\n#yum update #全部更新\n#yum update package-name #更新程序包\n#sudo yum groupupdate groupn-name 升级程序组\n#sudo yum upgrade # 更新源列表\n#yum upgrade package-name #升级程序包\n#sudo yum clean all # 清除缓存\n#更新\nsudo yum update\n#清理缓存\nsudo yum clean all && yum clean metadata && yum clean dbcache\n```\n\n##安装编译工具\n\n###方法一\n去 http://gcc.gnu.org/ 下载源码\n\n``` bash\n# TODO\n```\n\n###方法二\n\n``` bash\nsudo yum groupinstall \"Development Tools\"\n```\n该命令类似于 Ubuntu 下的`apt-get install build-essential`，会自动安装一下软件包：autoconf automake bison byacc cscope ctags diffstat doxygen flex gcc gcc-c++ gcc-gfortran git indent intltool libtool patchutils rcs redhat-rpm-config rpm-build subversion swig systemtap，同时安装了以下依赖包：apr, apr-util, 等等。\n\n\n##安装JDK\n\n``` bash\n#删除旧的JDK\nyum list installed | grep jdk\n#复制显示出来的JDK，卸载\nsudo yum remove java-1.6.0-openjdk.x86_64\n#安装新的jdk\n```\n\n###方法一\n\n``` bash\n#从官网下载最新版的，当前是jdk6u32\n#开始安装\nchmod u+x chmod u+x jdk-6u32-linux-x64-rpm.bin\nsudo ./jdk-6u32-linux-x64-rpm.bin\n#设置环境变量，.bash_profile是当前用户，/etc/profile是所有用户的\nsudo vim /etc/profile\n#在末尾添加\nexport JAVA_HOME=/usr/java/default\nexport JRE_HOME=$JAVA_HOME/jre\nexport PATH=$PATH:$JAVA_HOME/bin\nexport CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar\n# 保存退出，输入以下命令使之立即生效：\nsource /etc/profile\n# 测试\njava -version\n```\n\n###方法二\n\n``` bash\nyum search jdk\n# java-1.6.0-openjdk只包含了JRE，如果在这台机器上开发java程序，则需要安装JDK，\n# 要选择 java-1.6.0-openjdk-devel，在服务器上我们只需要运行java程序，因此选择前者\nsudo yum install java-1.6.0-openjdk-devel\n# 使用 alternatives 工具设置默认JDK，参考：Installing a Java Development Kit on Red Hat Enterprise Linux\n/usr/sbin/alternatives --config java\n/usr/sbin/alternatives --config javac\n# 设置环境变量\n# 查询JDK路径\nwhereis java\nll /usr/bin/java\nll /etc/alternatives/java #这是可以看到JDK路径了\nsudo vim /etc/profile\n# 在末尾添加\nexport JAVA_HOME=/usr/lib/jvm/jre-1.6.0-openjdk.x86_64\nexport JRE_HOME=$JAVA_HOME/jre\nexport PATH=$PATH:$JAVA_HOME/bin\nexport CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar\n#保存退出，输入以下命令使之立即生效：\n# source /etc/profile\n# 测试\njava -version\n```\n\n##安装 apache\n\n###方法一\n源码在官网 http://httpd.apache.org/ 下载。  \n先下载apt, apr-util, pcre三个库，httpd 在编译时需要用到这三个库  \napr, apr-util官网 http://apr.apache.org , pcre官网为 [http://pcre.org ](http://pcre.org )\n\n``` bash\n# 编译，安装 apr\ntar -jxf apr-1.4.6.tar.bz2\ncd apr-1.4.6\n./configure\nmake\nsudo make install    # 默认会安装到 /usr/local/apr/\ncd ~\n#编译，安装 apr-util\ntar -jxf apr-util-1.4.1.tar.bz2\ncd apr-util-1.4.1\n./configure --with-apr=/usr/local/apr/\nmake\nsudo make install    # 默认会安装到 /usr/local/apr/\ncd ~\n#编译，安装 pcre\ntar -jxf pcre-8.30.tar.bz2\ncd  pcre-8.30\n./configure --with-apr=/usr/local/apr/\nmake\n# By default, `make install' installs the package's commands under\n#`/usr/local/bin', include files under `/usr/local/include', etc. \nsudo make install\ncd ~\n#编译，安装 apache\ntar -jxf httpd-2.2.22.tar.bz2\ncd httpd-2.2.22\n./configure\nmake\nsudo make install    # 默认会安装到/usr/local/apache2/\ncd ~\n#添加防火墙规则，让防火墙允许 apache的端口 80通过\nsudo vim /etc/sysconfig/iptables\n#添加如下一行（实际上是拷贝了原来的一行，仅仅改变了端口号），位置必须#要放在 含有 \"REJECT --reject-with\" 的行的前面\n-A INPUT -m state --state NEW -m tcp -p tcp --dport 80 -j ACCEPT\nsudo service iptables restart\n#测试\nsudo /usr/local/apache2/bin/apachectl start\n#在浏览器输入 http://ip地址 ，如果看到“It works”，说明安装成功\n/usr/local/apache2/bin/apachectl stop\n\n\n#设置为开机启动\n#将httpd注册为服务，通过chkconfig实现开机启动\n#以apachectl 为模板\nsudo cp /usr/local/apache2/bin/apachectl /etc/init.d/httpd\nsudo vim /etc/init.d/httpd\n# 在第一行 #!/bin/sh，添加如下一行，使其支持chkconfig命令\n# chkconfig: 2345 85 15\n# 保存，退出VIM编辑器\nsudo chmod u+x /etc/init.d/httpd\nsudo chkconfig --add httpd\nsudo chkconfig httpd on\n#检查一下，是否添加成功\nchkconfig --list httpd \n```\n\n###方法二\n\n``` bash\nsudo yum install httpd\n#可选？sudo yum install httpd-devel\n#测试\n#启动 apache http server\nsudo service httpd start\n#添加规则，让防火墙允许 apache的端口 80\nsudo vim /etc/sysconfig/iptables\n#添加如下一行，位置必须要放在 含有 \"REJECT --reject-with\" 的行的前面\n-A INPUT -m state --state NEW -m tcp -p tcp --dport 80 -j ACCEPT\nsudo service iptables restart\n#可以在浏览器输入 http://ip地址 测试了\n#设置为开机启动\nsudo chkconfig httpd on\n```\n\n##安装 mysql\n\n###方法一\n\n``` bash\n#去官网下载 Oracle & Red Hat 6的安装包，64位为MySQL-5.5.23-1.el6.x86_64.tar，\n#32位为 MySQL-5.5.23-1.el6.i686.tar\ntar -xf MySQL-5.5.23-1.el6.x86_64.tar\n#加 --force 是因为可能会与mysqllib库冲突\nsudo rpm -ivh --force  MySQL-server-5.5.23-1.el6.x86_64.rpm\nsudo rpm -ivh MySQL-client-5.5.23-1.el6.x86_64.rpm\n# 启动 mysql 服务器\nsudo service mysql start\n#设置为开机启动\nsudo chkconfig mysql on\n```\n\n###方法二\n\n``` bash\nsudo yum install mysql-server\nsudo chgrp -R mysql /var/lib/mysql\nsudo chmod -R 770 /var/lib/mysql\n# 启动 mysql 服务器\nsudo service mysqld start\n#设置为开机启动\nsudo chkconfig mysqld on\n```\n\n###公共的操作\n\n``` bash\n# root 初始密码为空，修改root密码\nmysql -u root\nmysql> use mysql;\nmysql> update user set password=password('root123') where user='root' AND host='localhost';\nmysql> flush privileges;\n# 打开MySQL中root账户的远程登录，参考：如何打开MySQL中root账户的远程登录mysql> GRANT ALL PRIVILEGES ON *.* TO root@\"%\" IDENTIFIED BY \"root\";\nmysql> update user set password=password('root123') where user='root' AND host='%';\nmysql> flush privileges;\nmysql> quit;\n#添加防火墙规则，让防火墙允许 mysql 的端口 3306通过\nsudo vim /etc/sysconfig/iptables\n#添加如下一行（实际上是拷贝了原来的一行，仅仅改变了端口号），位置必须#要放在 含有 \"REJECT --reject-with\" 的行的前面\n-A INPUT -m state --state NEW -m tcp -p tcp --dport 3306 -j ACCEPT\nsudo service iptables restart\n```\n\n##安装 php5\n\n###方法一\nTODO\n\n###方法二\n\n``` bash\nsudo yum install php php-pear\n#重启 apache，以确保apache 加载PHP模块\nsudo service httpd restart\n# 在 /var/www/html/下新建一个index.php文件，用于测试\ncd /var/www/html\nsudo vim index.php\n# 添加如下一行\n<?php phpinfo(); ?>\n# 在浏览器输入 http://xxx.xxx.xxx.xxx/index.php ，测试PHP是否成功安装\n\n# 如果需要在PHP中支持mysql，则需要安装 php-mysql 模块\nsudo yum install php-mysql\n# 如果需要在PHP中支持memcached，则需要安装 php-pecl-memcache 模块\nsudo yum install php-pecl-memcache\n#安装一些常用的PHP扩展模块\nsudo yum install php-devel php-gd php-mbstring php-xml\n\n#可以安装一个wordpress进行测试，注意要修改文件夹权限\nsudo chown -R apache.apache /var/www/html\n```\n\n## 安装 memcached\n\n###方法一\n\n``` bash\n# memcached依赖libevent，首先要安装 libevent\n# 去 http://libevent.org/ 下载libevent源码，然后编译，安装\ntar -zxf libevent-2.0.18-stable.tar.gz\ncd libevent-2.0.18-stable\n./configure\nmake\nsudo make install\n# 对于64位操作系统(32位不需要)，还需要配置：\nsudo ln -s /usr/local/lib/libevent-2.0.so.5 /usr/lib64//libevent-2.0.so.5\n# 去 http://www.memcached.org/ 下载 memcached，然后编译，安装\ntar -zxf memcached-1.4.13.tar.gz\ncd memcached-1.4.13\n./configure\nmake\nsudo make install\n# 启动, -p，端口,-m，内存, -u\nmemcached -p 11211 -m 512m -u root -d\n# 开机启动\n# centos设置开机启动有两种方式，一是把启动程序的命令添加到/etc/rc.d/rc.local文件中，二是把写好的启动脚本添加到目录/etc/rc.d/init.d/，然后使用命令chkconfig设置开机启动。第二种方式可以用 service xxx start|stop来启动或停止，所以推荐第二种。\n#将 memcached启动命令注册为一个服务\ncd /etc/init.d/\nsudo vim memcached\n#代码如下，参考：Linux中将memcached注册成服务并可以随机器启动时启动服务\n#chkconfig: 345 60 60\n#!/bin/bash\n\nstart()\n{\n        echo -n $\"Starting memcached: \"\n        /usr/local/bin/memcached -p 11211 -m 512m -u root -d\n        echo \"[OK]\"\n}\nstop()\n{\n        echo -n $\"Shutting down memcached: \"\n        memcached_pid_list=`pidof memcached` \n        kill -9 $memcached_pid_list\n        echo \"[OK]\"\n}\ncase \"$1\" in\n  start)\n        start\n        ;;\n  stop)\n        stop\n        ;;\n  restart)\n        stop\n        sleep 3\n        start\n        ;;\n    *)\n             echo $\"Usage: $0 {start|stop|restart}\"\n        exit 1\nesac\nexit 0\n#保存退出\nsudo chmod u+x memcached\nsudo chkconfig --add memcached\nsudo chkconfig  memcached on\n```\n\n###方法二\nTODO\n\n##安装 tomcat6\n\n###方法一\n\n``` bash\n# 去 http://tomcat.apache.org 下载 apache-tomcat-6.0.35.tar.gz\ntar -zxf apache-tomcat-6.0.35.tar.gz\nsudo mv apache-tomcat-6.0.35 /usr/local/\ncd /usr/local/apache-tomcat-6.0.35/bin\n#【可选】添加环境变量\nsudo vim /etc/profile\nexport CATALINA_HOME=/usr/local/apache-tomcat-6.0.35\n#启动 tomcat \nsudo ./startup.sh\n# 在浏览器输入 http://xxx.xxx.xxx.xxx:8080/ ，如果能看见tomcat页面，则表示安装成功了\n#设置开机启动\n#将 tomcat启动命令注册为一个服务\ncd /etc/init.d/\nsudo vim tomcatd\n#代码如下\n#chkconfig: 345 60 60\n#!/bin/bash\nCATALINA_HOME=/usr/local/apache-tomcat-6.0.35\n\nstart()\n{\n        echo -n $\"Starting Tomcat: \"\n        $CATALINA_HOME/bin/startup.sh\n        echo \"[OK]\"\n}\nstop()\n{\n        echo -n $\"Shutting down Tomcat: \"\n        $CATALINA_HOME/bin/shutdown.sh\n        echo \"[OK]\"\n}\ncase \"$1\" in\n  start)\n        start\n        ;;\n  stop)\n        stop\n        ;;\n  restart)\n        stop\n        sleep 3\n        start\n        ;;\n    *)\n             echo $\"Usage: $0 {start|stop|restart}\"\n        exit 1\nesac\nexit 0\n#保存退出\nsudo chmod u+x tomcatd\nsudo chkconfig --add tomcatd\nsudo chkconfig tomcatd on\n\n#添加防火墙规则，让防火墙允许 tomcat 的端口 8080 通过\nsudo vim /etc/sysconfig/iptables\n#添加如下一行（实际上是拷贝了原来的一行，仅仅改变了端口号），位置必须#要放在 含有 \"REJECT --reject-with\" 的行的前面\n-A INPUT -m state --state NEW -m tcp -p tcp --dport 8080 -j ACCEPT\nsudo service iptables restart\n```\n\n###方法二\n\n``` bash\n#搜索一下 tomcat包的名字\nyum search tomcat\nsudo yum search tomcat6.noarch\n```\n\n##安装Python\n\n###方法一：去[官网](http://www.python.org)下载源码，编译，安装\n\n``` bash\n#开始解压，编译，安装\ntar -jxf Python-3.2.3.tar.bz2\ncd Python-3.2.3\n# 查看一下说明, vim README\nsudo yum install zlib-devel bzip2-devel openssl-devel ncurses-devel sqlite-devel readline-devel tk-devel\n./configure\nmake\n#为了加快安装速度，这步可以省略\nmake test\n#卸载旧的python，注意，不能用 yum remove python，这会卸载几百个包，最终损坏系统\nsudo rpm -evf --nodeps python\nsudo make install\n#默认安装在 /usr/local/bin/python3\n```\n\n###方法二\n\n``` bash\nsudo yum install python\n```\n\n##安装ruby\n\n###方法一\n\n``` bash\n# http://www.ruby-lang.org/en/downloads/ ，选择 \"Stable Snapshot\"\ntar -zxf ruby-1.9-stable.tar.gz\ncd  cd ruby-1.9.3-p194/\n./configure\nmake\nsudo make install\n```\n\n###方法二\n\n``` bash\nsudo yum install ruby\n```\n\n##安装go\n\n``` bash\n#去官网 http://code.google.com/p/go/downloads 下载，go1.0.1.linux-i386.tar.gz (32位)，go1.0.1.linux-amd64.tar.gz（64位）\ntar -zxf go1.0.1.linux-amd64.tar.gz\nsudo mv go/ /usr/local/\n#设置环境变量\nsudo vim /etc/profile\nexport GOROOT=/usr/local/go\nexport PATH=$PATH:$GOROOT/bin\nsource /etc/profile\n#测试一下\ngo version\n```\n\n##安装lua\n\n``` bash\n# 去官网下载源码，编译，安装。由于官网仅提供源码，故推荐源码编译安装方式。\n# 去官网 http://www.lua.org/ 下载源码，lua-5.2.0.tar.gz\ntar -zxf lua-5.2.0.tar.gz \ncd lua-5.2.0\n# lua 依赖 readline.h 头文件\nsudo yum install  readline-devel\nmake linux\nsudo make install\n#安装 google protobuf\n#去官网 http://code.google.com/p/protobuf/下载\ntar -jxf protobuf-2.4.1.tar.bz2\ncd protobuf-2.4.1\n./configure\nmake\nsudo make install\n#测试\nprotoc\n```\n\n##清理安装包\n\n``` bash\ncd ~\nrm * -rf\n```\n\n##压缩打包\n安装完后，可以Clone，压缩打包成一个zip文件，方便分享给别人。\n\n在关机之前，有一件事需要做，\n\n\tsudo vim /etc/sysconfig/network-scripts/ifcfg-eth0, 把HWADDR=.... 这行删掉\n\tsudo rm /etc/udev/rules.d/70-persistent-net.rules\n\tsudo shutdown -h now\n\n如果没有执行上述命令，克隆后的虚拟机，开机后无法上网，重启网络，`sudo service network restart`也没有效果，会出现错误“Device eth0 does not seem to be present, delaying initialization.” \n\n这是因为克隆后的虚拟机，它的MAC地址变了，即在它的.vmx文件里，MAC地址变了（`ethernet0.generatedAddress`这项），但是linux不知道这个变化，网络配置文件还是旧的，这样跟它的而真实mac不匹配，网络就无法启动。\n\n执行上述命令，删除了`70-persistent-net.rules`后，相当于删除了旧的配置文件，在开机时会生成新的配置文件。\n\n关机后，右击标签，选择\"Manage->Clone\"，选择\"Create a full clone\"，克隆完成后，关闭这台虚拟机的标签（否则文件夹里有一些临时垃圾文件），然后把文件夹压缩打包。以后就可以把这个zip包拷贝给周围的人，别人就不用经历一遍重装的过程了。\n\n\n##参考资料\n[LAMP Server on CentOS 6](http://library.linode.com/lamp-guides/centos-6)\n\n[CentOS - Installing Apache and PHP5](http://articles.slicehost.com/2008/2/6/centos-installing-apache-and-php5)\n\n[Setting up a LAMP stack](http://fedorasolved.org/server-solutions/lamp-stack)\n\n[CentOS5.5使用yum来安装LAMP](http://myohmy.blog.51cto.com/140917/327310)\n\n[Install Java JDK on CentOS without prompts using an automated script!](http://it.megocollector.com/?p=1719)\n","source":"_posts/2012-04-23-install-and-configure-a-centos-server-from-scratch.md","raw":"---\nlayout: post\ntitle: \"安装和配置CentOS服务器的详细步骤\"\ndate: 2012-04-23 20:43\ncomments: true\ncategories: Tools\n---\n\n这是我安装CentOS服务器的过程，记录下来，与大家一起分享。Ubuntu请见[安装和配置Ubuntu服务器的详细步骤](http://cn.soulmachine.me/blog/20140417/)。\n\n##安装操作系统\nCentOS 6.2 ，CentOS-6.2-i386-bin-DVD1.iso（32位） ，CentOS-6.2-x86_64-bin-DVD1.iso（64位）\n\n安装 CentOS时，选择 \"Basic Server\"  \nroot密码：root123  \nCentOS 自带了ssh  \n \n安装完操作系统后，添加一个用户 manong\n\n``` bash\n[root@localhost ~]$ useradd manong\n\n```\n然后密码设为 manong123\n\n``` bash\n[root@localhost ~]$ passwd manong\n```\n\n给予 sudo 权限\n\n``` bash\n[root@localhost ~]$ chmod u+w /etc/sudoers\n[root@localhost ~]$ vim /etc/sudoers\n# 在root ALL=(ALL) ALL 下 添加manong ALL=(ALL) ALL\n[root@localhost ~]$ chmod u-w /etc/sudoers \n```\n\n##设置上网\n安装完操作系统后，还不能上网，配置DHCP方式上网：\n\n``` bash\nvim /etc/sysconfig/network-scripts/ifcfg-eth0\nDEVICE=\"eth0\"\nHWADDR=\"00:0C:29:BD:E1:19\"\nNM_CONTROLLED=\"yes\"\nONBOOT=\"yes\"\nBOOTPROTO=dhcp\nUSECTL=no\nTYPE=Ethernet\nPEERDNS=yes\n#保存退出\nsudo service network restart\n```\n\n<!-- more -->\n\n或者，配置静态IP\n\n``` bash\nDEVICE=\"eth0\"\nHWADDR=\"00:0C:29:10:F4:4C\"\nONBOOT=\"yes\"\nBOOTPROTO=static\nTYPE=Ethernet\nIPADDR=192.168.0.162\nNETMASK=255.255.255.0\nBROADCAST=192.168.0.255\nNETWORK=192.168.0.0\n#保存退出  \n#修改/etc/sysconfig/network\nsudo vim /etc/sysconfig/network\nNETWORKING=yes\nHOSTNAME=localhost.localdomain\nGATEWAY=192.168.0.1\n#保存退出，重启网络\nsudo service network restart\n```\n如果失败，比如IP已被占用，换一个IP试试\n\n修改DNS，即时生效\n\n``` bash\nsudo vim /etc/resolv.conf\nnameserver 192.168.0.1\n# google提供的域名服务器\nnameserver 8.8.8.8\nsearch localhost\n```\n\n##安装常用软件\n有两种方式，方法一，去官网下载已经编译好的二进制文件，或源代码，编译安装\n方法二，用yum 命令安装，安装官方yum源里已经编译好的程序包。  \n第一种方式要敲很多命令，比yum麻烦，但是可以预先下载好文件，省略了下载的时间，整体速度比yum安装方式快很多，而且可以安装最新版。推荐第一种方式\n\n第二种方式操作简单，敲打的命令少，但是往往yum源的更新速度跟不上各个软件的官网速度，用Yum安装的版本经常比较旧。\n\nyum的命令形式一般是如下：`yum [options] [command] [package ...]`，其中的[options]是可选的，选项包括-h（帮助），-y（当安装过程提示选择全部为\"yes\"），-q（不显示安装的过程）等等。[command]为所要进行的操作，[package ...]是操作的对象。\n\n``` bash\n#yum search package-name # 在线搜索包 \n#yum list installed # 列出所有已经安装的包\n#\n#sudo yum install package-name # 安装程序包 \n#sudo yum groupinsall group-name 安装程序组\n#\n#sudo yum remove package-name 删除程序包\n#sudo yum groupremove group-name 删除程序组\n#\n#yum update #全部更新\n#yum update package-name #更新程序包\n#sudo yum groupupdate groupn-name 升级程序组\n#sudo yum upgrade # 更新源列表\n#yum upgrade package-name #升级程序包\n#sudo yum clean all # 清除缓存\n#更新\nsudo yum update\n#清理缓存\nsudo yum clean all && yum clean metadata && yum clean dbcache\n```\n\n##安装编译工具\n\n###方法一\n去 http://gcc.gnu.org/ 下载源码\n\n``` bash\n# TODO\n```\n\n###方法二\n\n``` bash\nsudo yum groupinstall \"Development Tools\"\n```\n该命令类似于 Ubuntu 下的`apt-get install build-essential`，会自动安装一下软件包：autoconf automake bison byacc cscope ctags diffstat doxygen flex gcc gcc-c++ gcc-gfortran git indent intltool libtool patchutils rcs redhat-rpm-config rpm-build subversion swig systemtap，同时安装了以下依赖包：apr, apr-util, 等等。\n\n\n##安装JDK\n\n``` bash\n#删除旧的JDK\nyum list installed | grep jdk\n#复制显示出来的JDK，卸载\nsudo yum remove java-1.6.0-openjdk.x86_64\n#安装新的jdk\n```\n\n###方法一\n\n``` bash\n#从官网下载最新版的，当前是jdk6u32\n#开始安装\nchmod u+x chmod u+x jdk-6u32-linux-x64-rpm.bin\nsudo ./jdk-6u32-linux-x64-rpm.bin\n#设置环境变量，.bash_profile是当前用户，/etc/profile是所有用户的\nsudo vim /etc/profile\n#在末尾添加\nexport JAVA_HOME=/usr/java/default\nexport JRE_HOME=$JAVA_HOME/jre\nexport PATH=$PATH:$JAVA_HOME/bin\nexport CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar\n# 保存退出，输入以下命令使之立即生效：\nsource /etc/profile\n# 测试\njava -version\n```\n\n###方法二\n\n``` bash\nyum search jdk\n# java-1.6.0-openjdk只包含了JRE，如果在这台机器上开发java程序，则需要安装JDK，\n# 要选择 java-1.6.0-openjdk-devel，在服务器上我们只需要运行java程序，因此选择前者\nsudo yum install java-1.6.0-openjdk-devel\n# 使用 alternatives 工具设置默认JDK，参考：Installing a Java Development Kit on Red Hat Enterprise Linux\n/usr/sbin/alternatives --config java\n/usr/sbin/alternatives --config javac\n# 设置环境变量\n# 查询JDK路径\nwhereis java\nll /usr/bin/java\nll /etc/alternatives/java #这是可以看到JDK路径了\nsudo vim /etc/profile\n# 在末尾添加\nexport JAVA_HOME=/usr/lib/jvm/jre-1.6.0-openjdk.x86_64\nexport JRE_HOME=$JAVA_HOME/jre\nexport PATH=$PATH:$JAVA_HOME/bin\nexport CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar\n#保存退出，输入以下命令使之立即生效：\n# source /etc/profile\n# 测试\njava -version\n```\n\n##安装 apache\n\n###方法一\n源码在官网 http://httpd.apache.org/ 下载。  \n先下载apt, apr-util, pcre三个库，httpd 在编译时需要用到这三个库  \napr, apr-util官网 http://apr.apache.org , pcre官网为 [http://pcre.org ](http://pcre.org )\n\n``` bash\n# 编译，安装 apr\ntar -jxf apr-1.4.6.tar.bz2\ncd apr-1.4.6\n./configure\nmake\nsudo make install    # 默认会安装到 /usr/local/apr/\ncd ~\n#编译，安装 apr-util\ntar -jxf apr-util-1.4.1.tar.bz2\ncd apr-util-1.4.1\n./configure --with-apr=/usr/local/apr/\nmake\nsudo make install    # 默认会安装到 /usr/local/apr/\ncd ~\n#编译，安装 pcre\ntar -jxf pcre-8.30.tar.bz2\ncd  pcre-8.30\n./configure --with-apr=/usr/local/apr/\nmake\n# By default, `make install' installs the package's commands under\n#`/usr/local/bin', include files under `/usr/local/include', etc. \nsudo make install\ncd ~\n#编译，安装 apache\ntar -jxf httpd-2.2.22.tar.bz2\ncd httpd-2.2.22\n./configure\nmake\nsudo make install    # 默认会安装到/usr/local/apache2/\ncd ~\n#添加防火墙规则，让防火墙允许 apache的端口 80通过\nsudo vim /etc/sysconfig/iptables\n#添加如下一行（实际上是拷贝了原来的一行，仅仅改变了端口号），位置必须#要放在 含有 \"REJECT --reject-with\" 的行的前面\n-A INPUT -m state --state NEW -m tcp -p tcp --dport 80 -j ACCEPT\nsudo service iptables restart\n#测试\nsudo /usr/local/apache2/bin/apachectl start\n#在浏览器输入 http://ip地址 ，如果看到“It works”，说明安装成功\n/usr/local/apache2/bin/apachectl stop\n\n\n#设置为开机启动\n#将httpd注册为服务，通过chkconfig实现开机启动\n#以apachectl 为模板\nsudo cp /usr/local/apache2/bin/apachectl /etc/init.d/httpd\nsudo vim /etc/init.d/httpd\n# 在第一行 #!/bin/sh，添加如下一行，使其支持chkconfig命令\n# chkconfig: 2345 85 15\n# 保存，退出VIM编辑器\nsudo chmod u+x /etc/init.d/httpd\nsudo chkconfig --add httpd\nsudo chkconfig httpd on\n#检查一下，是否添加成功\nchkconfig --list httpd \n```\n\n###方法二\n\n``` bash\nsudo yum install httpd\n#可选？sudo yum install httpd-devel\n#测试\n#启动 apache http server\nsudo service httpd start\n#添加规则，让防火墙允许 apache的端口 80\nsudo vim /etc/sysconfig/iptables\n#添加如下一行，位置必须要放在 含有 \"REJECT --reject-with\" 的行的前面\n-A INPUT -m state --state NEW -m tcp -p tcp --dport 80 -j ACCEPT\nsudo service iptables restart\n#可以在浏览器输入 http://ip地址 测试了\n#设置为开机启动\nsudo chkconfig httpd on\n```\n\n##安装 mysql\n\n###方法一\n\n``` bash\n#去官网下载 Oracle & Red Hat 6的安装包，64位为MySQL-5.5.23-1.el6.x86_64.tar，\n#32位为 MySQL-5.5.23-1.el6.i686.tar\ntar -xf MySQL-5.5.23-1.el6.x86_64.tar\n#加 --force 是因为可能会与mysqllib库冲突\nsudo rpm -ivh --force  MySQL-server-5.5.23-1.el6.x86_64.rpm\nsudo rpm -ivh MySQL-client-5.5.23-1.el6.x86_64.rpm\n# 启动 mysql 服务器\nsudo service mysql start\n#设置为开机启动\nsudo chkconfig mysql on\n```\n\n###方法二\n\n``` bash\nsudo yum install mysql-server\nsudo chgrp -R mysql /var/lib/mysql\nsudo chmod -R 770 /var/lib/mysql\n# 启动 mysql 服务器\nsudo service mysqld start\n#设置为开机启动\nsudo chkconfig mysqld on\n```\n\n###公共的操作\n\n``` bash\n# root 初始密码为空，修改root密码\nmysql -u root\nmysql> use mysql;\nmysql> update user set password=password('root123') where user='root' AND host='localhost';\nmysql> flush privileges;\n# 打开MySQL中root账户的远程登录，参考：如何打开MySQL中root账户的远程登录mysql> GRANT ALL PRIVILEGES ON *.* TO root@\"%\" IDENTIFIED BY \"root\";\nmysql> update user set password=password('root123') where user='root' AND host='%';\nmysql> flush privileges;\nmysql> quit;\n#添加防火墙规则，让防火墙允许 mysql 的端口 3306通过\nsudo vim /etc/sysconfig/iptables\n#添加如下一行（实际上是拷贝了原来的一行，仅仅改变了端口号），位置必须#要放在 含有 \"REJECT --reject-with\" 的行的前面\n-A INPUT -m state --state NEW -m tcp -p tcp --dport 3306 -j ACCEPT\nsudo service iptables restart\n```\n\n##安装 php5\n\n###方法一\nTODO\n\n###方法二\n\n``` bash\nsudo yum install php php-pear\n#重启 apache，以确保apache 加载PHP模块\nsudo service httpd restart\n# 在 /var/www/html/下新建一个index.php文件，用于测试\ncd /var/www/html\nsudo vim index.php\n# 添加如下一行\n<?php phpinfo(); ?>\n# 在浏览器输入 http://xxx.xxx.xxx.xxx/index.php ，测试PHP是否成功安装\n\n# 如果需要在PHP中支持mysql，则需要安装 php-mysql 模块\nsudo yum install php-mysql\n# 如果需要在PHP中支持memcached，则需要安装 php-pecl-memcache 模块\nsudo yum install php-pecl-memcache\n#安装一些常用的PHP扩展模块\nsudo yum install php-devel php-gd php-mbstring php-xml\n\n#可以安装一个wordpress进行测试，注意要修改文件夹权限\nsudo chown -R apache.apache /var/www/html\n```\n\n## 安装 memcached\n\n###方法一\n\n``` bash\n# memcached依赖libevent，首先要安装 libevent\n# 去 http://libevent.org/ 下载libevent源码，然后编译，安装\ntar -zxf libevent-2.0.18-stable.tar.gz\ncd libevent-2.0.18-stable\n./configure\nmake\nsudo make install\n# 对于64位操作系统(32位不需要)，还需要配置：\nsudo ln -s /usr/local/lib/libevent-2.0.so.5 /usr/lib64//libevent-2.0.so.5\n# 去 http://www.memcached.org/ 下载 memcached，然后编译，安装\ntar -zxf memcached-1.4.13.tar.gz\ncd memcached-1.4.13\n./configure\nmake\nsudo make install\n# 启动, -p，端口,-m，内存, -u\nmemcached -p 11211 -m 512m -u root -d\n# 开机启动\n# centos设置开机启动有两种方式，一是把启动程序的命令添加到/etc/rc.d/rc.local文件中，二是把写好的启动脚本添加到目录/etc/rc.d/init.d/，然后使用命令chkconfig设置开机启动。第二种方式可以用 service xxx start|stop来启动或停止，所以推荐第二种。\n#将 memcached启动命令注册为一个服务\ncd /etc/init.d/\nsudo vim memcached\n#代码如下，参考：Linux中将memcached注册成服务并可以随机器启动时启动服务\n#chkconfig: 345 60 60\n#!/bin/bash\n\nstart()\n{\n        echo -n $\"Starting memcached: \"\n        /usr/local/bin/memcached -p 11211 -m 512m -u root -d\n        echo \"[OK]\"\n}\nstop()\n{\n        echo -n $\"Shutting down memcached: \"\n        memcached_pid_list=`pidof memcached` \n        kill -9 $memcached_pid_list\n        echo \"[OK]\"\n}\ncase \"$1\" in\n  start)\n        start\n        ;;\n  stop)\n        stop\n        ;;\n  restart)\n        stop\n        sleep 3\n        start\n        ;;\n    *)\n             echo $\"Usage: $0 {start|stop|restart}\"\n        exit 1\nesac\nexit 0\n#保存退出\nsudo chmod u+x memcached\nsudo chkconfig --add memcached\nsudo chkconfig  memcached on\n```\n\n###方法二\nTODO\n\n##安装 tomcat6\n\n###方法一\n\n``` bash\n# 去 http://tomcat.apache.org 下载 apache-tomcat-6.0.35.tar.gz\ntar -zxf apache-tomcat-6.0.35.tar.gz\nsudo mv apache-tomcat-6.0.35 /usr/local/\ncd /usr/local/apache-tomcat-6.0.35/bin\n#【可选】添加环境变量\nsudo vim /etc/profile\nexport CATALINA_HOME=/usr/local/apache-tomcat-6.0.35\n#启动 tomcat \nsudo ./startup.sh\n# 在浏览器输入 http://xxx.xxx.xxx.xxx:8080/ ，如果能看见tomcat页面，则表示安装成功了\n#设置开机启动\n#将 tomcat启动命令注册为一个服务\ncd /etc/init.d/\nsudo vim tomcatd\n#代码如下\n#chkconfig: 345 60 60\n#!/bin/bash\nCATALINA_HOME=/usr/local/apache-tomcat-6.0.35\n\nstart()\n{\n        echo -n $\"Starting Tomcat: \"\n        $CATALINA_HOME/bin/startup.sh\n        echo \"[OK]\"\n}\nstop()\n{\n        echo -n $\"Shutting down Tomcat: \"\n        $CATALINA_HOME/bin/shutdown.sh\n        echo \"[OK]\"\n}\ncase \"$1\" in\n  start)\n        start\n        ;;\n  stop)\n        stop\n        ;;\n  restart)\n        stop\n        sleep 3\n        start\n        ;;\n    *)\n             echo $\"Usage: $0 {start|stop|restart}\"\n        exit 1\nesac\nexit 0\n#保存退出\nsudo chmod u+x tomcatd\nsudo chkconfig --add tomcatd\nsudo chkconfig tomcatd on\n\n#添加防火墙规则，让防火墙允许 tomcat 的端口 8080 通过\nsudo vim /etc/sysconfig/iptables\n#添加如下一行（实际上是拷贝了原来的一行，仅仅改变了端口号），位置必须#要放在 含有 \"REJECT --reject-with\" 的行的前面\n-A INPUT -m state --state NEW -m tcp -p tcp --dport 8080 -j ACCEPT\nsudo service iptables restart\n```\n\n###方法二\n\n``` bash\n#搜索一下 tomcat包的名字\nyum search tomcat\nsudo yum search tomcat6.noarch\n```\n\n##安装Python\n\n###方法一：去[官网](http://www.python.org)下载源码，编译，安装\n\n``` bash\n#开始解压，编译，安装\ntar -jxf Python-3.2.3.tar.bz2\ncd Python-3.2.3\n# 查看一下说明, vim README\nsudo yum install zlib-devel bzip2-devel openssl-devel ncurses-devel sqlite-devel readline-devel tk-devel\n./configure\nmake\n#为了加快安装速度，这步可以省略\nmake test\n#卸载旧的python，注意，不能用 yum remove python，这会卸载几百个包，最终损坏系统\nsudo rpm -evf --nodeps python\nsudo make install\n#默认安装在 /usr/local/bin/python3\n```\n\n###方法二\n\n``` bash\nsudo yum install python\n```\n\n##安装ruby\n\n###方法一\n\n``` bash\n# http://www.ruby-lang.org/en/downloads/ ，选择 \"Stable Snapshot\"\ntar -zxf ruby-1.9-stable.tar.gz\ncd  cd ruby-1.9.3-p194/\n./configure\nmake\nsudo make install\n```\n\n###方法二\n\n``` bash\nsudo yum install ruby\n```\n\n##安装go\n\n``` bash\n#去官网 http://code.google.com/p/go/downloads 下载，go1.0.1.linux-i386.tar.gz (32位)，go1.0.1.linux-amd64.tar.gz（64位）\ntar -zxf go1.0.1.linux-amd64.tar.gz\nsudo mv go/ /usr/local/\n#设置环境变量\nsudo vim /etc/profile\nexport GOROOT=/usr/local/go\nexport PATH=$PATH:$GOROOT/bin\nsource /etc/profile\n#测试一下\ngo version\n```\n\n##安装lua\n\n``` bash\n# 去官网下载源码，编译，安装。由于官网仅提供源码，故推荐源码编译安装方式。\n# 去官网 http://www.lua.org/ 下载源码，lua-5.2.0.tar.gz\ntar -zxf lua-5.2.0.tar.gz \ncd lua-5.2.0\n# lua 依赖 readline.h 头文件\nsudo yum install  readline-devel\nmake linux\nsudo make install\n#安装 google protobuf\n#去官网 http://code.google.com/p/protobuf/下载\ntar -jxf protobuf-2.4.1.tar.bz2\ncd protobuf-2.4.1\n./configure\nmake\nsudo make install\n#测试\nprotoc\n```\n\n##清理安装包\n\n``` bash\ncd ~\nrm * -rf\n```\n\n##压缩打包\n安装完后，可以Clone，压缩打包成一个zip文件，方便分享给别人。\n\n在关机之前，有一件事需要做，\n\n\tsudo vim /etc/sysconfig/network-scripts/ifcfg-eth0, 把HWADDR=.... 这行删掉\n\tsudo rm /etc/udev/rules.d/70-persistent-net.rules\n\tsudo shutdown -h now\n\n如果没有执行上述命令，克隆后的虚拟机，开机后无法上网，重启网络，`sudo service network restart`也没有效果，会出现错误“Device eth0 does not seem to be present, delaying initialization.” \n\n这是因为克隆后的虚拟机，它的MAC地址变了，即在它的.vmx文件里，MAC地址变了（`ethernet0.generatedAddress`这项），但是linux不知道这个变化，网络配置文件还是旧的，这样跟它的而真实mac不匹配，网络就无法启动。\n\n执行上述命令，删除了`70-persistent-net.rules`后，相当于删除了旧的配置文件，在开机时会生成新的配置文件。\n\n关机后，右击标签，选择\"Manage->Clone\"，选择\"Create a full clone\"，克隆完成后，关闭这台虚拟机的标签（否则文件夹里有一些临时垃圾文件），然后把文件夹压缩打包。以后就可以把这个zip包拷贝给周围的人，别人就不用经历一遍重装的过程了。\n\n\n##参考资料\n[LAMP Server on CentOS 6](http://library.linode.com/lamp-guides/centos-6)\n\n[CentOS - Installing Apache and PHP5](http://articles.slicehost.com/2008/2/6/centos-installing-apache-and-php5)\n\n[Setting up a LAMP stack](http://fedorasolved.org/server-solutions/lamp-stack)\n\n[CentOS5.5使用yum来安装LAMP](http://myohmy.blog.51cto.com/140917/327310)\n\n[Install Java JDK on CentOS without prompts using an automated script!](http://it.megocollector.com/?p=1719)\n","slug":"2012-04-23-install-and-configure-a-centos-server-from-scratch","published":1,"updated":"2016-08-18T09:21:04.000Z","photos":[],"link":"","_id":"cis07pf2g000h01pqpp5xbo3h","content":"<p>这是我安装CentOS服务器的过程，记录下来，与大家一起分享。Ubuntu请见<a href=\"http://cn.soulmachine.me/blog/20140417/\">安装和配置Ubuntu服务器的详细步骤</a>。</p>\n<p>##安装操作系统<br>CentOS 6.2 ，CentOS-6.2-i386-bin-DVD1.iso（32位） ，CentOS-6.2-x86_64-bin-DVD1.iso（64位）</p>\n<p>安装 CentOS时，选择 “Basic Server”<br>root密码：root123<br>CentOS 自带了ssh  </p>\n<p>安装完操作系统后，添加一个用户 manong</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">[root@localhost ~]$ useradd manong</div></pre></td></tr></table></figure>\n<p>然后密码设为 manong123</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">[root@localhost ~]$ passwd manong</div></pre></td></tr></table></figure>\n<p>给予 sudo 权限</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\">[root@localhost ~]$ chmod u+w /etc/sudoers</div><div class=\"line\">[root@localhost ~]$ vim /etc/sudoers</div><div class=\"line\"><span class=\"comment\"># 在root ALL=(ALL) ALL 下 添加manong ALL=(ALL) ALL</span></div><div class=\"line\">[root@localhost ~]$ chmod u-w /etc/sudoers</div></pre></td></tr></table></figure>\n<p>##设置上网<br>安装完操作系统后，还不能上网，配置DHCP方式上网：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div></pre></td><td class=\"code\"><pre><div class=\"line\">vim /etc/sysconfig/network-scripts/ifcfg-eth0</div><div class=\"line\">DEVICE=<span class=\"string\">\"eth0\"</span></div><div class=\"line\">HWADDR=<span class=\"string\">\"00:0C:29:BD:E1:19\"</span></div><div class=\"line\">NM_CONTROLLED=<span class=\"string\">\"yes\"</span></div><div class=\"line\">ONBOOT=<span class=\"string\">\"yes\"</span></div><div class=\"line\">BOOTPROTO=dhcp</div><div class=\"line\">USECTL=no</div><div class=\"line\">TYPE=Ethernet</div><div class=\"line\">PEERDNS=yes</div><div class=\"line\"><span class=\"comment\">#保存退出</span></div><div class=\"line\">sudo service network restart</div></pre></td></tr></table></figure>\n<a id=\"more\"></a>\n<p>或者，配置静态IP</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div></pre></td><td class=\"code\"><pre><div class=\"line\">DEVICE=<span class=\"string\">\"eth0\"</span></div><div class=\"line\">HWADDR=<span class=\"string\">\"00:0C:29:10:F4:4C\"</span></div><div class=\"line\">ONBOOT=<span class=\"string\">\"yes\"</span></div><div class=\"line\">BOOTPROTO=static</div><div class=\"line\">TYPE=Ethernet</div><div class=\"line\">IPADDR=192.168.0.162</div><div class=\"line\">NETMASK=255.255.255.0</div><div class=\"line\">BROADCAST=192.168.0.255</div><div class=\"line\">NETWORK=192.168.0.0</div><div class=\"line\"><span class=\"comment\">#保存退出  </span></div><div class=\"line\"><span class=\"comment\">#修改/etc/sysconfig/network</span></div><div class=\"line\">sudo vim /etc/sysconfig/network</div><div class=\"line\">NETWORKING=yes</div><div class=\"line\">HOSTNAME=localhost.localdomain</div><div class=\"line\">GATEWAY=192.168.0.1</div><div class=\"line\"><span class=\"comment\">#保存退出，重启网络</span></div><div class=\"line\">sudo service network restart</div></pre></td></tr></table></figure>\n<p>如果失败，比如IP已被占用，换一个IP试试</p>\n<p>修改DNS，即时生效</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\">sudo vim /etc/resolv.conf</div><div class=\"line\">nameserver 192.168.0.1</div><div class=\"line\"><span class=\"comment\"># google提供的域名服务器</span></div><div class=\"line\">nameserver 8.8.8.8</div><div class=\"line\">search localhost</div></pre></td></tr></table></figure>\n<p>##安装常用软件<br>有两种方式，方法一，去官网下载已经编译好的二进制文件，或源代码，编译安装<br>方法二，用yum 命令安装，安装官方yum源里已经编译好的程序包。<br>第一种方式要敲很多命令，比yum麻烦，但是可以预先下载好文件，省略了下载的时间，整体速度比yum安装方式快很多，而且可以安装最新版。推荐第一种方式</p>\n<p>第二种方式操作简单，敲打的命令少，但是往往yum源的更新速度跟不上各个软件的官网速度，用Yum安装的版本经常比较旧。</p>\n<p>yum的命令形式一般是如下：<code>yum [options] [command] [package ...]</code>，其中的[options]是可选的，选项包括-h（帮助），-y（当安装过程提示选择全部为”yes”），-q（不显示安装的过程）等等。[command]为所要进行的操作，[package …]是操作的对象。</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">#yum search package-name # 在线搜索包 </span></div><div class=\"line\"><span class=\"comment\">#yum list installed # 列出所有已经安装的包</span></div><div class=\"line\"><span class=\"comment\">#</span></div><div class=\"line\"><span class=\"comment\">#sudo yum install package-name # 安装程序包 </span></div><div class=\"line\"><span class=\"comment\">#sudo yum groupinsall group-name 安装程序组</span></div><div class=\"line\"><span class=\"comment\">#</span></div><div class=\"line\"><span class=\"comment\">#sudo yum remove package-name 删除程序包</span></div><div class=\"line\"><span class=\"comment\">#sudo yum groupremove group-name 删除程序组</span></div><div class=\"line\"><span class=\"comment\">#</span></div><div class=\"line\"><span class=\"comment\">#yum update #全部更新</span></div><div class=\"line\"><span class=\"comment\">#yum update package-name #更新程序包</span></div><div class=\"line\"><span class=\"comment\">#sudo yum groupupdate groupn-name 升级程序组</span></div><div class=\"line\"><span class=\"comment\">#sudo yum upgrade # 更新源列表</span></div><div class=\"line\"><span class=\"comment\">#yum upgrade package-name #升级程序包</span></div><div class=\"line\"><span class=\"comment\">#sudo yum clean all # 清除缓存</span></div><div class=\"line\"><span class=\"comment\">#更新</span></div><div class=\"line\">sudo yum update</div><div class=\"line\"><span class=\"comment\">#清理缓存</span></div><div class=\"line\">sudo yum clean all &amp;&amp; yum clean metadata &amp;&amp; yum clean dbcache</div></pre></td></tr></table></figure>\n<p>##安装编译工具</p>\n<p>###方法一<br>去 <a href=\"http://gcc.gnu.org/\" target=\"_blank\" rel=\"external\">http://gcc.gnu.org/</a> 下载源码</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># TODO</span></div></pre></td></tr></table></figure>\n<p>###方法二</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">sudo yum groupinstall <span class=\"string\">\"Development Tools\"</span></div></pre></td></tr></table></figure>\n<p>该命令类似于 Ubuntu 下的<code>apt-get install build-essential</code>，会自动安装一下软件包：autoconf automake bison byacc cscope ctags diffstat doxygen flex gcc gcc-c++ gcc-gfortran git indent intltool libtool patchutils rcs redhat-rpm-config rpm-build subversion swig systemtap，同时安装了以下依赖包：apr, apr-util, 等等。</p>\n<p>##安装JDK</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">#删除旧的JDK</span></div><div class=\"line\">yum list installed | grep jdk</div><div class=\"line\"><span class=\"comment\">#复制显示出来的JDK，卸载</span></div><div class=\"line\">sudo yum remove java-1.6.0-openjdk.x86_64</div><div class=\"line\"><span class=\"comment\">#安装新的jdk</span></div></pre></td></tr></table></figure>\n<p>###方法一</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">#从官网下载最新版的，当前是jdk6u32</span></div><div class=\"line\"><span class=\"comment\">#开始安装</span></div><div class=\"line\">chmod u+x chmod u+x jdk-6u32-linux-x64-rpm.bin</div><div class=\"line\">sudo ./jdk-6u32-linux-x64-rpm.bin</div><div class=\"line\"><span class=\"comment\">#设置环境变量，.bash_profile是当前用户，/etc/profile是所有用户的</span></div><div class=\"line\">sudo vim /etc/profile</div><div class=\"line\"><span class=\"comment\">#在末尾添加</span></div><div class=\"line\"><span class=\"built_in\">export</span> JAVA_HOME=/usr/java/default</div><div class=\"line\"><span class=\"built_in\">export</span> JRE_HOME=<span class=\"variable\">$JAVA_HOME</span>/jre</div><div class=\"line\"><span class=\"built_in\">export</span> PATH=<span class=\"variable\">$PATH</span>:<span class=\"variable\">$JAVA_HOME</span>/bin</div><div class=\"line\"><span class=\"built_in\">export</span> CLASSPATH=.:<span class=\"variable\">$JAVA_HOME</span>/lib/dt.jar:<span class=\"variable\">$JAVA_HOME</span>/lib/tools.jar</div><div class=\"line\"><span class=\"comment\"># 保存退出，输入以下命令使之立即生效：</span></div><div class=\"line\"><span class=\"built_in\">source</span> /etc/profile</div><div class=\"line\"><span class=\"comment\"># 测试</span></div><div class=\"line\">java -version</div></pre></td></tr></table></figure>\n<p>###方法二</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div></pre></td><td class=\"code\"><pre><div class=\"line\">yum search jdk</div><div class=\"line\"><span class=\"comment\"># java-1.6.0-openjdk只包含了JRE，如果在这台机器上开发java程序，则需要安装JDK，</span></div><div class=\"line\"><span class=\"comment\"># 要选择 java-1.6.0-openjdk-devel，在服务器上我们只需要运行java程序，因此选择前者</span></div><div class=\"line\">sudo yum install java-1.6.0-openjdk-devel</div><div class=\"line\"><span class=\"comment\"># 使用 alternatives 工具设置默认JDK，参考：Installing a Java Development Kit on Red Hat Enterprise Linux</span></div><div class=\"line\">/usr/sbin/alternatives --config java</div><div class=\"line\">/usr/sbin/alternatives --config javac</div><div class=\"line\"><span class=\"comment\"># 设置环境变量</span></div><div class=\"line\"><span class=\"comment\"># 查询JDK路径</span></div><div class=\"line\">whereis java</div><div class=\"line\">ll /usr/bin/java</div><div class=\"line\">ll /etc/alternatives/java <span class=\"comment\">#这是可以看到JDK路径了</span></div><div class=\"line\">sudo vim /etc/profile</div><div class=\"line\"><span class=\"comment\"># 在末尾添加</span></div><div class=\"line\"><span class=\"built_in\">export</span> JAVA_HOME=/usr/lib/jvm/jre-1.6.0-openjdk.x86_64</div><div class=\"line\"><span class=\"built_in\">export</span> JRE_HOME=<span class=\"variable\">$JAVA_HOME</span>/jre</div><div class=\"line\"><span class=\"built_in\">export</span> PATH=<span class=\"variable\">$PATH</span>:<span class=\"variable\">$JAVA_HOME</span>/bin</div><div class=\"line\"><span class=\"built_in\">export</span> CLASSPATH=.:<span class=\"variable\">$JAVA_HOME</span>/lib/dt.jar:<span class=\"variable\">$JAVA_HOME</span>/lib/tools.jar</div><div class=\"line\"><span class=\"comment\">#保存退出，输入以下命令使之立即生效：</span></div><div class=\"line\"><span class=\"comment\"># source /etc/profile</span></div><div class=\"line\"><span class=\"comment\"># 测试</span></div><div class=\"line\">java -version</div></pre></td></tr></table></figure>\n<p>##安装 apache</p>\n<p>###方法一<br>源码在官网 <a href=\"http://httpd.apache.org/\" target=\"_blank\" rel=\"external\">http://httpd.apache.org/</a> 下载。<br>先下载apt, apr-util, pcre三个库，httpd 在编译时需要用到这三个库<br>apr, apr-util官网 <a href=\"http://apr.apache.org\" target=\"_blank\" rel=\"external\">http://apr.apache.org</a> , pcre官网为 <a href=\"http://pcre.org\" target=\"_blank\" rel=\"external\">http://pcre.org </a></p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div><div class=\"line\">51</div><div class=\"line\">52</div><div class=\"line\">53</div><div class=\"line\">54</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># 编译，安装 apr</span></div><div class=\"line\">tar -jxf apr-1.4.6.tar.bz2</div><div class=\"line\"><span class=\"built_in\">cd</span> apr-1.4.6</div><div class=\"line\">./configure</div><div class=\"line\">make</div><div class=\"line\">sudo make install    <span class=\"comment\"># 默认会安装到 /usr/local/apr/</span></div><div class=\"line\"><span class=\"built_in\">cd</span> ~</div><div class=\"line\"><span class=\"comment\">#编译，安装 apr-util</span></div><div class=\"line\">tar -jxf apr-util-1.4.1.tar.bz2</div><div class=\"line\"><span class=\"built_in\">cd</span> apr-util-1.4.1</div><div class=\"line\">./configure --with-apr=/usr/<span class=\"built_in\">local</span>/apr/</div><div class=\"line\">make</div><div class=\"line\">sudo make install    <span class=\"comment\"># 默认会安装到 /usr/local/apr/</span></div><div class=\"line\"><span class=\"built_in\">cd</span> ~</div><div class=\"line\"><span class=\"comment\">#编译，安装 pcre</span></div><div class=\"line\">tar -jxf pcre-8.30.tar.bz2</div><div class=\"line\"><span class=\"built_in\">cd</span>  pcre-8.30</div><div class=\"line\">./configure --with-apr=/usr/<span class=\"built_in\">local</span>/apr/</div><div class=\"line\">make</div><div class=\"line\"><span class=\"comment\"># By default, `make install' installs the package's commands under</span></div><div class=\"line\"><span class=\"comment\">#`/usr/local/bin', include files under `/usr/local/include', etc. </span></div><div class=\"line\">sudo make install</div><div class=\"line\"><span class=\"built_in\">cd</span> ~</div><div class=\"line\"><span class=\"comment\">#编译，安装 apache</span></div><div class=\"line\">tar -jxf httpd-2.2.22.tar.bz2</div><div class=\"line\"><span class=\"built_in\">cd</span> httpd-2.2.22</div><div class=\"line\">./configure</div><div class=\"line\">make</div><div class=\"line\">sudo make install    <span class=\"comment\"># 默认会安装到/usr/local/apache2/</span></div><div class=\"line\"><span class=\"built_in\">cd</span> ~</div><div class=\"line\"><span class=\"comment\">#添加防火墙规则，让防火墙允许 apache的端口 80通过</span></div><div class=\"line\">sudo vim /etc/sysconfig/iptables</div><div class=\"line\"><span class=\"comment\">#添加如下一行（实际上是拷贝了原来的一行，仅仅改变了端口号），位置必须#要放在 含有 \"REJECT --reject-with\" 的行的前面</span></div><div class=\"line\">-A INPUT -m state --state NEW -m tcp -p tcp --dport 80 -j ACCEPT</div><div class=\"line\">sudo service iptables restart</div><div class=\"line\"><span class=\"comment\">#测试</span></div><div class=\"line\">sudo /usr/<span class=\"built_in\">local</span>/apache2/bin/apachectl start</div><div class=\"line\"><span class=\"comment\">#在浏览器输入 http://ip地址 ，如果看到“It works”，说明安装成功</span></div><div class=\"line\">/usr/<span class=\"built_in\">local</span>/apache2/bin/apachectl stop</div><div class=\"line\"></div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\">#设置为开机启动</span></div><div class=\"line\"><span class=\"comment\">#将httpd注册为服务，通过chkconfig实现开机启动</span></div><div class=\"line\"><span class=\"comment\">#以apachectl 为模板</span></div><div class=\"line\">sudo cp /usr/<span class=\"built_in\">local</span>/apache2/bin/apachectl /etc/init.d/httpd</div><div class=\"line\">sudo vim /etc/init.d/httpd</div><div class=\"line\"><span class=\"comment\"># 在第一行 #!/bin/sh，添加如下一行，使其支持chkconfig命令</span></div><div class=\"line\"><span class=\"comment\"># chkconfig: 2345 85 15</span></div><div class=\"line\"><span class=\"comment\"># 保存，退出VIM编辑器</span></div><div class=\"line\">sudo chmod u+x /etc/init.d/httpd</div><div class=\"line\">sudo chkconfig --add httpd</div><div class=\"line\">sudo chkconfig httpd on</div><div class=\"line\"><span class=\"comment\">#检查一下，是否添加成功</span></div><div class=\"line\">chkconfig --list httpd</div></pre></td></tr></table></figure>\n<p>###方法二</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div></pre></td><td class=\"code\"><pre><div class=\"line\">sudo yum install httpd</div><div class=\"line\"><span class=\"comment\">#可选？sudo yum install httpd-devel</span></div><div class=\"line\"><span class=\"comment\">#测试</span></div><div class=\"line\"><span class=\"comment\">#启动 apache http server</span></div><div class=\"line\">sudo service httpd start</div><div class=\"line\"><span class=\"comment\">#添加规则，让防火墙允许 apache的端口 80</span></div><div class=\"line\">sudo vim /etc/sysconfig/iptables</div><div class=\"line\"><span class=\"comment\">#添加如下一行，位置必须要放在 含有 \"REJECT --reject-with\" 的行的前面</span></div><div class=\"line\">-A INPUT -m state --state NEW -m tcp -p tcp --dport 80 -j ACCEPT</div><div class=\"line\">sudo service iptables restart</div><div class=\"line\"><span class=\"comment\">#可以在浏览器输入 http://ip地址 测试了</span></div><div class=\"line\"><span class=\"comment\">#设置为开机启动</span></div><div class=\"line\">sudo chkconfig httpd on</div></pre></td></tr></table></figure>\n<p>##安装 mysql</p>\n<p>###方法一</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">#去官网下载 Oracle &amp; Red Hat 6的安装包，64位为MySQL-5.5.23-1.el6.x86_64.tar，</span></div><div class=\"line\"><span class=\"comment\">#32位为 MySQL-5.5.23-1.el6.i686.tar</span></div><div class=\"line\">tar -xf MySQL-5.5.23-1.el6.x86_64.tar</div><div class=\"line\"><span class=\"comment\">#加 --force 是因为可能会与mysqllib库冲突</span></div><div class=\"line\">sudo rpm -ivh --force  MySQL-server-5.5.23-1.el6.x86_64.rpm</div><div class=\"line\">sudo rpm -ivh MySQL-client-5.5.23-1.el6.x86_64.rpm</div><div class=\"line\"><span class=\"comment\"># 启动 mysql 服务器</span></div><div class=\"line\">sudo service mysql start</div><div class=\"line\"><span class=\"comment\">#设置为开机启动</span></div><div class=\"line\">sudo chkconfig mysql on</div></pre></td></tr></table></figure>\n<p>###方法二</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div></pre></td><td class=\"code\"><pre><div class=\"line\">sudo yum install mysql-server</div><div class=\"line\">sudo chgrp -R mysql /var/lib/mysql</div><div class=\"line\">sudo chmod -R 770 /var/lib/mysql</div><div class=\"line\"><span class=\"comment\"># 启动 mysql 服务器</span></div><div class=\"line\">sudo service mysqld start</div><div class=\"line\"><span class=\"comment\">#设置为开机启动</span></div><div class=\"line\">sudo chkconfig mysqld on</div></pre></td></tr></table></figure>\n<p>###公共的操作</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># root 初始密码为空，修改root密码</span></div><div class=\"line\">mysql -u root</div><div class=\"line\">mysql&gt; use mysql;</div><div class=\"line\">mysql&gt; update user <span class=\"built_in\">set</span> password=password(<span class=\"string\">'root123'</span>) <span class=\"built_in\">where</span> user=<span class=\"string\">'root'</span> AND host=<span class=\"string\">'localhost'</span>;</div><div class=\"line\">mysql&gt; flush privileges;</div><div class=\"line\"><span class=\"comment\"># 打开MySQL中root账户的远程登录，参考：如何打开MySQL中root账户的远程登录mysql&gt; GRANT ALL PRIVILEGES ON *.* TO root@\"%\" IDENTIFIED BY \"root\";</span></div><div class=\"line\">mysql&gt; update user <span class=\"built_in\">set</span> password=password(<span class=\"string\">'root123'</span>) <span class=\"built_in\">where</span> user=<span class=\"string\">'root'</span> AND host=<span class=\"string\">'%'</span>;</div><div class=\"line\">mysql&gt; flush privileges;</div><div class=\"line\">mysql&gt; quit;</div><div class=\"line\"><span class=\"comment\">#添加防火墙规则，让防火墙允许 mysql 的端口 3306通过</span></div><div class=\"line\">sudo vim /etc/sysconfig/iptables</div><div class=\"line\"><span class=\"comment\">#添加如下一行（实际上是拷贝了原来的一行，仅仅改变了端口号），位置必须#要放在 含有 \"REJECT --reject-with\" 的行的前面</span></div><div class=\"line\">-A INPUT -m state --state NEW -m tcp -p tcp --dport 3306 -j ACCEPT</div><div class=\"line\">sudo service iptables restart</div></pre></td></tr></table></figure>\n<p>##安装 php5</p>\n<p>###方法一<br>TODO</p>\n<p>###方法二</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div></pre></td><td class=\"code\"><pre><div class=\"line\">sudo yum install php php-pear</div><div class=\"line\"><span class=\"comment\">#重启 apache，以确保apache 加载PHP模块</span></div><div class=\"line\">sudo service httpd restart</div><div class=\"line\"><span class=\"comment\"># 在 /var/www/html/下新建一个index.php文件，用于测试</span></div><div class=\"line\"><span class=\"built_in\">cd</span> /var/www/html</div><div class=\"line\">sudo vim index.php</div><div class=\"line\"><span class=\"comment\"># 添加如下一行</span></div><div class=\"line\">&lt;?php phpinfo(); ?&gt;</div><div class=\"line\"><span class=\"comment\"># 在浏览器输入 http://xxx.xxx.xxx.xxx/index.php ，测试PHP是否成功安装</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\"># 如果需要在PHP中支持mysql，则需要安装 php-mysql 模块</span></div><div class=\"line\">sudo yum install php-mysql</div><div class=\"line\"><span class=\"comment\"># 如果需要在PHP中支持memcached，则需要安装 php-pecl-memcache 模块</span></div><div class=\"line\">sudo yum install php-pecl-memcache</div><div class=\"line\"><span class=\"comment\">#安装一些常用的PHP扩展模块</span></div><div class=\"line\">sudo yum install php-devel php-gd php-mbstring php-xml</div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\">#可以安装一个wordpress进行测试，注意要修改文件夹权限</span></div><div class=\"line\">sudo chown -R apache.apache /var/www/html</div></pre></td></tr></table></figure>\n<h2 id=\"安装-memcached\"><a href=\"#安装-memcached\" class=\"headerlink\" title=\"安装 memcached\"></a>安装 memcached</h2><p>###方法一</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div><div class=\"line\">51</div><div class=\"line\">52</div><div class=\"line\">53</div><div class=\"line\">54</div><div class=\"line\">55</div><div class=\"line\">56</div><div class=\"line\">57</div><div class=\"line\">58</div><div class=\"line\">59</div><div class=\"line\">60</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># memcached依赖libevent，首先要安装 libevent</span></div><div class=\"line\"><span class=\"comment\"># 去 http://libevent.org/ 下载libevent源码，然后编译，安装</span></div><div class=\"line\">tar -zxf libevent-2.0.18-stable.tar.gz</div><div class=\"line\"><span class=\"built_in\">cd</span> libevent-2.0.18-stable</div><div class=\"line\">./configure</div><div class=\"line\">make</div><div class=\"line\">sudo make install</div><div class=\"line\"><span class=\"comment\"># 对于64位操作系统(32位不需要)，还需要配置：</span></div><div class=\"line\">sudo ln <span class=\"_\">-s</span> /usr/<span class=\"built_in\">local</span>/lib/libevent-2.0.so.5 /usr/lib64//libevent-2.0.so.5</div><div class=\"line\"><span class=\"comment\"># 去 http://www.memcached.org/ 下载 memcached，然后编译，安装</span></div><div class=\"line\">tar -zxf memcached-1.4.13.tar.gz</div><div class=\"line\"><span class=\"built_in\">cd</span> memcached-1.4.13</div><div class=\"line\">./configure</div><div class=\"line\">make</div><div class=\"line\">sudo make install</div><div class=\"line\"><span class=\"comment\"># 启动, -p，端口,-m，内存, -u</span></div><div class=\"line\">memcached -p 11211 -m 512m -u root <span class=\"_\">-d</span></div><div class=\"line\"><span class=\"comment\"># 开机启动</span></div><div class=\"line\"><span class=\"comment\"># centos设置开机启动有两种方式，一是把启动程序的命令添加到/etc/rc.d/rc.local文件中，二是把写好的启动脚本添加到目录/etc/rc.d/init.d/，然后使用命令chkconfig设置开机启动。第二种方式可以用 service xxx start|stop来启动或停止，所以推荐第二种。</span></div><div class=\"line\"><span class=\"comment\">#将 memcached启动命令注册为一个服务</span></div><div class=\"line\"><span class=\"built_in\">cd</span> /etc/init.d/</div><div class=\"line\">sudo vim memcached</div><div class=\"line\"><span class=\"comment\">#代码如下，参考：Linux中将memcached注册成服务并可以随机器启动时启动服务</span></div><div class=\"line\"><span class=\"comment\">#chkconfig: 345 60 60</span></div><div class=\"line\"><span class=\"meta\">#!/bin/bash</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"function\"><span class=\"title\">start</span></span>()</div><div class=\"line\">&#123;</div><div class=\"line\">        <span class=\"built_in\">echo</span> -n $<span class=\"string\">\"Starting memcached: \"</span></div><div class=\"line\">        /usr/<span class=\"built_in\">local</span>/bin/memcached -p 11211 -m 512m -u root <span class=\"_\">-d</span></div><div class=\"line\">        <span class=\"built_in\">echo</span> <span class=\"string\">\"[OK]\"</span></div><div class=\"line\">&#125;</div><div class=\"line\"><span class=\"function\"><span class=\"title\">stop</span></span>()</div><div class=\"line\">&#123;</div><div class=\"line\">        <span class=\"built_in\">echo</span> -n $<span class=\"string\">\"Shutting down memcached: \"</span></div><div class=\"line\">        memcached_pid_list=`pidof memcached` </div><div class=\"line\">        <span class=\"built_in\">kill</span> -9 <span class=\"variable\">$memcached_pid_list</span></div><div class=\"line\">        <span class=\"built_in\">echo</span> <span class=\"string\">\"[OK]\"</span></div><div class=\"line\">&#125;</div><div class=\"line\"><span class=\"keyword\">case</span> <span class=\"string\">\"<span class=\"variable\">$1</span>\"</span> <span class=\"keyword\">in</span></div><div class=\"line\">  start)</div><div class=\"line\">        start</div><div class=\"line\">        ;;</div><div class=\"line\">  stop)</div><div class=\"line\">        stop</div><div class=\"line\">        ;;</div><div class=\"line\">  restart)</div><div class=\"line\">        stop</div><div class=\"line\">        sleep 3</div><div class=\"line\">        start</div><div class=\"line\">        ;;</div><div class=\"line\">    *)</div><div class=\"line\">             <span class=\"built_in\">echo</span> $<span class=\"string\">\"Usage: <span class=\"variable\">$0</span> &#123;start|stop|restart&#125;\"</span></div><div class=\"line\">        <span class=\"built_in\">exit</span> 1</div><div class=\"line\"><span class=\"keyword\">esac</span></div><div class=\"line\"><span class=\"built_in\">exit</span> 0</div><div class=\"line\"><span class=\"comment\">#保存退出</span></div><div class=\"line\">sudo chmod u+x memcached</div><div class=\"line\">sudo chkconfig --add memcached</div><div class=\"line\">sudo chkconfig  memcached on</div></pre></td></tr></table></figure>\n<p>###方法二<br>TODO</p>\n<p>##安装 tomcat6</p>\n<p>###方法一</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div><div class=\"line\">51</div><div class=\"line\">52</div><div class=\"line\">53</div><div class=\"line\">54</div><div class=\"line\">55</div><div class=\"line\">56</div><div class=\"line\">57</div><div class=\"line\">58</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># 去 http://tomcat.apache.org 下载 apache-tomcat-6.0.35.tar.gz</span></div><div class=\"line\">tar -zxf apache-tomcat-6.0.35.tar.gz</div><div class=\"line\">sudo mv apache-tomcat-6.0.35 /usr/<span class=\"built_in\">local</span>/</div><div class=\"line\"><span class=\"built_in\">cd</span> /usr/<span class=\"built_in\">local</span>/apache-tomcat-6.0.35/bin</div><div class=\"line\"><span class=\"comment\">#【可选】添加环境变量</span></div><div class=\"line\">sudo vim /etc/profile</div><div class=\"line\"><span class=\"built_in\">export</span> CATALINA_HOME=/usr/<span class=\"built_in\">local</span>/apache-tomcat-6.0.35</div><div class=\"line\"><span class=\"comment\">#启动 tomcat </span></div><div class=\"line\">sudo ./startup.sh</div><div class=\"line\"><span class=\"comment\"># 在浏览器输入 http://xxx.xxx.xxx.xxx:8080/ ，如果能看见tomcat页面，则表示安装成功了</span></div><div class=\"line\"><span class=\"comment\">#设置开机启动</span></div><div class=\"line\"><span class=\"comment\">#将 tomcat启动命令注册为一个服务</span></div><div class=\"line\"><span class=\"built_in\">cd</span> /etc/init.d/</div><div class=\"line\">sudo vim tomcatd</div><div class=\"line\"><span class=\"comment\">#代码如下</span></div><div class=\"line\"><span class=\"comment\">#chkconfig: 345 60 60</span></div><div class=\"line\"><span class=\"meta\">#!/bin/bash</span></div><div class=\"line\">CATALINA_HOME=/usr/<span class=\"built_in\">local</span>/apache-tomcat-6.0.35</div><div class=\"line\"></div><div class=\"line\"><span class=\"function\"><span class=\"title\">start</span></span>()</div><div class=\"line\">&#123;</div><div class=\"line\">        <span class=\"built_in\">echo</span> -n $<span class=\"string\">\"Starting Tomcat: \"</span></div><div class=\"line\">        <span class=\"variable\">$CATALINA_HOME</span>/bin/startup.sh</div><div class=\"line\">        <span class=\"built_in\">echo</span> <span class=\"string\">\"[OK]\"</span></div><div class=\"line\">&#125;</div><div class=\"line\"><span class=\"function\"><span class=\"title\">stop</span></span>()</div><div class=\"line\">&#123;</div><div class=\"line\">        <span class=\"built_in\">echo</span> -n $<span class=\"string\">\"Shutting down Tomcat: \"</span></div><div class=\"line\">        <span class=\"variable\">$CATALINA_HOME</span>/bin/shutdown.sh</div><div class=\"line\">        <span class=\"built_in\">echo</span> <span class=\"string\">\"[OK]\"</span></div><div class=\"line\">&#125;</div><div class=\"line\"><span class=\"keyword\">case</span> <span class=\"string\">\"<span class=\"variable\">$1</span>\"</span> <span class=\"keyword\">in</span></div><div class=\"line\">  start)</div><div class=\"line\">        start</div><div class=\"line\">        ;;</div><div class=\"line\">  stop)</div><div class=\"line\">        stop</div><div class=\"line\">        ;;</div><div class=\"line\">  restart)</div><div class=\"line\">        stop</div><div class=\"line\">        sleep 3</div><div class=\"line\">        start</div><div class=\"line\">        ;;</div><div class=\"line\">    *)</div><div class=\"line\">             <span class=\"built_in\">echo</span> $<span class=\"string\">\"Usage: <span class=\"variable\">$0</span> &#123;start|stop|restart&#125;\"</span></div><div class=\"line\">        <span class=\"built_in\">exit</span> 1</div><div class=\"line\"><span class=\"keyword\">esac</span></div><div class=\"line\"><span class=\"built_in\">exit</span> 0</div><div class=\"line\"><span class=\"comment\">#保存退出</span></div><div class=\"line\">sudo chmod u+x tomcatd</div><div class=\"line\">sudo chkconfig --add tomcatd</div><div class=\"line\">sudo chkconfig tomcatd on</div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\">#添加防火墙规则，让防火墙允许 tomcat 的端口 8080 通过</span></div><div class=\"line\">sudo vim /etc/sysconfig/iptables</div><div class=\"line\"><span class=\"comment\">#添加如下一行（实际上是拷贝了原来的一行，仅仅改变了端口号），位置必须#要放在 含有 \"REJECT --reject-with\" 的行的前面</span></div><div class=\"line\">-A INPUT -m state --state NEW -m tcp -p tcp --dport 8080 -j ACCEPT</div><div class=\"line\">sudo service iptables restart</div></pre></td></tr></table></figure>\n<p>###方法二</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">#搜索一下 tomcat包的名字</span></div><div class=\"line\">yum search tomcat</div><div class=\"line\">sudo yum search tomcat6.noarch</div></pre></td></tr></table></figure>\n<p>##安装Python</p>\n<p>###方法一：去<a href=\"http://www.python.org\" target=\"_blank\" rel=\"external\">官网</a>下载源码，编译，安装</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">#开始解压，编译，安装</span></div><div class=\"line\">tar -jxf Python-3.2.3.tar.bz2</div><div class=\"line\"><span class=\"built_in\">cd</span> Python-3.2.3</div><div class=\"line\"><span class=\"comment\"># 查看一下说明, vim README</span></div><div class=\"line\">sudo yum install zlib-devel bzip2-devel openssl-devel ncurses-devel sqlite-devel readline-devel tk-devel</div><div class=\"line\">./configure</div><div class=\"line\">make</div><div class=\"line\"><span class=\"comment\">#为了加快安装速度，这步可以省略</span></div><div class=\"line\">make <span class=\"built_in\">test</span></div><div class=\"line\"><span class=\"comment\">#卸载旧的python，注意，不能用 yum remove python，这会卸载几百个包，最终损坏系统</span></div><div class=\"line\">sudo rpm -evf --nodeps python</div><div class=\"line\">sudo make install</div><div class=\"line\"><span class=\"comment\">#默认安装在 /usr/local/bin/python3</span></div></pre></td></tr></table></figure>\n<p>###方法二</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">sudo yum install python</div></pre></td></tr></table></figure>\n<p>##安装ruby</p>\n<p>###方法一</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># http://www.ruby-lang.org/en/downloads/ ，选择 \"Stable Snapshot\"</span></div><div class=\"line\">tar -zxf ruby-1.9-stable.tar.gz</div><div class=\"line\"><span class=\"built_in\">cd</span>  <span class=\"built_in\">cd</span> ruby-1.9.3-p194/</div><div class=\"line\">./configure</div><div class=\"line\">make</div><div class=\"line\">sudo make install</div></pre></td></tr></table></figure>\n<p>###方法二</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">sudo yum install ruby</div></pre></td></tr></table></figure>\n<p>##安装go</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">#去官网 http://code.google.com/p/go/downloads 下载，go1.0.1.linux-i386.tar.gz (32位)，go1.0.1.linux-amd64.tar.gz（64位）</span></div><div class=\"line\">tar -zxf go1.0.1.linux-amd64.tar.gz</div><div class=\"line\">sudo mv go/ /usr/<span class=\"built_in\">local</span>/</div><div class=\"line\"><span class=\"comment\">#设置环境变量</span></div><div class=\"line\">sudo vim /etc/profile</div><div class=\"line\"><span class=\"built_in\">export</span> GOROOT=/usr/<span class=\"built_in\">local</span>/go</div><div class=\"line\"><span class=\"built_in\">export</span> PATH=<span class=\"variable\">$PATH</span>:<span class=\"variable\">$GOROOT</span>/bin</div><div class=\"line\"><span class=\"built_in\">source</span> /etc/profile</div><div class=\"line\"><span class=\"comment\">#测试一下</span></div><div class=\"line\">go version</div></pre></td></tr></table></figure>\n<p>##安装lua</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># 去官网下载源码，编译，安装。由于官网仅提供源码，故推荐源码编译安装方式。</span></div><div class=\"line\"><span class=\"comment\"># 去官网 http://www.lua.org/ 下载源码，lua-5.2.0.tar.gz</span></div><div class=\"line\">tar -zxf lua-5.2.0.tar.gz </div><div class=\"line\"><span class=\"built_in\">cd</span> lua-5.2.0</div><div class=\"line\"><span class=\"comment\"># lua 依赖 readline.h 头文件</span></div><div class=\"line\">sudo yum install  readline-devel</div><div class=\"line\">make linux</div><div class=\"line\">sudo make install</div><div class=\"line\"><span class=\"comment\">#安装 google protobuf</span></div><div class=\"line\"><span class=\"comment\">#去官网 http://code.google.com/p/protobuf/下载</span></div><div class=\"line\">tar -jxf protobuf-2.4.1.tar.bz2</div><div class=\"line\"><span class=\"built_in\">cd</span> protobuf-2.4.1</div><div class=\"line\">./configure</div><div class=\"line\">make</div><div class=\"line\">sudo make install</div><div class=\"line\"><span class=\"comment\">#测试</span></div><div class=\"line\">protoc</div></pre></td></tr></table></figure>\n<p>##清理安装包</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"built_in\">cd</span> ~</div><div class=\"line\">rm * -rf</div></pre></td></tr></table></figure>\n<p>##压缩打包<br>安装完后，可以Clone，压缩打包成一个zip文件，方便分享给别人。</p>\n<p>在关机之前，有一件事需要做，</p>\n<pre><code>sudo vim /etc/sysconfig/network-scripts/ifcfg-eth0, 把HWADDR=.... 这行删掉\nsudo rm /etc/udev/rules.d/70-persistent-net.rules\nsudo shutdown -h now\n</code></pre><p>如果没有执行上述命令，克隆后的虚拟机，开机后无法上网，重启网络，<code>sudo service network restart</code>也没有效果，会出现错误“Device eth0 does not seem to be present, delaying initialization.” </p>\n<p>这是因为克隆后的虚拟机，它的MAC地址变了，即在它的.vmx文件里，MAC地址变了（<code>ethernet0.generatedAddress</code>这项），但是linux不知道这个变化，网络配置文件还是旧的，这样跟它的而真实mac不匹配，网络就无法启动。</p>\n<p>执行上述命令，删除了<code>70-persistent-net.rules</code>后，相当于删除了旧的配置文件，在开机时会生成新的配置文件。</p>\n<p>关机后，右击标签，选择”Manage-&gt;Clone”，选择”Create a full clone”，克隆完成后，关闭这台虚拟机的标签（否则文件夹里有一些临时垃圾文件），然后把文件夹压缩打包。以后就可以把这个zip包拷贝给周围的人，别人就不用经历一遍重装的过程了。</p>\n<p>##参考资料<br><a href=\"http://library.linode.com/lamp-guides/centos-6\" target=\"_blank\" rel=\"external\">LAMP Server on CentOS 6</a></p>\n<p><a href=\"http://articles.slicehost.com/2008/2/6/centos-installing-apache-and-php5\" target=\"_blank\" rel=\"external\">CentOS - Installing Apache and PHP5</a></p>\n<p><a href=\"http://fedorasolved.org/server-solutions/lamp-stack\" target=\"_blank\" rel=\"external\">Setting up a LAMP stack</a></p>\n<p><a href=\"http://myohmy.blog.51cto.com/140917/327310\" target=\"_blank\" rel=\"external\">CentOS5.5使用yum来安装LAMP</a></p>\n<p><a href=\"http://it.megocollector.com/?p=1719\" target=\"_blank\" rel=\"external\">Install Java JDK on CentOS without prompts using an automated script!</a></p>\n","excerpt":"<p>这是我安装CentOS服务器的过程，记录下来，与大家一起分享。Ubuntu请见<a href=\"http://cn.soulmachine.me/blog/20140417/\">安装和配置Ubuntu服务器的详细步骤</a>。</p>\n<p>##安装操作系统<br>CentOS 6.2 ，CentOS-6.2-i386-bin-DVD1.iso（32位） ，CentOS-6.2-x86_64-bin-DVD1.iso（64位）</p>\n<p>安装 CentOS时，选择 “Basic Server”<br>root密码：root123<br>CentOS 自带了ssh  </p>\n<p>安装完操作系统后，添加一个用户 manong</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">[root@localhost ~]$ useradd manong</div></pre></td></tr></table></figure>\n<p>然后密码设为 manong123</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">[root@localhost ~]$ passwd manong</div></pre></td></tr></table></figure>\n<p>给予 sudo 权限</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\">[root@localhost ~]$ chmod u+w /etc/sudoers</div><div class=\"line\">[root@localhost ~]$ vim /etc/sudoers</div><div class=\"line\"><span class=\"comment\"># 在root ALL=(ALL) ALL 下 添加manong ALL=(ALL) ALL</span></div><div class=\"line\">[root@localhost ~]$ chmod u-w /etc/sudoers</div></pre></td></tr></table></figure>\n<p>##设置上网<br>安装完操作系统后，还不能上网，配置DHCP方式上网：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div></pre></td><td class=\"code\"><pre><div class=\"line\">vim /etc/sysconfig/network-scripts/ifcfg-eth0</div><div class=\"line\">DEVICE=<span class=\"string\">\"eth0\"</span></div><div class=\"line\">HWADDR=<span class=\"string\">\"00:0C:29:BD:E1:19\"</span></div><div class=\"line\">NM_CONTROLLED=<span class=\"string\">\"yes\"</span></div><div class=\"line\">ONBOOT=<span class=\"string\">\"yes\"</span></div><div class=\"line\">BOOTPROTO=dhcp</div><div class=\"line\">USECTL=no</div><div class=\"line\">TYPE=Ethernet</div><div class=\"line\">PEERDNS=yes</div><div class=\"line\"><span class=\"comment\">#保存退出</span></div><div class=\"line\">sudo service network restart</div></pre></td></tr></table></figure>","more":"<p>或者，配置静态IP</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div></pre></td><td class=\"code\"><pre><div class=\"line\">DEVICE=<span class=\"string\">\"eth0\"</span></div><div class=\"line\">HWADDR=<span class=\"string\">\"00:0C:29:10:F4:4C\"</span></div><div class=\"line\">ONBOOT=<span class=\"string\">\"yes\"</span></div><div class=\"line\">BOOTPROTO=static</div><div class=\"line\">TYPE=Ethernet</div><div class=\"line\">IPADDR=192.168.0.162</div><div class=\"line\">NETMASK=255.255.255.0</div><div class=\"line\">BROADCAST=192.168.0.255</div><div class=\"line\">NETWORK=192.168.0.0</div><div class=\"line\"><span class=\"comment\">#保存退出  </span></div><div class=\"line\"><span class=\"comment\">#修改/etc/sysconfig/network</span></div><div class=\"line\">sudo vim /etc/sysconfig/network</div><div class=\"line\">NETWORKING=yes</div><div class=\"line\">HOSTNAME=localhost.localdomain</div><div class=\"line\">GATEWAY=192.168.0.1</div><div class=\"line\"><span class=\"comment\">#保存退出，重启网络</span></div><div class=\"line\">sudo service network restart</div></pre></td></tr></table></figure>\n<p>如果失败，比如IP已被占用，换一个IP试试</p>\n<p>修改DNS，即时生效</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\">sudo vim /etc/resolv.conf</div><div class=\"line\">nameserver 192.168.0.1</div><div class=\"line\"><span class=\"comment\"># google提供的域名服务器</span></div><div class=\"line\">nameserver 8.8.8.8</div><div class=\"line\">search localhost</div></pre></td></tr></table></figure>\n<p>##安装常用软件<br>有两种方式，方法一，去官网下载已经编译好的二进制文件，或源代码，编译安装<br>方法二，用yum 命令安装，安装官方yum源里已经编译好的程序包。<br>第一种方式要敲很多命令，比yum麻烦，但是可以预先下载好文件，省略了下载的时间，整体速度比yum安装方式快很多，而且可以安装最新版。推荐第一种方式</p>\n<p>第二种方式操作简单，敲打的命令少，但是往往yum源的更新速度跟不上各个软件的官网速度，用Yum安装的版本经常比较旧。</p>\n<p>yum的命令形式一般是如下：<code>yum [options] [command] [package ...]</code>，其中的[options]是可选的，选项包括-h（帮助），-y（当安装过程提示选择全部为”yes”），-q（不显示安装的过程）等等。[command]为所要进行的操作，[package …]是操作的对象。</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">#yum search package-name # 在线搜索包 </span></div><div class=\"line\"><span class=\"comment\">#yum list installed # 列出所有已经安装的包</span></div><div class=\"line\"><span class=\"comment\">#</span></div><div class=\"line\"><span class=\"comment\">#sudo yum install package-name # 安装程序包 </span></div><div class=\"line\"><span class=\"comment\">#sudo yum groupinsall group-name 安装程序组</span></div><div class=\"line\"><span class=\"comment\">#</span></div><div class=\"line\"><span class=\"comment\">#sudo yum remove package-name 删除程序包</span></div><div class=\"line\"><span class=\"comment\">#sudo yum groupremove group-name 删除程序组</span></div><div class=\"line\"><span class=\"comment\">#</span></div><div class=\"line\"><span class=\"comment\">#yum update #全部更新</span></div><div class=\"line\"><span class=\"comment\">#yum update package-name #更新程序包</span></div><div class=\"line\"><span class=\"comment\">#sudo yum groupupdate groupn-name 升级程序组</span></div><div class=\"line\"><span class=\"comment\">#sudo yum upgrade # 更新源列表</span></div><div class=\"line\"><span class=\"comment\">#yum upgrade package-name #升级程序包</span></div><div class=\"line\"><span class=\"comment\">#sudo yum clean all # 清除缓存</span></div><div class=\"line\"><span class=\"comment\">#更新</span></div><div class=\"line\">sudo yum update</div><div class=\"line\"><span class=\"comment\">#清理缓存</span></div><div class=\"line\">sudo yum clean all &amp;&amp; yum clean metadata &amp;&amp; yum clean dbcache</div></pre></td></tr></table></figure>\n<p>##安装编译工具</p>\n<p>###方法一<br>去 <a href=\"http://gcc.gnu.org/\">http://gcc.gnu.org/</a> 下载源码</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># TODO</span></div></pre></td></tr></table></figure>\n<p>###方法二</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">sudo yum groupinstall <span class=\"string\">\"Development Tools\"</span></div></pre></td></tr></table></figure>\n<p>该命令类似于 Ubuntu 下的<code>apt-get install build-essential</code>，会自动安装一下软件包：autoconf automake bison byacc cscope ctags diffstat doxygen flex gcc gcc-c++ gcc-gfortran git indent intltool libtool patchutils rcs redhat-rpm-config rpm-build subversion swig systemtap，同时安装了以下依赖包：apr, apr-util, 等等。</p>\n<p>##安装JDK</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">#删除旧的JDK</span></div><div class=\"line\">yum list installed | grep jdk</div><div class=\"line\"><span class=\"comment\">#复制显示出来的JDK，卸载</span></div><div class=\"line\">sudo yum remove java-1.6.0-openjdk.x86_64</div><div class=\"line\"><span class=\"comment\">#安装新的jdk</span></div></pre></td></tr></table></figure>\n<p>###方法一</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">#从官网下载最新版的，当前是jdk6u32</span></div><div class=\"line\"><span class=\"comment\">#开始安装</span></div><div class=\"line\">chmod u+x chmod u+x jdk-6u32-linux-x64-rpm.bin</div><div class=\"line\">sudo ./jdk-6u32-linux-x64-rpm.bin</div><div class=\"line\"><span class=\"comment\">#设置环境变量，.bash_profile是当前用户，/etc/profile是所有用户的</span></div><div class=\"line\">sudo vim /etc/profile</div><div class=\"line\"><span class=\"comment\">#在末尾添加</span></div><div class=\"line\"><span class=\"built_in\">export</span> JAVA_HOME=/usr/java/default</div><div class=\"line\"><span class=\"built_in\">export</span> JRE_HOME=<span class=\"variable\">$JAVA_HOME</span>/jre</div><div class=\"line\"><span class=\"built_in\">export</span> PATH=<span class=\"variable\">$PATH</span>:<span class=\"variable\">$JAVA_HOME</span>/bin</div><div class=\"line\"><span class=\"built_in\">export</span> CLASSPATH=.:<span class=\"variable\">$JAVA_HOME</span>/lib/dt.jar:<span class=\"variable\">$JAVA_HOME</span>/lib/tools.jar</div><div class=\"line\"><span class=\"comment\"># 保存退出，输入以下命令使之立即生效：</span></div><div class=\"line\"><span class=\"built_in\">source</span> /etc/profile</div><div class=\"line\"><span class=\"comment\"># 测试</span></div><div class=\"line\">java -version</div></pre></td></tr></table></figure>\n<p>###方法二</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div></pre></td><td class=\"code\"><pre><div class=\"line\">yum search jdk</div><div class=\"line\"><span class=\"comment\"># java-1.6.0-openjdk只包含了JRE，如果在这台机器上开发java程序，则需要安装JDK，</span></div><div class=\"line\"><span class=\"comment\"># 要选择 java-1.6.0-openjdk-devel，在服务器上我们只需要运行java程序，因此选择前者</span></div><div class=\"line\">sudo yum install java-1.6.0-openjdk-devel</div><div class=\"line\"><span class=\"comment\"># 使用 alternatives 工具设置默认JDK，参考：Installing a Java Development Kit on Red Hat Enterprise Linux</span></div><div class=\"line\">/usr/sbin/alternatives --config java</div><div class=\"line\">/usr/sbin/alternatives --config javac</div><div class=\"line\"><span class=\"comment\"># 设置环境变量</span></div><div class=\"line\"><span class=\"comment\"># 查询JDK路径</span></div><div class=\"line\">whereis java</div><div class=\"line\">ll /usr/bin/java</div><div class=\"line\">ll /etc/alternatives/java <span class=\"comment\">#这是可以看到JDK路径了</span></div><div class=\"line\">sudo vim /etc/profile</div><div class=\"line\"><span class=\"comment\"># 在末尾添加</span></div><div class=\"line\"><span class=\"built_in\">export</span> JAVA_HOME=/usr/lib/jvm/jre-1.6.0-openjdk.x86_64</div><div class=\"line\"><span class=\"built_in\">export</span> JRE_HOME=<span class=\"variable\">$JAVA_HOME</span>/jre</div><div class=\"line\"><span class=\"built_in\">export</span> PATH=<span class=\"variable\">$PATH</span>:<span class=\"variable\">$JAVA_HOME</span>/bin</div><div class=\"line\"><span class=\"built_in\">export</span> CLASSPATH=.:<span class=\"variable\">$JAVA_HOME</span>/lib/dt.jar:<span class=\"variable\">$JAVA_HOME</span>/lib/tools.jar</div><div class=\"line\"><span class=\"comment\">#保存退出，输入以下命令使之立即生效：</span></div><div class=\"line\"><span class=\"comment\"># source /etc/profile</span></div><div class=\"line\"><span class=\"comment\"># 测试</span></div><div class=\"line\">java -version</div></pre></td></tr></table></figure>\n<p>##安装 apache</p>\n<p>###方法一<br>源码在官网 <a href=\"http://httpd.apache.org/\">http://httpd.apache.org/</a> 下载。<br>先下载apt, apr-util, pcre三个库，httpd 在编译时需要用到这三个库<br>apr, apr-util官网 <a href=\"http://apr.apache.org\">http://apr.apache.org</a> , pcre官网为 <a href=\"http://pcre.org\">http://pcre.org </a></p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div><div class=\"line\">51</div><div class=\"line\">52</div><div class=\"line\">53</div><div class=\"line\">54</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># 编译，安装 apr</span></div><div class=\"line\">tar -jxf apr-1.4.6.tar.bz2</div><div class=\"line\"><span class=\"built_in\">cd</span> apr-1.4.6</div><div class=\"line\">./configure</div><div class=\"line\">make</div><div class=\"line\">sudo make install    <span class=\"comment\"># 默认会安装到 /usr/local/apr/</span></div><div class=\"line\"><span class=\"built_in\">cd</span> ~</div><div class=\"line\"><span class=\"comment\">#编译，安装 apr-util</span></div><div class=\"line\">tar -jxf apr-util-1.4.1.tar.bz2</div><div class=\"line\"><span class=\"built_in\">cd</span> apr-util-1.4.1</div><div class=\"line\">./configure --with-apr=/usr/<span class=\"built_in\">local</span>/apr/</div><div class=\"line\">make</div><div class=\"line\">sudo make install    <span class=\"comment\"># 默认会安装到 /usr/local/apr/</span></div><div class=\"line\"><span class=\"built_in\">cd</span> ~</div><div class=\"line\"><span class=\"comment\">#编译，安装 pcre</span></div><div class=\"line\">tar -jxf pcre-8.30.tar.bz2</div><div class=\"line\"><span class=\"built_in\">cd</span>  pcre-8.30</div><div class=\"line\">./configure --with-apr=/usr/<span class=\"built_in\">local</span>/apr/</div><div class=\"line\">make</div><div class=\"line\"><span class=\"comment\"># By default, `make install' installs the package's commands under</span></div><div class=\"line\"><span class=\"comment\">#`/usr/local/bin', include files under `/usr/local/include', etc. </span></div><div class=\"line\">sudo make install</div><div class=\"line\"><span class=\"built_in\">cd</span> ~</div><div class=\"line\"><span class=\"comment\">#编译，安装 apache</span></div><div class=\"line\">tar -jxf httpd-2.2.22.tar.bz2</div><div class=\"line\"><span class=\"built_in\">cd</span> httpd-2.2.22</div><div class=\"line\">./configure</div><div class=\"line\">make</div><div class=\"line\">sudo make install    <span class=\"comment\"># 默认会安装到/usr/local/apache2/</span></div><div class=\"line\"><span class=\"built_in\">cd</span> ~</div><div class=\"line\"><span class=\"comment\">#添加防火墙规则，让防火墙允许 apache的端口 80通过</span></div><div class=\"line\">sudo vim /etc/sysconfig/iptables</div><div class=\"line\"><span class=\"comment\">#添加如下一行（实际上是拷贝了原来的一行，仅仅改变了端口号），位置必须#要放在 含有 \"REJECT --reject-with\" 的行的前面</span></div><div class=\"line\">-A INPUT -m state --state NEW -m tcp -p tcp --dport 80 -j ACCEPT</div><div class=\"line\">sudo service iptables restart</div><div class=\"line\"><span class=\"comment\">#测试</span></div><div class=\"line\">sudo /usr/<span class=\"built_in\">local</span>/apache2/bin/apachectl start</div><div class=\"line\"><span class=\"comment\">#在浏览器输入 http://ip地址 ，如果看到“It works”，说明安装成功</span></div><div class=\"line\">/usr/<span class=\"built_in\">local</span>/apache2/bin/apachectl stop</div><div class=\"line\"></div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\">#设置为开机启动</span></div><div class=\"line\"><span class=\"comment\">#将httpd注册为服务，通过chkconfig实现开机启动</span></div><div class=\"line\"><span class=\"comment\">#以apachectl 为模板</span></div><div class=\"line\">sudo cp /usr/<span class=\"built_in\">local</span>/apache2/bin/apachectl /etc/init.d/httpd</div><div class=\"line\">sudo vim /etc/init.d/httpd</div><div class=\"line\"><span class=\"comment\"># 在第一行 #!/bin/sh，添加如下一行，使其支持chkconfig命令</span></div><div class=\"line\"><span class=\"comment\"># chkconfig: 2345 85 15</span></div><div class=\"line\"><span class=\"comment\"># 保存，退出VIM编辑器</span></div><div class=\"line\">sudo chmod u+x /etc/init.d/httpd</div><div class=\"line\">sudo chkconfig --add httpd</div><div class=\"line\">sudo chkconfig httpd on</div><div class=\"line\"><span class=\"comment\">#检查一下，是否添加成功</span></div><div class=\"line\">chkconfig --list httpd</div></pre></td></tr></table></figure>\n<p>###方法二</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div></pre></td><td class=\"code\"><pre><div class=\"line\">sudo yum install httpd</div><div class=\"line\"><span class=\"comment\">#可选？sudo yum install httpd-devel</span></div><div class=\"line\"><span class=\"comment\">#测试</span></div><div class=\"line\"><span class=\"comment\">#启动 apache http server</span></div><div class=\"line\">sudo service httpd start</div><div class=\"line\"><span class=\"comment\">#添加规则，让防火墙允许 apache的端口 80</span></div><div class=\"line\">sudo vim /etc/sysconfig/iptables</div><div class=\"line\"><span class=\"comment\">#添加如下一行，位置必须要放在 含有 \"REJECT --reject-with\" 的行的前面</span></div><div class=\"line\">-A INPUT -m state --state NEW -m tcp -p tcp --dport 80 -j ACCEPT</div><div class=\"line\">sudo service iptables restart</div><div class=\"line\"><span class=\"comment\">#可以在浏览器输入 http://ip地址 测试了</span></div><div class=\"line\"><span class=\"comment\">#设置为开机启动</span></div><div class=\"line\">sudo chkconfig httpd on</div></pre></td></tr></table></figure>\n<p>##安装 mysql</p>\n<p>###方法一</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">#去官网下载 Oracle &amp; Red Hat 6的安装包，64位为MySQL-5.5.23-1.el6.x86_64.tar，</span></div><div class=\"line\"><span class=\"comment\">#32位为 MySQL-5.5.23-1.el6.i686.tar</span></div><div class=\"line\">tar -xf MySQL-5.5.23-1.el6.x86_64.tar</div><div class=\"line\"><span class=\"comment\">#加 --force 是因为可能会与mysqllib库冲突</span></div><div class=\"line\">sudo rpm -ivh --force  MySQL-server-5.5.23-1.el6.x86_64.rpm</div><div class=\"line\">sudo rpm -ivh MySQL-client-5.5.23-1.el6.x86_64.rpm</div><div class=\"line\"><span class=\"comment\"># 启动 mysql 服务器</span></div><div class=\"line\">sudo service mysql start</div><div class=\"line\"><span class=\"comment\">#设置为开机启动</span></div><div class=\"line\">sudo chkconfig mysql on</div></pre></td></tr></table></figure>\n<p>###方法二</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div></pre></td><td class=\"code\"><pre><div class=\"line\">sudo yum install mysql-server</div><div class=\"line\">sudo chgrp -R mysql /var/lib/mysql</div><div class=\"line\">sudo chmod -R 770 /var/lib/mysql</div><div class=\"line\"><span class=\"comment\"># 启动 mysql 服务器</span></div><div class=\"line\">sudo service mysqld start</div><div class=\"line\"><span class=\"comment\">#设置为开机启动</span></div><div class=\"line\">sudo chkconfig mysqld on</div></pre></td></tr></table></figure>\n<p>###公共的操作</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># root 初始密码为空，修改root密码</span></div><div class=\"line\">mysql -u root</div><div class=\"line\">mysql&gt; use mysql;</div><div class=\"line\">mysql&gt; update user <span class=\"built_in\">set</span> password=password(<span class=\"string\">'root123'</span>) <span class=\"built_in\">where</span> user=<span class=\"string\">'root'</span> AND host=<span class=\"string\">'localhost'</span>;</div><div class=\"line\">mysql&gt; flush privileges;</div><div class=\"line\"><span class=\"comment\"># 打开MySQL中root账户的远程登录，参考：如何打开MySQL中root账户的远程登录mysql&gt; GRANT ALL PRIVILEGES ON *.* TO root@\"%\" IDENTIFIED BY \"root\";</span></div><div class=\"line\">mysql&gt; update user <span class=\"built_in\">set</span> password=password(<span class=\"string\">'root123'</span>) <span class=\"built_in\">where</span> user=<span class=\"string\">'root'</span> AND host=<span class=\"string\">'%'</span>;</div><div class=\"line\">mysql&gt; flush privileges;</div><div class=\"line\">mysql&gt; quit;</div><div class=\"line\"><span class=\"comment\">#添加防火墙规则，让防火墙允许 mysql 的端口 3306通过</span></div><div class=\"line\">sudo vim /etc/sysconfig/iptables</div><div class=\"line\"><span class=\"comment\">#添加如下一行（实际上是拷贝了原来的一行，仅仅改变了端口号），位置必须#要放在 含有 \"REJECT --reject-with\" 的行的前面</span></div><div class=\"line\">-A INPUT -m state --state NEW -m tcp -p tcp --dport 3306 -j ACCEPT</div><div class=\"line\">sudo service iptables restart</div></pre></td></tr></table></figure>\n<p>##安装 php5</p>\n<p>###方法一<br>TODO</p>\n<p>###方法二</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div></pre></td><td class=\"code\"><pre><div class=\"line\">sudo yum install php php-pear</div><div class=\"line\"><span class=\"comment\">#重启 apache，以确保apache 加载PHP模块</span></div><div class=\"line\">sudo service httpd restart</div><div class=\"line\"><span class=\"comment\"># 在 /var/www/html/下新建一个index.php文件，用于测试</span></div><div class=\"line\"><span class=\"built_in\">cd</span> /var/www/html</div><div class=\"line\">sudo vim index.php</div><div class=\"line\"><span class=\"comment\"># 添加如下一行</span></div><div class=\"line\">&lt;?php phpinfo(); ?&gt;</div><div class=\"line\"><span class=\"comment\"># 在浏览器输入 http://xxx.xxx.xxx.xxx/index.php ，测试PHP是否成功安装</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\"># 如果需要在PHP中支持mysql，则需要安装 php-mysql 模块</span></div><div class=\"line\">sudo yum install php-mysql</div><div class=\"line\"><span class=\"comment\"># 如果需要在PHP中支持memcached，则需要安装 php-pecl-memcache 模块</span></div><div class=\"line\">sudo yum install php-pecl-memcache</div><div class=\"line\"><span class=\"comment\">#安装一些常用的PHP扩展模块</span></div><div class=\"line\">sudo yum install php-devel php-gd php-mbstring php-xml</div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\">#可以安装一个wordpress进行测试，注意要修改文件夹权限</span></div><div class=\"line\">sudo chown -R apache.apache /var/www/html</div></pre></td></tr></table></figure>\n<h2 id=\"安装-memcached\"><a href=\"#安装-memcached\" class=\"headerlink\" title=\"安装 memcached\"></a>安装 memcached</h2><p>###方法一</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div><div class=\"line\">51</div><div class=\"line\">52</div><div class=\"line\">53</div><div class=\"line\">54</div><div class=\"line\">55</div><div class=\"line\">56</div><div class=\"line\">57</div><div class=\"line\">58</div><div class=\"line\">59</div><div class=\"line\">60</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># memcached依赖libevent，首先要安装 libevent</span></div><div class=\"line\"><span class=\"comment\"># 去 http://libevent.org/ 下载libevent源码，然后编译，安装</span></div><div class=\"line\">tar -zxf libevent-2.0.18-stable.tar.gz</div><div class=\"line\"><span class=\"built_in\">cd</span> libevent-2.0.18-stable</div><div class=\"line\">./configure</div><div class=\"line\">make</div><div class=\"line\">sudo make install</div><div class=\"line\"><span class=\"comment\"># 对于64位操作系统(32位不需要)，还需要配置：</span></div><div class=\"line\">sudo ln <span class=\"_\">-s</span> /usr/<span class=\"built_in\">local</span>/lib/libevent-2.0.so.5 /usr/lib64//libevent-2.0.so.5</div><div class=\"line\"><span class=\"comment\"># 去 http://www.memcached.org/ 下载 memcached，然后编译，安装</span></div><div class=\"line\">tar -zxf memcached-1.4.13.tar.gz</div><div class=\"line\"><span class=\"built_in\">cd</span> memcached-1.4.13</div><div class=\"line\">./configure</div><div class=\"line\">make</div><div class=\"line\">sudo make install</div><div class=\"line\"><span class=\"comment\"># 启动, -p，端口,-m，内存, -u</span></div><div class=\"line\">memcached -p 11211 -m 512m -u root <span class=\"_\">-d</span></div><div class=\"line\"><span class=\"comment\"># 开机启动</span></div><div class=\"line\"><span class=\"comment\"># centos设置开机启动有两种方式，一是把启动程序的命令添加到/etc/rc.d/rc.local文件中，二是把写好的启动脚本添加到目录/etc/rc.d/init.d/，然后使用命令chkconfig设置开机启动。第二种方式可以用 service xxx start|stop来启动或停止，所以推荐第二种。</span></div><div class=\"line\"><span class=\"comment\">#将 memcached启动命令注册为一个服务</span></div><div class=\"line\"><span class=\"built_in\">cd</span> /etc/init.d/</div><div class=\"line\">sudo vim memcached</div><div class=\"line\"><span class=\"comment\">#代码如下，参考：Linux中将memcached注册成服务并可以随机器启动时启动服务</span></div><div class=\"line\"><span class=\"comment\">#chkconfig: 345 60 60</span></div><div class=\"line\"><span class=\"meta\">#!/bin/bash</div><div class=\"line\"></span></div><div class=\"line\"><span class=\"function\"><span class=\"title\">start</span></span>()</div><div class=\"line\">&#123;</div><div class=\"line\">        <span class=\"built_in\">echo</span> -n $<span class=\"string\">\"Starting memcached: \"</span></div><div class=\"line\">        /usr/<span class=\"built_in\">local</span>/bin/memcached -p 11211 -m 512m -u root <span class=\"_\">-d</span></div><div class=\"line\">        <span class=\"built_in\">echo</span> <span class=\"string\">\"[OK]\"</span></div><div class=\"line\">&#125;</div><div class=\"line\"><span class=\"function\"><span class=\"title\">stop</span></span>()</div><div class=\"line\">&#123;</div><div class=\"line\">        <span class=\"built_in\">echo</span> -n $<span class=\"string\">\"Shutting down memcached: \"</span></div><div class=\"line\">        memcached_pid_list=`pidof memcached` </div><div class=\"line\">        <span class=\"built_in\">kill</span> -9 <span class=\"variable\">$memcached_pid_list</span></div><div class=\"line\">        <span class=\"built_in\">echo</span> <span class=\"string\">\"[OK]\"</span></div><div class=\"line\">&#125;</div><div class=\"line\"><span class=\"keyword\">case</span> <span class=\"string\">\"<span class=\"variable\">$1</span>\"</span> <span class=\"keyword\">in</span></div><div class=\"line\">  start)</div><div class=\"line\">        start</div><div class=\"line\">        ;;</div><div class=\"line\">  stop)</div><div class=\"line\">        stop</div><div class=\"line\">        ;;</div><div class=\"line\">  restart)</div><div class=\"line\">        stop</div><div class=\"line\">        sleep 3</div><div class=\"line\">        start</div><div class=\"line\">        ;;</div><div class=\"line\">    *)</div><div class=\"line\">             <span class=\"built_in\">echo</span> $<span class=\"string\">\"Usage: <span class=\"variable\">$0</span> &#123;start|stop|restart&#125;\"</span></div><div class=\"line\">        <span class=\"built_in\">exit</span> 1</div><div class=\"line\"><span class=\"keyword\">esac</span></div><div class=\"line\"><span class=\"built_in\">exit</span> 0</div><div class=\"line\"><span class=\"comment\">#保存退出</span></div><div class=\"line\">sudo chmod u+x memcached</div><div class=\"line\">sudo chkconfig --add memcached</div><div class=\"line\">sudo chkconfig  memcached on</div></pre></td></tr></table></figure>\n<p>###方法二<br>TODO</p>\n<p>##安装 tomcat6</p>\n<p>###方法一</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div><div class=\"line\">51</div><div class=\"line\">52</div><div class=\"line\">53</div><div class=\"line\">54</div><div class=\"line\">55</div><div class=\"line\">56</div><div class=\"line\">57</div><div class=\"line\">58</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># 去 http://tomcat.apache.org 下载 apache-tomcat-6.0.35.tar.gz</span></div><div class=\"line\">tar -zxf apache-tomcat-6.0.35.tar.gz</div><div class=\"line\">sudo mv apache-tomcat-6.0.35 /usr/<span class=\"built_in\">local</span>/</div><div class=\"line\"><span class=\"built_in\">cd</span> /usr/<span class=\"built_in\">local</span>/apache-tomcat-6.0.35/bin</div><div class=\"line\"><span class=\"comment\">#【可选】添加环境变量</span></div><div class=\"line\">sudo vim /etc/profile</div><div class=\"line\"><span class=\"built_in\">export</span> CATALINA_HOME=/usr/<span class=\"built_in\">local</span>/apache-tomcat-6.0.35</div><div class=\"line\"><span class=\"comment\">#启动 tomcat </span></div><div class=\"line\">sudo ./startup.sh</div><div class=\"line\"><span class=\"comment\"># 在浏览器输入 http://xxx.xxx.xxx.xxx:8080/ ，如果能看见tomcat页面，则表示安装成功了</span></div><div class=\"line\"><span class=\"comment\">#设置开机启动</span></div><div class=\"line\"><span class=\"comment\">#将 tomcat启动命令注册为一个服务</span></div><div class=\"line\"><span class=\"built_in\">cd</span> /etc/init.d/</div><div class=\"line\">sudo vim tomcatd</div><div class=\"line\"><span class=\"comment\">#代码如下</span></div><div class=\"line\"><span class=\"comment\">#chkconfig: 345 60 60</span></div><div class=\"line\"><span class=\"meta\">#!/bin/bash</span></div><div class=\"line\">CATALINA_HOME=/usr/<span class=\"built_in\">local</span>/apache-tomcat-6.0.35</div><div class=\"line\"></div><div class=\"line\"><span class=\"function\"><span class=\"title\">start</span></span>()</div><div class=\"line\">&#123;</div><div class=\"line\">        <span class=\"built_in\">echo</span> -n $<span class=\"string\">\"Starting Tomcat: \"</span></div><div class=\"line\">        <span class=\"variable\">$CATALINA_HOME</span>/bin/startup.sh</div><div class=\"line\">        <span class=\"built_in\">echo</span> <span class=\"string\">\"[OK]\"</span></div><div class=\"line\">&#125;</div><div class=\"line\"><span class=\"function\"><span class=\"title\">stop</span></span>()</div><div class=\"line\">&#123;</div><div class=\"line\">        <span class=\"built_in\">echo</span> -n $<span class=\"string\">\"Shutting down Tomcat: \"</span></div><div class=\"line\">        <span class=\"variable\">$CATALINA_HOME</span>/bin/shutdown.sh</div><div class=\"line\">        <span class=\"built_in\">echo</span> <span class=\"string\">\"[OK]\"</span></div><div class=\"line\">&#125;</div><div class=\"line\"><span class=\"keyword\">case</span> <span class=\"string\">\"<span class=\"variable\">$1</span>\"</span> <span class=\"keyword\">in</span></div><div class=\"line\">  start)</div><div class=\"line\">        start</div><div class=\"line\">        ;;</div><div class=\"line\">  stop)</div><div class=\"line\">        stop</div><div class=\"line\">        ;;</div><div class=\"line\">  restart)</div><div class=\"line\">        stop</div><div class=\"line\">        sleep 3</div><div class=\"line\">        start</div><div class=\"line\">        ;;</div><div class=\"line\">    *)</div><div class=\"line\">             <span class=\"built_in\">echo</span> $<span class=\"string\">\"Usage: <span class=\"variable\">$0</span> &#123;start|stop|restart&#125;\"</span></div><div class=\"line\">        <span class=\"built_in\">exit</span> 1</div><div class=\"line\"><span class=\"keyword\">esac</span></div><div class=\"line\"><span class=\"built_in\">exit</span> 0</div><div class=\"line\"><span class=\"comment\">#保存退出</span></div><div class=\"line\">sudo chmod u+x tomcatd</div><div class=\"line\">sudo chkconfig --add tomcatd</div><div class=\"line\">sudo chkconfig tomcatd on</div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\">#添加防火墙规则，让防火墙允许 tomcat 的端口 8080 通过</span></div><div class=\"line\">sudo vim /etc/sysconfig/iptables</div><div class=\"line\"><span class=\"comment\">#添加如下一行（实际上是拷贝了原来的一行，仅仅改变了端口号），位置必须#要放在 含有 \"REJECT --reject-with\" 的行的前面</span></div><div class=\"line\">-A INPUT -m state --state NEW -m tcp -p tcp --dport 8080 -j ACCEPT</div><div class=\"line\">sudo service iptables restart</div></pre></td></tr></table></figure>\n<p>###方法二</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">#搜索一下 tomcat包的名字</span></div><div class=\"line\">yum search tomcat</div><div class=\"line\">sudo yum search tomcat6.noarch</div></pre></td></tr></table></figure>\n<p>##安装Python</p>\n<p>###方法一：去<a href=\"http://www.python.org\">官网</a>下载源码，编译，安装</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">#开始解压，编译，安装</span></div><div class=\"line\">tar -jxf Python-3.2.3.tar.bz2</div><div class=\"line\"><span class=\"built_in\">cd</span> Python-3.2.3</div><div class=\"line\"><span class=\"comment\"># 查看一下说明, vim README</span></div><div class=\"line\">sudo yum install zlib-devel bzip2-devel openssl-devel ncurses-devel sqlite-devel readline-devel tk-devel</div><div class=\"line\">./configure</div><div class=\"line\">make</div><div class=\"line\"><span class=\"comment\">#为了加快安装速度，这步可以省略</span></div><div class=\"line\">make <span class=\"built_in\">test</span></div><div class=\"line\"><span class=\"comment\">#卸载旧的python，注意，不能用 yum remove python，这会卸载几百个包，最终损坏系统</span></div><div class=\"line\">sudo rpm -evf --nodeps python</div><div class=\"line\">sudo make install</div><div class=\"line\"><span class=\"comment\">#默认安装在 /usr/local/bin/python3</span></div></pre></td></tr></table></figure>\n<p>###方法二</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">sudo yum install python</div></pre></td></tr></table></figure>\n<p>##安装ruby</p>\n<p>###方法一</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># http://www.ruby-lang.org/en/downloads/ ，选择 \"Stable Snapshot\"</span></div><div class=\"line\">tar -zxf ruby-1.9-stable.tar.gz</div><div class=\"line\"><span class=\"built_in\">cd</span>  <span class=\"built_in\">cd</span> ruby-1.9.3-p194/</div><div class=\"line\">./configure</div><div class=\"line\">make</div><div class=\"line\">sudo make install</div></pre></td></tr></table></figure>\n<p>###方法二</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">sudo yum install ruby</div></pre></td></tr></table></figure>\n<p>##安装go</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">#去官网 http://code.google.com/p/go/downloads 下载，go1.0.1.linux-i386.tar.gz (32位)，go1.0.1.linux-amd64.tar.gz（64位）</span></div><div class=\"line\">tar -zxf go1.0.1.linux-amd64.tar.gz</div><div class=\"line\">sudo mv go/ /usr/<span class=\"built_in\">local</span>/</div><div class=\"line\"><span class=\"comment\">#设置环境变量</span></div><div class=\"line\">sudo vim /etc/profile</div><div class=\"line\"><span class=\"built_in\">export</span> GOROOT=/usr/<span class=\"built_in\">local</span>/go</div><div class=\"line\"><span class=\"built_in\">export</span> PATH=<span class=\"variable\">$PATH</span>:<span class=\"variable\">$GOROOT</span>/bin</div><div class=\"line\"><span class=\"built_in\">source</span> /etc/profile</div><div class=\"line\"><span class=\"comment\">#测试一下</span></div><div class=\"line\">go version</div></pre></td></tr></table></figure>\n<p>##安装lua</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># 去官网下载源码，编译，安装。由于官网仅提供源码，故推荐源码编译安装方式。</span></div><div class=\"line\"><span class=\"comment\"># 去官网 http://www.lua.org/ 下载源码，lua-5.2.0.tar.gz</span></div><div class=\"line\">tar -zxf lua-5.2.0.tar.gz </div><div class=\"line\"><span class=\"built_in\">cd</span> lua-5.2.0</div><div class=\"line\"><span class=\"comment\"># lua 依赖 readline.h 头文件</span></div><div class=\"line\">sudo yum install  readline-devel</div><div class=\"line\">make linux</div><div class=\"line\">sudo make install</div><div class=\"line\"><span class=\"comment\">#安装 google protobuf</span></div><div class=\"line\"><span class=\"comment\">#去官网 http://code.google.com/p/protobuf/下载</span></div><div class=\"line\">tar -jxf protobuf-2.4.1.tar.bz2</div><div class=\"line\"><span class=\"built_in\">cd</span> protobuf-2.4.1</div><div class=\"line\">./configure</div><div class=\"line\">make</div><div class=\"line\">sudo make install</div><div class=\"line\"><span class=\"comment\">#测试</span></div><div class=\"line\">protoc</div></pre></td></tr></table></figure>\n<p>##清理安装包</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"built_in\">cd</span> ~</div><div class=\"line\">rm * -rf</div></pre></td></tr></table></figure>\n<p>##压缩打包<br>安装完后，可以Clone，压缩打包成一个zip文件，方便分享给别人。</p>\n<p>在关机之前，有一件事需要做，</p>\n<pre><code>sudo vim /etc/sysconfig/network-scripts/ifcfg-eth0, 把HWADDR=.... 这行删掉\nsudo rm /etc/udev/rules.d/70-persistent-net.rules\nsudo shutdown -h now\n</code></pre><p>如果没有执行上述命令，克隆后的虚拟机，开机后无法上网，重启网络，<code>sudo service network restart</code>也没有效果，会出现错误“Device eth0 does not seem to be present, delaying initialization.” </p>\n<p>这是因为克隆后的虚拟机，它的MAC地址变了，即在它的.vmx文件里，MAC地址变了（<code>ethernet0.generatedAddress</code>这项），但是linux不知道这个变化，网络配置文件还是旧的，这样跟它的而真实mac不匹配，网络就无法启动。</p>\n<p>执行上述命令，删除了<code>70-persistent-net.rules</code>后，相当于删除了旧的配置文件，在开机时会生成新的配置文件。</p>\n<p>关机后，右击标签，选择”Manage-&gt;Clone”，选择”Create a full clone”，克隆完成后，关闭这台虚拟机的标签（否则文件夹里有一些临时垃圾文件），然后把文件夹压缩打包。以后就可以把这个zip包拷贝给周围的人，别人就不用经历一遍重装的过程了。</p>\n<p>##参考资料<br><a href=\"http://library.linode.com/lamp-guides/centos-6\">LAMP Server on CentOS 6</a></p>\n<p><a href=\"http://articles.slicehost.com/2008/2/6/centos-installing-apache-and-php5\">CentOS - Installing Apache and PHP5</a></p>\n<p><a href=\"http://fedorasolved.org/server-solutions/lamp-stack\">Setting up a LAMP stack</a></p>\n<p><a href=\"http://myohmy.blog.51cto.com/140917/327310\">CentOS5.5使用yum来安装LAMP</a></p>\n<p><a href=\"http://it.megocollector.com/?p=1719\">Install Java JDK on CentOS without prompts using an automated script!</a></p>"},{"layout":"post","title":"制作 VMware ESXI 5 U盘安装盘","date":"2012-04-18T20:17:00.000Z","comments":1,"_content":"有两种方法，使用 unetbootin ，或使用 LinuxLive USB Creator刻录可启动U盘。 \n##使用 unetbootin\n这个方法最自动化，点击两下按钮即可，但是有时候会失败(我用EXSi 5.0 的ISO失败，但是用 EXSi 5.0U1可以成功)，U盘启动不了。 \n\n1. 单击 光盘镜像，选择ISO文件VMware-VMvisor-Installer-5.0.0.update01-623860.x86_64.iso。 \n2. 选择U盘，点击“确定”开始刻录。刻录后用U盘启动机器开始安装即可。如下图所示。\n{% img http://yanjiuyanjiu-wordpress.stor.sinaapp.com/uploads/2012/04/unetbootin1.jpg %}\n\n##使用 LinuxLive USB Creator\n\n1. 格式化U盘，文件系统为FAT32，并设置为主分区，命令如下：\n\t\t# 使用管理员权限运行cmd \n\t\tdiskpart \n\t\tlist disk \n\t\tselect disk USB number （例如 select dist 1） \n\t\tclean \n\t\tcreate partition primary \n\t\tactive \n\t\tformat fs=fat32 quick \n\t\tassign \n\t\texit\n\n<!-- more -->\n\n2. 下载，安装 LinuxLive USB Creator([http://www.linuxliveusb.com/](http://www.linuxliveusb.com/)) \n3. 按照上图中的步骤 1,2,4，选择ISO文件`VMware-VMvisor-Installer-5.0.0.update01-623860.x86_64.iso`，然后点击 5 ，开始创建U盘安装盘。等待U盘刻录结束。\n\n\t{% img http://yanjiuyanjiu-wordpress.stor.sinaapp.com/uploads/2012/04/liliusb_thumb1.png %}\n\n\t大功告成，是不是很简单？！ \n\n4. 编辑U盘根目录下的BOOT.CFG文件。注意，不要添加 \"ks=usb\"，因为下面会用交互模式来安装。 \n5. 大功告成\n6. 注意，本文主要参考了末尾的参考资料。但是不需要原文的第4步和第5步。因为用普通的 “interactive installation”安装就很方便了。第4步和第5步用于一键自动化安装，适用于大量安装的情况，这里不详细讨论。 \n见文章末尾的评论，\n\n> @Cesar: if you do not edit the boot.cfg with the “ks=usb” option and select a interactive installation it will work。\n\n**参考资料**  \n[Create a bootable VMware ESXi 5 USB stick in Windows and perform a scripted installation](http://www.ivobeerens.nl/2011/09/17/create-a-bootable-vmware-esxi-5-usb-stick-in-windows-and-perform-a-scripted-installation/)\n","source":"_posts/2012-04-18-create-a-bootable-vmware-esxi-5-usb-stick.md","raw":"---\nlayout: post\ntitle: \"制作 VMware ESXI 5 U盘安装盘\"\ndate: 2012-04-18 20:17\ncomments: true\ncategories: Tools\n---\n有两种方法，使用 unetbootin ，或使用 LinuxLive USB Creator刻录可启动U盘。 \n##使用 unetbootin\n这个方法最自动化，点击两下按钮即可，但是有时候会失败(我用EXSi 5.0 的ISO失败，但是用 EXSi 5.0U1可以成功)，U盘启动不了。 \n\n1. 单击 光盘镜像，选择ISO文件VMware-VMvisor-Installer-5.0.0.update01-623860.x86_64.iso。 \n2. 选择U盘，点击“确定”开始刻录。刻录后用U盘启动机器开始安装即可。如下图所示。\n{% img http://yanjiuyanjiu-wordpress.stor.sinaapp.com/uploads/2012/04/unetbootin1.jpg %}\n\n##使用 LinuxLive USB Creator\n\n1. 格式化U盘，文件系统为FAT32，并设置为主分区，命令如下：\n\t\t# 使用管理员权限运行cmd \n\t\tdiskpart \n\t\tlist disk \n\t\tselect disk USB number （例如 select dist 1） \n\t\tclean \n\t\tcreate partition primary \n\t\tactive \n\t\tformat fs=fat32 quick \n\t\tassign \n\t\texit\n\n<!-- more -->\n\n2. 下载，安装 LinuxLive USB Creator([http://www.linuxliveusb.com/](http://www.linuxliveusb.com/)) \n3. 按照上图中的步骤 1,2,4，选择ISO文件`VMware-VMvisor-Installer-5.0.0.update01-623860.x86_64.iso`，然后点击 5 ，开始创建U盘安装盘。等待U盘刻录结束。\n\n\t{% img http://yanjiuyanjiu-wordpress.stor.sinaapp.com/uploads/2012/04/liliusb_thumb1.png %}\n\n\t大功告成，是不是很简单？！ \n\n4. 编辑U盘根目录下的BOOT.CFG文件。注意，不要添加 \"ks=usb\"，因为下面会用交互模式来安装。 \n5. 大功告成\n6. 注意，本文主要参考了末尾的参考资料。但是不需要原文的第4步和第5步。因为用普通的 “interactive installation”安装就很方便了。第4步和第5步用于一键自动化安装，适用于大量安装的情况，这里不详细讨论。 \n见文章末尾的评论，\n\n> @Cesar: if you do not edit the boot.cfg with the “ks=usb” option and select a interactive installation it will work。\n\n**参考资料**  \n[Create a bootable VMware ESXi 5 USB stick in Windows and perform a scripted installation](http://www.ivobeerens.nl/2011/09/17/create-a-bootable-vmware-esxi-5-usb-stick-in-windows-and-perform-a-scripted-installation/)\n","slug":"2012-04-18-create-a-bootable-vmware-esxi-5-usb-stick","published":1,"updated":"2016-08-18T09:21:04.000Z","photos":[],"link":"","_id":"cis07pf2h000j01pqgbjoy4zt","content":"<p>有两种方法，使用 unetbootin ，或使用 LinuxLive USB Creator刻录可启动U盘。 </p>\n<p>##使用 unetbootin<br>这个方法最自动化，点击两下按钮即可，但是有时候会失败(我用EXSi 5.0 的ISO失败，但是用 EXSi 5.0U1可以成功)，U盘启动不了。 </p>\n<ol>\n<li>单击 光盘镜像，选择ISO文件VMware-VMvisor-Installer-5.0.0.update01-623860.x86_64.iso。 </li>\n<li>选择U盘，点击“确定”开始刻录。刻录后用U盘启动机器开始安装即可。如下图所示。<img src=\"http://yanjiuyanjiu-wordpress.stor.sinaapp.com/uploads/2012/04/unetbootin1.jpg\">\n</li>\n</ol>\n<p>##使用 LinuxLive USB Creator</p>\n<ol>\n<li>格式化U盘，文件系统为FAT32，并设置为主分区，命令如下：<pre><code># 使用管理员权限运行cmd \ndiskpart \nlist disk \nselect disk USB number （例如 select dist 1） \nclean \ncreate partition primary \nactive \nformat fs=fat32 quick \nassign \nexit\n</code></pre></li>\n</ol>\n<a id=\"more\"></a>\n<ol>\n<li>下载，安装 LinuxLive USB Creator(<a href=\"http://www.linuxliveusb.com/\" target=\"_blank\" rel=\"external\">http://www.linuxliveusb.com/</a>) </li>\n<li><p>按照上图中的步骤 1,2,4，选择ISO文件<code>VMware-VMvisor-Installer-5.0.0.update01-623860.x86_64.iso</code>，然后点击 5 ，开始创建U盘安装盘。等待U盘刻录结束。</p>\n <img src=\"http://yanjiuyanjiu-wordpress.stor.sinaapp.com/uploads/2012/04/liliusb_thumb1.png\">\n<p> 大功告成，是不是很简单？！ </p>\n</li>\n<li><p>编辑U盘根目录下的BOOT.CFG文件。注意，不要添加 “ks=usb”，因为下面会用交互模式来安装。 </p>\n</li>\n<li>大功告成</li>\n<li>注意，本文主要参考了末尾的参考资料。但是不需要原文的第4步和第5步。因为用普通的 “interactive installation”安装就很方便了。第4步和第5步用于一键自动化安装，适用于大量安装的情况，这里不详细讨论。<br>见文章末尾的评论，</li>\n</ol>\n<blockquote>\n<p>@Cesar: if you do not edit the boot.cfg with the “ks=usb” option and select a interactive installation it will work。</p>\n</blockquote>\n<p><strong>参考资料</strong><br><a href=\"http://www.ivobeerens.nl/2011/09/17/create-a-bootable-vmware-esxi-5-usb-stick-in-windows-and-perform-a-scripted-installation/\" target=\"_blank\" rel=\"external\">Create a bootable VMware ESXi 5 USB stick in Windows and perform a scripted installation</a></p>\n","excerpt":"<p>有两种方法，使用 unetbootin ，或使用 LinuxLive USB Creator刻录可启动U盘。 </p>\n<p>##使用 unetbootin<br>这个方法最自动化，点击两下按钮即可，但是有时候会失败(我用EXSi 5.0 的ISO失败，但是用 EXSi 5.0U1可以成功)，U盘启动不了。 </p>\n<ol>\n<li>单击 光盘镜像，选择ISO文件VMware-VMvisor-Installer-5.0.0.update01-623860.x86_64.iso。 </li>\n<li>选择U盘，点击“确定”开始刻录。刻录后用U盘启动机器开始安装即可。如下图所示。<img src=\"http://yanjiuyanjiu-wordpress.stor.sinaapp.com/uploads/2012/04/unetbootin1.jpg\">\n</li>\n</ol>\n<p>##使用 LinuxLive USB Creator</p>\n<ol>\n<li>格式化U盘，文件系统为FAT32，并设置为主分区，命令如下：<pre><code># 使用管理员权限运行cmd \ndiskpart \nlist disk \nselect disk USB number （例如 select dist 1） \nclean \ncreate partition primary \nactive \nformat fs=fat32 quick \nassign \nexit\n</code></pre></li>\n</ol>","more":"<ol>\n<li>下载，安装 LinuxLive USB Creator(<a href=\"http://www.linuxliveusb.com/\">http://www.linuxliveusb.com/</a>) </li>\n<li><p>按照上图中的步骤 1,2,4，选择ISO文件<code>VMware-VMvisor-Installer-5.0.0.update01-623860.x86_64.iso</code>，然后点击 5 ，开始创建U盘安装盘。等待U盘刻录结束。</p>\n <img src=\"http://yanjiuyanjiu-wordpress.stor.sinaapp.com/uploads/2012/04/liliusb_thumb1.png\">\n<p> 大功告成，是不是很简单？！ </p>\n</li>\n<li><p>编辑U盘根目录下的BOOT.CFG文件。注意，不要添加 “ks=usb”，因为下面会用交互模式来安装。 </p>\n</li>\n<li>大功告成</li>\n<li>注意，本文主要参考了末尾的参考资料。但是不需要原文的第4步和第5步。因为用普通的 “interactive installation”安装就很方便了。第4步和第5步用于一键自动化安装，适用于大量安装的情况，这里不详细讨论。<br>见文章末尾的评论，</li>\n</ol>\n<blockquote>\n<p>@Cesar: if you do not edit the boot.cfg with the “ks=usb” option and select a interactive installation it will work。</p>\n</blockquote>\n<p><strong>参考资料</strong><br><a href=\"http://www.ivobeerens.nl/2011/09/17/create-a-bootable-vmware-esxi-5-usb-stick-in-windows-and-perform-a-scripted-installation/\">Create a bootable VMware ESXi 5 USB stick in Windows and perform a scripted installation</a></p>"},{"layout":"post","title":"一些主流的编程竞赛网站","date":"2013-03-22T21:57:00.000Z","comments":1,"_content":"今天把各个主流的编程网站仔细对比了一下，下面从各个角度对比一下这些编程竞赛网站。\n\n##分类和排名\n<table border=\"1\" cellspacing=\"0\" cellpadding=\"0\">\n<tbody>\n<tr>\n<td valign=\"top\" width=\"94\">\n<p><a name=\"OLE_LINK30\"></a><a name=\"OLE_LINK1\"><b>网站地址</b></a></p>\n</td>\n<td valign=\"top\" width=\"57\">\n<p><b>类别</b></p>\n</td>\n<td valign=\"top\" width=\"38\">\n<p><b>PR</b></p>\n</td>\n<td valign=\"top\" width=\"60\">\n<p><b>ATR</b></p>\n</td>\n<td valign=\"top\" width=\"44\">\n<p><b>QF</b></p>\n</td>\n<td valign=\"top\" width=\"151\">\n<p><b>主办方</b></p>\n</td>\n<td valign=\"top\" width=\"47\">\n<p><b>备注</b></p>\n</td>\n</tr>\n<tr>\n<td valign=\"top\" width=\"94\">\n<p><a name=\"_Hlk352791085\"></a><a href=\"http://www.topcoder.com/\" onclick=\"javascript:_gaq.push(['_trackEvent','outbound-article','http://www.topcoder.com']);\">TopCoder </a></p>\n</td>\n<td valign=\"top\" width=\"57\">\n<p>综合</p>\n</td>\n<td valign=\"top\" width=\"38\">\n<p>6</p>\n</td>\n<td valign=\"top\" width=\"60\">\n<p>33,586</p>\n</td>\n<td valign=\"top\" width=\"44\">\n<p>4167</p>\n</td>\n<td valign=\"top\" width=\"151\">\n<p>TopCoder公司</p>\n</td>\n<td valign=\"top\" width=\"47\">&nbsp;</td>\n</tr>\n<tr>\n<td valign=\"top\" width=\"94\">\n<p><a href=\"http://www.codechef.com/\" onclick=\"javascript:_gaq.push(['_trackEvent','outbound-article','http://www.codechef.com']);\">CodeChef </a></p>\n</td>\n<td valign=\"top\" width=\"57\">\n<p>综合</p>\n</td>\n<td valign=\"top\" width=\"38\">\n<p>6</p>\n</td>\n<td valign=\"top\" width=\"60\">\n<p>41,217</p>\n</td>\n<td valign=\"top\" width=\"44\">\n<p>5758</p>\n</td>\n<td valign=\"top\" width=\"151\">\n<p>Directi公司</p>\n</td>\n<td valign=\"top\" width=\"47\">&nbsp;</td>\n</tr>\n<tr>\n<td valign=\"top\" width=\"94\">\n<p><a href=\"http://codeforces.com/\" onclick=\"javascript:_gaq.push(['_trackEvent','outbound-article','http://codeforces.com']);\">CodeForces </a></p>\n</td>\n<td valign=\"top\" width=\"57\">\n<p>综合</p>\n</td>\n<td valign=\"top\" width=\"38\">\n<p>5</p>\n</td>\n<td valign=\"top\" width=\"60\">\n<p>73,012</p>\n</td>\n<td valign=\"top\" width=\"44\">\n<p>599</p>\n</td>\n<td valign=\"top\" width=\"151\">\n<p>CodeForces公司</p>\n</td>\n<td valign=\"top\" width=\"47\">&nbsp;</td>\n</tr>\n<tr>\n<td valign=\"top\" width=\"94\">\n<p><a href=\"http://www.spoj.com/\" onclick=\"javascript:_gaq.push(['_trackEvent','outbound-article','http://www.spoj.com']);\">SPOJ</a></p>\n</td>\n<td valign=\"top\" width=\"57\">\n<p>ACM</p>\n</td>\n<td valign=\"top\" width=\"38\">\n<p>3</p>\n</td>\n<td valign=\"top\" width=\"60\">\n<p>75,653</p>\n</td>\n<td valign=\"top\" width=\"44\">\n<p>1520</p>\n</td>\n<td valign=\"top\" width=\"151\">\n<p>Sphere Research Labs</p>\n</td>\n<td valign=\"top\" width=\"47\">&nbsp;</td>\n</tr>\n<tr>\n<td valign=\"top\" width=\"94\">\n<p><a href=\"http://poj.org/\" onclick=\"javascript:_gaq.push(['_trackEvent','outbound-article','http://poj.org']);\">POJ</a></p>\n</td>\n<td valign=\"top\" width=\"57\">\n<p>ACM</p>\n</td>\n<td valign=\"top\" width=\"38\">\n<p>7</p>\n</td>\n<td valign=\"top\" width=\"60\">\n<p>364,925</p>\n</td>\n<td valign=\"top\" width=\"44\">\n<p>N/A</p>\n</td>\n<td valign=\"top\" width=\"151\">\n<p>北京大学</p>\n</td>\n<td valign=\"top\" width=\"47\">&nbsp;</td>\n</tr>\n<tr>\n<td valign=\"top\" width=\"94\">\n<p><a href=\"http://acm.zju.edu.cn\" onclick=\"javascript:_gaq.push(['_trackEvent','outbound-article','http://acm.zju.edu.cn']);\">ZOJ</a></p>\n</td>\n<td valign=\"top\" width=\"57\">\n<p>ACM</p>\n</td>\n<td valign=\"top\" width=\"38\">\n<p>6</p>\n</td>\n<td valign=\"top\" width=\"60\">\n<p>N/A</p>\n</td>\n<td valign=\"top\" width=\"44\">\n<p>N/A</p>\n</td>\n<td valign=\"top\" width=\"151\">\n<p>浙江大学</p>\n</td>\n<td valign=\"top\" width=\"47\">&nbsp;</td>\n</tr>\n<tr>\n<td valign=\"top\" width=\"94\">\n<p><a href=\"http://uva.onlinejudge.org/\" onclick=\"javascript:_gaq.push(['_trackEvent','outbound-article','http://uva.onlinejudge.org']);\">UVA OJ</a></p>\n</td>\n<td valign=\"top\" width=\"57\">\n<p>ACM</p>\n</td>\n<td valign=\"top\" width=\"38\">\n<p>6</p>\n</td>\n<td valign=\"top\" width=\"60\">\n<p>166,991</p>\n</td>\n<td valign=\"top\" width=\"44\">\n<p>N/A</p>\n</td>\n<td valign=\"top\" width=\"151\">\n<p>University of Virginia</p>\n</td>\n<td valign=\"top\" width=\"47\">&nbsp;</td>\n</tr>\n<tr>\n<td valign=\"top\" width=\"94\">\n<p><a href=\"http://acm.sgu.ru/\" onclick=\"javascript:_gaq.push(['_trackEvent','outbound-article','http://acm.sgu.ru']);\">SGU OJ</a></p>\n</td>\n<td valign=\"top\" width=\"57\">\n<p>ACM</p>\n</td>\n<td valign=\"top\" width=\"38\">\n<p>5</p>\n</td>\n<td valign=\"top\" width=\"60\">\n<p>194,881</p>\n</td>\n<td valign=\"top\" width=\"44\">\n<p>N/A</p>\n</td>\n<td valign=\"top\" width=\"151\">\n<p>Saratov State University</p>\n</td>\n<td valign=\"top\" width=\"47\">&nbsp;</td>\n</tr>\n<tr>\n<td valign=\"top\" width=\"94\">\n<p><a href=\"https://www.hackerrank.com/\" onclick=\"javascript:_gaq.push(['_trackEvent','outbound-article','http://www.hackerrank.com']);\">HackerRank</a></p>\n</td>\n<td valign=\"top\" width=\"57\">\n<p>综合</p>\n</td>\n<td valign=\"top\" width=\"38\">\n<p>5</p>\n</td>\n<td valign=\"top\" width=\"60\">\n<p>126,192</p>\n</td>\n<td valign=\"top\" width=\"44\">\n<p>56</p>\n</td>\n<td valign=\"top\" width=\"151\">\n<p>InterviewStreet公司</p>\n</td>\n<td valign=\"top\" width=\"47\">&nbsp;</td>\n</tr>\n<tr>\n<td valign=\"top\" width=\"94\">\n<p><a href=\"http://projecteuler.net/\" onclick=\"javascript:_gaq.push(['_trackEvent','outbound-article','http://projecteuler.net']);\">Project Euler</a></p>\n</td>\n<td valign=\"top\" width=\"57\">\n<p>数学</p>\n</td>\n<td valign=\"top\" width=\"38\">\n<p>6</p>\n</td>\n<td valign=\"top\" width=\"60\">\n<p>53,854</p>\n</td>\n<td valign=\"top\" width=\"44\">\n<p>428</p>\n</td>\n<td valign=\"top\" width=\"151\">\n<p>Project Euler公司</p>\n</td>\n<td valign=\"top\" width=\"47\">&nbsp;</td>\n</tr>\n<tr>\n<td valign=\"top\" width=\"94\">\n<p><a href=\"http://www.careercup.com/\" onclick=\"javascript:_gaq.push(['_trackEvent','outbound-article','http://www.careercup.com']);\">CareerUp</a></p>\n</td>\n<td valign=\"top\" width=\"57\">\n<p>面试</p>\n</td>\n<td valign=\"top\" width=\"38\">\n<p>4</p>\n</td>\n<td valign=\"top\" width=\"60\">\n<p>51,089</p>\n</td>\n<td valign=\"top\" width=\"44\">\n<p>654</p>\n</td>\n<td valign=\"top\" width=\"151\">\n<p>CareerUp公司</p>\n</td>\n<td valign=\"top\" width=\"47\">&nbsp;</td>\n</tr>\n<tr>\n<td valign=\"top\" width=\"94\">\n<p><a href=\"http://leetcode.com/\" onclick=\"javascript:_gaq.push(['_trackEvent','outbound-article','http://leetcode.com']);\">LeetCode</a></p>\n</td>\n<td valign=\"top\" width=\"57\">\n<p>面试</p>\n</td>\n<td valign=\"top\" width=\"38\">\n<p>4</p>\n</td>\n<td valign=\"top\" width=\"60\">\n<p>188,196</p>\n</td>\n<td valign=\"top\" width=\"44\">\n<p>N/A</p>\n</td>\n<td valign=\"top\" width=\"151\">\n<p>LeetCode公司</p>\n</td>\n<td valign=\"top\" width=\"47\">&nbsp;</td>\n</tr>\n</tbody>\n</table>\n\n说明：PR是Google PageRank的缩写；ATR是Alexa Trafic Rank的缩写，即Alexa排名；QF是Quora Followers的缩写，具体含义是在Quora上关于某Topic的follower数量，例如[CodeChef的topic](http://www.quora.com/CodeChef) 有5758个followers。\n\n<!-- more -->\n\n##支持的语言\n<table cellspacing=\"0\" cellpadding=\"0\" border=\"1\">\n<tbody>\n<tr>\n<td valign=\"top\" width=\"72\"><strong>网站</strong>\n<p><strong>语言</strong></p>\n</td>\n<td valign=\"top\" width=\"79\"><strong>TopCoder</strong></td>\n<td valign=\"top\" width=\"47\"><strong>CodeChef</strong></td>\n<td valign=\"top\" width=\"57\"><strong>CodeForces</strong></td>\n<td valign=\"top\" width=\"47\"><strong>SPOJ</strong></td>\n<td valign=\"top\" width=\"38\"><strong>POJ</strong></td>\n<td valign=\"top\" width=\"47\"><strong>ZOJ</strong></td>\n<td valign=\"top\" width=\"47\"><strong>UVA OJ</strong></td>\n<td valign=\"top\" width=\"47\"><strong>SGU OJ</strong></td>\n<td valign=\"top\" width=\"57\"><strong>HackerRank</strong></td>\n<td valign=\"top\" width=\"57\"><strong>Project Euler</strong></td>\n</tr>\n<tr>\n<td valign=\"top\" width=\"72\">Java</td>\n<td valign=\"top\" width=\"79\"><a name=\"OLE_LINK5\"></a><a name=\"OLE_LINK3\"></a>√</td>\n<td valign=\"top\" width=\"47\">√<strong></strong></td>\n<td valign=\"top\" width=\"57\">√</td>\n<td valign=\"top\" width=\"47\">√</td>\n<td valign=\"top\" width=\"38\">√</td>\n<td valign=\"top\" width=\"47\">√</td>\n<td valign=\"top\" width=\"47\">&nbsp;</td>\n<td valign=\"top\" width=\"47\">√</td>\n<td valign=\"top\" width=\"57\">√</td>\n<td valign=\"top\" width=\"57\">不</td>\n</tr>\n<tr>\n<td valign=\"top\" width=\"72\">C</td>\n<td valign=\"top\" width=\"79\">√</td>\n<td valign=\"top\" width=\"47\">√</td>\n<td valign=\"top\" width=\"57\">√</td>\n<td valign=\"top\" width=\"47\">√</td>\n<td valign=\"top\" width=\"38\">√</td>\n<td valign=\"top\" width=\"47\">√</td>\n<td valign=\"top\" width=\"47\">&nbsp;</td>\n<td valign=\"top\" width=\"47\">√</td>\n<td valign=\"top\" width=\"57\">√</td>\n<td valign=\"top\" width=\"57\">限</td>\n</tr>\n<tr>\n<td valign=\"top\" width=\"72\">C++</td>\n<td valign=\"top\" width=\"79\">√</td>\n<td valign=\"top\" width=\"47\"><a name=\"OLE_LINK19\"></a><a name=\"OLE_LINK18\"></a>√</td>\n<td valign=\"top\" width=\"57\">√</td>\n<td valign=\"top\" width=\"47\">√</td>\n<td valign=\"top\" width=\"38\">√</td>\n<td valign=\"top\" width=\"47\">√</td>\n<td valign=\"top\" width=\"47\">&nbsp;</td>\n<td valign=\"top\" width=\"47\">√</td>\n<td valign=\"top\" width=\"57\">√</td>\n<td valign=\"top\" width=\"57\">语</td>\n</tr>\n<tr>\n<td valign=\"top\" width=\"72\">Pascal</td>\n<td valign=\"top\" width=\"79\">×</td>\n<td valign=\"top\" width=\"47\">√</td>\n<td valign=\"top\" width=\"57\">√</td>\n<td valign=\"top\" width=\"47\">√</td>\n<td valign=\"top\" width=\"38\">√</td>\n<td valign=\"top\" width=\"47\">√</td>\n<td valign=\"top\" width=\"47\">&nbsp;</td>\n<td valign=\"top\" width=\"47\">√</td>\n<td valign=\"top\" width=\"57\">√</td>\n<td valign=\"top\" width=\"57\">言</td>\n</tr>\n<tr>\n<td valign=\"top\" width=\"72\">Fortran</td>\n<td valign=\"top\" width=\"79\">×</td>\n<td valign=\"top\" width=\"47\"><a name=\"OLE_LINK9\"></a><a name=\"OLE_LINK8\"></a>√</td>\n<td valign=\"top\" width=\"57\">×</td>\n<td valign=\"top\" width=\"47\"><a name=\"OLE_LINK21\"></a><a name=\"OLE_LINK20\"></a>√</td>\n<td valign=\"top\" width=\"38\">√</td>\n<td valign=\"top\" width=\"47\">×</td>\n<td valign=\"top\" width=\"47\">&nbsp;</td>\n<td valign=\"top\" width=\"47\">×</td>\n<td valign=\"top\" width=\"57\"><a name=\"OLE_LINK7\"></a><a name=\"OLE_LINK6\"></a>×</td>\n<td valign=\"top\" width=\"57\">，</td>\n</tr>\n<tr>\n<td valign=\"top\" width=\"72\">Obj-C</td>\n<td valign=\"top\" width=\"79\">×</td>\n<td valign=\"top\" width=\"47\">×</td>\n<td valign=\"top\" width=\"57\">×</td>\n<td valign=\"top\" width=\"47\">×</td>\n<td valign=\"top\" width=\"38\">×</td>\n<td valign=\"top\" width=\"47\">×</td>\n<td valign=\"top\" width=\"47\">&nbsp;</td>\n<td valign=\"top\" width=\"47\">×</td>\n<td valign=\"top\" width=\"57\">×</td>\n<td valign=\"top\" width=\"57\">只</td>\n</tr>\n<tr>\n<td valign=\"top\" width=\"72\">C#</td>\n<td valign=\"top\" width=\"79\">√</td>\n<td valign=\"top\" width=\"47\">√</td>\n<td valign=\"top\" width=\"57\">√</td>\n<td valign=\"top\" width=\"47\">√</td>\n<td valign=\"top\" width=\"38\">×</td>\n<td valign=\"top\" width=\"47\">×</td>\n<td valign=\"top\" width=\"47\">&nbsp;</td>\n<td valign=\"top\" width=\"47\">√</td>\n<td valign=\"top\" width=\"57\">√</td>\n<td valign=\"top\" width=\"57\">需</td>\n</tr>\n<tr>\n<td valign=\"top\" width=\"72\">Python 2</td>\n<td valign=\"top\" width=\"79\">×</td>\n<td valign=\"top\" width=\"47\">√</td>\n<td valign=\"top\" width=\"57\">√</td>\n<td valign=\"top\" width=\"47\">√</td>\n<td valign=\"top\" width=\"38\">×</td>\n<td valign=\"top\" width=\"47\">√</td>\n<td valign=\"top\" width=\"47\">&nbsp;</td>\n<td valign=\"top\" width=\"47\">×</td>\n<td valign=\"top\" width=\"57\">√</td>\n<td valign=\"top\" width=\"57\">提</td>\n</tr>\n<tr>\n<td valign=\"top\" width=\"72\">Python 3</td>\n<td valign=\"top\" width=\"79\">×</td>\n<td valign=\"top\" width=\"47\">√</td>\n<td valign=\"top\" width=\"57\">×</td>\n<td valign=\"top\" width=\"47\">√</td>\n<td valign=\"top\" width=\"38\">×</td>\n<td valign=\"top\" width=\"47\">×</td>\n<td valign=\"top\" width=\"47\">&nbsp;</td>\n<td valign=\"top\" width=\"47\">×</td>\n<td valign=\"top\" width=\"57\">√</td>\n<td valign=\"top\" width=\"57\">交</td>\n</tr>\n<tr>\n<td valign=\"top\" width=\"72\">Ruby</td>\n<td valign=\"top\" width=\"79\">×</td>\n<td valign=\"top\" width=\"47\">√</td>\n<td valign=\"top\" width=\"57\">√</td>\n<td valign=\"top\" width=\"47\">√</td>\n<td valign=\"top\" width=\"38\">×</td>\n<td valign=\"top\" width=\"47\">×</td>\n<td valign=\"top\" width=\"47\">&nbsp;</td>\n<td valign=\"top\" width=\"47\">×</td>\n<td valign=\"top\" width=\"57\">√</td>\n<td valign=\"top\" width=\"57\">答</td>\n</tr>\n<tr>\n<td valign=\"top\" width=\"72\">JavaScript</td>\n<td valign=\"top\" width=\"79\">×</td>\n<td valign=\"top\" width=\"47\">√</td>\n<td valign=\"top\" width=\"57\">×</td>\n<td valign=\"top\" width=\"47\">√</td>\n<td valign=\"top\" width=\"38\">×</td>\n<td valign=\"top\" width=\"47\">×</td>\n<td valign=\"top\" width=\"47\">&nbsp;</td>\n<td valign=\"top\" width=\"47\">×</td>\n<td valign=\"top\" width=\"57\">√</td>\n<td valign=\"top\" width=\"57\">案</td>\n</tr>\n<tr>\n<td valign=\"top\" width=\"72\">PHP</td>\n<td valign=\"top\" width=\"79\">×</td>\n<td valign=\"top\" width=\"47\"><a name=\"OLE_LINK11\"></a><a name=\"OLE_LINK10\"></a>√</td>\n<td valign=\"top\" width=\"57\">√</td>\n<td valign=\"top\" width=\"47\">√</td>\n<td valign=\"top\" width=\"38\">×</td>\n<td valign=\"top\" width=\"47\">√</td>\n<td valign=\"top\" width=\"47\">&nbsp;</td>\n<td valign=\"top\" width=\"47\">×</td>\n<td valign=\"top\" width=\"57\">√</td>\n<td valign=\"top\" width=\"57\">&nbsp;</td>\n</tr>\n<tr>\n<td valign=\"top\" width=\"72\">VB</td>\n<td valign=\"top\" width=\"79\">√</td>\n<td valign=\"top\" width=\"47\"><a name=\"OLE_LINK28\"></a><a name=\"OLE_LINK12\"></a>×</td>\n<td valign=\"top\" width=\"57\">×</td>\n<td valign=\"top\" width=\"47\">×</td>\n<td valign=\"top\" width=\"38\">×</td>\n<td valign=\"top\" width=\"47\">×</td>\n<td valign=\"top\" width=\"47\">&nbsp;</td>\n<td valign=\"top\" width=\"47\">×</td>\n<td valign=\"top\" width=\"57\">×</td>\n<td valign=\"top\" width=\"57\">&nbsp;</td>\n</tr>\n<tr>\n<td valign=\"top\" width=\"72\">Perl</td>\n<td valign=\"top\" width=\"79\">×</td>\n<td valign=\"top\" width=\"47\">√</td>\n<td valign=\"top\" width=\"57\">√</td>\n<td valign=\"top\" width=\"47\"><a name=\"OLE_LINK22\"></a>√</td>\n<td valign=\"top\" width=\"38\">×</td>\n<td valign=\"top\" width=\"47\">√</td>\n<td valign=\"top\" width=\"47\">&nbsp;</td>\n<td valign=\"top\" width=\"47\">×</td>\n<td valign=\"top\" width=\"57\">√</td>\n<td valign=\"top\" width=\"57\">&nbsp;</td>\n</tr>\n<tr>\n<td valign=\"top\" width=\"72\">Go</td>\n<td valign=\"top\" width=\"79\">×</td>\n<td valign=\"top\" width=\"47\">√</td>\n<td valign=\"top\" width=\"57\">×</td>\n<td valign=\"top\" width=\"47\">√</td>\n<td valign=\"top\" width=\"38\">×</td>\n<td valign=\"top\" width=\"47\">×</td>\n<td valign=\"top\" width=\"47\">&nbsp;</td>\n<td valign=\"top\" width=\"47\">×</td>\n<td valign=\"top\" width=\"57\">√</td>\n<td valign=\"top\" width=\"57\">&nbsp;</td>\n</tr>\n<tr>\n<td valign=\"top\" width=\"72\">Scala</td>\n<td valign=\"top\" width=\"79\">×</td>\n<td valign=\"top\" width=\"47\">√</td>\n<td valign=\"top\" width=\"57\">√</td>\n<td valign=\"top\" width=\"47\">√</td>\n<td valign=\"top\" width=\"38\">×</td>\n<td valign=\"top\" width=\"47\">×</td>\n<td valign=\"top\" width=\"47\">&nbsp;</td>\n<td valign=\"top\" width=\"47\">×</td>\n<td valign=\"top\" width=\"57\">√</td>\n<td valign=\"top\" width=\"57\">&nbsp;</td>\n</tr>\n<tr>\n<td valign=\"top\" width=\"72\">Groovy</td>\n<td valign=\"top\" width=\"79\">×</td>\n<td valign=\"top\" width=\"47\">×</td>\n<td valign=\"top\" width=\"57\">×</td>\n<td valign=\"top\" width=\"47\">×</td>\n<td valign=\"top\" width=\"38\">×</td>\n<td valign=\"top\" width=\"47\">×</td>\n<td valign=\"top\" width=\"47\">&nbsp;</td>\n<td valign=\"top\" width=\"47\">×</td>\n<td valign=\"top\" width=\"57\">√</td>\n<td valign=\"top\" width=\"57\">&nbsp;</td>\n</tr>\n<tr>\n<td valign=\"top\" width=\"72\">Erlang</td>\n<td valign=\"top\" width=\"79\">×</td>\n<td valign=\"top\" width=\"47\">√</td>\n<td valign=\"top\" width=\"57\"><a name=\"OLE_LINK15\"></a>×</td>\n<td valign=\"top\" width=\"47\">√</td>\n<td valign=\"top\" width=\"38\">×</td>\n<td valign=\"top\" width=\"47\">×</td>\n<td valign=\"top\" width=\"47\">&nbsp;</td>\n<td valign=\"top\" width=\"47\">×</td>\n<td valign=\"top\" width=\"57\">√</td>\n<td valign=\"top\" width=\"57\">&nbsp;</td>\n</tr>\n<tr>\n<td valign=\"top\" width=\"72\">Lua</td>\n<td valign=\"top\" width=\"79\">×</td>\n<td valign=\"top\" width=\"47\">√</td>\n<td valign=\"top\" width=\"57\">×</td>\n<td valign=\"top\" width=\"47\">√</td>\n<td valign=\"top\" width=\"38\">×</td>\n<td valign=\"top\" width=\"47\">×</td>\n<td valign=\"top\" width=\"47\">&nbsp;</td>\n<td valign=\"top\" width=\"47\">×</td>\n<td valign=\"top\" width=\"57\">√</td>\n<td valign=\"top\" width=\"57\">&nbsp;</td>\n</tr>\n<tr>\n<td valign=\"top\" width=\"72\">D</td>\n<td valign=\"top\" width=\"79\">×</td>\n<td valign=\"top\" width=\"47\">√</td>\n<td valign=\"top\" width=\"57\">√</td>\n<td valign=\"top\" width=\"47\">√</td>\n<td valign=\"top\" width=\"38\">×</td>\n<td valign=\"top\" width=\"47\">×</td>\n<td valign=\"top\" width=\"47\">&nbsp;</td>\n<td valign=\"top\" width=\"47\">×</td>\n<td valign=\"top\" width=\"57\">√</td>\n<td valign=\"top\" width=\"57\">&nbsp;</td>\n</tr>\n<tr>\n<td valign=\"top\" width=\"72\">Fortran</td>\n<td valign=\"top\" width=\"79\">×</td>\n<td valign=\"top\" width=\"47\">√</td>\n<td valign=\"top\" width=\"57\">×</td>\n<td valign=\"top\" width=\"47\">√</td>\n<td valign=\"top\" width=\"38\">×</td>\n<td valign=\"top\" width=\"47\">×</td>\n<td valign=\"top\" width=\"47\">&nbsp;</td>\n<td valign=\"top\" width=\"47\">×</td>\n<td valign=\"top\" width=\"57\"><a name=\"OLE_LINK4\"></a>×</td>\n<td valign=\"top\" width=\"57\">&nbsp;</td>\n</tr>\n<tr>\n<td valign=\"top\" width=\"72\">CommonLisp</td>\n<td valign=\"top\" width=\"79\">×</td>\n<td valign=\"top\" width=\"47\">√</td>\n<td valign=\"top\" width=\"57\">×</td>\n<td valign=\"top\" width=\"47\">√</td>\n<td valign=\"top\" width=\"38\">×</td>\n<td valign=\"top\" width=\"47\"><a name=\"OLE_LINK26\"></a><a name=\"OLE_LINK25\"></a>×</td>\n<td valign=\"top\" width=\"47\">&nbsp;</td>\n<td valign=\"top\" width=\"47\">×</td>\n<td valign=\"top\" width=\"57\">√</td>\n<td valign=\"top\" width=\"57\">&nbsp;</td>\n</tr>\n<tr>\n<td valign=\"top\" width=\"72\">Clojure</td>\n<td valign=\"top\" width=\"79\">×</td>\n<td valign=\"top\" width=\"47\"><a name=\"OLE_LINK14\"></a><a name=\"OLE_LINK13\"></a>√</td>\n<td valign=\"top\" width=\"57\">×</td>\n<td valign=\"top\" width=\"47\">√</td>\n<td valign=\"top\" width=\"38\">×</td>\n<td valign=\"top\" width=\"47\">×</td>\n<td valign=\"top\" width=\"47\">&nbsp;</td>\n<td valign=\"top\" width=\"47\">×</td>\n<td valign=\"top\" width=\"57\">√</td>\n<td valign=\"top\" width=\"57\">&nbsp;</td>\n</tr>\n<tr>\n<td valign=\"top\" width=\"72\">Scheme</td>\n<td valign=\"top\" width=\"79\">×</td>\n<td valign=\"top\" width=\"47\">√</td>\n<td valign=\"top\" width=\"57\">×</td>\n<td valign=\"top\" width=\"47\">√</td>\n<td valign=\"top\" width=\"38\">×</td>\n<td valign=\"top\" width=\"47\">√</td>\n<td valign=\"top\" width=\"47\">&nbsp;</td>\n<td valign=\"top\" width=\"47\">×</td>\n<td valign=\"top\" width=\"57\">×</td>\n<td valign=\"top\" width=\"57\">&nbsp;</td>\n</tr>\n<tr>\n<td valign=\"top\" width=\"72\">Haskell</td>\n<td valign=\"top\" width=\"79\">×</td>\n<td valign=\"top\" width=\"47\">√</td>\n<td valign=\"top\" width=\"57\">√</td>\n<td valign=\"top\" width=\"47\">√</td>\n<td valign=\"top\" width=\"38\"><a name=\"OLE_LINK24\"></a><a name=\"OLE_LINK23\"></a>×</td>\n<td valign=\"top\" width=\"47\">×</td>\n<td valign=\"top\" width=\"47\">&nbsp;</td>\n<td valign=\"top\" width=\"47\">×</td>\n<td valign=\"top\" width=\"57\">√</td>\n<td valign=\"top\" width=\"57\">&nbsp;</td>\n</tr>\n<tr>\n<td valign=\"top\" width=\"72\">OCaml</td>\n<td valign=\"top\" width=\"79\">×</td>\n<td valign=\"top\" width=\"47\">√</td>\n<td valign=\"top\" width=\"57\">√</td>\n<td valign=\"top\" width=\"47\">√</td>\n<td valign=\"top\" width=\"38\">×</td>\n<td valign=\"top\" width=\"47\">×</td>\n<td valign=\"top\" width=\"47\">&nbsp;</td>\n<td valign=\"top\" width=\"47\">×</td>\n<td valign=\"top\" width=\"57\">√</td>\n<td valign=\"top\" width=\"57\">&nbsp;</td>\n</tr>\n<tr>\n<td valign=\"top\" width=\"72\">其他</td>\n<td valign=\"top\" width=\"79\">×</td>\n<td valign=\"top\" width=\"47\"><a name=\"OLE_LINK17\"></a><a name=\"OLE_LINK16\"></a>√</td>\n<td valign=\"top\" width=\"57\">×</td>\n<td valign=\"top\" width=\"47\">√</td>\n<td valign=\"top\" width=\"38\">×</td>\n<td valign=\"top\" width=\"47\">×</td>\n<td valign=\"top\" width=\"47\">&nbsp;</td>\n<td valign=\"top\" width=\"47\">×</td>\n<td valign=\"top\" width=\"57\">×</td>\n<td valign=\"top\" width=\"57\">&nbsp;</td>\n</tr>\n</tbody>\n</table>\n\n##大牛在哪里玩\n[CodeChef的Long Consest 排名榜](http://www.codechef.com/long/ranklist/AX/?page=0)  \n[CodeForces的排名榜](http://codeforces.com/ratings)\n\n看看一些神牛在哪些编程网站上玩。\n\n<table cellspacing=\"0\" cellpadding=\"0\" border=\"1\">\n<tbody>\n<tr>\n<td valign=\"top\" width=\"98\">\n<p><strong>大牛名字</strong></p>\n</td>\n<td valign=\"top\" width=\"393\">\n<p><strong>在哪些网站活动</strong></p>\n</td>\n<td valign=\"top\" width=\"100\">\n<p><strong>结论</strong></p>\n</td>\n</tr>\n<tr>\n<td valign=\"top\" width=\"98\">\n<p>清华 楼天城 ACRush</p>\n<p>现在Google工作</p>\n</td>\n<td valign=\"top\" width=\"393\">\n<p><a href=\"http://community.topcoder.com/tc?module=MemberProfile&amp;cr=19849563\" onclick=\"javascript:_gaq.push(['_trackEvent','outbound-article','http://community.topcoder.com']);\">http://community.topcoder.com/tc?module=MemberProfile&amp;cr=19849563</a> 最后活动日期14/03/13</p>\n<p><a href=\"http://www.codechef.com/users/ACRush21\" onclick=\"javascript:_gaq.push(['_trackEvent','outbound-article','http://www.codechef.com']);\">http://www.codechef.com/users/ACRush21</a> long contest排名第一</p>\n<p><a href=\"http://codeforces.com/profile/ACRush\" onclick=\"javascript:_gaq.push(['_trackEvent','outbound-article','http://codeforces.com']);\">http://codeforces.com/profile/ACRush</a> 排名18 </p>\n</td>\n<td valign=\"top\" width=\"100\">\n<p>楼教主在TopCoder, CodeChef, CodeForces玩</p>\n</td>\n</tr>\n<tr>\n<td valign=\"top\" width=\"98\">\n<p>俄罗斯 petr</p>\n<p>现在Google工作</p>\n</td>\n<td valign=\"top\" width=\"393\">\n<p><a href=\"http://community.topcoder.com/tc?module=MemberProfile&amp;tab=alg&amp;cr=10574855\" onclick=\"javascript:_gaq.push(['_trackEvent','outbound-article','http://community.topcoder.com']);\">http://community.topcoder.com/tc?module=MemberProfile&amp;tab=alg&amp;cr=10574855</a></p>\n<p><a href=\"http://www.codechef.com/users/petr\" onclick=\"javascript:_gaq.push(['_trackEvent','outbound-article','http://www.codechef.com']);\">http://www.codechef.com/users/petr</a> N/A</p>\n<p><a href=\"http://codeforces.com/profile/Petr\" onclick=\"javascript:_gaq.push(['_trackEvent','outbound-article','http://codeforces.com']);\">http://codeforces.com/profile/Petr</a> 排名第三</p>\n</td>\n<td valign=\"top\" width=\"100\">\n<p>Petr主要在TopCoder, CodeForces玩</p>\n</td>\n</tr>\n<tr>\n<td valign=\"top\" width=\"98\">\n<p>波兰 tomek</p>\n<p>现在Google工作</p>\n</td>\n<td valign=\"top\" width=\"393\">\n<p><a href=\"http://community.topcoder.com/tc?module=MemberProfile&amp;cr=144400\" onclick=\"javascript:_gaq.push(['_trackEvent','outbound-article','http://community.topcoder.com']);\">http://community.topcoder.com/tc?module=MemberProfile&amp;cr=144400</a></p>\n<p><a href=\"http://www.codechef.com/users/tomek\" onclick=\"javascript:_gaq.push(['_trackEvent','outbound-article','http://www.codechef.com']);\">http://www.codechef.com/users/tomek</a> long contest排名第六</p>\n<p><a href=\"http://codeforces.com/profile/tomek\" onclick=\"javascript:_gaq.push(['_trackEvent','outbound-article','http://codeforces.com']);\">http://codeforces.com/profile/tomek</a> N/A</p>\n</td>\n<td valign=\"top\" width=\"100\">\n<p>Tomek主要在TopCoder, codechef玩</p>\n</td>\n</tr>\n<tr>\n<td valign=\"top\" width=\"98\">\n<p>俄罗斯 Egor</p>\n</td>\n<td valign=\"top\" width=\"393\">\n<p><a href=\"http://community.topcoder.com/tc?module=MemberProfile&amp;cr=14970299\" onclick=\"javascript:_gaq.push(['_trackEvent','outbound-article','http://community.topcoder.com']);\">http://community.topcoder.com/tc?module=MemberProfile&amp;cr=14970299</a></p>\n<p><a href=\"http://www.codechef.com/users/Egor\" onclick=\"javascript:_gaq.push(['_trackEvent','outbound-article','http://www.codechef.com']);\">http://www.codechef.com/users/Egor</a> N/A</p>\n<p><a href=\"http://codeforces.com/profile/Egor\" onclick=\"javascript:_gaq.push(['_trackEvent','outbound-article','http://codeforces.com']);\">http://codeforces.com/profile/Egor</a> 排名第七</p>\n</td>\n<td valign=\"top\" width=\"100\">\n<p>Egor主要在TopCoder, CodeForces玩</p>\n</td>\n</tr>\n<tr>\n<td valign=\"top\" width=\"98\">\n<p>俄罗斯 Tourist</p>\n<p>高三学生</p>\n</td>\n<td valign=\"top\" width=\"393\">\n<p><a href=\"http://www.codechef.com/teams/view/tourist\" onclick=\"javascript:_gaq.push(['_trackEvent','outbound-article','http://www.codechef.com']);\">http://www.codechef.com/teams/view/tourist</a> N/A</p>\n<p><a href=\"http://www.codeforces.com/profile/tourist\" onclick=\"javascript:_gaq.push(['_trackEvent','outbound-article','http://www.codeforces.com']);\">http://www.codeforces.com/profile/tourist</a> 排名第一</p>\n</td>\n<td valign=\"top\" width=\"100\">\n<p>少年天才，主要在CodeForces玩</p>\n</td>\n</tr>\n</tbody>\n</table>\n\n由于CodeForcess是俄罗斯的网站，所以俄罗斯选手几乎全部在CodeForces上玩，例如Petr, Egor, Tourist都是俄罗斯人，都在CodeForces上。\n也可以发现，神牛大部分来自俄罗斯，大家或许也会联想到，俄罗斯出数学家和计算机黑客，的确如此。像楼教主，Petr属于老牌的霸主，近两年出现一个天才少年tourist，才高三，竟然在CodeForces上力压Petr，真是逆天的存在。Quora上有个问题How does it feel to beat Petr Mitrichev, Egor, ACRush in SRM? 最佳答案 It feels a lot like being Tourist. 既幽默又霸气。\n\n##大牛们使用什么语言？\n来看一下高手提交的代码列表：  \n[http://codeforces.com/submissions/ACRush](http://codeforces.com/submissions/ACRush)  \n[http://codeforces.com/submissions/Petr](http://codeforces.com/submissions/Petr)  \n[http://codeforces.com/submissions/Egor](http://codeforces.com/submissions/Egor)  \n[http://www.codeforces.com/submissions/tourist](http://www.codeforces.com/submissions/tourist)\n\n可以看出ACRush和Tourist使用C++，Petr和Egor使用Java。从我的亲身经验，周围参加ACM的同学大部分用C++。不过，注意一点，大部分人认为Java慢，这在五六年前是对的，但是到了在现在，JVM经过各大IT巨头的重金打造，性能已经跟C++一样持平了，至少不再有数量级上的差距。因此Java也是一个很好地选择。\n\n\n##更新历史\n2013-04-06，从 [加州求职记](http://blog.liancheng.info/job-hunting-in-california/) 得知了两个专门针对面试的新兴网站，[CareerCup](http://www.careercup.com/) 和 [LeetCode](http://leetcode.com/onlinejudge)，跟 InterviewStreet 很类似。\n","source":"_posts/2013-03-22-some-popular-programming-contest-websites.md","raw":"---\nlayout: post\ntitle: \"一些主流的编程竞赛网站\"\ndate: 2013-03-22 21:57\ncomments: true\ncategories: Algorithm\n---\n今天把各个主流的编程网站仔细对比了一下，下面从各个角度对比一下这些编程竞赛网站。\n\n##分类和排名\n<table border=\"1\" cellspacing=\"0\" cellpadding=\"0\">\n<tbody>\n<tr>\n<td valign=\"top\" width=\"94\">\n<p><a name=\"OLE_LINK30\"></a><a name=\"OLE_LINK1\"><b>网站地址</b></a></p>\n</td>\n<td valign=\"top\" width=\"57\">\n<p><b>类别</b></p>\n</td>\n<td valign=\"top\" width=\"38\">\n<p><b>PR</b></p>\n</td>\n<td valign=\"top\" width=\"60\">\n<p><b>ATR</b></p>\n</td>\n<td valign=\"top\" width=\"44\">\n<p><b>QF</b></p>\n</td>\n<td valign=\"top\" width=\"151\">\n<p><b>主办方</b></p>\n</td>\n<td valign=\"top\" width=\"47\">\n<p><b>备注</b></p>\n</td>\n</tr>\n<tr>\n<td valign=\"top\" width=\"94\">\n<p><a name=\"_Hlk352791085\"></a><a href=\"http://www.topcoder.com/\" onclick=\"javascript:_gaq.push(['_trackEvent','outbound-article','http://www.topcoder.com']);\">TopCoder </a></p>\n</td>\n<td valign=\"top\" width=\"57\">\n<p>综合</p>\n</td>\n<td valign=\"top\" width=\"38\">\n<p>6</p>\n</td>\n<td valign=\"top\" width=\"60\">\n<p>33,586</p>\n</td>\n<td valign=\"top\" width=\"44\">\n<p>4167</p>\n</td>\n<td valign=\"top\" width=\"151\">\n<p>TopCoder公司</p>\n</td>\n<td valign=\"top\" width=\"47\">&nbsp;</td>\n</tr>\n<tr>\n<td valign=\"top\" width=\"94\">\n<p><a href=\"http://www.codechef.com/\" onclick=\"javascript:_gaq.push(['_trackEvent','outbound-article','http://www.codechef.com']);\">CodeChef </a></p>\n</td>\n<td valign=\"top\" width=\"57\">\n<p>综合</p>\n</td>\n<td valign=\"top\" width=\"38\">\n<p>6</p>\n</td>\n<td valign=\"top\" width=\"60\">\n<p>41,217</p>\n</td>\n<td valign=\"top\" width=\"44\">\n<p>5758</p>\n</td>\n<td valign=\"top\" width=\"151\">\n<p>Directi公司</p>\n</td>\n<td valign=\"top\" width=\"47\">&nbsp;</td>\n</tr>\n<tr>\n<td valign=\"top\" width=\"94\">\n<p><a href=\"http://codeforces.com/\" onclick=\"javascript:_gaq.push(['_trackEvent','outbound-article','http://codeforces.com']);\">CodeForces </a></p>\n</td>\n<td valign=\"top\" width=\"57\">\n<p>综合</p>\n</td>\n<td valign=\"top\" width=\"38\">\n<p>5</p>\n</td>\n<td valign=\"top\" width=\"60\">\n<p>73,012</p>\n</td>\n<td valign=\"top\" width=\"44\">\n<p>599</p>\n</td>\n<td valign=\"top\" width=\"151\">\n<p>CodeForces公司</p>\n</td>\n<td valign=\"top\" width=\"47\">&nbsp;</td>\n</tr>\n<tr>\n<td valign=\"top\" width=\"94\">\n<p><a href=\"http://www.spoj.com/\" onclick=\"javascript:_gaq.push(['_trackEvent','outbound-article','http://www.spoj.com']);\">SPOJ</a></p>\n</td>\n<td valign=\"top\" width=\"57\">\n<p>ACM</p>\n</td>\n<td valign=\"top\" width=\"38\">\n<p>3</p>\n</td>\n<td valign=\"top\" width=\"60\">\n<p>75,653</p>\n</td>\n<td valign=\"top\" width=\"44\">\n<p>1520</p>\n</td>\n<td valign=\"top\" width=\"151\">\n<p>Sphere Research Labs</p>\n</td>\n<td valign=\"top\" width=\"47\">&nbsp;</td>\n</tr>\n<tr>\n<td valign=\"top\" width=\"94\">\n<p><a href=\"http://poj.org/\" onclick=\"javascript:_gaq.push(['_trackEvent','outbound-article','http://poj.org']);\">POJ</a></p>\n</td>\n<td valign=\"top\" width=\"57\">\n<p>ACM</p>\n</td>\n<td valign=\"top\" width=\"38\">\n<p>7</p>\n</td>\n<td valign=\"top\" width=\"60\">\n<p>364,925</p>\n</td>\n<td valign=\"top\" width=\"44\">\n<p>N/A</p>\n</td>\n<td valign=\"top\" width=\"151\">\n<p>北京大学</p>\n</td>\n<td valign=\"top\" width=\"47\">&nbsp;</td>\n</tr>\n<tr>\n<td valign=\"top\" width=\"94\">\n<p><a href=\"http://acm.zju.edu.cn\" onclick=\"javascript:_gaq.push(['_trackEvent','outbound-article','http://acm.zju.edu.cn']);\">ZOJ</a></p>\n</td>\n<td valign=\"top\" width=\"57\">\n<p>ACM</p>\n</td>\n<td valign=\"top\" width=\"38\">\n<p>6</p>\n</td>\n<td valign=\"top\" width=\"60\">\n<p>N/A</p>\n</td>\n<td valign=\"top\" width=\"44\">\n<p>N/A</p>\n</td>\n<td valign=\"top\" width=\"151\">\n<p>浙江大学</p>\n</td>\n<td valign=\"top\" width=\"47\">&nbsp;</td>\n</tr>\n<tr>\n<td valign=\"top\" width=\"94\">\n<p><a href=\"http://uva.onlinejudge.org/\" onclick=\"javascript:_gaq.push(['_trackEvent','outbound-article','http://uva.onlinejudge.org']);\">UVA OJ</a></p>\n</td>\n<td valign=\"top\" width=\"57\">\n<p>ACM</p>\n</td>\n<td valign=\"top\" width=\"38\">\n<p>6</p>\n</td>\n<td valign=\"top\" width=\"60\">\n<p>166,991</p>\n</td>\n<td valign=\"top\" width=\"44\">\n<p>N/A</p>\n</td>\n<td valign=\"top\" width=\"151\">\n<p>University of Virginia</p>\n</td>\n<td valign=\"top\" width=\"47\">&nbsp;</td>\n</tr>\n<tr>\n<td valign=\"top\" width=\"94\">\n<p><a href=\"http://acm.sgu.ru/\" onclick=\"javascript:_gaq.push(['_trackEvent','outbound-article','http://acm.sgu.ru']);\">SGU OJ</a></p>\n</td>\n<td valign=\"top\" width=\"57\">\n<p>ACM</p>\n</td>\n<td valign=\"top\" width=\"38\">\n<p>5</p>\n</td>\n<td valign=\"top\" width=\"60\">\n<p>194,881</p>\n</td>\n<td valign=\"top\" width=\"44\">\n<p>N/A</p>\n</td>\n<td valign=\"top\" width=\"151\">\n<p>Saratov State University</p>\n</td>\n<td valign=\"top\" width=\"47\">&nbsp;</td>\n</tr>\n<tr>\n<td valign=\"top\" width=\"94\">\n<p><a href=\"https://www.hackerrank.com/\" onclick=\"javascript:_gaq.push(['_trackEvent','outbound-article','http://www.hackerrank.com']);\">HackerRank</a></p>\n</td>\n<td valign=\"top\" width=\"57\">\n<p>综合</p>\n</td>\n<td valign=\"top\" width=\"38\">\n<p>5</p>\n</td>\n<td valign=\"top\" width=\"60\">\n<p>126,192</p>\n</td>\n<td valign=\"top\" width=\"44\">\n<p>56</p>\n</td>\n<td valign=\"top\" width=\"151\">\n<p>InterviewStreet公司</p>\n</td>\n<td valign=\"top\" width=\"47\">&nbsp;</td>\n</tr>\n<tr>\n<td valign=\"top\" width=\"94\">\n<p><a href=\"http://projecteuler.net/\" onclick=\"javascript:_gaq.push(['_trackEvent','outbound-article','http://projecteuler.net']);\">Project Euler</a></p>\n</td>\n<td valign=\"top\" width=\"57\">\n<p>数学</p>\n</td>\n<td valign=\"top\" width=\"38\">\n<p>6</p>\n</td>\n<td valign=\"top\" width=\"60\">\n<p>53,854</p>\n</td>\n<td valign=\"top\" width=\"44\">\n<p>428</p>\n</td>\n<td valign=\"top\" width=\"151\">\n<p>Project Euler公司</p>\n</td>\n<td valign=\"top\" width=\"47\">&nbsp;</td>\n</tr>\n<tr>\n<td valign=\"top\" width=\"94\">\n<p><a href=\"http://www.careercup.com/\" onclick=\"javascript:_gaq.push(['_trackEvent','outbound-article','http://www.careercup.com']);\">CareerUp</a></p>\n</td>\n<td valign=\"top\" width=\"57\">\n<p>面试</p>\n</td>\n<td valign=\"top\" width=\"38\">\n<p>4</p>\n</td>\n<td valign=\"top\" width=\"60\">\n<p>51,089</p>\n</td>\n<td valign=\"top\" width=\"44\">\n<p>654</p>\n</td>\n<td valign=\"top\" width=\"151\">\n<p>CareerUp公司</p>\n</td>\n<td valign=\"top\" width=\"47\">&nbsp;</td>\n</tr>\n<tr>\n<td valign=\"top\" width=\"94\">\n<p><a href=\"http://leetcode.com/\" onclick=\"javascript:_gaq.push(['_trackEvent','outbound-article','http://leetcode.com']);\">LeetCode</a></p>\n</td>\n<td valign=\"top\" width=\"57\">\n<p>面试</p>\n</td>\n<td valign=\"top\" width=\"38\">\n<p>4</p>\n</td>\n<td valign=\"top\" width=\"60\">\n<p>188,196</p>\n</td>\n<td valign=\"top\" width=\"44\">\n<p>N/A</p>\n</td>\n<td valign=\"top\" width=\"151\">\n<p>LeetCode公司</p>\n</td>\n<td valign=\"top\" width=\"47\">&nbsp;</td>\n</tr>\n</tbody>\n</table>\n\n说明：PR是Google PageRank的缩写；ATR是Alexa Trafic Rank的缩写，即Alexa排名；QF是Quora Followers的缩写，具体含义是在Quora上关于某Topic的follower数量，例如[CodeChef的topic](http://www.quora.com/CodeChef) 有5758个followers。\n\n<!-- more -->\n\n##支持的语言\n<table cellspacing=\"0\" cellpadding=\"0\" border=\"1\">\n<tbody>\n<tr>\n<td valign=\"top\" width=\"72\"><strong>网站</strong>\n<p><strong>语言</strong></p>\n</td>\n<td valign=\"top\" width=\"79\"><strong>TopCoder</strong></td>\n<td valign=\"top\" width=\"47\"><strong>CodeChef</strong></td>\n<td valign=\"top\" width=\"57\"><strong>CodeForces</strong></td>\n<td valign=\"top\" width=\"47\"><strong>SPOJ</strong></td>\n<td valign=\"top\" width=\"38\"><strong>POJ</strong></td>\n<td valign=\"top\" width=\"47\"><strong>ZOJ</strong></td>\n<td valign=\"top\" width=\"47\"><strong>UVA OJ</strong></td>\n<td valign=\"top\" width=\"47\"><strong>SGU OJ</strong></td>\n<td valign=\"top\" width=\"57\"><strong>HackerRank</strong></td>\n<td valign=\"top\" width=\"57\"><strong>Project Euler</strong></td>\n</tr>\n<tr>\n<td valign=\"top\" width=\"72\">Java</td>\n<td valign=\"top\" width=\"79\"><a name=\"OLE_LINK5\"></a><a name=\"OLE_LINK3\"></a>√</td>\n<td valign=\"top\" width=\"47\">√<strong></strong></td>\n<td valign=\"top\" width=\"57\">√</td>\n<td valign=\"top\" width=\"47\">√</td>\n<td valign=\"top\" width=\"38\">√</td>\n<td valign=\"top\" width=\"47\">√</td>\n<td valign=\"top\" width=\"47\">&nbsp;</td>\n<td valign=\"top\" width=\"47\">√</td>\n<td valign=\"top\" width=\"57\">√</td>\n<td valign=\"top\" width=\"57\">不</td>\n</tr>\n<tr>\n<td valign=\"top\" width=\"72\">C</td>\n<td valign=\"top\" width=\"79\">√</td>\n<td valign=\"top\" width=\"47\">√</td>\n<td valign=\"top\" width=\"57\">√</td>\n<td valign=\"top\" width=\"47\">√</td>\n<td valign=\"top\" width=\"38\">√</td>\n<td valign=\"top\" width=\"47\">√</td>\n<td valign=\"top\" width=\"47\">&nbsp;</td>\n<td valign=\"top\" width=\"47\">√</td>\n<td valign=\"top\" width=\"57\">√</td>\n<td valign=\"top\" width=\"57\">限</td>\n</tr>\n<tr>\n<td valign=\"top\" width=\"72\">C++</td>\n<td valign=\"top\" width=\"79\">√</td>\n<td valign=\"top\" width=\"47\"><a name=\"OLE_LINK19\"></a><a name=\"OLE_LINK18\"></a>√</td>\n<td valign=\"top\" width=\"57\">√</td>\n<td valign=\"top\" width=\"47\">√</td>\n<td valign=\"top\" width=\"38\">√</td>\n<td valign=\"top\" width=\"47\">√</td>\n<td valign=\"top\" width=\"47\">&nbsp;</td>\n<td valign=\"top\" width=\"47\">√</td>\n<td valign=\"top\" width=\"57\">√</td>\n<td valign=\"top\" width=\"57\">语</td>\n</tr>\n<tr>\n<td valign=\"top\" width=\"72\">Pascal</td>\n<td valign=\"top\" width=\"79\">×</td>\n<td valign=\"top\" width=\"47\">√</td>\n<td valign=\"top\" width=\"57\">√</td>\n<td valign=\"top\" width=\"47\">√</td>\n<td valign=\"top\" width=\"38\">√</td>\n<td valign=\"top\" width=\"47\">√</td>\n<td valign=\"top\" width=\"47\">&nbsp;</td>\n<td valign=\"top\" width=\"47\">√</td>\n<td valign=\"top\" width=\"57\">√</td>\n<td valign=\"top\" width=\"57\">言</td>\n</tr>\n<tr>\n<td valign=\"top\" width=\"72\">Fortran</td>\n<td valign=\"top\" width=\"79\">×</td>\n<td valign=\"top\" width=\"47\"><a name=\"OLE_LINK9\"></a><a name=\"OLE_LINK8\"></a>√</td>\n<td valign=\"top\" width=\"57\">×</td>\n<td valign=\"top\" width=\"47\"><a name=\"OLE_LINK21\"></a><a name=\"OLE_LINK20\"></a>√</td>\n<td valign=\"top\" width=\"38\">√</td>\n<td valign=\"top\" width=\"47\">×</td>\n<td valign=\"top\" width=\"47\">&nbsp;</td>\n<td valign=\"top\" width=\"47\">×</td>\n<td valign=\"top\" width=\"57\"><a name=\"OLE_LINK7\"></a><a name=\"OLE_LINK6\"></a>×</td>\n<td valign=\"top\" width=\"57\">，</td>\n</tr>\n<tr>\n<td valign=\"top\" width=\"72\">Obj-C</td>\n<td valign=\"top\" width=\"79\">×</td>\n<td valign=\"top\" width=\"47\">×</td>\n<td valign=\"top\" width=\"57\">×</td>\n<td valign=\"top\" width=\"47\">×</td>\n<td valign=\"top\" width=\"38\">×</td>\n<td valign=\"top\" width=\"47\">×</td>\n<td valign=\"top\" width=\"47\">&nbsp;</td>\n<td valign=\"top\" width=\"47\">×</td>\n<td valign=\"top\" width=\"57\">×</td>\n<td valign=\"top\" width=\"57\">只</td>\n</tr>\n<tr>\n<td valign=\"top\" width=\"72\">C#</td>\n<td valign=\"top\" width=\"79\">√</td>\n<td valign=\"top\" width=\"47\">√</td>\n<td valign=\"top\" width=\"57\">√</td>\n<td valign=\"top\" width=\"47\">√</td>\n<td valign=\"top\" width=\"38\">×</td>\n<td valign=\"top\" width=\"47\">×</td>\n<td valign=\"top\" width=\"47\">&nbsp;</td>\n<td valign=\"top\" width=\"47\">√</td>\n<td valign=\"top\" width=\"57\">√</td>\n<td valign=\"top\" width=\"57\">需</td>\n</tr>\n<tr>\n<td valign=\"top\" width=\"72\">Python 2</td>\n<td valign=\"top\" width=\"79\">×</td>\n<td valign=\"top\" width=\"47\">√</td>\n<td valign=\"top\" width=\"57\">√</td>\n<td valign=\"top\" width=\"47\">√</td>\n<td valign=\"top\" width=\"38\">×</td>\n<td valign=\"top\" width=\"47\">√</td>\n<td valign=\"top\" width=\"47\">&nbsp;</td>\n<td valign=\"top\" width=\"47\">×</td>\n<td valign=\"top\" width=\"57\">√</td>\n<td valign=\"top\" width=\"57\">提</td>\n</tr>\n<tr>\n<td valign=\"top\" width=\"72\">Python 3</td>\n<td valign=\"top\" width=\"79\">×</td>\n<td valign=\"top\" width=\"47\">√</td>\n<td valign=\"top\" width=\"57\">×</td>\n<td valign=\"top\" width=\"47\">√</td>\n<td valign=\"top\" width=\"38\">×</td>\n<td valign=\"top\" width=\"47\">×</td>\n<td valign=\"top\" width=\"47\">&nbsp;</td>\n<td valign=\"top\" width=\"47\">×</td>\n<td valign=\"top\" width=\"57\">√</td>\n<td valign=\"top\" width=\"57\">交</td>\n</tr>\n<tr>\n<td valign=\"top\" width=\"72\">Ruby</td>\n<td valign=\"top\" width=\"79\">×</td>\n<td valign=\"top\" width=\"47\">√</td>\n<td valign=\"top\" width=\"57\">√</td>\n<td valign=\"top\" width=\"47\">√</td>\n<td valign=\"top\" width=\"38\">×</td>\n<td valign=\"top\" width=\"47\">×</td>\n<td valign=\"top\" width=\"47\">&nbsp;</td>\n<td valign=\"top\" width=\"47\">×</td>\n<td valign=\"top\" width=\"57\">√</td>\n<td valign=\"top\" width=\"57\">答</td>\n</tr>\n<tr>\n<td valign=\"top\" width=\"72\">JavaScript</td>\n<td valign=\"top\" width=\"79\">×</td>\n<td valign=\"top\" width=\"47\">√</td>\n<td valign=\"top\" width=\"57\">×</td>\n<td valign=\"top\" width=\"47\">√</td>\n<td valign=\"top\" width=\"38\">×</td>\n<td valign=\"top\" width=\"47\">×</td>\n<td valign=\"top\" width=\"47\">&nbsp;</td>\n<td valign=\"top\" width=\"47\">×</td>\n<td valign=\"top\" width=\"57\">√</td>\n<td valign=\"top\" width=\"57\">案</td>\n</tr>\n<tr>\n<td valign=\"top\" width=\"72\">PHP</td>\n<td valign=\"top\" width=\"79\">×</td>\n<td valign=\"top\" width=\"47\"><a name=\"OLE_LINK11\"></a><a name=\"OLE_LINK10\"></a>√</td>\n<td valign=\"top\" width=\"57\">√</td>\n<td valign=\"top\" width=\"47\">√</td>\n<td valign=\"top\" width=\"38\">×</td>\n<td valign=\"top\" width=\"47\">√</td>\n<td valign=\"top\" width=\"47\">&nbsp;</td>\n<td valign=\"top\" width=\"47\">×</td>\n<td valign=\"top\" width=\"57\">√</td>\n<td valign=\"top\" width=\"57\">&nbsp;</td>\n</tr>\n<tr>\n<td valign=\"top\" width=\"72\">VB</td>\n<td valign=\"top\" width=\"79\">√</td>\n<td valign=\"top\" width=\"47\"><a name=\"OLE_LINK28\"></a><a name=\"OLE_LINK12\"></a>×</td>\n<td valign=\"top\" width=\"57\">×</td>\n<td valign=\"top\" width=\"47\">×</td>\n<td valign=\"top\" width=\"38\">×</td>\n<td valign=\"top\" width=\"47\">×</td>\n<td valign=\"top\" width=\"47\">&nbsp;</td>\n<td valign=\"top\" width=\"47\">×</td>\n<td valign=\"top\" width=\"57\">×</td>\n<td valign=\"top\" width=\"57\">&nbsp;</td>\n</tr>\n<tr>\n<td valign=\"top\" width=\"72\">Perl</td>\n<td valign=\"top\" width=\"79\">×</td>\n<td valign=\"top\" width=\"47\">√</td>\n<td valign=\"top\" width=\"57\">√</td>\n<td valign=\"top\" width=\"47\"><a name=\"OLE_LINK22\"></a>√</td>\n<td valign=\"top\" width=\"38\">×</td>\n<td valign=\"top\" width=\"47\">√</td>\n<td valign=\"top\" width=\"47\">&nbsp;</td>\n<td valign=\"top\" width=\"47\">×</td>\n<td valign=\"top\" width=\"57\">√</td>\n<td valign=\"top\" width=\"57\">&nbsp;</td>\n</tr>\n<tr>\n<td valign=\"top\" width=\"72\">Go</td>\n<td valign=\"top\" width=\"79\">×</td>\n<td valign=\"top\" width=\"47\">√</td>\n<td valign=\"top\" width=\"57\">×</td>\n<td valign=\"top\" width=\"47\">√</td>\n<td valign=\"top\" width=\"38\">×</td>\n<td valign=\"top\" width=\"47\">×</td>\n<td valign=\"top\" width=\"47\">&nbsp;</td>\n<td valign=\"top\" width=\"47\">×</td>\n<td valign=\"top\" width=\"57\">√</td>\n<td valign=\"top\" width=\"57\">&nbsp;</td>\n</tr>\n<tr>\n<td valign=\"top\" width=\"72\">Scala</td>\n<td valign=\"top\" width=\"79\">×</td>\n<td valign=\"top\" width=\"47\">√</td>\n<td valign=\"top\" width=\"57\">√</td>\n<td valign=\"top\" width=\"47\">√</td>\n<td valign=\"top\" width=\"38\">×</td>\n<td valign=\"top\" width=\"47\">×</td>\n<td valign=\"top\" width=\"47\">&nbsp;</td>\n<td valign=\"top\" width=\"47\">×</td>\n<td valign=\"top\" width=\"57\">√</td>\n<td valign=\"top\" width=\"57\">&nbsp;</td>\n</tr>\n<tr>\n<td valign=\"top\" width=\"72\">Groovy</td>\n<td valign=\"top\" width=\"79\">×</td>\n<td valign=\"top\" width=\"47\">×</td>\n<td valign=\"top\" width=\"57\">×</td>\n<td valign=\"top\" width=\"47\">×</td>\n<td valign=\"top\" width=\"38\">×</td>\n<td valign=\"top\" width=\"47\">×</td>\n<td valign=\"top\" width=\"47\">&nbsp;</td>\n<td valign=\"top\" width=\"47\">×</td>\n<td valign=\"top\" width=\"57\">√</td>\n<td valign=\"top\" width=\"57\">&nbsp;</td>\n</tr>\n<tr>\n<td valign=\"top\" width=\"72\">Erlang</td>\n<td valign=\"top\" width=\"79\">×</td>\n<td valign=\"top\" width=\"47\">√</td>\n<td valign=\"top\" width=\"57\"><a name=\"OLE_LINK15\"></a>×</td>\n<td valign=\"top\" width=\"47\">√</td>\n<td valign=\"top\" width=\"38\">×</td>\n<td valign=\"top\" width=\"47\">×</td>\n<td valign=\"top\" width=\"47\">&nbsp;</td>\n<td valign=\"top\" width=\"47\">×</td>\n<td valign=\"top\" width=\"57\">√</td>\n<td valign=\"top\" width=\"57\">&nbsp;</td>\n</tr>\n<tr>\n<td valign=\"top\" width=\"72\">Lua</td>\n<td valign=\"top\" width=\"79\">×</td>\n<td valign=\"top\" width=\"47\">√</td>\n<td valign=\"top\" width=\"57\">×</td>\n<td valign=\"top\" width=\"47\">√</td>\n<td valign=\"top\" width=\"38\">×</td>\n<td valign=\"top\" width=\"47\">×</td>\n<td valign=\"top\" width=\"47\">&nbsp;</td>\n<td valign=\"top\" width=\"47\">×</td>\n<td valign=\"top\" width=\"57\">√</td>\n<td valign=\"top\" width=\"57\">&nbsp;</td>\n</tr>\n<tr>\n<td valign=\"top\" width=\"72\">D</td>\n<td valign=\"top\" width=\"79\">×</td>\n<td valign=\"top\" width=\"47\">√</td>\n<td valign=\"top\" width=\"57\">√</td>\n<td valign=\"top\" width=\"47\">√</td>\n<td valign=\"top\" width=\"38\">×</td>\n<td valign=\"top\" width=\"47\">×</td>\n<td valign=\"top\" width=\"47\">&nbsp;</td>\n<td valign=\"top\" width=\"47\">×</td>\n<td valign=\"top\" width=\"57\">√</td>\n<td valign=\"top\" width=\"57\">&nbsp;</td>\n</tr>\n<tr>\n<td valign=\"top\" width=\"72\">Fortran</td>\n<td valign=\"top\" width=\"79\">×</td>\n<td valign=\"top\" width=\"47\">√</td>\n<td valign=\"top\" width=\"57\">×</td>\n<td valign=\"top\" width=\"47\">√</td>\n<td valign=\"top\" width=\"38\">×</td>\n<td valign=\"top\" width=\"47\">×</td>\n<td valign=\"top\" width=\"47\">&nbsp;</td>\n<td valign=\"top\" width=\"47\">×</td>\n<td valign=\"top\" width=\"57\"><a name=\"OLE_LINK4\"></a>×</td>\n<td valign=\"top\" width=\"57\">&nbsp;</td>\n</tr>\n<tr>\n<td valign=\"top\" width=\"72\">CommonLisp</td>\n<td valign=\"top\" width=\"79\">×</td>\n<td valign=\"top\" width=\"47\">√</td>\n<td valign=\"top\" width=\"57\">×</td>\n<td valign=\"top\" width=\"47\">√</td>\n<td valign=\"top\" width=\"38\">×</td>\n<td valign=\"top\" width=\"47\"><a name=\"OLE_LINK26\"></a><a name=\"OLE_LINK25\"></a>×</td>\n<td valign=\"top\" width=\"47\">&nbsp;</td>\n<td valign=\"top\" width=\"47\">×</td>\n<td valign=\"top\" width=\"57\">√</td>\n<td valign=\"top\" width=\"57\">&nbsp;</td>\n</tr>\n<tr>\n<td valign=\"top\" width=\"72\">Clojure</td>\n<td valign=\"top\" width=\"79\">×</td>\n<td valign=\"top\" width=\"47\"><a name=\"OLE_LINK14\"></a><a name=\"OLE_LINK13\"></a>√</td>\n<td valign=\"top\" width=\"57\">×</td>\n<td valign=\"top\" width=\"47\">√</td>\n<td valign=\"top\" width=\"38\">×</td>\n<td valign=\"top\" width=\"47\">×</td>\n<td valign=\"top\" width=\"47\">&nbsp;</td>\n<td valign=\"top\" width=\"47\">×</td>\n<td valign=\"top\" width=\"57\">√</td>\n<td valign=\"top\" width=\"57\">&nbsp;</td>\n</tr>\n<tr>\n<td valign=\"top\" width=\"72\">Scheme</td>\n<td valign=\"top\" width=\"79\">×</td>\n<td valign=\"top\" width=\"47\">√</td>\n<td valign=\"top\" width=\"57\">×</td>\n<td valign=\"top\" width=\"47\">√</td>\n<td valign=\"top\" width=\"38\">×</td>\n<td valign=\"top\" width=\"47\">√</td>\n<td valign=\"top\" width=\"47\">&nbsp;</td>\n<td valign=\"top\" width=\"47\">×</td>\n<td valign=\"top\" width=\"57\">×</td>\n<td valign=\"top\" width=\"57\">&nbsp;</td>\n</tr>\n<tr>\n<td valign=\"top\" width=\"72\">Haskell</td>\n<td valign=\"top\" width=\"79\">×</td>\n<td valign=\"top\" width=\"47\">√</td>\n<td valign=\"top\" width=\"57\">√</td>\n<td valign=\"top\" width=\"47\">√</td>\n<td valign=\"top\" width=\"38\"><a name=\"OLE_LINK24\"></a><a name=\"OLE_LINK23\"></a>×</td>\n<td valign=\"top\" width=\"47\">×</td>\n<td valign=\"top\" width=\"47\">&nbsp;</td>\n<td valign=\"top\" width=\"47\">×</td>\n<td valign=\"top\" width=\"57\">√</td>\n<td valign=\"top\" width=\"57\">&nbsp;</td>\n</tr>\n<tr>\n<td valign=\"top\" width=\"72\">OCaml</td>\n<td valign=\"top\" width=\"79\">×</td>\n<td valign=\"top\" width=\"47\">√</td>\n<td valign=\"top\" width=\"57\">√</td>\n<td valign=\"top\" width=\"47\">√</td>\n<td valign=\"top\" width=\"38\">×</td>\n<td valign=\"top\" width=\"47\">×</td>\n<td valign=\"top\" width=\"47\">&nbsp;</td>\n<td valign=\"top\" width=\"47\">×</td>\n<td valign=\"top\" width=\"57\">√</td>\n<td valign=\"top\" width=\"57\">&nbsp;</td>\n</tr>\n<tr>\n<td valign=\"top\" width=\"72\">其他</td>\n<td valign=\"top\" width=\"79\">×</td>\n<td valign=\"top\" width=\"47\"><a name=\"OLE_LINK17\"></a><a name=\"OLE_LINK16\"></a>√</td>\n<td valign=\"top\" width=\"57\">×</td>\n<td valign=\"top\" width=\"47\">√</td>\n<td valign=\"top\" width=\"38\">×</td>\n<td valign=\"top\" width=\"47\">×</td>\n<td valign=\"top\" width=\"47\">&nbsp;</td>\n<td valign=\"top\" width=\"47\">×</td>\n<td valign=\"top\" width=\"57\">×</td>\n<td valign=\"top\" width=\"57\">&nbsp;</td>\n</tr>\n</tbody>\n</table>\n\n##大牛在哪里玩\n[CodeChef的Long Consest 排名榜](http://www.codechef.com/long/ranklist/AX/?page=0)  \n[CodeForces的排名榜](http://codeforces.com/ratings)\n\n看看一些神牛在哪些编程网站上玩。\n\n<table cellspacing=\"0\" cellpadding=\"0\" border=\"1\">\n<tbody>\n<tr>\n<td valign=\"top\" width=\"98\">\n<p><strong>大牛名字</strong></p>\n</td>\n<td valign=\"top\" width=\"393\">\n<p><strong>在哪些网站活动</strong></p>\n</td>\n<td valign=\"top\" width=\"100\">\n<p><strong>结论</strong></p>\n</td>\n</tr>\n<tr>\n<td valign=\"top\" width=\"98\">\n<p>清华 楼天城 ACRush</p>\n<p>现在Google工作</p>\n</td>\n<td valign=\"top\" width=\"393\">\n<p><a href=\"http://community.topcoder.com/tc?module=MemberProfile&amp;cr=19849563\" onclick=\"javascript:_gaq.push(['_trackEvent','outbound-article','http://community.topcoder.com']);\">http://community.topcoder.com/tc?module=MemberProfile&amp;cr=19849563</a> 最后活动日期14/03/13</p>\n<p><a href=\"http://www.codechef.com/users/ACRush21\" onclick=\"javascript:_gaq.push(['_trackEvent','outbound-article','http://www.codechef.com']);\">http://www.codechef.com/users/ACRush21</a> long contest排名第一</p>\n<p><a href=\"http://codeforces.com/profile/ACRush\" onclick=\"javascript:_gaq.push(['_trackEvent','outbound-article','http://codeforces.com']);\">http://codeforces.com/profile/ACRush</a> 排名18 </p>\n</td>\n<td valign=\"top\" width=\"100\">\n<p>楼教主在TopCoder, CodeChef, CodeForces玩</p>\n</td>\n</tr>\n<tr>\n<td valign=\"top\" width=\"98\">\n<p>俄罗斯 petr</p>\n<p>现在Google工作</p>\n</td>\n<td valign=\"top\" width=\"393\">\n<p><a href=\"http://community.topcoder.com/tc?module=MemberProfile&amp;tab=alg&amp;cr=10574855\" onclick=\"javascript:_gaq.push(['_trackEvent','outbound-article','http://community.topcoder.com']);\">http://community.topcoder.com/tc?module=MemberProfile&amp;tab=alg&amp;cr=10574855</a></p>\n<p><a href=\"http://www.codechef.com/users/petr\" onclick=\"javascript:_gaq.push(['_trackEvent','outbound-article','http://www.codechef.com']);\">http://www.codechef.com/users/petr</a> N/A</p>\n<p><a href=\"http://codeforces.com/profile/Petr\" onclick=\"javascript:_gaq.push(['_trackEvent','outbound-article','http://codeforces.com']);\">http://codeforces.com/profile/Petr</a> 排名第三</p>\n</td>\n<td valign=\"top\" width=\"100\">\n<p>Petr主要在TopCoder, CodeForces玩</p>\n</td>\n</tr>\n<tr>\n<td valign=\"top\" width=\"98\">\n<p>波兰 tomek</p>\n<p>现在Google工作</p>\n</td>\n<td valign=\"top\" width=\"393\">\n<p><a href=\"http://community.topcoder.com/tc?module=MemberProfile&amp;cr=144400\" onclick=\"javascript:_gaq.push(['_trackEvent','outbound-article','http://community.topcoder.com']);\">http://community.topcoder.com/tc?module=MemberProfile&amp;cr=144400</a></p>\n<p><a href=\"http://www.codechef.com/users/tomek\" onclick=\"javascript:_gaq.push(['_trackEvent','outbound-article','http://www.codechef.com']);\">http://www.codechef.com/users/tomek</a> long contest排名第六</p>\n<p><a href=\"http://codeforces.com/profile/tomek\" onclick=\"javascript:_gaq.push(['_trackEvent','outbound-article','http://codeforces.com']);\">http://codeforces.com/profile/tomek</a> N/A</p>\n</td>\n<td valign=\"top\" width=\"100\">\n<p>Tomek主要在TopCoder, codechef玩</p>\n</td>\n</tr>\n<tr>\n<td valign=\"top\" width=\"98\">\n<p>俄罗斯 Egor</p>\n</td>\n<td valign=\"top\" width=\"393\">\n<p><a href=\"http://community.topcoder.com/tc?module=MemberProfile&amp;cr=14970299\" onclick=\"javascript:_gaq.push(['_trackEvent','outbound-article','http://community.topcoder.com']);\">http://community.topcoder.com/tc?module=MemberProfile&amp;cr=14970299</a></p>\n<p><a href=\"http://www.codechef.com/users/Egor\" onclick=\"javascript:_gaq.push(['_trackEvent','outbound-article','http://www.codechef.com']);\">http://www.codechef.com/users/Egor</a> N/A</p>\n<p><a href=\"http://codeforces.com/profile/Egor\" onclick=\"javascript:_gaq.push(['_trackEvent','outbound-article','http://codeforces.com']);\">http://codeforces.com/profile/Egor</a> 排名第七</p>\n</td>\n<td valign=\"top\" width=\"100\">\n<p>Egor主要在TopCoder, CodeForces玩</p>\n</td>\n</tr>\n<tr>\n<td valign=\"top\" width=\"98\">\n<p>俄罗斯 Tourist</p>\n<p>高三学生</p>\n</td>\n<td valign=\"top\" width=\"393\">\n<p><a href=\"http://www.codechef.com/teams/view/tourist\" onclick=\"javascript:_gaq.push(['_trackEvent','outbound-article','http://www.codechef.com']);\">http://www.codechef.com/teams/view/tourist</a> N/A</p>\n<p><a href=\"http://www.codeforces.com/profile/tourist\" onclick=\"javascript:_gaq.push(['_trackEvent','outbound-article','http://www.codeforces.com']);\">http://www.codeforces.com/profile/tourist</a> 排名第一</p>\n</td>\n<td valign=\"top\" width=\"100\">\n<p>少年天才，主要在CodeForces玩</p>\n</td>\n</tr>\n</tbody>\n</table>\n\n由于CodeForcess是俄罗斯的网站，所以俄罗斯选手几乎全部在CodeForces上玩，例如Petr, Egor, Tourist都是俄罗斯人，都在CodeForces上。\n也可以发现，神牛大部分来自俄罗斯，大家或许也会联想到，俄罗斯出数学家和计算机黑客，的确如此。像楼教主，Petr属于老牌的霸主，近两年出现一个天才少年tourist，才高三，竟然在CodeForces上力压Petr，真是逆天的存在。Quora上有个问题How does it feel to beat Petr Mitrichev, Egor, ACRush in SRM? 最佳答案 It feels a lot like being Tourist. 既幽默又霸气。\n\n##大牛们使用什么语言？\n来看一下高手提交的代码列表：  \n[http://codeforces.com/submissions/ACRush](http://codeforces.com/submissions/ACRush)  \n[http://codeforces.com/submissions/Petr](http://codeforces.com/submissions/Petr)  \n[http://codeforces.com/submissions/Egor](http://codeforces.com/submissions/Egor)  \n[http://www.codeforces.com/submissions/tourist](http://www.codeforces.com/submissions/tourist)\n\n可以看出ACRush和Tourist使用C++，Petr和Egor使用Java。从我的亲身经验，周围参加ACM的同学大部分用C++。不过，注意一点，大部分人认为Java慢，这在五六年前是对的，但是到了在现在，JVM经过各大IT巨头的重金打造，性能已经跟C++一样持平了，至少不再有数量级上的差距。因此Java也是一个很好地选择。\n\n\n##更新历史\n2013-04-06，从 [加州求职记](http://blog.liancheng.info/job-hunting-in-california/) 得知了两个专门针对面试的新兴网站，[CareerCup](http://www.careercup.com/) 和 [LeetCode](http://leetcode.com/onlinejudge)，跟 InterviewStreet 很类似。\n","slug":"2013-03-22-some-popular-programming-contest-websites","published":1,"updated":"2016-08-18T09:21:04.000Z","photos":[],"link":"","_id":"cis07pf2j000l01pqc0ll7fra","content":"<p>今天把各个主流的编程网站仔细对比了一下，下面从各个角度对比一下这些编程竞赛网站。</p>\n<p>##分类和排名</p>\n<table border=\"1\" cellspacing=\"0\" cellpadding=\"0\"><br><tbody><br><tr><br><td valign=\"top\" width=\"94\"><br><p><a name=\"OLE_LINK30\"></a><a name=\"OLE_LINK1\"><b>网站地址</b></a></p><br></td><br><td valign=\"top\" width=\"57\"><br><p><b>类别</b></p><br></td><br><td valign=\"top\" width=\"38\"><br><p><b>PR</b></p><br></td><br><td valign=\"top\" width=\"60\"><br><p><b>ATR</b></p><br></td><br><td valign=\"top\" width=\"44\"><br><p><b>QF</b></p><br></td><br><td valign=\"top\" width=\"151\"><br><p><b>主办方</b></p><br></td><br><td valign=\"top\" width=\"47\"><br><p><b>备注</b></p><br></td><br></tr><br><tr><br><td valign=\"top\" width=\"94\"><br><p><a name=\"_Hlk352791085\"></a><a href=\"http://www.topcoder.com/\" onclick=\"javascript:_gaq.push(['_trackEvent','outbound-article','http://www.topcoder.com']);\" target=\"_blank\" rel=\"external\">TopCoder </a></p><br></td><br><td valign=\"top\" width=\"57\"><br><p>综合</p><br></td><br><td valign=\"top\" width=\"38\"><br><p>6</p><br></td><br><td valign=\"top\" width=\"60\"><br><p>33,586</p><br></td><br><td valign=\"top\" width=\"44\"><br><p>4167</p><br></td><br><td valign=\"top\" width=\"151\"><br><p>TopCoder公司</p><br></td><br><td valign=\"top\" width=\"47\">&nbsp;</td><br></tr><br><tr><br><td valign=\"top\" width=\"94\"><br><p><a href=\"http://www.codechef.com/\" onclick=\"javascript:_gaq.push(['_trackEvent','outbound-article','http://www.codechef.com']);\" target=\"_blank\" rel=\"external\">CodeChef </a></p><br></td><br><td valign=\"top\" width=\"57\"><br><p>综合</p><br></td><br><td valign=\"top\" width=\"38\"><br><p>6</p><br></td><br><td valign=\"top\" width=\"60\"><br><p>41,217</p><br></td><br><td valign=\"top\" width=\"44\"><br><p>5758</p><br></td><br><td valign=\"top\" width=\"151\"><br><p>Directi公司</p><br></td><br><td valign=\"top\" width=\"47\">&nbsp;</td><br></tr><br><tr><br><td valign=\"top\" width=\"94\"><br><p><a href=\"http://codeforces.com/\" onclick=\"javascript:_gaq.push(['_trackEvent','outbound-article','http://codeforces.com']);\" target=\"_blank\" rel=\"external\">CodeForces </a></p><br></td><br><td valign=\"top\" width=\"57\"><br><p>综合</p><br></td><br><td valign=\"top\" width=\"38\"><br><p>5</p><br></td><br><td valign=\"top\" width=\"60\"><br><p>73,012</p><br></td><br><td valign=\"top\" width=\"44\"><br><p>599</p><br></td><br><td valign=\"top\" width=\"151\"><br><p>CodeForces公司</p><br></td><br><td valign=\"top\" width=\"47\">&nbsp;</td><br></tr><br><tr><br><td valign=\"top\" width=\"94\"><br><p><a href=\"http://www.spoj.com/\" onclick=\"javascript:_gaq.push(['_trackEvent','outbound-article','http://www.spoj.com']);\" target=\"_blank\" rel=\"external\">SPOJ</a></p><br></td><br><td valign=\"top\" width=\"57\"><br><p>ACM</p><br></td><br><td valign=\"top\" width=\"38\"><br><p>3</p><br></td><br><td valign=\"top\" width=\"60\"><br><p>75,653</p><br></td><br><td valign=\"top\" width=\"44\"><br><p>1520</p><br></td><br><td valign=\"top\" width=\"151\"><br><p>Sphere Research Labs</p><br></td><br><td valign=\"top\" width=\"47\">&nbsp;</td><br></tr><br><tr><br><td valign=\"top\" width=\"94\"><br><p><a href=\"http://poj.org/\" onclick=\"javascript:_gaq.push(['_trackEvent','outbound-article','http://poj.org']);\" target=\"_blank\" rel=\"external\">POJ</a></p><br></td><br><td valign=\"top\" width=\"57\"><br><p>ACM</p><br></td><br><td valign=\"top\" width=\"38\"><br><p>7</p><br></td><br><td valign=\"top\" width=\"60\"><br><p>364,925</p><br></td><br><td valign=\"top\" width=\"44\"><br><p>N/A</p><br></td><br><td valign=\"top\" width=\"151\"><br><p>北京大学</p><br></td><br><td valign=\"top\" width=\"47\">&nbsp;</td><br></tr><br><tr><br><td valign=\"top\" width=\"94\"><br><p><a href=\"http://acm.zju.edu.cn\" onclick=\"javascript:_gaq.push(['_trackEvent','outbound-article','http://acm.zju.edu.cn']);\" target=\"_blank\" rel=\"external\">ZOJ</a></p><br></td><br><td valign=\"top\" width=\"57\"><br><p>ACM</p><br></td><br><td valign=\"top\" width=\"38\"><br><p>6</p><br></td><br><td valign=\"top\" width=\"60\"><br><p>N/A</p><br></td><br><td valign=\"top\" width=\"44\"><br><p>N/A</p><br></td><br><td valign=\"top\" width=\"151\"><br><p>浙江大学</p><br></td><br><td valign=\"top\" width=\"47\">&nbsp;</td><br></tr><br><tr><br><td valign=\"top\" width=\"94\"><br><p><a href=\"http://uva.onlinejudge.org/\" onclick=\"javascript:_gaq.push(['_trackEvent','outbound-article','http://uva.onlinejudge.org']);\" target=\"_blank\" rel=\"external\">UVA OJ</a></p><br></td><br><td valign=\"top\" width=\"57\"><br><p>ACM</p><br></td><br><td valign=\"top\" width=\"38\"><br><p>6</p><br></td><br><td valign=\"top\" width=\"60\"><br><p>166,991</p><br></td><br><td valign=\"top\" width=\"44\"><br><p>N/A</p><br></td><br><td valign=\"top\" width=\"151\"><br><p>University of Virginia</p><br></td><br><td valign=\"top\" width=\"47\">&nbsp;</td><br></tr><br><tr><br><td valign=\"top\" width=\"94\"><br><p><a href=\"http://acm.sgu.ru/\" onclick=\"javascript:_gaq.push(['_trackEvent','outbound-article','http://acm.sgu.ru']);\" target=\"_blank\" rel=\"external\">SGU OJ</a></p><br></td><br><td valign=\"top\" width=\"57\"><br><p>ACM</p><br></td><br><td valign=\"top\" width=\"38\"><br><p>5</p><br></td><br><td valign=\"top\" width=\"60\"><br><p>194,881</p><br></td><br><td valign=\"top\" width=\"44\"><br><p>N/A</p><br></td><br><td valign=\"top\" width=\"151\"><br><p>Saratov State University</p><br></td><br><td valign=\"top\" width=\"47\">&nbsp;</td><br></tr><br><tr><br><td valign=\"top\" width=\"94\"><br><p><a href=\"https://www.hackerrank.com/\" onclick=\"javascript:_gaq.push(['_trackEvent','outbound-article','http://www.hackerrank.com']);\" target=\"_blank\" rel=\"external\">HackerRank</a></p><br></td><br><td valign=\"top\" width=\"57\"><br><p>综合</p><br></td><br><td valign=\"top\" width=\"38\"><br><p>5</p><br></td><br><td valign=\"top\" width=\"60\"><br><p>126,192</p><br></td><br><td valign=\"top\" width=\"44\"><br><p>56</p><br></td><br><td valign=\"top\" width=\"151\"><br><p>InterviewStreet公司</p><br></td><br><td valign=\"top\" width=\"47\">&nbsp;</td><br></tr><br><tr><br><td valign=\"top\" width=\"94\"><br><p><a href=\"http://projecteuler.net/\" onclick=\"javascript:_gaq.push(['_trackEvent','outbound-article','http://projecteuler.net']);\" target=\"_blank\" rel=\"external\">Project Euler</a></p><br></td><br><td valign=\"top\" width=\"57\"><br><p>数学</p><br></td><br><td valign=\"top\" width=\"38\"><br><p>6</p><br></td><br><td valign=\"top\" width=\"60\"><br><p>53,854</p><br></td><br><td valign=\"top\" width=\"44\"><br><p>428</p><br></td><br><td valign=\"top\" width=\"151\"><br><p>Project Euler公司</p><br></td><br><td valign=\"top\" width=\"47\">&nbsp;</td><br></tr><br><tr><br><td valign=\"top\" width=\"94\"><br><p><a href=\"http://www.careercup.com/\" onclick=\"javascript:_gaq.push(['_trackEvent','outbound-article','http://www.careercup.com']);\" target=\"_blank\" rel=\"external\">CareerUp</a></p><br></td><br><td valign=\"top\" width=\"57\"><br><p>面试</p><br></td><br><td valign=\"top\" width=\"38\"><br><p>4</p><br></td><br><td valign=\"top\" width=\"60\"><br><p>51,089</p><br></td><br><td valign=\"top\" width=\"44\"><br><p>654</p><br></td><br><td valign=\"top\" width=\"151\"><br><p>CareerUp公司</p><br></td><br><td valign=\"top\" width=\"47\">&nbsp;</td><br></tr><br><tr><br><td valign=\"top\" width=\"94\"><br><p><a href=\"http://leetcode.com/\" onclick=\"javascript:_gaq.push(['_trackEvent','outbound-article','http://leetcode.com']);\" target=\"_blank\" rel=\"external\">LeetCode</a></p><br></td><br><td valign=\"top\" width=\"57\"><br><p>面试</p><br></td><br><td valign=\"top\" width=\"38\"><br><p>4</p><br></td><br><td valign=\"top\" width=\"60\"><br><p>188,196</p><br></td><br><td valign=\"top\" width=\"44\"><br><p>N/A</p><br></td><br><td valign=\"top\" width=\"151\"><br><p>LeetCode公司</p><br></td><br><td valign=\"top\" width=\"47\">&nbsp;</td><br></tr><br></tbody><br></table>\n\n<p>说明：PR是Google PageRank的缩写；ATR是Alexa Trafic Rank的缩写，即Alexa排名；QF是Quora Followers的缩写，具体含义是在Quora上关于某Topic的follower数量，例如<a href=\"http://www.quora.com/CodeChef\" target=\"_blank\" rel=\"external\">CodeChef的topic</a> 有5758个followers。</p>\n<a id=\"more\"></a>\n<p>##支持的语言</p>\n<table cellspacing=\"0\" cellpadding=\"0\" border=\"1\"><br><tbody><br><tr><br><td valign=\"top\" width=\"72\"><strong>网站</strong><br><p><strong>语言</strong></p><br></td><br><td valign=\"top\" width=\"79\"><strong>TopCoder</strong></td><br><td valign=\"top\" width=\"47\"><strong>CodeChef</strong></td><br><td valign=\"top\" width=\"57\"><strong>CodeForces</strong></td><br><td valign=\"top\" width=\"47\"><strong>SPOJ</strong></td><br><td valign=\"top\" width=\"38\"><strong>POJ</strong></td><br><td valign=\"top\" width=\"47\"><strong>ZOJ</strong></td><br><td valign=\"top\" width=\"47\"><strong>UVA OJ</strong></td><br><td valign=\"top\" width=\"47\"><strong>SGU OJ</strong></td><br><td valign=\"top\" width=\"57\"><strong>HackerRank</strong></td><br><td valign=\"top\" width=\"57\"><strong>Project Euler</strong></td><br></tr><br><tr><br><td valign=\"top\" width=\"72\">Java</td><br><td valign=\"top\" width=\"79\"><a name=\"OLE_LINK5\"></a><a name=\"OLE_LINK3\"></a>√</td><br><td valign=\"top\" width=\"47\">√<strong></strong></td><br><td valign=\"top\" width=\"57\">√</td><br><td valign=\"top\" width=\"47\">√</td><br><td valign=\"top\" width=\"38\">√</td><br><td valign=\"top\" width=\"47\">√</td><br><td valign=\"top\" width=\"47\">&nbsp;</td><br><td valign=\"top\" width=\"47\">√</td><br><td valign=\"top\" width=\"57\">√</td><br><td valign=\"top\" width=\"57\">不</td><br></tr><br><tr><br><td valign=\"top\" width=\"72\">C</td><br><td valign=\"top\" width=\"79\">√</td><br><td valign=\"top\" width=\"47\">√</td><br><td valign=\"top\" width=\"57\">√</td><br><td valign=\"top\" width=\"47\">√</td><br><td valign=\"top\" width=\"38\">√</td><br><td valign=\"top\" width=\"47\">√</td><br><td valign=\"top\" width=\"47\">&nbsp;</td><br><td valign=\"top\" width=\"47\">√</td><br><td valign=\"top\" width=\"57\">√</td><br><td valign=\"top\" width=\"57\">限</td><br></tr><br><tr><br><td valign=\"top\" width=\"72\">C++</td><br><td valign=\"top\" width=\"79\">√</td><br><td valign=\"top\" width=\"47\"><a name=\"OLE_LINK19\"></a><a name=\"OLE_LINK18\"></a>√</td><br><td valign=\"top\" width=\"57\">√</td><br><td valign=\"top\" width=\"47\">√</td><br><td valign=\"top\" width=\"38\">√</td><br><td valign=\"top\" width=\"47\">√</td><br><td valign=\"top\" width=\"47\">&nbsp;</td><br><td valign=\"top\" width=\"47\">√</td><br><td valign=\"top\" width=\"57\">√</td><br><td valign=\"top\" width=\"57\">语</td><br></tr><br><tr><br><td valign=\"top\" width=\"72\">Pascal</td><br><td valign=\"top\" width=\"79\">×</td><br><td valign=\"top\" width=\"47\">√</td><br><td valign=\"top\" width=\"57\">√</td><br><td valign=\"top\" width=\"47\">√</td><br><td valign=\"top\" width=\"38\">√</td><br><td valign=\"top\" width=\"47\">√</td><br><td valign=\"top\" width=\"47\">&nbsp;</td><br><td valign=\"top\" width=\"47\">√</td><br><td valign=\"top\" width=\"57\">√</td><br><td valign=\"top\" width=\"57\">言</td><br></tr><br><tr><br><td valign=\"top\" width=\"72\">Fortran</td><br><td valign=\"top\" width=\"79\">×</td><br><td valign=\"top\" width=\"47\"><a name=\"OLE_LINK9\"></a><a name=\"OLE_LINK8\"></a>√</td><br><td valign=\"top\" width=\"57\">×</td><br><td valign=\"top\" width=\"47\"><a name=\"OLE_LINK21\"></a><a name=\"OLE_LINK20\"></a>√</td><br><td valign=\"top\" width=\"38\">√</td><br><td valign=\"top\" width=\"47\">×</td><br><td valign=\"top\" width=\"47\">&nbsp;</td><br><td valign=\"top\" width=\"47\">×</td><br><td valign=\"top\" width=\"57\"><a name=\"OLE_LINK7\"></a><a name=\"OLE_LINK6\"></a>×</td><br><td valign=\"top\" width=\"57\">，</td><br></tr><br><tr><br><td valign=\"top\" width=\"72\">Obj-C</td><br><td valign=\"top\" width=\"79\">×</td><br><td valign=\"top\" width=\"47\">×</td><br><td valign=\"top\" width=\"57\">×</td><br><td valign=\"top\" width=\"47\">×</td><br><td valign=\"top\" width=\"38\">×</td><br><td valign=\"top\" width=\"47\">×</td><br><td valign=\"top\" width=\"47\">&nbsp;</td><br><td valign=\"top\" width=\"47\">×</td><br><td valign=\"top\" width=\"57\">×</td><br><td valign=\"top\" width=\"57\">只</td><br></tr><br><tr><br><td valign=\"top\" width=\"72\">C#</td><br><td valign=\"top\" width=\"79\">√</td><br><td valign=\"top\" width=\"47\">√</td><br><td valign=\"top\" width=\"57\">√</td><br><td valign=\"top\" width=\"47\">√</td><br><td valign=\"top\" width=\"38\">×</td><br><td valign=\"top\" width=\"47\">×</td><br><td valign=\"top\" width=\"47\">&nbsp;</td><br><td valign=\"top\" width=\"47\">√</td><br><td valign=\"top\" width=\"57\">√</td><br><td valign=\"top\" width=\"57\">需</td><br></tr><br><tr><br><td valign=\"top\" width=\"72\">Python 2</td><br><td valign=\"top\" width=\"79\">×</td><br><td valign=\"top\" width=\"47\">√</td><br><td valign=\"top\" width=\"57\">√</td><br><td valign=\"top\" width=\"47\">√</td><br><td valign=\"top\" width=\"38\">×</td><br><td valign=\"top\" width=\"47\">√</td><br><td valign=\"top\" width=\"47\">&nbsp;</td><br><td valign=\"top\" width=\"47\">×</td><br><td valign=\"top\" width=\"57\">√</td><br><td valign=\"top\" width=\"57\">提</td><br></tr><br><tr><br><td valign=\"top\" width=\"72\">Python 3</td><br><td valign=\"top\" width=\"79\">×</td><br><td valign=\"top\" width=\"47\">√</td><br><td valign=\"top\" width=\"57\">×</td><br><td valign=\"top\" width=\"47\">√</td><br><td valign=\"top\" width=\"38\">×</td><br><td valign=\"top\" width=\"47\">×</td><br><td valign=\"top\" width=\"47\">&nbsp;</td><br><td valign=\"top\" width=\"47\">×</td><br><td valign=\"top\" width=\"57\">√</td><br><td valign=\"top\" width=\"57\">交</td><br></tr><br><tr><br><td valign=\"top\" width=\"72\">Ruby</td><br><td valign=\"top\" width=\"79\">×</td><br><td valign=\"top\" width=\"47\">√</td><br><td valign=\"top\" width=\"57\">√</td><br><td valign=\"top\" width=\"47\">√</td><br><td valign=\"top\" width=\"38\">×</td><br><td valign=\"top\" width=\"47\">×</td><br><td valign=\"top\" width=\"47\">&nbsp;</td><br><td valign=\"top\" width=\"47\">×</td><br><td valign=\"top\" width=\"57\">√</td><br><td valign=\"top\" width=\"57\">答</td><br></tr><br><tr><br><td valign=\"top\" width=\"72\">JavaScript</td><br><td valign=\"top\" width=\"79\">×</td><br><td valign=\"top\" width=\"47\">√</td><br><td valign=\"top\" width=\"57\">×</td><br><td valign=\"top\" width=\"47\">√</td><br><td valign=\"top\" width=\"38\">×</td><br><td valign=\"top\" width=\"47\">×</td><br><td valign=\"top\" width=\"47\">&nbsp;</td><br><td valign=\"top\" width=\"47\">×</td><br><td valign=\"top\" width=\"57\">√</td><br><td valign=\"top\" width=\"57\">案</td><br></tr><br><tr><br><td valign=\"top\" width=\"72\">PHP</td><br><td valign=\"top\" width=\"79\">×</td><br><td valign=\"top\" width=\"47\"><a name=\"OLE_LINK11\"></a><a name=\"OLE_LINK10\"></a>√</td><br><td valign=\"top\" width=\"57\">√</td><br><td valign=\"top\" width=\"47\">√</td><br><td valign=\"top\" width=\"38\">×</td><br><td valign=\"top\" width=\"47\">√</td><br><td valign=\"top\" width=\"47\">&nbsp;</td><br><td valign=\"top\" width=\"47\">×</td><br><td valign=\"top\" width=\"57\">√</td><br><td valign=\"top\" width=\"57\">&nbsp;</td><br></tr><br><tr><br><td valign=\"top\" width=\"72\">VB</td><br><td valign=\"top\" width=\"79\">√</td><br><td valign=\"top\" width=\"47\"><a name=\"OLE_LINK28\"></a><a name=\"OLE_LINK12\"></a>×</td><br><td valign=\"top\" width=\"57\">×</td><br><td valign=\"top\" width=\"47\">×</td><br><td valign=\"top\" width=\"38\">×</td><br><td valign=\"top\" width=\"47\">×</td><br><td valign=\"top\" width=\"47\">&nbsp;</td><br><td valign=\"top\" width=\"47\">×</td><br><td valign=\"top\" width=\"57\">×</td><br><td valign=\"top\" width=\"57\">&nbsp;</td><br></tr><br><tr><br><td valign=\"top\" width=\"72\">Perl</td><br><td valign=\"top\" width=\"79\">×</td><br><td valign=\"top\" width=\"47\">√</td><br><td valign=\"top\" width=\"57\">√</td><br><td valign=\"top\" width=\"47\"><a name=\"OLE_LINK22\"></a>√</td><br><td valign=\"top\" width=\"38\">×</td><br><td valign=\"top\" width=\"47\">√</td><br><td valign=\"top\" width=\"47\">&nbsp;</td><br><td valign=\"top\" width=\"47\">×</td><br><td valign=\"top\" width=\"57\">√</td><br><td valign=\"top\" width=\"57\">&nbsp;</td><br></tr><br><tr><br><td valign=\"top\" width=\"72\">Go</td><br><td valign=\"top\" width=\"79\">×</td><br><td valign=\"top\" width=\"47\">√</td><br><td valign=\"top\" width=\"57\">×</td><br><td valign=\"top\" width=\"47\">√</td><br><td valign=\"top\" width=\"38\">×</td><br><td valign=\"top\" width=\"47\">×</td><br><td valign=\"top\" width=\"47\">&nbsp;</td><br><td valign=\"top\" width=\"47\">×</td><br><td valign=\"top\" width=\"57\">√</td><br><td valign=\"top\" width=\"57\">&nbsp;</td><br></tr><br><tr><br><td valign=\"top\" width=\"72\">Scala</td><br><td valign=\"top\" width=\"79\">×</td><br><td valign=\"top\" width=\"47\">√</td><br><td valign=\"top\" width=\"57\">√</td><br><td valign=\"top\" width=\"47\">√</td><br><td valign=\"top\" width=\"38\">×</td><br><td valign=\"top\" width=\"47\">×</td><br><td valign=\"top\" width=\"47\">&nbsp;</td><br><td valign=\"top\" width=\"47\">×</td><br><td valign=\"top\" width=\"57\">√</td><br><td valign=\"top\" width=\"57\">&nbsp;</td><br></tr><br><tr><br><td valign=\"top\" width=\"72\">Groovy</td><br><td valign=\"top\" width=\"79\">×</td><br><td valign=\"top\" width=\"47\">×</td><br><td valign=\"top\" width=\"57\">×</td><br><td valign=\"top\" width=\"47\">×</td><br><td valign=\"top\" width=\"38\">×</td><br><td valign=\"top\" width=\"47\">×</td><br><td valign=\"top\" width=\"47\">&nbsp;</td><br><td valign=\"top\" width=\"47\">×</td><br><td valign=\"top\" width=\"57\">√</td><br><td valign=\"top\" width=\"57\">&nbsp;</td><br></tr><br><tr><br><td valign=\"top\" width=\"72\">Erlang</td><br><td valign=\"top\" width=\"79\">×</td><br><td valign=\"top\" width=\"47\">√</td><br><td valign=\"top\" width=\"57\"><a name=\"OLE_LINK15\"></a>×</td><br><td valign=\"top\" width=\"47\">√</td><br><td valign=\"top\" width=\"38\">×</td><br><td valign=\"top\" width=\"47\">×</td><br><td valign=\"top\" width=\"47\">&nbsp;</td><br><td valign=\"top\" width=\"47\">×</td><br><td valign=\"top\" width=\"57\">√</td><br><td valign=\"top\" width=\"57\">&nbsp;</td><br></tr><br><tr><br><td valign=\"top\" width=\"72\">Lua</td><br><td valign=\"top\" width=\"79\">×</td><br><td valign=\"top\" width=\"47\">√</td><br><td valign=\"top\" width=\"57\">×</td><br><td valign=\"top\" width=\"47\">√</td><br><td valign=\"top\" width=\"38\">×</td><br><td valign=\"top\" width=\"47\">×</td><br><td valign=\"top\" width=\"47\">&nbsp;</td><br><td valign=\"top\" width=\"47\">×</td><br><td valign=\"top\" width=\"57\">√</td><br><td valign=\"top\" width=\"57\">&nbsp;</td><br></tr><br><tr><br><td valign=\"top\" width=\"72\">D</td><br><td valign=\"top\" width=\"79\">×</td><br><td valign=\"top\" width=\"47\">√</td><br><td valign=\"top\" width=\"57\">√</td><br><td valign=\"top\" width=\"47\">√</td><br><td valign=\"top\" width=\"38\">×</td><br><td valign=\"top\" width=\"47\">×</td><br><td valign=\"top\" width=\"47\">&nbsp;</td><br><td valign=\"top\" width=\"47\">×</td><br><td valign=\"top\" width=\"57\">√</td><br><td valign=\"top\" width=\"57\">&nbsp;</td><br></tr><br><tr><br><td valign=\"top\" width=\"72\">Fortran</td><br><td valign=\"top\" width=\"79\">×</td><br><td valign=\"top\" width=\"47\">√</td><br><td valign=\"top\" width=\"57\">×</td><br><td valign=\"top\" width=\"47\">√</td><br><td valign=\"top\" width=\"38\">×</td><br><td valign=\"top\" width=\"47\">×</td><br><td valign=\"top\" width=\"47\">&nbsp;</td><br><td valign=\"top\" width=\"47\">×</td><br><td valign=\"top\" width=\"57\"><a name=\"OLE_LINK4\"></a>×</td><br><td valign=\"top\" width=\"57\">&nbsp;</td><br></tr><br><tr><br><td valign=\"top\" width=\"72\">CommonLisp</td><br><td valign=\"top\" width=\"79\">×</td><br><td valign=\"top\" width=\"47\">√</td><br><td valign=\"top\" width=\"57\">×</td><br><td valign=\"top\" width=\"47\">√</td><br><td valign=\"top\" width=\"38\">×</td><br><td valign=\"top\" width=\"47\"><a name=\"OLE_LINK26\"></a><a name=\"OLE_LINK25\"></a>×</td><br><td valign=\"top\" width=\"47\">&nbsp;</td><br><td valign=\"top\" width=\"47\">×</td><br><td valign=\"top\" width=\"57\">√</td><br><td valign=\"top\" width=\"57\">&nbsp;</td><br></tr><br><tr><br><td valign=\"top\" width=\"72\">Clojure</td><br><td valign=\"top\" width=\"79\">×</td><br><td valign=\"top\" width=\"47\"><a name=\"OLE_LINK14\"></a><a name=\"OLE_LINK13\"></a>√</td><br><td valign=\"top\" width=\"57\">×</td><br><td valign=\"top\" width=\"47\">√</td><br><td valign=\"top\" width=\"38\">×</td><br><td valign=\"top\" width=\"47\">×</td><br><td valign=\"top\" width=\"47\">&nbsp;</td><br><td valign=\"top\" width=\"47\">×</td><br><td valign=\"top\" width=\"57\">√</td><br><td valign=\"top\" width=\"57\">&nbsp;</td><br></tr><br><tr><br><td valign=\"top\" width=\"72\">Scheme</td><br><td valign=\"top\" width=\"79\">×</td><br><td valign=\"top\" width=\"47\">√</td><br><td valign=\"top\" width=\"57\">×</td><br><td valign=\"top\" width=\"47\">√</td><br><td valign=\"top\" width=\"38\">×</td><br><td valign=\"top\" width=\"47\">√</td><br><td valign=\"top\" width=\"47\">&nbsp;</td><br><td valign=\"top\" width=\"47\">×</td><br><td valign=\"top\" width=\"57\">×</td><br><td valign=\"top\" width=\"57\">&nbsp;</td><br></tr><br><tr><br><td valign=\"top\" width=\"72\">Haskell</td><br><td valign=\"top\" width=\"79\">×</td><br><td valign=\"top\" width=\"47\">√</td><br><td valign=\"top\" width=\"57\">√</td><br><td valign=\"top\" width=\"47\">√</td><br><td valign=\"top\" width=\"38\"><a name=\"OLE_LINK24\"></a><a name=\"OLE_LINK23\"></a>×</td><br><td valign=\"top\" width=\"47\">×</td><br><td valign=\"top\" width=\"47\">&nbsp;</td><br><td valign=\"top\" width=\"47\">×</td><br><td valign=\"top\" width=\"57\">√</td><br><td valign=\"top\" width=\"57\">&nbsp;</td><br></tr><br><tr><br><td valign=\"top\" width=\"72\">OCaml</td><br><td valign=\"top\" width=\"79\">×</td><br><td valign=\"top\" width=\"47\">√</td><br><td valign=\"top\" width=\"57\">√</td><br><td valign=\"top\" width=\"47\">√</td><br><td valign=\"top\" width=\"38\">×</td><br><td valign=\"top\" width=\"47\">×</td><br><td valign=\"top\" width=\"47\">&nbsp;</td><br><td valign=\"top\" width=\"47\">×</td><br><td valign=\"top\" width=\"57\">√</td><br><td valign=\"top\" width=\"57\">&nbsp;</td><br></tr><br><tr><br><td valign=\"top\" width=\"72\">其他</td><br><td valign=\"top\" width=\"79\">×</td><br><td valign=\"top\" width=\"47\"><a name=\"OLE_LINK17\"></a><a name=\"OLE_LINK16\"></a>√</td><br><td valign=\"top\" width=\"57\">×</td><br><td valign=\"top\" width=\"47\">√</td><br><td valign=\"top\" width=\"38\">×</td><br><td valign=\"top\" width=\"47\">×</td><br><td valign=\"top\" width=\"47\">&nbsp;</td><br><td valign=\"top\" width=\"47\">×</td><br><td valign=\"top\" width=\"57\">×</td><br><td valign=\"top\" width=\"57\">&nbsp;</td><br></tr><br></tbody><br></table>\n\n<p>##大牛在哪里玩<br><a href=\"http://www.codechef.com/long/ranklist/AX/?page=0\" target=\"_blank\" rel=\"external\">CodeChef的Long Consest 排名榜</a><br><a href=\"http://codeforces.com/ratings\" target=\"_blank\" rel=\"external\">CodeForces的排名榜</a></p>\n<p>看看一些神牛在哪些编程网站上玩。</p>\n<table cellspacing=\"0\" cellpadding=\"0\" border=\"1\"><br><tbody><br><tr><br><td valign=\"top\" width=\"98\"><br><p><strong>大牛名字</strong></p><br></td><br><td valign=\"top\" width=\"393\"><br><p><strong>在哪些网站活动</strong></p><br></td><br><td valign=\"top\" width=\"100\"><br><p><strong>结论</strong></p><br></td><br></tr><br><tr><br><td valign=\"top\" width=\"98\"><br><p>清华 楼天城 ACRush</p><br><p>现在Google工作</p><br></td><br><td valign=\"top\" width=\"393\"><br><p><a href=\"http://community.topcoder.com/tc?module=MemberProfile&amp;cr=19849563\" onclick=\"javascript:_gaq.push(['_trackEvent','outbound-article','http://community.topcoder.com']);\" target=\"_blank\" rel=\"external\">http://community.topcoder.com/tc?module=MemberProfile&amp;cr=19849563</a> 最后活动日期14/03/13</p><br><p><a href=\"http://www.codechef.com/users/ACRush21\" onclick=\"javascript:_gaq.push(['_trackEvent','outbound-article','http://www.codechef.com']);\" target=\"_blank\" rel=\"external\">http://www.codechef.com/users/ACRush21</a> long contest排名第一</p><br><p><a href=\"http://codeforces.com/profile/ACRush\" onclick=\"javascript:_gaq.push(['_trackEvent','outbound-article','http://codeforces.com']);\" target=\"_blank\" rel=\"external\">http://codeforces.com/profile/ACRush</a> 排名18 </p><br></td><br><td valign=\"top\" width=\"100\"><br><p>楼教主在TopCoder, CodeChef, CodeForces玩</p><br></td><br></tr><br><tr><br><td valign=\"top\" width=\"98\"><br><p>俄罗斯 petr</p><br><p>现在Google工作</p><br></td><br><td valign=\"top\" width=\"393\"><br><p><a href=\"http://community.topcoder.com/tc?module=MemberProfile&amp;tab=alg&amp;cr=10574855\" onclick=\"javascript:_gaq.push(['_trackEvent','outbound-article','http://community.topcoder.com']);\" target=\"_blank\" rel=\"external\">http://community.topcoder.com/tc?module=MemberProfile&amp;tab=alg&amp;cr=10574855</a></p><br><p><a href=\"http://www.codechef.com/users/petr\" onclick=\"javascript:_gaq.push(['_trackEvent','outbound-article','http://www.codechef.com']);\" target=\"_blank\" rel=\"external\">http://www.codechef.com/users/petr</a> N/A</p><br><p><a href=\"http://codeforces.com/profile/Petr\" onclick=\"javascript:_gaq.push(['_trackEvent','outbound-article','http://codeforces.com']);\" target=\"_blank\" rel=\"external\">http://codeforces.com/profile/Petr</a> 排名第三</p><br></td><br><td valign=\"top\" width=\"100\"><br><p>Petr主要在TopCoder, CodeForces玩</p><br></td><br></tr><br><tr><br><td valign=\"top\" width=\"98\"><br><p>波兰 tomek</p><br><p>现在Google工作</p><br></td><br><td valign=\"top\" width=\"393\"><br><p><a href=\"http://community.topcoder.com/tc?module=MemberProfile&amp;cr=144400\" onclick=\"javascript:_gaq.push(['_trackEvent','outbound-article','http://community.topcoder.com']);\" target=\"_blank\" rel=\"external\">http://community.topcoder.com/tc?module=MemberProfile&amp;cr=144400</a></p><br><p><a href=\"http://www.codechef.com/users/tomek\" onclick=\"javascript:_gaq.push(['_trackEvent','outbound-article','http://www.codechef.com']);\" target=\"_blank\" rel=\"external\">http://www.codechef.com/users/tomek</a> long contest排名第六</p><br><p><a href=\"http://codeforces.com/profile/tomek\" onclick=\"javascript:_gaq.push(['_trackEvent','outbound-article','http://codeforces.com']);\" target=\"_blank\" rel=\"external\">http://codeforces.com/profile/tomek</a> N/A</p><br></td><br><td valign=\"top\" width=\"100\"><br><p>Tomek主要在TopCoder, codechef玩</p><br></td><br></tr><br><tr><br><td valign=\"top\" width=\"98\"><br><p>俄罗斯 Egor</p><br></td><br><td valign=\"top\" width=\"393\"><br><p><a href=\"http://community.topcoder.com/tc?module=MemberProfile&amp;cr=14970299\" onclick=\"javascript:_gaq.push(['_trackEvent','outbound-article','http://community.topcoder.com']);\" target=\"_blank\" rel=\"external\">http://community.topcoder.com/tc?module=MemberProfile&amp;cr=14970299</a></p><br><p><a href=\"http://www.codechef.com/users/Egor\" onclick=\"javascript:_gaq.push(['_trackEvent','outbound-article','http://www.codechef.com']);\" target=\"_blank\" rel=\"external\">http://www.codechef.com/users/Egor</a> N/A</p><br><p><a href=\"http://codeforces.com/profile/Egor\" onclick=\"javascript:_gaq.push(['_trackEvent','outbound-article','http://codeforces.com']);\" target=\"_blank\" rel=\"external\">http://codeforces.com/profile/Egor</a> 排名第七</p><br></td><br><td valign=\"top\" width=\"100\"><br><p>Egor主要在TopCoder, CodeForces玩</p><br></td><br></tr><br><tr><br><td valign=\"top\" width=\"98\"><br><p>俄罗斯 Tourist</p><br><p>高三学生</p><br></td><br><td valign=\"top\" width=\"393\"><br><p><a href=\"http://www.codechef.com/teams/view/tourist\" onclick=\"javascript:_gaq.push(['_trackEvent','outbound-article','http://www.codechef.com']);\" target=\"_blank\" rel=\"external\">http://www.codechef.com/teams/view/tourist</a> N/A</p><br><p><a href=\"http://www.codeforces.com/profile/tourist\" onclick=\"javascript:_gaq.push(['_trackEvent','outbound-article','http://www.codeforces.com']);\" target=\"_blank\" rel=\"external\">http://www.codeforces.com/profile/tourist</a> 排名第一</p><br></td><br><td valign=\"top\" width=\"100\"><br><p>少年天才，主要在CodeForces玩</p><br></td><br></tr><br></tbody><br></table>\n\n<p>由于CodeForcess是俄罗斯的网站，所以俄罗斯选手几乎全部在CodeForces上玩，例如Petr, Egor, Tourist都是俄罗斯人，都在CodeForces上。<br>也可以发现，神牛大部分来自俄罗斯，大家或许也会联想到，俄罗斯出数学家和计算机黑客，的确如此。像楼教主，Petr属于老牌的霸主，近两年出现一个天才少年tourist，才高三，竟然在CodeForces上力压Petr，真是逆天的存在。Quora上有个问题How does it feel to beat Petr Mitrichev, Egor, ACRush in SRM? 最佳答案 It feels a lot like being Tourist. 既幽默又霸气。</p>\n<p>##大牛们使用什么语言？<br>来看一下高手提交的代码列表：<br><a href=\"http://codeforces.com/submissions/ACRush\" target=\"_blank\" rel=\"external\">http://codeforces.com/submissions/ACRush</a><br><a href=\"http://codeforces.com/submissions/Petr\" target=\"_blank\" rel=\"external\">http://codeforces.com/submissions/Petr</a><br><a href=\"http://codeforces.com/submissions/Egor\" target=\"_blank\" rel=\"external\">http://codeforces.com/submissions/Egor</a><br><a href=\"http://www.codeforces.com/submissions/tourist\" target=\"_blank\" rel=\"external\">http://www.codeforces.com/submissions/tourist</a></p>\n<p>可以看出ACRush和Tourist使用C++，Petr和Egor使用Java。从我的亲身经验，周围参加ACM的同学大部分用C++。不过，注意一点，大部分人认为Java慢，这在五六年前是对的，但是到了在现在，JVM经过各大IT巨头的重金打造，性能已经跟C++一样持平了，至少不再有数量级上的差距。因此Java也是一个很好地选择。</p>\n<p>##更新历史<br>2013-04-06，从 <a href=\"http://blog.liancheng.info/job-hunting-in-california/\" target=\"_blank\" rel=\"external\">加州求职记</a> 得知了两个专门针对面试的新兴网站，<a href=\"http://www.careercup.com/\" target=\"_blank\" rel=\"external\">CareerCup</a> 和 <a href=\"http://leetcode.com/onlinejudge\" target=\"_blank\" rel=\"external\">LeetCode</a>，跟 InterviewStreet 很类似。</p>\n","excerpt":"<p>今天把各个主流的编程网站仔细对比了一下，下面从各个角度对比一下这些编程竞赛网站。</p>\n<p>##分类和排名</p>\n<table border=\"1\" cellspacing=\"0\" cellpadding=\"0\"><br><tbody><br><tr><br><td valign=\"top\" width=\"94\"><br><p><a name=\"OLE_LINK30\"></a><a name=\"OLE_LINK1\"><b>网站地址</b></a></p><br></td><br><td valign=\"top\" width=\"57\"><br><p><b>类别</b></p><br></td><br><td valign=\"top\" width=\"38\"><br><p><b>PR</b></p><br></td><br><td valign=\"top\" width=\"60\"><br><p><b>ATR</b></p><br></td><br><td valign=\"top\" width=\"44\"><br><p><b>QF</b></p><br></td><br><td valign=\"top\" width=\"151\"><br><p><b>主办方</b></p><br></td><br><td valign=\"top\" width=\"47\"><br><p><b>备注</b></p><br></td><br></tr><br><tr><br><td valign=\"top\" width=\"94\"><br><p><a name=\"_Hlk352791085\"></a><a href=\"http://www.topcoder.com/\" onclick=\"javascript:_gaq.push(['_trackEvent','outbound-article','http://www.topcoder.com']);\">TopCoder </a></p><br></td><br><td valign=\"top\" width=\"57\"><br><p>综合</p><br></td><br><td valign=\"top\" width=\"38\"><br><p>6</p><br></td><br><td valign=\"top\" width=\"60\"><br><p>33,586</p><br></td><br><td valign=\"top\" width=\"44\"><br><p>4167</p><br></td><br><td valign=\"top\" width=\"151\"><br><p>TopCoder公司</p><br></td><br><td valign=\"top\" width=\"47\">&nbsp;</td><br></tr><br><tr><br><td valign=\"top\" width=\"94\"><br><p><a href=\"http://www.codechef.com/\" onclick=\"javascript:_gaq.push(['_trackEvent','outbound-article','http://www.codechef.com']);\">CodeChef </a></p><br></td><br><td valign=\"top\" width=\"57\"><br><p>综合</p><br></td><br><td valign=\"top\" width=\"38\"><br><p>6</p><br></td><br><td valign=\"top\" width=\"60\"><br><p>41,217</p><br></td><br><td valign=\"top\" width=\"44\"><br><p>5758</p><br></td><br><td valign=\"top\" width=\"151\"><br><p>Directi公司</p><br></td><br><td valign=\"top\" width=\"47\">&nbsp;</td><br></tr><br><tr><br><td valign=\"top\" width=\"94\"><br><p><a href=\"http://codeforces.com/\" onclick=\"javascript:_gaq.push(['_trackEvent','outbound-article','http://codeforces.com']);\">CodeForces </a></p><br></td><br><td valign=\"top\" width=\"57\"><br><p>综合</p><br></td><br><td valign=\"top\" width=\"38\"><br><p>5</p><br></td><br><td valign=\"top\" width=\"60\"><br><p>73,012</p><br></td><br><td valign=\"top\" width=\"44\"><br><p>599</p><br></td><br><td valign=\"top\" width=\"151\"><br><p>CodeForces公司</p><br></td><br><td valign=\"top\" width=\"47\">&nbsp;</td><br></tr><br><tr><br><td valign=\"top\" width=\"94\"><br><p><a href=\"http://www.spoj.com/\" onclick=\"javascript:_gaq.push(['_trackEvent','outbound-article','http://www.spoj.com']);\">SPOJ</a></p><br></td><br><td valign=\"top\" width=\"57\"><br><p>ACM</p><br></td><br><td valign=\"top\" width=\"38\"><br><p>3</p><br></td><br><td valign=\"top\" width=\"60\"><br><p>75,653</p><br></td><br><td valign=\"top\" width=\"44\"><br><p>1520</p><br></td><br><td valign=\"top\" width=\"151\"><br><p>Sphere Research Labs</p><br></td><br><td valign=\"top\" width=\"47\">&nbsp;</td><br></tr><br><tr><br><td valign=\"top\" width=\"94\"><br><p><a href=\"http://poj.org/\" onclick=\"javascript:_gaq.push(['_trackEvent','outbound-article','http://poj.org']);\">POJ</a></p><br></td><br><td valign=\"top\" width=\"57\"><br><p>ACM</p><br></td><br><td valign=\"top\" width=\"38\"><br><p>7</p><br></td><br><td valign=\"top\" width=\"60\"><br><p>364,925</p><br></td><br><td valign=\"top\" width=\"44\"><br><p>N/A</p><br></td><br><td valign=\"top\" width=\"151\"><br><p>北京大学</p><br></td><br><td valign=\"top\" width=\"47\">&nbsp;</td><br></tr><br><tr><br><td valign=\"top\" width=\"94\"><br><p><a href=\"http://acm.zju.edu.cn\" onclick=\"javascript:_gaq.push(['_trackEvent','outbound-article','http://acm.zju.edu.cn']);\">ZOJ</a></p><br></td><br><td valign=\"top\" width=\"57\"><br><p>ACM</p><br></td><br><td valign=\"top\" width=\"38\"><br><p>6</p><br></td><br><td valign=\"top\" width=\"60\"><br><p>N/A</p><br></td><br><td valign=\"top\" width=\"44\"><br><p>N/A</p><br></td><br><td valign=\"top\" width=\"151\"><br><p>浙江大学</p><br></td><br><td valign=\"top\" width=\"47\">&nbsp;</td><br></tr><br><tr><br><td valign=\"top\" width=\"94\"><br><p><a href=\"http://uva.onlinejudge.org/\" onclick=\"javascript:_gaq.push(['_trackEvent','outbound-article','http://uva.onlinejudge.org']);\">UVA OJ</a></p><br></td><br><td valign=\"top\" width=\"57\"><br><p>ACM</p><br></td><br><td valign=\"top\" width=\"38\"><br><p>6</p><br></td><br><td valign=\"top\" width=\"60\"><br><p>166,991</p><br></td><br><td valign=\"top\" width=\"44\"><br><p>N/A</p><br></td><br><td valign=\"top\" width=\"151\"><br><p>University of Virginia</p><br></td><br><td valign=\"top\" width=\"47\">&nbsp;</td><br></tr><br><tr><br><td valign=\"top\" width=\"94\"><br><p><a href=\"http://acm.sgu.ru/\" onclick=\"javascript:_gaq.push(['_trackEvent','outbound-article','http://acm.sgu.ru']);\">SGU OJ</a></p><br></td><br><td valign=\"top\" width=\"57\"><br><p>ACM</p><br></td><br><td valign=\"top\" width=\"38\"><br><p>5</p><br></td><br><td valign=\"top\" width=\"60\"><br><p>194,881</p><br></td><br><td valign=\"top\" width=\"44\"><br><p>N/A</p><br></td><br><td valign=\"top\" width=\"151\"><br><p>Saratov State University</p><br></td><br><td valign=\"top\" width=\"47\">&nbsp;</td><br></tr><br><tr><br><td valign=\"top\" width=\"94\"><br><p><a href=\"https://www.hackerrank.com/\" onclick=\"javascript:_gaq.push(['_trackEvent','outbound-article','http://www.hackerrank.com']);\">HackerRank</a></p><br></td><br><td valign=\"top\" width=\"57\"><br><p>综合</p><br></td><br><td valign=\"top\" width=\"38\"><br><p>5</p><br></td><br><td valign=\"top\" width=\"60\"><br><p>126,192</p><br></td><br><td valign=\"top\" width=\"44\"><br><p>56</p><br></td><br><td valign=\"top\" width=\"151\"><br><p>InterviewStreet公司</p><br></td><br><td valign=\"top\" width=\"47\">&nbsp;</td><br></tr><br><tr><br><td valign=\"top\" width=\"94\"><br><p><a href=\"http://projecteuler.net/\" onclick=\"javascript:_gaq.push(['_trackEvent','outbound-article','http://projecteuler.net']);\">Project Euler</a></p><br></td><br><td valign=\"top\" width=\"57\"><br><p>数学</p><br></td><br><td valign=\"top\" width=\"38\"><br><p>6</p><br></td><br><td valign=\"top\" width=\"60\"><br><p>53,854</p><br></td><br><td valign=\"top\" width=\"44\"><br><p>428</p><br></td><br><td valign=\"top\" width=\"151\"><br><p>Project Euler公司</p><br></td><br><td valign=\"top\" width=\"47\">&nbsp;</td><br></tr><br><tr><br><td valign=\"top\" width=\"94\"><br><p><a href=\"http://www.careercup.com/\" onclick=\"javascript:_gaq.push(['_trackEvent','outbound-article','http://www.careercup.com']);\">CareerUp</a></p><br></td><br><td valign=\"top\" width=\"57\"><br><p>面试</p><br></td><br><td valign=\"top\" width=\"38\"><br><p>4</p><br></td><br><td valign=\"top\" width=\"60\"><br><p>51,089</p><br></td><br><td valign=\"top\" width=\"44\"><br><p>654</p><br></td><br><td valign=\"top\" width=\"151\"><br><p>CareerUp公司</p><br></td><br><td valign=\"top\" width=\"47\">&nbsp;</td><br></tr><br><tr><br><td valign=\"top\" width=\"94\"><br><p><a href=\"http://leetcode.com/\" onclick=\"javascript:_gaq.push(['_trackEvent','outbound-article','http://leetcode.com']);\">LeetCode</a></p><br></td><br><td valign=\"top\" width=\"57\"><br><p>面试</p><br></td><br><td valign=\"top\" width=\"38\"><br><p>4</p><br></td><br><td valign=\"top\" width=\"60\"><br><p>188,196</p><br></td><br><td valign=\"top\" width=\"44\"><br><p>N/A</p><br></td><br><td valign=\"top\" width=\"151\"><br><p>LeetCode公司</p><br></td><br><td valign=\"top\" width=\"47\">&nbsp;</td><br></tr><br></tbody><br></table>\n\n<p>说明：PR是Google PageRank的缩写；ATR是Alexa Trafic Rank的缩写，即Alexa排名；QF是Quora Followers的缩写，具体含义是在Quora上关于某Topic的follower数量，例如<a href=\"http://www.quora.com/CodeChef\">CodeChef的topic</a> 有5758个followers。</p>","more":"<p>##支持的语言</p>\n<table cellspacing=\"0\" cellpadding=\"0\" border=\"1\"><br><tbody><br><tr><br><td valign=\"top\" width=\"72\"><strong>网站</strong><br><p><strong>语言</strong></p><br></td><br><td valign=\"top\" width=\"79\"><strong>TopCoder</strong></td><br><td valign=\"top\" width=\"47\"><strong>CodeChef</strong></td><br><td valign=\"top\" width=\"57\"><strong>CodeForces</strong></td><br><td valign=\"top\" width=\"47\"><strong>SPOJ</strong></td><br><td valign=\"top\" width=\"38\"><strong>POJ</strong></td><br><td valign=\"top\" width=\"47\"><strong>ZOJ</strong></td><br><td valign=\"top\" width=\"47\"><strong>UVA OJ</strong></td><br><td valign=\"top\" width=\"47\"><strong>SGU OJ</strong></td><br><td valign=\"top\" width=\"57\"><strong>HackerRank</strong></td><br><td valign=\"top\" width=\"57\"><strong>Project Euler</strong></td><br></tr><br><tr><br><td valign=\"top\" width=\"72\">Java</td><br><td valign=\"top\" width=\"79\"><a name=\"OLE_LINK5\"></a><a name=\"OLE_LINK3\"></a>√</td><br><td valign=\"top\" width=\"47\">√<strong></strong></td><br><td valign=\"top\" width=\"57\">√</td><br><td valign=\"top\" width=\"47\">√</td><br><td valign=\"top\" width=\"38\">√</td><br><td valign=\"top\" width=\"47\">√</td><br><td valign=\"top\" width=\"47\">&nbsp;</td><br><td valign=\"top\" width=\"47\">√</td><br><td valign=\"top\" width=\"57\">√</td><br><td valign=\"top\" width=\"57\">不</td><br></tr><br><tr><br><td valign=\"top\" width=\"72\">C</td><br><td valign=\"top\" width=\"79\">√</td><br><td valign=\"top\" width=\"47\">√</td><br><td valign=\"top\" width=\"57\">√</td><br><td valign=\"top\" width=\"47\">√</td><br><td valign=\"top\" width=\"38\">√</td><br><td valign=\"top\" width=\"47\">√</td><br><td valign=\"top\" width=\"47\">&nbsp;</td><br><td valign=\"top\" width=\"47\">√</td><br><td valign=\"top\" width=\"57\">√</td><br><td valign=\"top\" width=\"57\">限</td><br></tr><br><tr><br><td valign=\"top\" width=\"72\">C++</td><br><td valign=\"top\" width=\"79\">√</td><br><td valign=\"top\" width=\"47\"><a name=\"OLE_LINK19\"></a><a name=\"OLE_LINK18\"></a>√</td><br><td valign=\"top\" width=\"57\">√</td><br><td valign=\"top\" width=\"47\">√</td><br><td valign=\"top\" width=\"38\">√</td><br><td valign=\"top\" width=\"47\">√</td><br><td valign=\"top\" width=\"47\">&nbsp;</td><br><td valign=\"top\" width=\"47\">√</td><br><td valign=\"top\" width=\"57\">√</td><br><td valign=\"top\" width=\"57\">语</td><br></tr><br><tr><br><td valign=\"top\" width=\"72\">Pascal</td><br><td valign=\"top\" width=\"79\">×</td><br><td valign=\"top\" width=\"47\">√</td><br><td valign=\"top\" width=\"57\">√</td><br><td valign=\"top\" width=\"47\">√</td><br><td valign=\"top\" width=\"38\">√</td><br><td valign=\"top\" width=\"47\">√</td><br><td valign=\"top\" width=\"47\">&nbsp;</td><br><td valign=\"top\" width=\"47\">√</td><br><td valign=\"top\" width=\"57\">√</td><br><td valign=\"top\" width=\"57\">言</td><br></tr><br><tr><br><td valign=\"top\" width=\"72\">Fortran</td><br><td valign=\"top\" width=\"79\">×</td><br><td valign=\"top\" width=\"47\"><a name=\"OLE_LINK9\"></a><a name=\"OLE_LINK8\"></a>√</td><br><td valign=\"top\" width=\"57\">×</td><br><td valign=\"top\" width=\"47\"><a name=\"OLE_LINK21\"></a><a name=\"OLE_LINK20\"></a>√</td><br><td valign=\"top\" width=\"38\">√</td><br><td valign=\"top\" width=\"47\">×</td><br><td valign=\"top\" width=\"47\">&nbsp;</td><br><td valign=\"top\" width=\"47\">×</td><br><td valign=\"top\" width=\"57\"><a name=\"OLE_LINK7\"></a><a name=\"OLE_LINK6\"></a>×</td><br><td valign=\"top\" width=\"57\">，</td><br></tr><br><tr><br><td valign=\"top\" width=\"72\">Obj-C</td><br><td valign=\"top\" width=\"79\">×</td><br><td valign=\"top\" width=\"47\">×</td><br><td valign=\"top\" width=\"57\">×</td><br><td valign=\"top\" width=\"47\">×</td><br><td valign=\"top\" width=\"38\">×</td><br><td valign=\"top\" width=\"47\">×</td><br><td valign=\"top\" width=\"47\">&nbsp;</td><br><td valign=\"top\" width=\"47\">×</td><br><td valign=\"top\" width=\"57\">×</td><br><td valign=\"top\" width=\"57\">只</td><br></tr><br><tr><br><td valign=\"top\" width=\"72\">C#</td><br><td valign=\"top\" width=\"79\">√</td><br><td valign=\"top\" width=\"47\">√</td><br><td valign=\"top\" width=\"57\">√</td><br><td valign=\"top\" width=\"47\">√</td><br><td valign=\"top\" width=\"38\">×</td><br><td valign=\"top\" width=\"47\">×</td><br><td valign=\"top\" width=\"47\">&nbsp;</td><br><td valign=\"top\" width=\"47\">√</td><br><td valign=\"top\" width=\"57\">√</td><br><td valign=\"top\" width=\"57\">需</td><br></tr><br><tr><br><td valign=\"top\" width=\"72\">Python 2</td><br><td valign=\"top\" width=\"79\">×</td><br><td valign=\"top\" width=\"47\">√</td><br><td valign=\"top\" width=\"57\">√</td><br><td valign=\"top\" width=\"47\">√</td><br><td valign=\"top\" width=\"38\">×</td><br><td valign=\"top\" width=\"47\">√</td><br><td valign=\"top\" width=\"47\">&nbsp;</td><br><td valign=\"top\" width=\"47\">×</td><br><td valign=\"top\" width=\"57\">√</td><br><td valign=\"top\" width=\"57\">提</td><br></tr><br><tr><br><td valign=\"top\" width=\"72\">Python 3</td><br><td valign=\"top\" width=\"79\">×</td><br><td valign=\"top\" width=\"47\">√</td><br><td valign=\"top\" width=\"57\">×</td><br><td valign=\"top\" width=\"47\">√</td><br><td valign=\"top\" width=\"38\">×</td><br><td valign=\"top\" width=\"47\">×</td><br><td valign=\"top\" width=\"47\">&nbsp;</td><br><td valign=\"top\" width=\"47\">×</td><br><td valign=\"top\" width=\"57\">√</td><br><td valign=\"top\" width=\"57\">交</td><br></tr><br><tr><br><td valign=\"top\" width=\"72\">Ruby</td><br><td valign=\"top\" width=\"79\">×</td><br><td valign=\"top\" width=\"47\">√</td><br><td valign=\"top\" width=\"57\">√</td><br><td valign=\"top\" width=\"47\">√</td><br><td valign=\"top\" width=\"38\">×</td><br><td valign=\"top\" width=\"47\">×</td><br><td valign=\"top\" width=\"47\">&nbsp;</td><br><td valign=\"top\" width=\"47\">×</td><br><td valign=\"top\" width=\"57\">√</td><br><td valign=\"top\" width=\"57\">答</td><br></tr><br><tr><br><td valign=\"top\" width=\"72\">JavaScript</td><br><td valign=\"top\" width=\"79\">×</td><br><td valign=\"top\" width=\"47\">√</td><br><td valign=\"top\" width=\"57\">×</td><br><td valign=\"top\" width=\"47\">√</td><br><td valign=\"top\" width=\"38\">×</td><br><td valign=\"top\" width=\"47\">×</td><br><td valign=\"top\" width=\"47\">&nbsp;</td><br><td valign=\"top\" width=\"47\">×</td><br><td valign=\"top\" width=\"57\">√</td><br><td valign=\"top\" width=\"57\">案</td><br></tr><br><tr><br><td valign=\"top\" width=\"72\">PHP</td><br><td valign=\"top\" width=\"79\">×</td><br><td valign=\"top\" width=\"47\"><a name=\"OLE_LINK11\"></a><a name=\"OLE_LINK10\"></a>√</td><br><td valign=\"top\" width=\"57\">√</td><br><td valign=\"top\" width=\"47\">√</td><br><td valign=\"top\" width=\"38\">×</td><br><td valign=\"top\" width=\"47\">√</td><br><td valign=\"top\" width=\"47\">&nbsp;</td><br><td valign=\"top\" width=\"47\">×</td><br><td valign=\"top\" width=\"57\">√</td><br><td valign=\"top\" width=\"57\">&nbsp;</td><br></tr><br><tr><br><td valign=\"top\" width=\"72\">VB</td><br><td valign=\"top\" width=\"79\">√</td><br><td valign=\"top\" width=\"47\"><a name=\"OLE_LINK28\"></a><a name=\"OLE_LINK12\"></a>×</td><br><td valign=\"top\" width=\"57\">×</td><br><td valign=\"top\" width=\"47\">×</td><br><td valign=\"top\" width=\"38\">×</td><br><td valign=\"top\" width=\"47\">×</td><br><td valign=\"top\" width=\"47\">&nbsp;</td><br><td valign=\"top\" width=\"47\">×</td><br><td valign=\"top\" width=\"57\">×</td><br><td valign=\"top\" width=\"57\">&nbsp;</td><br></tr><br><tr><br><td valign=\"top\" width=\"72\">Perl</td><br><td valign=\"top\" width=\"79\">×</td><br><td valign=\"top\" width=\"47\">√</td><br><td valign=\"top\" width=\"57\">√</td><br><td valign=\"top\" width=\"47\"><a name=\"OLE_LINK22\"></a>√</td><br><td valign=\"top\" width=\"38\">×</td><br><td valign=\"top\" width=\"47\">√</td><br><td valign=\"top\" width=\"47\">&nbsp;</td><br><td valign=\"top\" width=\"47\">×</td><br><td valign=\"top\" width=\"57\">√</td><br><td valign=\"top\" width=\"57\">&nbsp;</td><br></tr><br><tr><br><td valign=\"top\" width=\"72\">Go</td><br><td valign=\"top\" width=\"79\">×</td><br><td valign=\"top\" width=\"47\">√</td><br><td valign=\"top\" width=\"57\">×</td><br><td valign=\"top\" width=\"47\">√</td><br><td valign=\"top\" width=\"38\">×</td><br><td valign=\"top\" width=\"47\">×</td><br><td valign=\"top\" width=\"47\">&nbsp;</td><br><td valign=\"top\" width=\"47\">×</td><br><td valign=\"top\" width=\"57\">√</td><br><td valign=\"top\" width=\"57\">&nbsp;</td><br></tr><br><tr><br><td valign=\"top\" width=\"72\">Scala</td><br><td valign=\"top\" width=\"79\">×</td><br><td valign=\"top\" width=\"47\">√</td><br><td valign=\"top\" width=\"57\">√</td><br><td valign=\"top\" width=\"47\">√</td><br><td valign=\"top\" width=\"38\">×</td><br><td valign=\"top\" width=\"47\">×</td><br><td valign=\"top\" width=\"47\">&nbsp;</td><br><td valign=\"top\" width=\"47\">×</td><br><td valign=\"top\" width=\"57\">√</td><br><td valign=\"top\" width=\"57\">&nbsp;</td><br></tr><br><tr><br><td valign=\"top\" width=\"72\">Groovy</td><br><td valign=\"top\" width=\"79\">×</td><br><td valign=\"top\" width=\"47\">×</td><br><td valign=\"top\" width=\"57\">×</td><br><td valign=\"top\" width=\"47\">×</td><br><td valign=\"top\" width=\"38\">×</td><br><td valign=\"top\" width=\"47\">×</td><br><td valign=\"top\" width=\"47\">&nbsp;</td><br><td valign=\"top\" width=\"47\">×</td><br><td valign=\"top\" width=\"57\">√</td><br><td valign=\"top\" width=\"57\">&nbsp;</td><br></tr><br><tr><br><td valign=\"top\" width=\"72\">Erlang</td><br><td valign=\"top\" width=\"79\">×</td><br><td valign=\"top\" width=\"47\">√</td><br><td valign=\"top\" width=\"57\"><a name=\"OLE_LINK15\"></a>×</td><br><td valign=\"top\" width=\"47\">√</td><br><td valign=\"top\" width=\"38\">×</td><br><td valign=\"top\" width=\"47\">×</td><br><td valign=\"top\" width=\"47\">&nbsp;</td><br><td valign=\"top\" width=\"47\">×</td><br><td valign=\"top\" width=\"57\">√</td><br><td valign=\"top\" width=\"57\">&nbsp;</td><br></tr><br><tr><br><td valign=\"top\" width=\"72\">Lua</td><br><td valign=\"top\" width=\"79\">×</td><br><td valign=\"top\" width=\"47\">√</td><br><td valign=\"top\" width=\"57\">×</td><br><td valign=\"top\" width=\"47\">√</td><br><td valign=\"top\" width=\"38\">×</td><br><td valign=\"top\" width=\"47\">×</td><br><td valign=\"top\" width=\"47\">&nbsp;</td><br><td valign=\"top\" width=\"47\">×</td><br><td valign=\"top\" width=\"57\">√</td><br><td valign=\"top\" width=\"57\">&nbsp;</td><br></tr><br><tr><br><td valign=\"top\" width=\"72\">D</td><br><td valign=\"top\" width=\"79\">×</td><br><td valign=\"top\" width=\"47\">√</td><br><td valign=\"top\" width=\"57\">√</td><br><td valign=\"top\" width=\"47\">√</td><br><td valign=\"top\" width=\"38\">×</td><br><td valign=\"top\" width=\"47\">×</td><br><td valign=\"top\" width=\"47\">&nbsp;</td><br><td valign=\"top\" width=\"47\">×</td><br><td valign=\"top\" width=\"57\">√</td><br><td valign=\"top\" width=\"57\">&nbsp;</td><br></tr><br><tr><br><td valign=\"top\" width=\"72\">Fortran</td><br><td valign=\"top\" width=\"79\">×</td><br><td valign=\"top\" width=\"47\">√</td><br><td valign=\"top\" width=\"57\">×</td><br><td valign=\"top\" width=\"47\">√</td><br><td valign=\"top\" width=\"38\">×</td><br><td valign=\"top\" width=\"47\">×</td><br><td valign=\"top\" width=\"47\">&nbsp;</td><br><td valign=\"top\" width=\"47\">×</td><br><td valign=\"top\" width=\"57\"><a name=\"OLE_LINK4\"></a>×</td><br><td valign=\"top\" width=\"57\">&nbsp;</td><br></tr><br><tr><br><td valign=\"top\" width=\"72\">CommonLisp</td><br><td valign=\"top\" width=\"79\">×</td><br><td valign=\"top\" width=\"47\">√</td><br><td valign=\"top\" width=\"57\">×</td><br><td valign=\"top\" width=\"47\">√</td><br><td valign=\"top\" width=\"38\">×</td><br><td valign=\"top\" width=\"47\"><a name=\"OLE_LINK26\"></a><a name=\"OLE_LINK25\"></a>×</td><br><td valign=\"top\" width=\"47\">&nbsp;</td><br><td valign=\"top\" width=\"47\">×</td><br><td valign=\"top\" width=\"57\">√</td><br><td valign=\"top\" width=\"57\">&nbsp;</td><br></tr><br><tr><br><td valign=\"top\" width=\"72\">Clojure</td><br><td valign=\"top\" width=\"79\">×</td><br><td valign=\"top\" width=\"47\"><a name=\"OLE_LINK14\"></a><a name=\"OLE_LINK13\"></a>√</td><br><td valign=\"top\" width=\"57\">×</td><br><td valign=\"top\" width=\"47\">√</td><br><td valign=\"top\" width=\"38\">×</td><br><td valign=\"top\" width=\"47\">×</td><br><td valign=\"top\" width=\"47\">&nbsp;</td><br><td valign=\"top\" width=\"47\">×</td><br><td valign=\"top\" width=\"57\">√</td><br><td valign=\"top\" width=\"57\">&nbsp;</td><br></tr><br><tr><br><td valign=\"top\" width=\"72\">Scheme</td><br><td valign=\"top\" width=\"79\">×</td><br><td valign=\"top\" width=\"47\">√</td><br><td valign=\"top\" width=\"57\">×</td><br><td valign=\"top\" width=\"47\">√</td><br><td valign=\"top\" width=\"38\">×</td><br><td valign=\"top\" width=\"47\">√</td><br><td valign=\"top\" width=\"47\">&nbsp;</td><br><td valign=\"top\" width=\"47\">×</td><br><td valign=\"top\" width=\"57\">×</td><br><td valign=\"top\" width=\"57\">&nbsp;</td><br></tr><br><tr><br><td valign=\"top\" width=\"72\">Haskell</td><br><td valign=\"top\" width=\"79\">×</td><br><td valign=\"top\" width=\"47\">√</td><br><td valign=\"top\" width=\"57\">√</td><br><td valign=\"top\" width=\"47\">√</td><br><td valign=\"top\" width=\"38\"><a name=\"OLE_LINK24\"></a><a name=\"OLE_LINK23\"></a>×</td><br><td valign=\"top\" width=\"47\">×</td><br><td valign=\"top\" width=\"47\">&nbsp;</td><br><td valign=\"top\" width=\"47\">×</td><br><td valign=\"top\" width=\"57\">√</td><br><td valign=\"top\" width=\"57\">&nbsp;</td><br></tr><br><tr><br><td valign=\"top\" width=\"72\">OCaml</td><br><td valign=\"top\" width=\"79\">×</td><br><td valign=\"top\" width=\"47\">√</td><br><td valign=\"top\" width=\"57\">√</td><br><td valign=\"top\" width=\"47\">√</td><br><td valign=\"top\" width=\"38\">×</td><br><td valign=\"top\" width=\"47\">×</td><br><td valign=\"top\" width=\"47\">&nbsp;</td><br><td valign=\"top\" width=\"47\">×</td><br><td valign=\"top\" width=\"57\">√</td><br><td valign=\"top\" width=\"57\">&nbsp;</td><br></tr><br><tr><br><td valign=\"top\" width=\"72\">其他</td><br><td valign=\"top\" width=\"79\">×</td><br><td valign=\"top\" width=\"47\"><a name=\"OLE_LINK17\"></a><a name=\"OLE_LINK16\"></a>√</td><br><td valign=\"top\" width=\"57\">×</td><br><td valign=\"top\" width=\"47\">√</td><br><td valign=\"top\" width=\"38\">×</td><br><td valign=\"top\" width=\"47\">×</td><br><td valign=\"top\" width=\"47\">&nbsp;</td><br><td valign=\"top\" width=\"47\">×</td><br><td valign=\"top\" width=\"57\">×</td><br><td valign=\"top\" width=\"57\">&nbsp;</td><br></tr><br></tbody><br></table>\n\n<p>##大牛在哪里玩<br><a href=\"http://www.codechef.com/long/ranklist/AX/?page=0\">CodeChef的Long Consest 排名榜</a><br><a href=\"http://codeforces.com/ratings\">CodeForces的排名榜</a></p>\n<p>看看一些神牛在哪些编程网站上玩。</p>\n<table cellspacing=\"0\" cellpadding=\"0\" border=\"1\"><br><tbody><br><tr><br><td valign=\"top\" width=\"98\"><br><p><strong>大牛名字</strong></p><br></td><br><td valign=\"top\" width=\"393\"><br><p><strong>在哪些网站活动</strong></p><br></td><br><td valign=\"top\" width=\"100\"><br><p><strong>结论</strong></p><br></td><br></tr><br><tr><br><td valign=\"top\" width=\"98\"><br><p>清华 楼天城 ACRush</p><br><p>现在Google工作</p><br></td><br><td valign=\"top\" width=\"393\"><br><p><a href=\"http://community.topcoder.com/tc?module=MemberProfile&amp;cr=19849563\" onclick=\"javascript:_gaq.push(['_trackEvent','outbound-article','http://community.topcoder.com']);\">http://community.topcoder.com/tc?module=MemberProfile&amp;cr=19849563</a> 最后活动日期14/03/13</p><br><p><a href=\"http://www.codechef.com/users/ACRush21\" onclick=\"javascript:_gaq.push(['_trackEvent','outbound-article','http://www.codechef.com']);\">http://www.codechef.com/users/ACRush21</a> long contest排名第一</p><br><p><a href=\"http://codeforces.com/profile/ACRush\" onclick=\"javascript:_gaq.push(['_trackEvent','outbound-article','http://codeforces.com']);\">http://codeforces.com/profile/ACRush</a> 排名18 </p><br></td><br><td valign=\"top\" width=\"100\"><br><p>楼教主在TopCoder, CodeChef, CodeForces玩</p><br></td><br></tr><br><tr><br><td valign=\"top\" width=\"98\"><br><p>俄罗斯 petr</p><br><p>现在Google工作</p><br></td><br><td valign=\"top\" width=\"393\"><br><p><a href=\"http://community.topcoder.com/tc?module=MemberProfile&amp;tab=alg&amp;cr=10574855\" onclick=\"javascript:_gaq.push(['_trackEvent','outbound-article','http://community.topcoder.com']);\">http://community.topcoder.com/tc?module=MemberProfile&amp;tab=alg&amp;cr=10574855</a></p><br><p><a href=\"http://www.codechef.com/users/petr\" onclick=\"javascript:_gaq.push(['_trackEvent','outbound-article','http://www.codechef.com']);\">http://www.codechef.com/users/petr</a> N/A</p><br><p><a href=\"http://codeforces.com/profile/Petr\" onclick=\"javascript:_gaq.push(['_trackEvent','outbound-article','http://codeforces.com']);\">http://codeforces.com/profile/Petr</a> 排名第三</p><br></td><br><td valign=\"top\" width=\"100\"><br><p>Petr主要在TopCoder, CodeForces玩</p><br></td><br></tr><br><tr><br><td valign=\"top\" width=\"98\"><br><p>波兰 tomek</p><br><p>现在Google工作</p><br></td><br><td valign=\"top\" width=\"393\"><br><p><a href=\"http://community.topcoder.com/tc?module=MemberProfile&amp;cr=144400\" onclick=\"javascript:_gaq.push(['_trackEvent','outbound-article','http://community.topcoder.com']);\">http://community.topcoder.com/tc?module=MemberProfile&amp;cr=144400</a></p><br><p><a href=\"http://www.codechef.com/users/tomek\" onclick=\"javascript:_gaq.push(['_trackEvent','outbound-article','http://www.codechef.com']);\">http://www.codechef.com/users/tomek</a> long contest排名第六</p><br><p><a href=\"http://codeforces.com/profile/tomek\" onclick=\"javascript:_gaq.push(['_trackEvent','outbound-article','http://codeforces.com']);\">http://codeforces.com/profile/tomek</a> N/A</p><br></td><br><td valign=\"top\" width=\"100\"><br><p>Tomek主要在TopCoder, codechef玩</p><br></td><br></tr><br><tr><br><td valign=\"top\" width=\"98\"><br><p>俄罗斯 Egor</p><br></td><br><td valign=\"top\" width=\"393\"><br><p><a href=\"http://community.topcoder.com/tc?module=MemberProfile&amp;cr=14970299\" onclick=\"javascript:_gaq.push(['_trackEvent','outbound-article','http://community.topcoder.com']);\">http://community.topcoder.com/tc?module=MemberProfile&amp;cr=14970299</a></p><br><p><a href=\"http://www.codechef.com/users/Egor\" onclick=\"javascript:_gaq.push(['_trackEvent','outbound-article','http://www.codechef.com']);\">http://www.codechef.com/users/Egor</a> N/A</p><br><p><a href=\"http://codeforces.com/profile/Egor\" onclick=\"javascript:_gaq.push(['_trackEvent','outbound-article','http://codeforces.com']);\">http://codeforces.com/profile/Egor</a> 排名第七</p><br></td><br><td valign=\"top\" width=\"100\"><br><p>Egor主要在TopCoder, CodeForces玩</p><br></td><br></tr><br><tr><br><td valign=\"top\" width=\"98\"><br><p>俄罗斯 Tourist</p><br><p>高三学生</p><br></td><br><td valign=\"top\" width=\"393\"><br><p><a href=\"http://www.codechef.com/teams/view/tourist\" onclick=\"javascript:_gaq.push(['_trackEvent','outbound-article','http://www.codechef.com']);\">http://www.codechef.com/teams/view/tourist</a> N/A</p><br><p><a href=\"http://www.codeforces.com/profile/tourist\" onclick=\"javascript:_gaq.push(['_trackEvent','outbound-article','http://www.codeforces.com']);\">http://www.codeforces.com/profile/tourist</a> 排名第一</p><br></td><br><td valign=\"top\" width=\"100\"><br><p>少年天才，主要在CodeForces玩</p><br></td><br></tr><br></tbody><br></table>\n\n<p>由于CodeForcess是俄罗斯的网站，所以俄罗斯选手几乎全部在CodeForces上玩，例如Petr, Egor, Tourist都是俄罗斯人，都在CodeForces上。<br>也可以发现，神牛大部分来自俄罗斯，大家或许也会联想到，俄罗斯出数学家和计算机黑客，的确如此。像楼教主，Petr属于老牌的霸主，近两年出现一个天才少年tourist，才高三，竟然在CodeForces上力压Petr，真是逆天的存在。Quora上有个问题How does it feel to beat Petr Mitrichev, Egor, ACRush in SRM? 最佳答案 It feels a lot like being Tourist. 既幽默又霸气。</p>\n<p>##大牛们使用什么语言？<br>来看一下高手提交的代码列表：<br><a href=\"http://codeforces.com/submissions/ACRush\">http://codeforces.com/submissions/ACRush</a><br><a href=\"http://codeforces.com/submissions/Petr\">http://codeforces.com/submissions/Petr</a><br><a href=\"http://codeforces.com/submissions/Egor\">http://codeforces.com/submissions/Egor</a><br><a href=\"http://www.codeforces.com/submissions/tourist\">http://www.codeforces.com/submissions/tourist</a></p>\n<p>可以看出ACRush和Tourist使用C++，Petr和Egor使用Java。从我的亲身经验，周围参加ACM的同学大部分用C++。不过，注意一点，大部分人认为Java慢，这在五六年前是对的，但是到了在现在，JVM经过各大IT巨头的重金打造，性能已经跟C++一样持平了，至少不再有数量级上的差距。因此Java也是一个很好地选择。</p>\n<p>##更新历史<br>2013-04-06，从 <a href=\"http://blog.liancheng.info/job-hunting-in-california/\">加州求职记</a> 得知了两个专门针对面试的新兴网站，<a href=\"http://www.careercup.com/\">CareerCup</a> 和 <a href=\"http://leetcode.com/onlinejudge\">LeetCode</a>，跟 InterviewStreet 很类似。</p>"},{"layout":"post","title":"KNN与K-Means的区别","date":"2013-02-25T23:41:00.000Z","comments":1,"_content":"##KNN(K-Nearest Neighbor)介绍\nWikipedia上的[KNN词条](http://en.wikipedia.org/wiki/K-nearest_neighbor_algorithm)中有一个比较经典的图如下：\n\n{% img http://yanjiuyanjiu-wordpress.stor.sinaapp.com/uploads/2013/02/022513_0955_KNNKMeans1.png %}\n\nKNN的算法过程是是这样的：\n\n从上图中我们可以看到，图中的数据集是良好的数据，即都打好了label，一类是蓝色的正方形，一类是红色的三角形，那个绿色的圆形是我们待分类的数据。\n\n如果K=3，那么离绿色点最近的有2个红色三角形和1个蓝色的正方形，这3个点投票，于是绿色的这个待分类点属于红色的三角形。\n\n如果K=5，那么离绿色点最近的有2个红色三角形和3个蓝色的正方形，这5个点投票，于是绿色的这个待分类点属于蓝色的正方形。（参考 [酷壳的 K Nearest Neighbor 算法](http://coolshell.cn/articles/8052.html)）\n\n我们可以看到，KNN本质是基于一种数据统计的方法！其实很多机器学习算法也是基于数据统计的。\n\n<!-- more -->\n\nKNN是一种memory-based learning，也叫instance-based learning，属于lazy learning。即它没有明显的前期训练过程，而是程序开始运行时，把数据集加载到内存后，不需要进行训练，就可以开始分类了。\n\n具体是每次来一个未知的样本点，就在附近找K个最近的点进行投票。\n\n再举一个例子，Locally weighted regression (LWR)也是一种 memory-based 方法，如下图所示的数据集。\n\n{% img http://yanjiuyanjiu-wordpress.stor.sinaapp.com/uploads/2013/02/022513_0955_KNNKMeans2.gif %}\n\n用任何一条直线来模拟这个数据集都是不行的，因为这个数据集看起来不像是一条直线。但是每个局部范围内的数据点，可以认为在一条直线上。每次来了一个位置样本x，我们在X轴上以该数据样本为中心，左右各找几个点，把这几个样本点进行线性回归，算出一条局部的直线，然后把位置样本x代入这条直线，就算出了对应的y，完成了一次线性回归。\n\n也就是每次来一个数据点，都要训练一条局部直线，也即训练一次，就用一次。\n\nLWR和KNN是不是很像？都是为位置数据量身定制，在局部进行训练。\n\n##K-Means介绍\n{% img http://yanjiuyanjiu-wordpress.stor.sinaapp.com/uploads/2013/02/022513_0955_KNNKMeans3.jpg %}\n\n如图所示，数据样本用圆点表示，每个簇的中心点用叉叉表示。(a)刚开始时是原始数据，杂乱无章，没有label，看起来都一样，都是绿色的。(b)假设数据集可以分为两类，令K=2，随机在坐标上选两个点，作为两个类的中心点。(c-f)演示了聚类的两种迭代。先划分，把每个数据样本划分到最近的中心点那一簇；划分完后，更新每个簇的中心，即把该簇的所有数据点的坐标加起来去平均值。这样不断进行”划分—更新—划分—更新”，直到每个簇的中心不在移动为止。(图文来自Andrew ng的机器学习公开课)。\n\n推荐关于K-Means的两篇博文，[K-Means 算法 _ 酷壳](http://coolshell.cn/articles/7779.html)，[漫谈 Clustering (1)_ k-means pluskid](http://blog.pluskid.org/?p=17)。\n\n##KNN和K-Means的区别\n<table style=\"border-collapse: collapse;\" border=\"0\">\n<colgroup>\n<col style=\"width: 277px;\">\n<col style=\"width: 277px;\"></colgroup>\n<tbody valign=\"top\">\n<tr>\n<td style=\"padding-left: 7px; padding-right: 7px; border: solid 0.5pt;\">\n<p style=\"text-align: center;\"><span style=\"font-size: 10pt;\"><strong>KNN</strong></span></p>\n</td>\n<td style=\"padding-left: 7px; padding-right: 7px; border-top: solid 0.5pt; border-left: none; border-bottom: solid 0.5pt; border-right: solid 0.5pt;\">\n<p style=\"text-align: center;\"><span style=\"font-size: 10pt;\"><strong>K-Means</strong></span></p>\n</td>\n</tr>\n<tr style=\"height: 85px;\">\n<td style=\"padding-left: 7px; padding-right: 7px; border-top: none; border-left: solid 0.5pt; border-bottom: solid 0.5pt; border-right: solid 0.5pt;\"><span style=\"font-size: 10pt;\">1.KNN是分类算法<br>\n</span><p></p>\n<p><span style=\"font-size: 10pt;\">2.监督学习<br>\n</span></p>\n<p style=\"text-align: justify;\"><span style=\"font-size: 10pt;\">3.喂给它的数据集是带label的数据，已经是完全正确的数据</span></p>\n</td>\n<td style=\"padding-left: 7px; padding-right: 7px; border-top: none; border-left: none; border-bottom: solid 0.5pt; border-right: solid 0.5pt;\"><span style=\"font-size: 10pt;\">1.K-Means是聚类算法<br>\n</span><p></p>\n<p><span style=\"font-size: 10pt;\">2.非监督学习<br>\n</span></p>\n<p style=\"text-align: justify;\"><span style=\"font-size: 10pt;\">3.喂给它的数据集是无label的数据，是杂乱无章的，经过聚类后才变得有点顺序，先无序，后有序</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"padding-left: 7px; padding-right: 7px; border-top: none; border-left: solid 0.5pt; border-bottom: solid 0.5pt; border-right: solid 0.5pt;\"><span style=\"font-size: 10pt;\">没有明显的前期训练过程，属于memory-based learning</span></td>\n<td style=\"padding-left: 7px; padding-right: 7px; border-top: none; border-left: none; border-bottom: solid 0.5pt; border-right: solid 0.5pt;\"><span style=\"font-size: 10pt;\">有明显的前期训练过程</span></td>\n</tr>\n<tr>\n<td style=\"padding-left: 7px; padding-right: 7px; border-top: none; border-left: solid 0.5pt; border-bottom: solid 0.5pt; border-right: solid 0.5pt;\"><span style=\"font-size: 10pt;\">K的含义：来了一个样本x，要给它分类，即求出它的y，就从数据集中，在x附近找离它最近的K个数据点，这K个数据点，类别c占的个数最多，就把x的label设为c</span></td>\n<td style=\"padding-left: 7px; padding-right: 7px; border-top: none; border-left: none; border-bottom: solid 0.5pt; border-right: solid 0.5pt;\"><span style=\"font-size: 10pt;\">K的含义：K是人工固定好的数字，假设数据集合可以分为K个簇，由于是依靠人工定好，需要一点先验知识</span></td>\n</tr>\n<tr>\n<td style=\"padding-left: 7px; padding-right: 7px; border-top: none; border-left: solid 0.5pt; border-bottom: solid 0.5pt; border-right: solid 0.5pt;\"></td>\n<td style=\"padding-left: 7px; padding-right: 7px; border-top: none; border-left: none; border-bottom: solid 0.5pt; border-right: solid 0.5pt;\"></td>\n</tr>\n<tr>\n<td style=\"padding-left: 7px; padding-right: 7px; border-top: none; border-left: solid 0.5pt; border-bottom: solid 0.5pt; border-right: solid 0.5pt;\" colspan=\"2\"><span style=\"font-size: 10pt;\">相似点：都包含这样的过程，给定一个点，在数据集中找离它最近的点。即二者都用到了NN(Nears Neighbor)算法，一般用KD树来实现NN。</span></td>\n</tr>\n</tbody>\n</table>\n","source":"_posts/2013-02-25-differences-between-knn-and-kmeans.md","raw":"---\nlayout: post\ntitle: \"KNN与K-Means的区别\"\ndate: 2013-02-25 23:41\ncomments: true\ncategories: Machine-Learning\n---\n##KNN(K-Nearest Neighbor)介绍\nWikipedia上的[KNN词条](http://en.wikipedia.org/wiki/K-nearest_neighbor_algorithm)中有一个比较经典的图如下：\n\n{% img http://yanjiuyanjiu-wordpress.stor.sinaapp.com/uploads/2013/02/022513_0955_KNNKMeans1.png %}\n\nKNN的算法过程是是这样的：\n\n从上图中我们可以看到，图中的数据集是良好的数据，即都打好了label，一类是蓝色的正方形，一类是红色的三角形，那个绿色的圆形是我们待分类的数据。\n\n如果K=3，那么离绿色点最近的有2个红色三角形和1个蓝色的正方形，这3个点投票，于是绿色的这个待分类点属于红色的三角形。\n\n如果K=5，那么离绿色点最近的有2个红色三角形和3个蓝色的正方形，这5个点投票，于是绿色的这个待分类点属于蓝色的正方形。（参考 [酷壳的 K Nearest Neighbor 算法](http://coolshell.cn/articles/8052.html)）\n\n我们可以看到，KNN本质是基于一种数据统计的方法！其实很多机器学习算法也是基于数据统计的。\n\n<!-- more -->\n\nKNN是一种memory-based learning，也叫instance-based learning，属于lazy learning。即它没有明显的前期训练过程，而是程序开始运行时，把数据集加载到内存后，不需要进行训练，就可以开始分类了。\n\n具体是每次来一个未知的样本点，就在附近找K个最近的点进行投票。\n\n再举一个例子，Locally weighted regression (LWR)也是一种 memory-based 方法，如下图所示的数据集。\n\n{% img http://yanjiuyanjiu-wordpress.stor.sinaapp.com/uploads/2013/02/022513_0955_KNNKMeans2.gif %}\n\n用任何一条直线来模拟这个数据集都是不行的，因为这个数据集看起来不像是一条直线。但是每个局部范围内的数据点，可以认为在一条直线上。每次来了一个位置样本x，我们在X轴上以该数据样本为中心，左右各找几个点，把这几个样本点进行线性回归，算出一条局部的直线，然后把位置样本x代入这条直线，就算出了对应的y，完成了一次线性回归。\n\n也就是每次来一个数据点，都要训练一条局部直线，也即训练一次，就用一次。\n\nLWR和KNN是不是很像？都是为位置数据量身定制，在局部进行训练。\n\n##K-Means介绍\n{% img http://yanjiuyanjiu-wordpress.stor.sinaapp.com/uploads/2013/02/022513_0955_KNNKMeans3.jpg %}\n\n如图所示，数据样本用圆点表示，每个簇的中心点用叉叉表示。(a)刚开始时是原始数据，杂乱无章，没有label，看起来都一样，都是绿色的。(b)假设数据集可以分为两类，令K=2，随机在坐标上选两个点，作为两个类的中心点。(c-f)演示了聚类的两种迭代。先划分，把每个数据样本划分到最近的中心点那一簇；划分完后，更新每个簇的中心，即把该簇的所有数据点的坐标加起来去平均值。这样不断进行”划分—更新—划分—更新”，直到每个簇的中心不在移动为止。(图文来自Andrew ng的机器学习公开课)。\n\n推荐关于K-Means的两篇博文，[K-Means 算法 _ 酷壳](http://coolshell.cn/articles/7779.html)，[漫谈 Clustering (1)_ k-means pluskid](http://blog.pluskid.org/?p=17)。\n\n##KNN和K-Means的区别\n<table style=\"border-collapse: collapse;\" border=\"0\">\n<colgroup>\n<col style=\"width: 277px;\">\n<col style=\"width: 277px;\"></colgroup>\n<tbody valign=\"top\">\n<tr>\n<td style=\"padding-left: 7px; padding-right: 7px; border: solid 0.5pt;\">\n<p style=\"text-align: center;\"><span style=\"font-size: 10pt;\"><strong>KNN</strong></span></p>\n</td>\n<td style=\"padding-left: 7px; padding-right: 7px; border-top: solid 0.5pt; border-left: none; border-bottom: solid 0.5pt; border-right: solid 0.5pt;\">\n<p style=\"text-align: center;\"><span style=\"font-size: 10pt;\"><strong>K-Means</strong></span></p>\n</td>\n</tr>\n<tr style=\"height: 85px;\">\n<td style=\"padding-left: 7px; padding-right: 7px; border-top: none; border-left: solid 0.5pt; border-bottom: solid 0.5pt; border-right: solid 0.5pt;\"><span style=\"font-size: 10pt;\">1.KNN是分类算法<br>\n</span><p></p>\n<p><span style=\"font-size: 10pt;\">2.监督学习<br>\n</span></p>\n<p style=\"text-align: justify;\"><span style=\"font-size: 10pt;\">3.喂给它的数据集是带label的数据，已经是完全正确的数据</span></p>\n</td>\n<td style=\"padding-left: 7px; padding-right: 7px; border-top: none; border-left: none; border-bottom: solid 0.5pt; border-right: solid 0.5pt;\"><span style=\"font-size: 10pt;\">1.K-Means是聚类算法<br>\n</span><p></p>\n<p><span style=\"font-size: 10pt;\">2.非监督学习<br>\n</span></p>\n<p style=\"text-align: justify;\"><span style=\"font-size: 10pt;\">3.喂给它的数据集是无label的数据，是杂乱无章的，经过聚类后才变得有点顺序，先无序，后有序</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"padding-left: 7px; padding-right: 7px; border-top: none; border-left: solid 0.5pt; border-bottom: solid 0.5pt; border-right: solid 0.5pt;\"><span style=\"font-size: 10pt;\">没有明显的前期训练过程，属于memory-based learning</span></td>\n<td style=\"padding-left: 7px; padding-right: 7px; border-top: none; border-left: none; border-bottom: solid 0.5pt; border-right: solid 0.5pt;\"><span style=\"font-size: 10pt;\">有明显的前期训练过程</span></td>\n</tr>\n<tr>\n<td style=\"padding-left: 7px; padding-right: 7px; border-top: none; border-left: solid 0.5pt; border-bottom: solid 0.5pt; border-right: solid 0.5pt;\"><span style=\"font-size: 10pt;\">K的含义：来了一个样本x，要给它分类，即求出它的y，就从数据集中，在x附近找离它最近的K个数据点，这K个数据点，类别c占的个数最多，就把x的label设为c</span></td>\n<td style=\"padding-left: 7px; padding-right: 7px; border-top: none; border-left: none; border-bottom: solid 0.5pt; border-right: solid 0.5pt;\"><span style=\"font-size: 10pt;\">K的含义：K是人工固定好的数字，假设数据集合可以分为K个簇，由于是依靠人工定好，需要一点先验知识</span></td>\n</tr>\n<tr>\n<td style=\"padding-left: 7px; padding-right: 7px; border-top: none; border-left: solid 0.5pt; border-bottom: solid 0.5pt; border-right: solid 0.5pt;\"></td>\n<td style=\"padding-left: 7px; padding-right: 7px; border-top: none; border-left: none; border-bottom: solid 0.5pt; border-right: solid 0.5pt;\"></td>\n</tr>\n<tr>\n<td style=\"padding-left: 7px; padding-right: 7px; border-top: none; border-left: solid 0.5pt; border-bottom: solid 0.5pt; border-right: solid 0.5pt;\" colspan=\"2\"><span style=\"font-size: 10pt;\">相似点：都包含这样的过程，给定一个点，在数据集中找离它最近的点。即二者都用到了NN(Nears Neighbor)算法，一般用KD树来实现NN。</span></td>\n</tr>\n</tbody>\n</table>\n","slug":"2013-02-25-differences-between-knn-and-kmeans","published":1,"updated":"2016-08-18T09:21:04.000Z","photos":[],"link":"","_id":"cis07pf2m000o01pq830elqf6","content":"<p>##KNN(K-Nearest Neighbor)介绍<br>Wikipedia上的<a href=\"http://en.wikipedia.org/wiki/K-nearest_neighbor_algorithm\" target=\"_blank\" rel=\"external\">KNN词条</a>中有一个比较经典的图如下：</p>\n<img src=\"http://yanjiuyanjiu-wordpress.stor.sinaapp.com/uploads/2013/02/022513_0955_KNNKMeans1.png\">\n<p>KNN的算法过程是是这样的：</p>\n<p>从上图中我们可以看到，图中的数据集是良好的数据，即都打好了label，一类是蓝色的正方形，一类是红色的三角形，那个绿色的圆形是我们待分类的数据。</p>\n<p>如果K=3，那么离绿色点最近的有2个红色三角形和1个蓝色的正方形，这3个点投票，于是绿色的这个待分类点属于红色的三角形。</p>\n<p>如果K=5，那么离绿色点最近的有2个红色三角形和3个蓝色的正方形，这5个点投票，于是绿色的这个待分类点属于蓝色的正方形。（参考 <a href=\"http://coolshell.cn/articles/8052.html\" target=\"_blank\" rel=\"external\">酷壳的 K Nearest Neighbor 算法</a>）</p>\n<p>我们可以看到，KNN本质是基于一种数据统计的方法！其实很多机器学习算法也是基于数据统计的。</p>\n<a id=\"more\"></a>\n<p>KNN是一种memory-based learning，也叫instance-based learning，属于lazy learning。即它没有明显的前期训练过程，而是程序开始运行时，把数据集加载到内存后，不需要进行训练，就可以开始分类了。</p>\n<p>具体是每次来一个未知的样本点，就在附近找K个最近的点进行投票。</p>\n<p>再举一个例子，Locally weighted regression (LWR)也是一种 memory-based 方法，如下图所示的数据集。</p>\n<img src=\"http://yanjiuyanjiu-wordpress.stor.sinaapp.com/uploads/2013/02/022513_0955_KNNKMeans2.gif\">\n<p>用任何一条直线来模拟这个数据集都是不行的，因为这个数据集看起来不像是一条直线。但是每个局部范围内的数据点，可以认为在一条直线上。每次来了一个位置样本x，我们在X轴上以该数据样本为中心，左右各找几个点，把这几个样本点进行线性回归，算出一条局部的直线，然后把位置样本x代入这条直线，就算出了对应的y，完成了一次线性回归。</p>\n<p>也就是每次来一个数据点，都要训练一条局部直线，也即训练一次，就用一次。</p>\n<p>LWR和KNN是不是很像？都是为位置数据量身定制，在局部进行训练。</p>\n<p>##K-Means介绍<br><img src=\"http://yanjiuyanjiu-wordpress.stor.sinaapp.com/uploads/2013/02/022513_0955_KNNKMeans3.jpg\"></p>\n<p>如图所示，数据样本用圆点表示，每个簇的中心点用叉叉表示。(a)刚开始时是原始数据，杂乱无章，没有label，看起来都一样，都是绿色的。(b)假设数据集可以分为两类，令K=2，随机在坐标上选两个点，作为两个类的中心点。(c-f)演示了聚类的两种迭代。先划分，把每个数据样本划分到最近的中心点那一簇；划分完后，更新每个簇的中心，即把该簇的所有数据点的坐标加起来去平均值。这样不断进行”划分—更新—划分—更新”，直到每个簇的中心不在移动为止。(图文来自Andrew ng的机器学习公开课)。</p>\n<p>推荐关于K-Means的两篇博文，<a href=\"http://coolshell.cn/articles/7779.html\" target=\"_blank\" rel=\"external\">K-Means 算法 _ 酷壳</a>，<a href=\"http://blog.pluskid.org/?p=17\" target=\"_blank\" rel=\"external\">漫谈 Clustering (1)_ k-means pluskid</a>。</p>\n<p>##KNN和K-Means的区别</p>\n<table style=\"border-collapse: collapse;\" border=\"0\"><br><colgroup><br><col style=\"width: 277px;\"><br><col style=\"width: 277px;\"></colgroup><br><tbody valign=\"top\"><br><tr><br><td style=\"padding-left: 7px; padding-right: 7px; border: solid 0.5pt;\"><br><p style=\"text-align: center;\"><span style=\"font-size: 10pt;\"><strong>KNN</strong></span></p><br></td><br><td style=\"padding-left: 7px; padding-right: 7px; border-top: solid 0.5pt; border-left: none; border-bottom: solid 0.5pt; border-right: solid 0.5pt;\"><br><p style=\"text-align: center;\"><span style=\"font-size: 10pt;\"><strong>K-Means</strong></span></p><br></td><br></tr><br><tr style=\"height: 85px;\"><br><td style=\"padding-left: 7px; padding-right: 7px; border-top: none; border-left: solid 0.5pt; border-bottom: solid 0.5pt; border-right: solid 0.5pt;\"><span style=\"font-size: 10pt;\">1.KNN是分类算法<br><br></span><p></p><br><p><span style=\"font-size: 10pt;\">2.监督学习<br><br></span></p><br><p style=\"text-align: justify;\"><span style=\"font-size: 10pt;\">3.喂给它的数据集是带label的数据，已经是完全正确的数据</span></p><br></td><br><td style=\"padding-left: 7px; padding-right: 7px; border-top: none; border-left: none; border-bottom: solid 0.5pt; border-right: solid 0.5pt;\"><span style=\"font-size: 10pt;\">1.K-Means是聚类算法<br><br></span><p></p><br><p><span style=\"font-size: 10pt;\">2.非监督学习<br><br></span></p><br><p style=\"text-align: justify;\"><span style=\"font-size: 10pt;\">3.喂给它的数据集是无label的数据，是杂乱无章的，经过聚类后才变得有点顺序，先无序，后有序</span></p><br></td><br></tr><br><tr><br><td style=\"padding-left: 7px; padding-right: 7px; border-top: none; border-left: solid 0.5pt; border-bottom: solid 0.5pt; border-right: solid 0.5pt;\"><span style=\"font-size: 10pt;\">没有明显的前期训练过程，属于memory-based learning</span></td><br><td style=\"padding-left: 7px; padding-right: 7px; border-top: none; border-left: none; border-bottom: solid 0.5pt; border-right: solid 0.5pt;\"><span style=\"font-size: 10pt;\">有明显的前期训练过程</span></td><br></tr><br><tr><br><td style=\"padding-left: 7px; padding-right: 7px; border-top: none; border-left: solid 0.5pt; border-bottom: solid 0.5pt; border-right: solid 0.5pt;\"><span style=\"font-size: 10pt;\">K的含义：来了一个样本x，要给它分类，即求出它的y，就从数据集中，在x附近找离它最近的K个数据点，这K个数据点，类别c占的个数最多，就把x的label设为c</span></td><br><td style=\"padding-left: 7px; padding-right: 7px; border-top: none; border-left: none; border-bottom: solid 0.5pt; border-right: solid 0.5pt;\"><span style=\"font-size: 10pt;\">K的含义：K是人工固定好的数字，假设数据集合可以分为K个簇，由于是依靠人工定好，需要一点先验知识</span></td><br></tr><br><tr><br><td style=\"padding-left: 7px; padding-right: 7px; border-top: none; border-left: solid 0.5pt; border-bottom: solid 0.5pt; border-right: solid 0.5pt;\"></td><br><td style=\"padding-left: 7px; padding-right: 7px; border-top: none; border-left: none; border-bottom: solid 0.5pt; border-right: solid 0.5pt;\"></td><br></tr><br><tr><br><td style=\"padding-left: 7px; padding-right: 7px; border-top: none; border-left: solid 0.5pt; border-bottom: solid 0.5pt; border-right: solid 0.5pt;\" colspan=\"2\"><span style=\"font-size: 10pt;\">相似点：都包含这样的过程，给定一个点，在数据集中找离它最近的点。即二者都用到了NN(Nears Neighbor)算法，一般用KD树来实现NN。</span></td><br></tr><br></tbody><br></table>\n","excerpt":"<p>##KNN(K-Nearest Neighbor)介绍<br>Wikipedia上的<a href=\"http://en.wikipedia.org/wiki/K-nearest_neighbor_algorithm\">KNN词条</a>中有一个比较经典的图如下：</p>\n<img src=\"http://yanjiuyanjiu-wordpress.stor.sinaapp.com/uploads/2013/02/022513_0955_KNNKMeans1.png\">\n<p>KNN的算法过程是是这样的：</p>\n<p>从上图中我们可以看到，图中的数据集是良好的数据，即都打好了label，一类是蓝色的正方形，一类是红色的三角形，那个绿色的圆形是我们待分类的数据。</p>\n<p>如果K=3，那么离绿色点最近的有2个红色三角形和1个蓝色的正方形，这3个点投票，于是绿色的这个待分类点属于红色的三角形。</p>\n<p>如果K=5，那么离绿色点最近的有2个红色三角形和3个蓝色的正方形，这5个点投票，于是绿色的这个待分类点属于蓝色的正方形。（参考 <a href=\"http://coolshell.cn/articles/8052.html\">酷壳的 K Nearest Neighbor 算法</a>）</p>\n<p>我们可以看到，KNN本质是基于一种数据统计的方法！其实很多机器学习算法也是基于数据统计的。</p>","more":"<p>KNN是一种memory-based learning，也叫instance-based learning，属于lazy learning。即它没有明显的前期训练过程，而是程序开始运行时，把数据集加载到内存后，不需要进行训练，就可以开始分类了。</p>\n<p>具体是每次来一个未知的样本点，就在附近找K个最近的点进行投票。</p>\n<p>再举一个例子，Locally weighted regression (LWR)也是一种 memory-based 方法，如下图所示的数据集。</p>\n<img src=\"http://yanjiuyanjiu-wordpress.stor.sinaapp.com/uploads/2013/02/022513_0955_KNNKMeans2.gif\">\n<p>用任何一条直线来模拟这个数据集都是不行的，因为这个数据集看起来不像是一条直线。但是每个局部范围内的数据点，可以认为在一条直线上。每次来了一个位置样本x，我们在X轴上以该数据样本为中心，左右各找几个点，把这几个样本点进行线性回归，算出一条局部的直线，然后把位置样本x代入这条直线，就算出了对应的y，完成了一次线性回归。</p>\n<p>也就是每次来一个数据点，都要训练一条局部直线，也即训练一次，就用一次。</p>\n<p>LWR和KNN是不是很像？都是为位置数据量身定制，在局部进行训练。</p>\n<p>##K-Means介绍<br><img src=\"http://yanjiuyanjiu-wordpress.stor.sinaapp.com/uploads/2013/02/022513_0955_KNNKMeans3.jpg\"></p>\n<p>如图所示，数据样本用圆点表示，每个簇的中心点用叉叉表示。(a)刚开始时是原始数据，杂乱无章，没有label，看起来都一样，都是绿色的。(b)假设数据集可以分为两类，令K=2，随机在坐标上选两个点，作为两个类的中心点。(c-f)演示了聚类的两种迭代。先划分，把每个数据样本划分到最近的中心点那一簇；划分完后，更新每个簇的中心，即把该簇的所有数据点的坐标加起来去平均值。这样不断进行”划分—更新—划分—更新”，直到每个簇的中心不在移动为止。(图文来自Andrew ng的机器学习公开课)。</p>\n<p>推荐关于K-Means的两篇博文，<a href=\"http://coolshell.cn/articles/7779.html\">K-Means 算法 _ 酷壳</a>，<a href=\"http://blog.pluskid.org/?p=17\">漫谈 Clustering (1)_ k-means pluskid</a>。</p>\n<p>##KNN和K-Means的区别</p>\n<table style=\"border-collapse: collapse;\" border=\"0\"><br><colgroup><br><col style=\"width: 277px;\"><br><col style=\"width: 277px;\"></colgroup><br><tbody valign=\"top\"><br><tr><br><td style=\"padding-left: 7px; padding-right: 7px; border: solid 0.5pt;\"><br><p style=\"text-align: center;\"><span style=\"font-size: 10pt;\"><strong>KNN</strong></span></p><br></td><br><td style=\"padding-left: 7px; padding-right: 7px; border-top: solid 0.5pt; border-left: none; border-bottom: solid 0.5pt; border-right: solid 0.5pt;\"><br><p style=\"text-align: center;\"><span style=\"font-size: 10pt;\"><strong>K-Means</strong></span></p><br></td><br></tr><br><tr style=\"height: 85px;\"><br><td style=\"padding-left: 7px; padding-right: 7px; border-top: none; border-left: solid 0.5pt; border-bottom: solid 0.5pt; border-right: solid 0.5pt;\"><span style=\"font-size: 10pt;\">1.KNN是分类算法<br><br></span><p></p><br><p><span style=\"font-size: 10pt;\">2.监督学习<br><br></span></p><br><p style=\"text-align: justify;\"><span style=\"font-size: 10pt;\">3.喂给它的数据集是带label的数据，已经是完全正确的数据</span></p><br></td><br><td style=\"padding-left: 7px; padding-right: 7px; border-top: none; border-left: none; border-bottom: solid 0.5pt; border-right: solid 0.5pt;\"><span style=\"font-size: 10pt;\">1.K-Means是聚类算法<br><br></span><p></p><br><p><span style=\"font-size: 10pt;\">2.非监督学习<br><br></span></p><br><p style=\"text-align: justify;\"><span style=\"font-size: 10pt;\">3.喂给它的数据集是无label的数据，是杂乱无章的，经过聚类后才变得有点顺序，先无序，后有序</span></p><br></td><br></tr><br><tr><br><td style=\"padding-left: 7px; padding-right: 7px; border-top: none; border-left: solid 0.5pt; border-bottom: solid 0.5pt; border-right: solid 0.5pt;\"><span style=\"font-size: 10pt;\">没有明显的前期训练过程，属于memory-based learning</span></td><br><td style=\"padding-left: 7px; padding-right: 7px; border-top: none; border-left: none; border-bottom: solid 0.5pt; border-right: solid 0.5pt;\"><span style=\"font-size: 10pt;\">有明显的前期训练过程</span></td><br></tr><br><tr><br><td style=\"padding-left: 7px; padding-right: 7px; border-top: none; border-left: solid 0.5pt; border-bottom: solid 0.5pt; border-right: solid 0.5pt;\"><span style=\"font-size: 10pt;\">K的含义：来了一个样本x，要给它分类，即求出它的y，就从数据集中，在x附近找离它最近的K个数据点，这K个数据点，类别c占的个数最多，就把x的label设为c</span></td><br><td style=\"padding-left: 7px; padding-right: 7px; border-top: none; border-left: none; border-bottom: solid 0.5pt; border-right: solid 0.5pt;\"><span style=\"font-size: 10pt;\">K的含义：K是人工固定好的数字，假设数据集合可以分为K个簇，由于是依靠人工定好，需要一点先验知识</span></td><br></tr><br><tr><br><td style=\"padding-left: 7px; padding-right: 7px; border-top: none; border-left: solid 0.5pt; border-bottom: solid 0.5pt; border-right: solid 0.5pt;\"></td><br><td style=\"padding-left: 7px; padding-right: 7px; border-top: none; border-left: none; border-bottom: solid 0.5pt; border-right: solid 0.5pt;\"></td><br></tr><br><tr><br><td style=\"padding-left: 7px; padding-right: 7px; border-top: none; border-left: solid 0.5pt; border-bottom: solid 0.5pt; border-right: solid 0.5pt;\" colspan=\"2\"><span style=\"font-size: 10pt;\">相似点：都包含这样的过程，给定一个点，在数据集中找离它最近的点。即二者都用到了NN(Nears Neighbor)算法，一般用KD树来实现NN。</span></td><br></tr><br></tbody><br></table>"},{"layout":"post","title":"机器学习的一些通俗易懂的tutorial","date":"2013-03-27T21:50:00.000Z","comments":1,"_content":"以下记录了我的学习历程，按我的阅读顺序排序。\n\n##Prior, Likelihood, Posterior\nMLAPP第3.2节，讲的很好，用了一个叫 number game 的小游戏做例子，通俗易懂\n\n##距离和相似度度量\n[距离和相似度度量 » webdataanalysis.net](http://webdataanalysis.net/reference-and-source/distance-and-similarity/)\n\n[欧氏距离和余弦相似度的区别是什么？ – 知乎](http://www.zhihu.com/question/19640394)\n\n##KNN(K Nearest Neighbor)\n[K Nearest Neighbor 算法 _ 酷壳 – CoolShell](http://coolshell.cn/articles/8052.html)\n\n[K-nearest neighbors algorithm – Wikipedia](http://en.wikipedia.org/wiki/KNN)\n\n##K-Means\n[K-Means 算法 _ 酷壳 – CoolShell](http://coolshell.cn/articles/7779.html)\n\n[k-means clustering – Wikipedia](http://en.wikipedia.org/wiki/K-means)\n\n[K-Means++ _ 愈宅屋](http://kylen314.blog.com/2012/09/10/k-means/)\n\n[算法杂货铺——k均值聚类(K-means) – T2噬菌体 – 博客园](http://www.cnblogs.com/leoo2sk/archive/2010/09/20/k-means.html)\n\n[漫谈 Clustering (1)_ k-means « Free Mind](http://blog.pluskid.org/?p=17)\n\n[Text Documents Clustering using K-Means Algorithm – CodeProject](http://www.codeproject.com/Articles/439890/Text-Documents-Clustering-using-K-Means-Algorithm)\n\n<!-- more -->\n\n\n##PCA(Principal Components Analysis)\n[2002. Lindsay I Smith. A tutorial on Principal Components Analysis](http://www.ce.yildiz.edu.tr/personal/songul/file/1097/principal_components.pdf)\n\n##因子分析(Factor analysis)\n[因子分析（Factor Analysis）- JerryLead - 博客园](http://www.cnblogs.com/jerrylead/archive/2011/05/11/2043317.html)\n\n\n##期望最大化(EM, Expectation Maximization)\n[2009. Sean Borman. The Expectation Maximization Algorithm A short tutorial](http://www.seanborman.com/publications/EM_algorithm.pdf)\n\n李航.《统计学习方法》，P155 第9章 EM算法及其推广. 2012.\n\n\n##支持向量机(SVM, Support Vector Machines)\n[Andrew Ng. CS229 Lecture notes Support Vector Machines](http://cs229.stanford.edu/notes/cs229-notes3.pdf)\n\n\n##隐马尔科夫模型(Hidden Markov Model, HMM)\n李航《统计学习方法》第10章 隐马尔科夫模型，讲得非常好，有非常具体的例子\n\n\n##条件随机场(CRF, Conditional Random Field)\n[Introduction to Conditional Random Fields](http://blog.echen.me/2012/01/03/introduction-to-conditional-random-fields/)\n\n李航.《统计学习方法》，P192 第11章 条件随机场. 2012.\n\n##LDA\n[LDA数学八卦](http://vdisk.weibo.com/s/bjfcErv7QQc/1384745764)\n\n[正态分布的前世今生](http://vdisk.weibo.com/s/aYEKfaE9OnRv)\n","source":"_posts/2013-03-27-some-classical-machine-learning-tutorials.md","raw":"---\nlayout: post\ntitle: \"机器学习的一些通俗易懂的tutorial\"\ndate: 2013-03-27 21:50\ncomments: true\ncategories: Machine-Learning\n---\n以下记录了我的学习历程，按我的阅读顺序排序。\n\n##Prior, Likelihood, Posterior\nMLAPP第3.2节，讲的很好，用了一个叫 number game 的小游戏做例子，通俗易懂\n\n##距离和相似度度量\n[距离和相似度度量 » webdataanalysis.net](http://webdataanalysis.net/reference-and-source/distance-and-similarity/)\n\n[欧氏距离和余弦相似度的区别是什么？ – 知乎](http://www.zhihu.com/question/19640394)\n\n##KNN(K Nearest Neighbor)\n[K Nearest Neighbor 算法 _ 酷壳 – CoolShell](http://coolshell.cn/articles/8052.html)\n\n[K-nearest neighbors algorithm – Wikipedia](http://en.wikipedia.org/wiki/KNN)\n\n##K-Means\n[K-Means 算法 _ 酷壳 – CoolShell](http://coolshell.cn/articles/7779.html)\n\n[k-means clustering – Wikipedia](http://en.wikipedia.org/wiki/K-means)\n\n[K-Means++ _ 愈宅屋](http://kylen314.blog.com/2012/09/10/k-means/)\n\n[算法杂货铺——k均值聚类(K-means) – T2噬菌体 – 博客园](http://www.cnblogs.com/leoo2sk/archive/2010/09/20/k-means.html)\n\n[漫谈 Clustering (1)_ k-means « Free Mind](http://blog.pluskid.org/?p=17)\n\n[Text Documents Clustering using K-Means Algorithm – CodeProject](http://www.codeproject.com/Articles/439890/Text-Documents-Clustering-using-K-Means-Algorithm)\n\n<!-- more -->\n\n\n##PCA(Principal Components Analysis)\n[2002. Lindsay I Smith. A tutorial on Principal Components Analysis](http://www.ce.yildiz.edu.tr/personal/songul/file/1097/principal_components.pdf)\n\n##因子分析(Factor analysis)\n[因子分析（Factor Analysis）- JerryLead - 博客园](http://www.cnblogs.com/jerrylead/archive/2011/05/11/2043317.html)\n\n\n##期望最大化(EM, Expectation Maximization)\n[2009. Sean Borman. The Expectation Maximization Algorithm A short tutorial](http://www.seanborman.com/publications/EM_algorithm.pdf)\n\n李航.《统计学习方法》，P155 第9章 EM算法及其推广. 2012.\n\n\n##支持向量机(SVM, Support Vector Machines)\n[Andrew Ng. CS229 Lecture notes Support Vector Machines](http://cs229.stanford.edu/notes/cs229-notes3.pdf)\n\n\n##隐马尔科夫模型(Hidden Markov Model, HMM)\n李航《统计学习方法》第10章 隐马尔科夫模型，讲得非常好，有非常具体的例子\n\n\n##条件随机场(CRF, Conditional Random Field)\n[Introduction to Conditional Random Fields](http://blog.echen.me/2012/01/03/introduction-to-conditional-random-fields/)\n\n李航.《统计学习方法》，P192 第11章 条件随机场. 2012.\n\n##LDA\n[LDA数学八卦](http://vdisk.weibo.com/s/bjfcErv7QQc/1384745764)\n\n[正态分布的前世今生](http://vdisk.weibo.com/s/aYEKfaE9OnRv)\n","slug":"2013-03-27-some-classical-machine-learning-tutorials","published":1,"updated":"2016-08-18T09:21:04.000Z","photos":[],"link":"","_id":"cis07pf2o000q01pq3a1o7p73","content":"<p>以下记录了我的学习历程，按我的阅读顺序排序。</p>\n<p>##Prior, Likelihood, Posterior<br>MLAPP第3.2节，讲的很好，用了一个叫 number game 的小游戏做例子，通俗易懂</p>\n<p>##距离和相似度度量<br><a href=\"http://webdataanalysis.net/reference-and-source/distance-and-similarity/\" target=\"_blank\" rel=\"external\">距离和相似度度量 » webdataanalysis.net</a></p>\n<p><a href=\"http://www.zhihu.com/question/19640394\" target=\"_blank\" rel=\"external\">欧氏距离和余弦相似度的区别是什么？ – 知乎</a></p>\n<p>##KNN(K Nearest Neighbor)<br><a href=\"http://coolshell.cn/articles/8052.html\" target=\"_blank\" rel=\"external\">K Nearest Neighbor 算法 _ 酷壳 – CoolShell</a></p>\n<p><a href=\"http://en.wikipedia.org/wiki/KNN\" target=\"_blank\" rel=\"external\">K-nearest neighbors algorithm – Wikipedia</a></p>\n<p>##K-Means<br><a href=\"http://coolshell.cn/articles/7779.html\" target=\"_blank\" rel=\"external\">K-Means 算法 _ 酷壳 – CoolShell</a></p>\n<p><a href=\"http://en.wikipedia.org/wiki/K-means\" target=\"_blank\" rel=\"external\">k-means clustering – Wikipedia</a></p>\n<p><a href=\"http://kylen314.blog.com/2012/09/10/k-means/\" target=\"_blank\" rel=\"external\">K-Means++ _ 愈宅屋</a></p>\n<p><a href=\"http://www.cnblogs.com/leoo2sk/archive/2010/09/20/k-means.html\" target=\"_blank\" rel=\"external\">算法杂货铺——k均值聚类(K-means) – T2噬菌体 – 博客园</a></p>\n<p><a href=\"http://blog.pluskid.org/?p=17\" target=\"_blank\" rel=\"external\">漫谈 Clustering (1)_ k-means « Free Mind</a></p>\n<p><a href=\"http://www.codeproject.com/Articles/439890/Text-Documents-Clustering-using-K-Means-Algorithm\" target=\"_blank\" rel=\"external\">Text Documents Clustering using K-Means Algorithm – CodeProject</a></p>\n<a id=\"more\"></a>\n<p>##PCA(Principal Components Analysis)<br><a href=\"http://www.ce.yildiz.edu.tr/personal/songul/file/1097/principal_components.pdf\" target=\"_blank\" rel=\"external\">2002. Lindsay I Smith. A tutorial on Principal Components Analysis</a></p>\n<p>##因子分析(Factor analysis)<br><a href=\"http://www.cnblogs.com/jerrylead/archive/2011/05/11/2043317.html\" target=\"_blank\" rel=\"external\">因子分析（Factor Analysis）- JerryLead - 博客园</a></p>\n<p>##期望最大化(EM, Expectation Maximization)<br><a href=\"http://www.seanborman.com/publications/EM_algorithm.pdf\" target=\"_blank\" rel=\"external\">2009. Sean Borman. The Expectation Maximization Algorithm A short tutorial</a></p>\n<p>李航.《统计学习方法》，P155 第9章 EM算法及其推广. 2012.</p>\n<p>##支持向量机(SVM, Support Vector Machines)<br><a href=\"http://cs229.stanford.edu/notes/cs229-notes3.pdf\" target=\"_blank\" rel=\"external\">Andrew Ng. CS229 Lecture notes Support Vector Machines</a></p>\n<p>##隐马尔科夫模型(Hidden Markov Model, HMM)<br>李航《统计学习方法》第10章 隐马尔科夫模型，讲得非常好，有非常具体的例子</p>\n<p>##条件随机场(CRF, Conditional Random Field)<br><a href=\"http://blog.echen.me/2012/01/03/introduction-to-conditional-random-fields/\" target=\"_blank\" rel=\"external\">Introduction to Conditional Random Fields</a></p>\n<p>李航.《统计学习方法》，P192 第11章 条件随机场. 2012.</p>\n<p>##LDA<br><a href=\"http://vdisk.weibo.com/s/bjfcErv7QQc/1384745764\" target=\"_blank\" rel=\"external\">LDA数学八卦</a></p>\n<p><a href=\"http://vdisk.weibo.com/s/aYEKfaE9OnRv\" target=\"_blank\" rel=\"external\">正态分布的前世今生</a></p>\n","excerpt":"<p>以下记录了我的学习历程，按我的阅读顺序排序。</p>\n<p>##Prior, Likelihood, Posterior<br>MLAPP第3.2节，讲的很好，用了一个叫 number game 的小游戏做例子，通俗易懂</p>\n<p>##距离和相似度度量<br><a href=\"http://webdataanalysis.net/reference-and-source/distance-and-similarity/\">距离和相似度度量 » webdataanalysis.net</a></p>\n<p><a href=\"http://www.zhihu.com/question/19640394\">欧氏距离和余弦相似度的区别是什么？ – 知乎</a></p>\n<p>##KNN(K Nearest Neighbor)<br><a href=\"http://coolshell.cn/articles/8052.html\">K Nearest Neighbor 算法 _ 酷壳 – CoolShell</a></p>\n<p><a href=\"http://en.wikipedia.org/wiki/KNN\">K-nearest neighbors algorithm – Wikipedia</a></p>\n<p>##K-Means<br><a href=\"http://coolshell.cn/articles/7779.html\">K-Means 算法 _ 酷壳 – CoolShell</a></p>\n<p><a href=\"http://en.wikipedia.org/wiki/K-means\">k-means clustering – Wikipedia</a></p>\n<p><a href=\"http://kylen314.blog.com/2012/09/10/k-means/\">K-Means++ _ 愈宅屋</a></p>\n<p><a href=\"http://www.cnblogs.com/leoo2sk/archive/2010/09/20/k-means.html\">算法杂货铺——k均值聚类(K-means) – T2噬菌体 – 博客园</a></p>\n<p><a href=\"http://blog.pluskid.org/?p=17\">漫谈 Clustering (1)_ k-means « Free Mind</a></p>\n<p><a href=\"http://www.codeproject.com/Articles/439890/Text-Documents-Clustering-using-K-Means-Algorithm\">Text Documents Clustering using K-Means Algorithm – CodeProject</a></p>","more":"<p>##PCA(Principal Components Analysis)<br><a href=\"http://www.ce.yildiz.edu.tr/personal/songul/file/1097/principal_components.pdf\">2002. Lindsay I Smith. A tutorial on Principal Components Analysis</a></p>\n<p>##因子分析(Factor analysis)<br><a href=\"http://www.cnblogs.com/jerrylead/archive/2011/05/11/2043317.html\">因子分析（Factor Analysis）- JerryLead - 博客园</a></p>\n<p>##期望最大化(EM, Expectation Maximization)<br><a href=\"http://www.seanborman.com/publications/EM_algorithm.pdf\">2009. Sean Borman. The Expectation Maximization Algorithm A short tutorial</a></p>\n<p>李航.《统计学习方法》，P155 第9章 EM算法及其推广. 2012.</p>\n<p>##支持向量机(SVM, Support Vector Machines)<br><a href=\"http://cs229.stanford.edu/notes/cs229-notes3.pdf\">Andrew Ng. CS229 Lecture notes Support Vector Machines</a></p>\n<p>##隐马尔科夫模型(Hidden Markov Model, HMM)<br>李航《统计学习方法》第10章 隐马尔科夫模型，讲得非常好，有非常具体的例子</p>\n<p>##条件随机场(CRF, Conditional Random Field)<br><a href=\"http://blog.echen.me/2012/01/03/introduction-to-conditional-random-fields/\">Introduction to Conditional Random Fields</a></p>\n<p>李航.《统计学习方法》，P192 第11章 条件随机场. 2012.</p>\n<p>##LDA<br><a href=\"http://vdisk.weibo.com/s/bjfcErv7QQc/1384745764\">LDA数学八卦</a></p>\n<p><a href=\"http://vdisk.weibo.com/s/aYEKfaE9OnRv\">正态分布的前世今生</a></p>"},{"layout":"post","title":"用VisualVM连接 tomcat 服务器时，如何配置tomcat启动JMX","date":"2012-08-11T21:37:00.000Z","comments":1,"_content":"用VisualVM连接 tomcat 服务器时，需要让tomcat启动JMX，在catalina.sh 中添加一行代码即可：\n\n``` bash\nJAVA_OPTS=”$JAVA_OPTS -Djava.rmi.server.hostname=192.168.0.123 -Dcom.sun.management.jmxremote=true -Dcom.sun.management.jmxremote.port=8086 -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.authenticate=false\n```\n注意，用hostname -i 查看是否为127.0.01，这步非常重要,否则会连接失败，如果是，必须要配置-Djava.rmi.server.hostname。\n\n参考：   \n[Using VisualVM to fix live Tomcat and JVM problems](http://blog.tty.nl/2010/09/03/using-visualvm-to-fix-live-tomcat-and-jvm-problems/)  \n[JVM内存监控:visualVM jconsole jstatd jmap](http://blog.csdn.net/linghunhong/article/details/6438572)\n","source":"_posts/2012-08-11-configure-tomcat-jmx-to-allow-visualvm-connect-tomcat.md","raw":"---\nlayout: post\ntitle: \"用VisualVM连接 tomcat 服务器时，如何配置tomcat启动JMX\"\ndate: 2012-08-11 21:37\ncomments: true\ncategories: Tools\n---\n用VisualVM连接 tomcat 服务器时，需要让tomcat启动JMX，在catalina.sh 中添加一行代码即可：\n\n``` bash\nJAVA_OPTS=”$JAVA_OPTS -Djava.rmi.server.hostname=192.168.0.123 -Dcom.sun.management.jmxremote=true -Dcom.sun.management.jmxremote.port=8086 -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.authenticate=false\n```\n注意，用hostname -i 查看是否为127.0.01，这步非常重要,否则会连接失败，如果是，必须要配置-Djava.rmi.server.hostname。\n\n参考：   \n[Using VisualVM to fix live Tomcat and JVM problems](http://blog.tty.nl/2010/09/03/using-visualvm-to-fix-live-tomcat-and-jvm-problems/)  \n[JVM内存监控:visualVM jconsole jstatd jmap](http://blog.csdn.net/linghunhong/article/details/6438572)\n","slug":"2012-08-11-configure-tomcat-jmx-to-allow-visualvm-connect-tomcat","published":1,"updated":"2016-08-18T09:21:04.000Z","photos":[],"link":"","_id":"cis07pf2w000t01pq7ejnbj9c","content":"<p>用VisualVM连接 tomcat 服务器时，需要让tomcat启动JMX，在catalina.sh 中添加一行代码即可：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">JAVA_OPTS=”<span class=\"variable\">$JAVA_OPTS</span> -Djava.rmi.server.hostname=192.168.0.123 -Dcom.sun.management.jmxremote=<span class=\"literal\">true</span> -Dcom.sun.management.jmxremote.port=8086 -Dcom.sun.management.jmxremote.ssl=<span class=\"literal\">false</span> -Dcom.sun.management.jmxremote.authenticate=<span class=\"literal\">false</span></div></pre></td></tr></table></figure>\n<p>注意，用hostname -i 查看是否为127.0.01，这步非常重要,否则会连接失败，如果是，必须要配置-Djava.rmi.server.hostname。</p>\n<p>参考：<br><a href=\"http://blog.tty.nl/2010/09/03/using-visualvm-to-fix-live-tomcat-and-jvm-problems/\" target=\"_blank\" rel=\"external\">Using VisualVM to fix live Tomcat and JVM problems</a><br><a href=\"http://blog.csdn.net/linghunhong/article/details/6438572\" target=\"_blank\" rel=\"external\">JVM内存监控:visualVM jconsole jstatd jmap</a></p>\n","excerpt":"","more":"<p>用VisualVM连接 tomcat 服务器时，需要让tomcat启动JMX，在catalina.sh 中添加一行代码即可：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">JAVA_OPTS=”<span class=\"variable\">$JAVA_OPTS</span> -Djava.rmi.server.hostname=192.168.0.123 -Dcom.sun.management.jmxremote=<span class=\"literal\">true</span> -Dcom.sun.management.jmxremote.port=8086 -Dcom.sun.management.jmxremote.ssl=<span class=\"literal\">false</span> -Dcom.sun.management.jmxremote.authenticate=<span class=\"literal\">false</span></div></pre></td></tr></table></figure>\n<p>注意，用hostname -i 查看是否为127.0.01，这步非常重要,否则会连接失败，如果是，必须要配置-Djava.rmi.server.hostname。</p>\n<p>参考：<br><a href=\"http://blog.tty.nl/2010/09/03/using-visualvm-to-fix-live-tomcat-and-jvm-problems/\">Using VisualVM to fix live Tomcat and JVM problems</a><br><a href=\"http://blog.csdn.net/linghunhong/article/details/6438572\">JVM内存监控:visualVM jconsole jstatd jmap</a></p>\n"},{"layout":"post","title":"收集的一些精彩的算法GIF动画","date":"2013-04-04T21:57:00.000Z","comments":1,"published":0,"_content":"##牛顿法\n来自 [Newton's method - Wikipedia](http://en.wikipedia.org/wiki/Newton%27s_method)\n\n{% img http://upload.wikimedia.org/wikipedia/commons/thumb/e/e0/NewtonIteration_Ani.gif/300px-NewtonIteration_Ani.gif %}","source":"_posts/2013-04-04-excellent-algorithm-gif-animations.md","raw":"---\nlayout: post\ntitle: \"收集的一些精彩的算法GIF动画\"\ndate: 2013-04-04 21:57\ncomments: true\ncategories: algorithm\npublished: false\n---\n##牛顿法\n来自 [Newton's method - Wikipedia](http://en.wikipedia.org/wiki/Newton%27s_method)\n\n{% img http://upload.wikimedia.org/wikipedia/commons/thumb/e/e0/NewtonIteration_Ani.gif/300px-NewtonIteration_Ani.gif %}","slug":"2013-04-04-excellent-algorithm-gif-animations","updated":"2016-08-18T09:21:04.000Z","photos":[],"link":"","_id":"cis07pf2y000v01pqx5o6blp2","content":"<p>##牛顿法<br>来自 <a href=\"http://en.wikipedia.org/wiki/Newton%27s_method\" target=\"_blank\" rel=\"external\">Newton’s method - Wikipedia</a></p>\n<img src=\"http://upload.wikimedia.org/wikipedia/commons/thumb/e/e0/NewtonIteration_Ani.gif/300px-NewtonIteration_Ani.gif\">","excerpt":"","more":"<p>##牛顿法<br>来自 <a href=\"http://en.wikipedia.org/wiki/Newton%27s_method\">Newton’s method - Wikipedia</a></p>\n<img src=\"http://upload.wikimedia.org/wikipedia/commons/thumb/e/e0/NewtonIteration_Ani.gif/300px-NewtonIteration_Ani.gif\">"},{"layout":"post","title":"数值计算库与科学计算库","date":"2013-02-26T23:15:00.000Z","comments":1,"_content":"##BLAS 接口\n[BLAS](http://www.netlib.org/blas/), [LAPACK](http://www.netlib.org/lapack/), [ATLAS](http://math-atlas.sourceforge.net/) 这些数值计算库的名字很类似，他们之间有什么关系呢？BLAS是一组线性代数运算接口，目前是事实上的标准，很多数值计算/科学计算都实现了这套接口。\n\nBLAS定义了那些函数呢？可以查看[官方文档](http://www.netlib.org/blas/)。\n\nLAPACK是BLAS的第一个实现，是最老牌的数值计算库，用FORTRAN 77语言写的。LAPACK实现了BLAS接口，并扩充了一些功能。很多数值计算库/科学计算库底层调用了LAPACK。\n\n很多硬件厂商都实现BLAS接口，例如[Intel MKL](http://software.intel.com/en-us/intel-mkl)(Math Kernel Library), [AMCL](http://developer.amd.com/tools/cpu-development/amd-core-math-library-acml/)(AMD Math Core Library)等。很多开源库也支持，例如ATLAS。\n\n还有非常多的库实现了BLAS接口，见[Wikipedia BLAS](http://en.wikipedia.org/wiki/Basic_Linear_Algebra_Subprograms) 的Implementations小节。\n\n下面介绍一些各种语言常用的数值计算/科学计算库。\n\n<!-- more -->\n\n##C/C++\n首先是Intel 的MKL 和 AMD 的AMCL，性能一流，不过是商业软件，价格昂贵。\n\n[GSL - GNU Scientific Library](http://www.gnu.org/software/gsl/)，GNU实现的库，质量很高，不过是用纯C写的，用起来比较繁琐。\n\n[Armadillo](http://arma.sourceforge.net/)，最新版 2013-02-20 Version 3.6.3\n\n[IT++](http://itpp.sourceforge.net/)，最后版本是4.2,2010-09-21。\n\n##Java\n这个页面[JavaNumerics page](http://math.nist.gov/javanumerics/)专门收集了关于Java数值计算的库。\n\n[java-matrix-benchmark](https://code.google.com/p/java-matrix-benchmark/)这个开源项目，比较了各类Java线性代数库的性能。\n\nJava的数值计算库主要分为两类：Pure Java和Natie Wrapper。Pure Java是指用纯Java编写的，Native Wrapper是指该库底层调用了C++或Fortan编写的第三方库，上面封装了一层，提供了更有好的接口。\n\nPure Java的有：[Colt](http://dsd.lbl.gov/~hoschek/colt/), [Commons Math](http://commons.apache.org/proper/commons-math/), [EJML](https://code.google.com/p/efficient-java-matrix-library/), [JAMA](http://math.nist.gov/javanumerics/jama/), [Trove](http://trove.starlight-systems.com/)\n\nNative Wrapper有：[jblas](http://jblas.org)，[Matrix Toolkit Java](https://github.com/fommil/matrix-toolkits-java)\n\n下面介绍一些影响力较大的java数值计算/科学计算库。\n\n[Commons Math](http://commons.apache.org/proper/commons-math/), 最新版本是3.1.1,2013年1月9号发布。这个库提供一些基本的数学运算，没有high-level的东西，例如矩阵，向量等，用起来会比较繁琐。\n\n[JAMA](http://math.nist.gov/javanumerics/jama/), 最新版是Version 1.0.3 (November 9, 2012)。\n\n[Colt](http://acs.lbl.gov/software/colt/)，已经不更新了，最后版本是1.2.0，2004年9月发布的。\n\nApache Mahout使用了Colt作为high performance collections，见官方[这个页面](https://cwiki.apache.org/MAHOUT/mahout-collections.html)，说“The implementation of Mahout Collections is derived from Cern Colt”，以及quora 这个帖子[What are the best resources for distributed numerical analysis/matrix algorithms](http://www.quora.com/Distributed-Algorithms/What-are-the-best-resources-for-distributed-numerical-analysis-matrix-algorithms)。\n\n##Python\n目前最有影响力的莫过于[NumPy](http://www.numpy.org/)和[SciPy](http://www.scipy.org/)。Amazon.com上可以搜到专门讲它们的书。\n\nSciPy依赖NumPy，主要是在数值计算方面调用了NumPy。\n\n##Ruby\n[SciRuby](http://sciruby.com/), 是SciPy和NumPy的克隆，目前还在开发中。\n\n##R\nR刚开始时是统计学家开发的语言，专门用于数理统计，现在功能不断增强，内置了很多数值计算和科学计算的功能。R在数据分析领域比较火。\n\n##Scala\n目前用google搜索 “scala numerical computing”，能找得到的就是[ScalaLab](http://code.google.com/p/scalalab/)了。\n\n##Matlab\n最后，别忘了Matlab是支持多语言调用的。\n\n可以用Matlab生成DLL，给C/C++语言调用。其实，凡是能调用DLL的语言，都可以使用这个DLL，例如Python, Ruby等。\n\n可以用[Matlab JavaBuilder](http://www.mathworks.cn/products/javabuilder/)将m文件转换为jar文件，然后在java代码中就可以调用了。\n\n##如何选择\n本文的重点在于选择一个高性能，同时又比较易用的库，即被让我们调用，用来写程序的库，不是一个集成环境或REPL环境。因此R和Matlab不在讨论范围内。R和Matlab用来做原型或前期Data Exploration比较适合。\n\n选择一个工具（语言，框架，库等），要看其是否成熟。我个人的一些判断指标，主要有\n\n1. 有没有大厂商的支持（作为vendor之类的）；\n2. amazon.com上能否搜到书。\n\n从厂商的支持来看，几个主要的大厂商如 Intel，AMD和Apple都开发了自己的数学库。Python则有很成熟的NumPy，在Amazon上能搜到书，例如“SciPy and NumPy”， “NumPy Cookbook”。 因此，目前来看，C++和Python是比较成熟的方案。\n\n##参考资料\n[Wikipedia BLAS](http://en.wikipedia.org/wiki/Basic_Linear_Algebra_Subprograms)  \n[Wikipedia LAPACK](http://en.wikipedia.org/wiki/LAPACK)  \n[用 BLAS/LAPACK 编写矩阵运算程序](http://blog.henix.info/blog/blas-lapack-do-matrix-operation.html)  \n[BLAS, LAPACK, ATLAS](https://wikis.utexas.edu/display/~cdupree/BLAS,+LAPACK,+ATLAS)  \n[BLAS 和 LAPACK ，以及其他常用数值计算库](http://hi.baidu.com/luckykele2012/item/6a3b25423018c40d6dc2f090)  \n[Any numerical computing environment on Java platform](http://fdatamining.blogspot.com/2011/10/any-numerical-computing-environment-on.html)  \n[C++ Libraries for Scientific Computing](http://www.myoutsourcedbrain.com/2009/04/c-libraries-for-numerical-processing.html)  \n[Scientific Library Options for C or C++](http://stackoverflow.com/questions/3121139/scientific-library-options-for-c-or-c)  \n[Why is Python used for high-performance/scientific computing (but Ruby isn't)?](http://programmers.stackexchange.com/questions/138643/why-is-python-used-for-high-performance-scientific-computing-but-ruby-isnt)  \n\n","source":"_posts/2013-02-26-numerical-or-scientific-computation-library.md","raw":"---\nlayout: post\ntitle: \"数值计算库与科学计算库\"\ndate: 2013-02-26 23:15\ncomments: true\ncategories: Machine-Learning\n---\n##BLAS 接口\n[BLAS](http://www.netlib.org/blas/), [LAPACK](http://www.netlib.org/lapack/), [ATLAS](http://math-atlas.sourceforge.net/) 这些数值计算库的名字很类似，他们之间有什么关系呢？BLAS是一组线性代数运算接口，目前是事实上的标准，很多数值计算/科学计算都实现了这套接口。\n\nBLAS定义了那些函数呢？可以查看[官方文档](http://www.netlib.org/blas/)。\n\nLAPACK是BLAS的第一个实现，是最老牌的数值计算库，用FORTRAN 77语言写的。LAPACK实现了BLAS接口，并扩充了一些功能。很多数值计算库/科学计算库底层调用了LAPACK。\n\n很多硬件厂商都实现BLAS接口，例如[Intel MKL](http://software.intel.com/en-us/intel-mkl)(Math Kernel Library), [AMCL](http://developer.amd.com/tools/cpu-development/amd-core-math-library-acml/)(AMD Math Core Library)等。很多开源库也支持，例如ATLAS。\n\n还有非常多的库实现了BLAS接口，见[Wikipedia BLAS](http://en.wikipedia.org/wiki/Basic_Linear_Algebra_Subprograms) 的Implementations小节。\n\n下面介绍一些各种语言常用的数值计算/科学计算库。\n\n<!-- more -->\n\n##C/C++\n首先是Intel 的MKL 和 AMD 的AMCL，性能一流，不过是商业软件，价格昂贵。\n\n[GSL - GNU Scientific Library](http://www.gnu.org/software/gsl/)，GNU实现的库，质量很高，不过是用纯C写的，用起来比较繁琐。\n\n[Armadillo](http://arma.sourceforge.net/)，最新版 2013-02-20 Version 3.6.3\n\n[IT++](http://itpp.sourceforge.net/)，最后版本是4.2,2010-09-21。\n\n##Java\n这个页面[JavaNumerics page](http://math.nist.gov/javanumerics/)专门收集了关于Java数值计算的库。\n\n[java-matrix-benchmark](https://code.google.com/p/java-matrix-benchmark/)这个开源项目，比较了各类Java线性代数库的性能。\n\nJava的数值计算库主要分为两类：Pure Java和Natie Wrapper。Pure Java是指用纯Java编写的，Native Wrapper是指该库底层调用了C++或Fortan编写的第三方库，上面封装了一层，提供了更有好的接口。\n\nPure Java的有：[Colt](http://dsd.lbl.gov/~hoschek/colt/), [Commons Math](http://commons.apache.org/proper/commons-math/), [EJML](https://code.google.com/p/efficient-java-matrix-library/), [JAMA](http://math.nist.gov/javanumerics/jama/), [Trove](http://trove.starlight-systems.com/)\n\nNative Wrapper有：[jblas](http://jblas.org)，[Matrix Toolkit Java](https://github.com/fommil/matrix-toolkits-java)\n\n下面介绍一些影响力较大的java数值计算/科学计算库。\n\n[Commons Math](http://commons.apache.org/proper/commons-math/), 最新版本是3.1.1,2013年1月9号发布。这个库提供一些基本的数学运算，没有high-level的东西，例如矩阵，向量等，用起来会比较繁琐。\n\n[JAMA](http://math.nist.gov/javanumerics/jama/), 最新版是Version 1.0.3 (November 9, 2012)。\n\n[Colt](http://acs.lbl.gov/software/colt/)，已经不更新了，最后版本是1.2.0，2004年9月发布的。\n\nApache Mahout使用了Colt作为high performance collections，见官方[这个页面](https://cwiki.apache.org/MAHOUT/mahout-collections.html)，说“The implementation of Mahout Collections is derived from Cern Colt”，以及quora 这个帖子[What are the best resources for distributed numerical analysis/matrix algorithms](http://www.quora.com/Distributed-Algorithms/What-are-the-best-resources-for-distributed-numerical-analysis-matrix-algorithms)。\n\n##Python\n目前最有影响力的莫过于[NumPy](http://www.numpy.org/)和[SciPy](http://www.scipy.org/)。Amazon.com上可以搜到专门讲它们的书。\n\nSciPy依赖NumPy，主要是在数值计算方面调用了NumPy。\n\n##Ruby\n[SciRuby](http://sciruby.com/), 是SciPy和NumPy的克隆，目前还在开发中。\n\n##R\nR刚开始时是统计学家开发的语言，专门用于数理统计，现在功能不断增强，内置了很多数值计算和科学计算的功能。R在数据分析领域比较火。\n\n##Scala\n目前用google搜索 “scala numerical computing”，能找得到的就是[ScalaLab](http://code.google.com/p/scalalab/)了。\n\n##Matlab\n最后，别忘了Matlab是支持多语言调用的。\n\n可以用Matlab生成DLL，给C/C++语言调用。其实，凡是能调用DLL的语言，都可以使用这个DLL，例如Python, Ruby等。\n\n可以用[Matlab JavaBuilder](http://www.mathworks.cn/products/javabuilder/)将m文件转换为jar文件，然后在java代码中就可以调用了。\n\n##如何选择\n本文的重点在于选择一个高性能，同时又比较易用的库，即被让我们调用，用来写程序的库，不是一个集成环境或REPL环境。因此R和Matlab不在讨论范围内。R和Matlab用来做原型或前期Data Exploration比较适合。\n\n选择一个工具（语言，框架，库等），要看其是否成熟。我个人的一些判断指标，主要有\n\n1. 有没有大厂商的支持（作为vendor之类的）；\n2. amazon.com上能否搜到书。\n\n从厂商的支持来看，几个主要的大厂商如 Intel，AMD和Apple都开发了自己的数学库。Python则有很成熟的NumPy，在Amazon上能搜到书，例如“SciPy and NumPy”， “NumPy Cookbook”。 因此，目前来看，C++和Python是比较成熟的方案。\n\n##参考资料\n[Wikipedia BLAS](http://en.wikipedia.org/wiki/Basic_Linear_Algebra_Subprograms)  \n[Wikipedia LAPACK](http://en.wikipedia.org/wiki/LAPACK)  \n[用 BLAS/LAPACK 编写矩阵运算程序](http://blog.henix.info/blog/blas-lapack-do-matrix-operation.html)  \n[BLAS, LAPACK, ATLAS](https://wikis.utexas.edu/display/~cdupree/BLAS,+LAPACK,+ATLAS)  \n[BLAS 和 LAPACK ，以及其他常用数值计算库](http://hi.baidu.com/luckykele2012/item/6a3b25423018c40d6dc2f090)  \n[Any numerical computing environment on Java platform](http://fdatamining.blogspot.com/2011/10/any-numerical-computing-environment-on.html)  \n[C++ Libraries for Scientific Computing](http://www.myoutsourcedbrain.com/2009/04/c-libraries-for-numerical-processing.html)  \n[Scientific Library Options for C or C++](http://stackoverflow.com/questions/3121139/scientific-library-options-for-c-or-c)  \n[Why is Python used for high-performance/scientific computing (but Ruby isn't)?](http://programmers.stackexchange.com/questions/138643/why-is-python-used-for-high-performance-scientific-computing-but-ruby-isnt)  \n\n","slug":"2013-02-26-numerical-or-scientific-computation-library","published":1,"updated":"2016-08-18T09:21:04.000Z","photos":[],"link":"","_id":"cis07pf2z000y01pqe6l2wfjh","content":"<p>##BLAS 接口<br><a href=\"http://www.netlib.org/blas/\" target=\"_blank\" rel=\"external\">BLAS</a>, <a href=\"http://www.netlib.org/lapack/\" target=\"_blank\" rel=\"external\">LAPACK</a>, <a href=\"http://math-atlas.sourceforge.net/\" target=\"_blank\" rel=\"external\">ATLAS</a> 这些数值计算库的名字很类似，他们之间有什么关系呢？BLAS是一组线性代数运算接口，目前是事实上的标准，很多数值计算/科学计算都实现了这套接口。</p>\n<p>BLAS定义了那些函数呢？可以查看<a href=\"http://www.netlib.org/blas/\" target=\"_blank\" rel=\"external\">官方文档</a>。</p>\n<p>LAPACK是BLAS的第一个实现，是最老牌的数值计算库，用FORTRAN 77语言写的。LAPACK实现了BLAS接口，并扩充了一些功能。很多数值计算库/科学计算库底层调用了LAPACK。</p>\n<p>很多硬件厂商都实现BLAS接口，例如<a href=\"http://software.intel.com/en-us/intel-mkl\" target=\"_blank\" rel=\"external\">Intel MKL</a>(Math Kernel Library), <a href=\"http://developer.amd.com/tools/cpu-development/amd-core-math-library-acml/\" target=\"_blank\" rel=\"external\">AMCL</a>(AMD Math Core Library)等。很多开源库也支持，例如ATLAS。</p>\n<p>还有非常多的库实现了BLAS接口，见<a href=\"http://en.wikipedia.org/wiki/Basic_Linear_Algebra_Subprograms\" target=\"_blank\" rel=\"external\">Wikipedia BLAS</a> 的Implementations小节。</p>\n<p>下面介绍一些各种语言常用的数值计算/科学计算库。</p>\n<a id=\"more\"></a>\n<p>##C/C++<br>首先是Intel 的MKL 和 AMD 的AMCL，性能一流，不过是商业软件，价格昂贵。</p>\n<p><a href=\"http://www.gnu.org/software/gsl/\" target=\"_blank\" rel=\"external\">GSL - GNU Scientific Library</a>，GNU实现的库，质量很高，不过是用纯C写的，用起来比较繁琐。</p>\n<p><a href=\"http://arma.sourceforge.net/\" target=\"_blank\" rel=\"external\">Armadillo</a>，最新版 2013-02-20 Version 3.6.3</p>\n<p><a href=\"http://itpp.sourceforge.net/\" target=\"_blank\" rel=\"external\">IT++</a>，最后版本是4.2,2010-09-21。</p>\n<p>##Java<br>这个页面<a href=\"http://math.nist.gov/javanumerics/\" target=\"_blank\" rel=\"external\">JavaNumerics page</a>专门收集了关于Java数值计算的库。</p>\n<p><a href=\"https://code.google.com/p/java-matrix-benchmark/\" target=\"_blank\" rel=\"external\">java-matrix-benchmark</a>这个开源项目，比较了各类Java线性代数库的性能。</p>\n<p>Java的数值计算库主要分为两类：Pure Java和Natie Wrapper。Pure Java是指用纯Java编写的，Native Wrapper是指该库底层调用了C++或Fortan编写的第三方库，上面封装了一层，提供了更有好的接口。</p>\n<p>Pure Java的有：<a href=\"http://dsd.lbl.gov/~hoschek/colt/\" target=\"_blank\" rel=\"external\">Colt</a>, <a href=\"http://commons.apache.org/proper/commons-math/\" target=\"_blank\" rel=\"external\">Commons Math</a>, <a href=\"https://code.google.com/p/efficient-java-matrix-library/\" target=\"_blank\" rel=\"external\">EJML</a>, <a href=\"http://math.nist.gov/javanumerics/jama/\" target=\"_blank\" rel=\"external\">JAMA</a>, <a href=\"http://trove.starlight-systems.com/\" target=\"_blank\" rel=\"external\">Trove</a></p>\n<p>Native Wrapper有：<a href=\"http://jblas.org\" target=\"_blank\" rel=\"external\">jblas</a>，<a href=\"https://github.com/fommil/matrix-toolkits-java\" target=\"_blank\" rel=\"external\">Matrix Toolkit Java</a></p>\n<p>下面介绍一些影响力较大的java数值计算/科学计算库。</p>\n<p><a href=\"http://commons.apache.org/proper/commons-math/\" target=\"_blank\" rel=\"external\">Commons Math</a>, 最新版本是3.1.1,2013年1月9号发布。这个库提供一些基本的数学运算，没有high-level的东西，例如矩阵，向量等，用起来会比较繁琐。</p>\n<p><a href=\"http://math.nist.gov/javanumerics/jama/\" target=\"_blank\" rel=\"external\">JAMA</a>, 最新版是Version 1.0.3 (November 9, 2012)。</p>\n<p><a href=\"http://acs.lbl.gov/software/colt/\" target=\"_blank\" rel=\"external\">Colt</a>，已经不更新了，最后版本是1.2.0，2004年9月发布的。</p>\n<p>Apache Mahout使用了Colt作为high performance collections，见官方<a href=\"https://cwiki.apache.org/MAHOUT/mahout-collections.html\" target=\"_blank\" rel=\"external\">这个页面</a>，说“The implementation of Mahout Collections is derived from Cern Colt”，以及quora 这个帖子<a href=\"http://www.quora.com/Distributed-Algorithms/What-are-the-best-resources-for-distributed-numerical-analysis-matrix-algorithms\" target=\"_blank\" rel=\"external\">What are the best resources for distributed numerical analysis/matrix algorithms</a>。</p>\n<p>##Python<br>目前最有影响力的莫过于<a href=\"http://www.numpy.org/\" target=\"_blank\" rel=\"external\">NumPy</a>和<a href=\"http://www.scipy.org/\" target=\"_blank\" rel=\"external\">SciPy</a>。Amazon.com上可以搜到专门讲它们的书。</p>\n<p>SciPy依赖NumPy，主要是在数值计算方面调用了NumPy。</p>\n<p>##Ruby<br><a href=\"http://sciruby.com/\" target=\"_blank\" rel=\"external\">SciRuby</a>, 是SciPy和NumPy的克隆，目前还在开发中。</p>\n<p>##R<br>R刚开始时是统计学家开发的语言，专门用于数理统计，现在功能不断增强，内置了很多数值计算和科学计算的功能。R在数据分析领域比较火。</p>\n<p>##Scala<br>目前用google搜索 “scala numerical computing”，能找得到的就是<a href=\"http://code.google.com/p/scalalab/\" target=\"_blank\" rel=\"external\">ScalaLab</a>了。</p>\n<p>##Matlab<br>最后，别忘了Matlab是支持多语言调用的。</p>\n<p>可以用Matlab生成DLL，给C/C++语言调用。其实，凡是能调用DLL的语言，都可以使用这个DLL，例如Python, Ruby等。</p>\n<p>可以用<a href=\"http://www.mathworks.cn/products/javabuilder/\" target=\"_blank\" rel=\"external\">Matlab JavaBuilder</a>将m文件转换为jar文件，然后在java代码中就可以调用了。</p>\n<p>##如何选择<br>本文的重点在于选择一个高性能，同时又比较易用的库，即被让我们调用，用来写程序的库，不是一个集成环境或REPL环境。因此R和Matlab不在讨论范围内。R和Matlab用来做原型或前期Data Exploration比较适合。</p>\n<p>选择一个工具（语言，框架，库等），要看其是否成熟。我个人的一些判断指标，主要有</p>\n<ol>\n<li>有没有大厂商的支持（作为vendor之类的）；</li>\n<li>amazon.com上能否搜到书。</li>\n</ol>\n<p>从厂商的支持来看，几个主要的大厂商如 Intel，AMD和Apple都开发了自己的数学库。Python则有很成熟的NumPy，在Amazon上能搜到书，例如“SciPy and NumPy”， “NumPy Cookbook”。 因此，目前来看，C++和Python是比较成熟的方案。</p>\n<p>##参考资料<br><a href=\"http://en.wikipedia.org/wiki/Basic_Linear_Algebra_Subprograms\" target=\"_blank\" rel=\"external\">Wikipedia BLAS</a><br><a href=\"http://en.wikipedia.org/wiki/LAPACK\" target=\"_blank\" rel=\"external\">Wikipedia LAPACK</a><br><a href=\"http://blog.henix.info/blog/blas-lapack-do-matrix-operation.html\" target=\"_blank\" rel=\"external\">用 BLAS/LAPACK 编写矩阵运算程序</a><br><a href=\"https://wikis.utexas.edu/display/~cdupree/BLAS,+LAPACK,+ATLAS\" target=\"_blank\" rel=\"external\">BLAS, LAPACK, ATLAS</a><br><a href=\"http://hi.baidu.com/luckykele2012/item/6a3b25423018c40d6dc2f090\" target=\"_blank\" rel=\"external\">BLAS 和 LAPACK ，以及其他常用数值计算库</a><br><a href=\"http://fdatamining.blogspot.com/2011/10/any-numerical-computing-environment-on.html\" target=\"_blank\" rel=\"external\">Any numerical computing environment on Java platform</a><br><a href=\"http://www.myoutsourcedbrain.com/2009/04/c-libraries-for-numerical-processing.html\" target=\"_blank\" rel=\"external\">C++ Libraries for Scientific Computing</a><br><a href=\"http://stackoverflow.com/questions/3121139/scientific-library-options-for-c-or-c\" target=\"_blank\" rel=\"external\">Scientific Library Options for C or C++</a><br><a href=\"http://programmers.stackexchange.com/questions/138643/why-is-python-used-for-high-performance-scientific-computing-but-ruby-isnt\" target=\"_blank\" rel=\"external\">Why is Python used for high-performance/scientific computing (but Ruby isn’t)?</a>  </p>\n","excerpt":"<p>##BLAS 接口<br><a href=\"http://www.netlib.org/blas/\">BLAS</a>, <a href=\"http://www.netlib.org/lapack/\">LAPACK</a>, <a href=\"http://math-atlas.sourceforge.net/\">ATLAS</a> 这些数值计算库的名字很类似，他们之间有什么关系呢？BLAS是一组线性代数运算接口，目前是事实上的标准，很多数值计算/科学计算都实现了这套接口。</p>\n<p>BLAS定义了那些函数呢？可以查看<a href=\"http://www.netlib.org/blas/\">官方文档</a>。</p>\n<p>LAPACK是BLAS的第一个实现，是最老牌的数值计算库，用FORTRAN 77语言写的。LAPACK实现了BLAS接口，并扩充了一些功能。很多数值计算库/科学计算库底层调用了LAPACK。</p>\n<p>很多硬件厂商都实现BLAS接口，例如<a href=\"http://software.intel.com/en-us/intel-mkl\">Intel MKL</a>(Math Kernel Library), <a href=\"http://developer.amd.com/tools/cpu-development/amd-core-math-library-acml/\">AMCL</a>(AMD Math Core Library)等。很多开源库也支持，例如ATLAS。</p>\n<p>还有非常多的库实现了BLAS接口，见<a href=\"http://en.wikipedia.org/wiki/Basic_Linear_Algebra_Subprograms\">Wikipedia BLAS</a> 的Implementations小节。</p>\n<p>下面介绍一些各种语言常用的数值计算/科学计算库。</p>","more":"<p>##C/C++<br>首先是Intel 的MKL 和 AMD 的AMCL，性能一流，不过是商业软件，价格昂贵。</p>\n<p><a href=\"http://www.gnu.org/software/gsl/\">GSL - GNU Scientific Library</a>，GNU实现的库，质量很高，不过是用纯C写的，用起来比较繁琐。</p>\n<p><a href=\"http://arma.sourceforge.net/\">Armadillo</a>，最新版 2013-02-20 Version 3.6.3</p>\n<p><a href=\"http://itpp.sourceforge.net/\">IT++</a>，最后版本是4.2,2010-09-21。</p>\n<p>##Java<br>这个页面<a href=\"http://math.nist.gov/javanumerics/\">JavaNumerics page</a>专门收集了关于Java数值计算的库。</p>\n<p><a href=\"https://code.google.com/p/java-matrix-benchmark/\">java-matrix-benchmark</a>这个开源项目，比较了各类Java线性代数库的性能。</p>\n<p>Java的数值计算库主要分为两类：Pure Java和Natie Wrapper。Pure Java是指用纯Java编写的，Native Wrapper是指该库底层调用了C++或Fortan编写的第三方库，上面封装了一层，提供了更有好的接口。</p>\n<p>Pure Java的有：<a href=\"http://dsd.lbl.gov/~hoschek/colt/\">Colt</a>, <a href=\"http://commons.apache.org/proper/commons-math/\">Commons Math</a>, <a href=\"https://code.google.com/p/efficient-java-matrix-library/\">EJML</a>, <a href=\"http://math.nist.gov/javanumerics/jama/\">JAMA</a>, <a href=\"http://trove.starlight-systems.com/\">Trove</a></p>\n<p>Native Wrapper有：<a href=\"http://jblas.org\">jblas</a>，<a href=\"https://github.com/fommil/matrix-toolkits-java\">Matrix Toolkit Java</a></p>\n<p>下面介绍一些影响力较大的java数值计算/科学计算库。</p>\n<p><a href=\"http://commons.apache.org/proper/commons-math/\">Commons Math</a>, 最新版本是3.1.1,2013年1月9号发布。这个库提供一些基本的数学运算，没有high-level的东西，例如矩阵，向量等，用起来会比较繁琐。</p>\n<p><a href=\"http://math.nist.gov/javanumerics/jama/\">JAMA</a>, 最新版是Version 1.0.3 (November 9, 2012)。</p>\n<p><a href=\"http://acs.lbl.gov/software/colt/\">Colt</a>，已经不更新了，最后版本是1.2.0，2004年9月发布的。</p>\n<p>Apache Mahout使用了Colt作为high performance collections，见官方<a href=\"https://cwiki.apache.org/MAHOUT/mahout-collections.html\">这个页面</a>，说“The implementation of Mahout Collections is derived from Cern Colt”，以及quora 这个帖子<a href=\"http://www.quora.com/Distributed-Algorithms/What-are-the-best-resources-for-distributed-numerical-analysis-matrix-algorithms\">What are the best resources for distributed numerical analysis/matrix algorithms</a>。</p>\n<p>##Python<br>目前最有影响力的莫过于<a href=\"http://www.numpy.org/\">NumPy</a>和<a href=\"http://www.scipy.org/\">SciPy</a>。Amazon.com上可以搜到专门讲它们的书。</p>\n<p>SciPy依赖NumPy，主要是在数值计算方面调用了NumPy。</p>\n<p>##Ruby<br><a href=\"http://sciruby.com/\">SciRuby</a>, 是SciPy和NumPy的克隆，目前还在开发中。</p>\n<p>##R<br>R刚开始时是统计学家开发的语言，专门用于数理统计，现在功能不断增强，内置了很多数值计算和科学计算的功能。R在数据分析领域比较火。</p>\n<p>##Scala<br>目前用google搜索 “scala numerical computing”，能找得到的就是<a href=\"http://code.google.com/p/scalalab/\">ScalaLab</a>了。</p>\n<p>##Matlab<br>最后，别忘了Matlab是支持多语言调用的。</p>\n<p>可以用Matlab生成DLL，给C/C++语言调用。其实，凡是能调用DLL的语言，都可以使用这个DLL，例如Python, Ruby等。</p>\n<p>可以用<a href=\"http://www.mathworks.cn/products/javabuilder/\">Matlab JavaBuilder</a>将m文件转换为jar文件，然后在java代码中就可以调用了。</p>\n<p>##如何选择<br>本文的重点在于选择一个高性能，同时又比较易用的库，即被让我们调用，用来写程序的库，不是一个集成环境或REPL环境。因此R和Matlab不在讨论范围内。R和Matlab用来做原型或前期Data Exploration比较适合。</p>\n<p>选择一个工具（语言，框架，库等），要看其是否成熟。我个人的一些判断指标，主要有</p>\n<ol>\n<li>有没有大厂商的支持（作为vendor之类的）；</li>\n<li>amazon.com上能否搜到书。</li>\n</ol>\n<p>从厂商的支持来看，几个主要的大厂商如 Intel，AMD和Apple都开发了自己的数学库。Python则有很成熟的NumPy，在Amazon上能搜到书，例如“SciPy and NumPy”， “NumPy Cookbook”。 因此，目前来看，C++和Python是比较成熟的方案。</p>\n<p>##参考资料<br><a href=\"http://en.wikipedia.org/wiki/Basic_Linear_Algebra_Subprograms\">Wikipedia BLAS</a><br><a href=\"http://en.wikipedia.org/wiki/LAPACK\">Wikipedia LAPACK</a><br><a href=\"http://blog.henix.info/blog/blas-lapack-do-matrix-operation.html\">用 BLAS/LAPACK 编写矩阵运算程序</a><br><a href=\"https://wikis.utexas.edu/display/~cdupree/BLAS,+LAPACK,+ATLAS\">BLAS, LAPACK, ATLAS</a><br><a href=\"http://hi.baidu.com/luckykele2012/item/6a3b25423018c40d6dc2f090\">BLAS 和 LAPACK ，以及其他常用数值计算库</a><br><a href=\"http://fdatamining.blogspot.com/2011/10/any-numerical-computing-environment-on.html\">Any numerical computing environment on Java platform</a><br><a href=\"http://www.myoutsourcedbrain.com/2009/04/c-libraries-for-numerical-processing.html\">C++ Libraries for Scientific Computing</a><br><a href=\"http://stackoverflow.com/questions/3121139/scientific-library-options-for-c-or-c\">Scientific Library Options for C or C++</a><br><a href=\"http://programmers.stackexchange.com/questions/138643/why-is-python-used-for-high-performance-scientific-computing-but-ruby-isnt\">Why is Python used for high-performance/scientific computing (but Ruby isn’t)?</a>  </p>"},{"layout":"post","title":"使用github + Octopress 搭建免费博客","date":"2013-04-01T15:14:00.000Z","comments":1,"share":true,"_content":"### 前提条件\n注册一个github账号。\n\n任何资料，都不如[Octopress](http://octopress.org/docs/) 和[Github Pages](https://help.github.com/categories/20/articles)的官方文档，建议首先阅读官方文档。\n\n### GitHub Pages快速体验\n在GitHub网站上，点击右上角的+号图标，创建一个新的Repo，Repository 的名字必须为 username.github.com。然后点击Settings进入该Repo的设置页面。看到\"Automatic Page Generator\"，说明这个Repo已经启用了GitHub Page。点击按钮进入设置。\n\n在\"Create a GitHub User Page\"填写一些基本信息，点击右下角的\"Continue to Layout\"。布局就用默认的，点击绿色的\"Publish\"按钮。\n\n大功告成，输入\"username.github.com\"，看到一个页面没？这就是你刚刚创建的一个页面。\n\n<!--more-->\n\nGitHub Pages分为两种类型，一种是\"User and Org Pages\"，一种是\"Project Pages\"。前者是用户的主页，一个用户仅有一个。后者是每个项目的主页。见github page官方的文档 [Creating Pages with the automatic generator](https://help.github.com/articles/user-organization-and-project-pages)。\n\n本文创建的是第一种类型。\n\n这篇博客 [搭建一个免费的，无限流量的Blog----github Pages和Jekyll入门 - 阮一峰的网络日志](http://www.ruanyifeng.com/blog/2012/08/blogging_with_jekyll.html)  很通俗易懂，不过它创建的是第二种类型，在一个Repo上新建了一个branch，并命名为gh-pages。\n\n下面正式开始折腾。\n\n### 安装 msysgit并配置\n\n* 下载[msysgit](http://msysgit.github.com/), 然后双击exe文件开始安装。\n* 双击桌面图标Git Bash，启动一个shell，输入如下命令进行配置：\n\n产生公钥ssh key，默认全部回车\n\n``` bash\n    ssh-keygen -C github-account-email -t rsa\n```\n\n\nNote: username@email.com需要更换成你自己的在Github上注册的Email地址。\n这样会在用户目录(C:\\Documents and Settings\\UserName)下产生一个.ssh文件夹，里面为对应的SSH Keys，其中id_rsa.pub是Github需要的SSH公钥文件。\n\n在Github的Account Settings里选择SSH Keys，在其中将id_rsa.pub文件里内容拷贝至 其中的Key里。\n\n这样以后就可以直接使用Git和GitHub了。  \n    \n测试一下\n\n``` bash  \nssh -T git@github.com\n```  \n\n如果出现 hi xxx! You've successfully authenticated, bug GitHub does not povide shell access。说明SSH链接成功。\n\n接下来配置其他信息。\n\n``` bash  \n\tgit config --global user.name github-username  \n\tgit config --global user.email github-account-email  \n\tgit config --global github.user github-username  \n\tgit config --global credential.helper cache  \n\tgit config --global credential.helper 'cache --timeout=3600'\n```\n本节参考了 [msysGit 安装后的配置](http://www.cnblogs.com/kysnail/archive/2012/03/16/2399589.html)。\n\n\n### 安装Octopress\n参考官方文档[setup](http://octopress.org/docs/setup/).  \n**安装Ruby**  \nOctopress 2.0 需要 Ruby 1.9.3，安装其他版本的Ruby可能会行不通。\n\n如果是Linux，使用RVM来安装Ruby，如果是Windows，则使用[RubyInstaller](http://rubyinstaller.org/downloads/)。在这个[下载页面](http://rubyinstaller.org/downloads/)下载Ruby 1.9.3-p392和DevKit(DevKit-tdm-32-4.5.2-20111229-1559-sfx.exe)，双击exe文件进行安装。  \n**安装DevKit**  \n双击DevKit的exe文件，解压到C:\\DevKit，在CMD下执行如下命令\n\n``` bash  \ncd C:\\DevKit\nruby dk.rb init\nruby dk.rb install\ngem install rdiscount --platform=ruby\n```\n  \n**安装Octopress**  \n下载Octopress。\n\n``` bash  \ncd d:\\github  \ngit clone git://github.com/imathis/octopress.git octopress  \ncd octopress  \nruby --version  # Should report Ruby 1.9.3\nrbenv rehash  # 可选，如果安装了rbenv，就需要执行这一步\n```  \n\n**注意**: rubygems.org在中国的下载速度很慢，会导致bundle install这一步下载gems的速度很慢，可能需要等待几个小时。因此需要事先切换到国内的镜像源。\n\n用记事本打开octopress目录下的Gemfile，将第一行修改为\n\n> source \"http://ruby.taobao.org\"\n\n然后可以开始安装依赖的gems了。\n\n``` bash  \nbundle install\n```  \n正常的话应该可以看到一行行的Installing xxx，表示正在安装所需要的gem。\n\n安装默认的Octopress主题。\n\n``` bash  \nrake install\n```  \n如果这一步出现问题，则试一下 bundle update再执行 rake install。\n\n### 部署到GitHub\n将Octopress和自己的Repo关联起来\n\n``` bash  \nrake setup_github_pages\n```  \n编译生成JeKyll所需要的静态文件\n\n``` bash  \nrake generate\n```  \n这个命令主要是根据source目录的内容，编译生成JeKyll所需要的静态文件，存放到public目录下。source 目录对应着git上的source分支。\n\n**UTF-8 编码**  \nWindows预设是Big5编码,所以要想’rake generate’的时候不报编码错误,我们需要设置一下编码! 方法有两个,一个是直接在Git Bash中设置环境:\n\n``` bash  \nset LANG=zh_CN.UTF-8  \nset LC_ALL=zh_CN.UTF-8\n```  \n还有一个是在环境变量中加入这两个变量: 右击电脑->属性，新添加LANG和LC\\_ALL两个环境变量，值为为zh_CN.UTF-8.\n\n然后在Git Bash中做如下设置:\n\n``` bash  \necho \"export LANG LC_ALL\" > ~/.bash_profile\n```\n\n预览\n\n``` bash  \nrake preview\n```\n用浏览器打开 <http://localhost:4000/>，就可以看到效果了。\n\n部署到github\n\n``` bash  \nrake deploy\n```  \n该命令首先清空\\_deploy目录，然后将public目录整个拷贝过来，然后commit到github。\\_deploy 目录对应着master分支。\n\n备份source到github\n\n```\ngit add .\ngit commit -m 'your message'\ngit push origin source\n```\nsource 目录下保存了所有的markdown源文件，是博客的原始数据，以及一些模板文件。因此很有必要备份。用上述命令提交到github，这样就用git管理起来了，再也不用担心数据丢失了。\n\n**终止预览**  \n启用`rake preview`后，直接按`ctrl+c`无法正常终止该进程，老提示`终止批处理操作吗（Y/N）？`，这时候可以另开一个Git Bash窗口，使用`ps aux | grep ruby`命令找出`pid(第一个数值)`，然后执行`kill <pid>`来停止该进程(参考[octopress on heroku (二)](http://linuxabc.heroku.com/blog/octopress-on-heroku-2))。  \n\n  \n### 绑定域名\n参考官方文档[Setting up a custom domain with Pages](https://help.github.com/articles/setting-up-a-custom-domain-with-pages)。\n\n非常简单，在`source`目录下，添加一个文本文件，名字为CNAME，里面的内容就是要绑定的域名，例如本博客CNAME文件的内容是：\n\n> www.yanjiuyanjiu.com\n\n然后去DNSPod，添加一条CNAME，指向 username.github.com。例如我的为：\n\n```\nwww\tCNAME\t默认\tsoulmachine.github.com.\t\t-\t600\n```\n\n很多人喜欢去掉www，用xxx.com的形式来访问，不过大家去试一下，在浏览器输入qq.com, douban.com, baidu.com，发现都会自动跳转到www，也就是说这些大网站，目前也是用www.example.com的域名为主，因此建议大家也这样做。\n\n用www, blog之类的二级域名，还有个好处是方便升级，比如新版本用www1指向，等测试完成后，改成www指向，无缝切换。\n\n如何让example.com 自动变成www.example.com呢？需要用 301重定向，在DNSPod上非常简单，添加一条显性URL即可，例如我的是：\n\n```\n@\t显性URL\t默认\thttp://www.yanjiuyanjiu.com\t-\t600\n```\n\n在使用Octopress的时候，每次`rake generate`, `rake deploy`后，master分支下面的CNAME文件消失了。正确的做法是，把CNAME文件放到在 source 目录下，其余的都删掉，`rake generate` 会自动拷贝到public目录下，`rake deploy`再拷贝public目录内容到\\_deploy目录，并提交到master分支。\n\n\n\n### 参考资料\n1. [【原创】用Github和Octopress搭建博客](http://corey600.github.com/blog/2013/02/28/use-github-and-octopress-create-blog/)\n1. [试用Octopress](http://www.blogjava.net/lishunli/archive/2012/03/18/372115.html)\n1. [windows下安装DevKit](http://rubyer.me/blog/134/)\n1. [在新Windows系统中重新部署Octopress](http://blog.sprabbit.com/blog/2012/12/21/recover-octopress/)\n1. [Windows 8安装Octopress记录](http://hivan.me/octopress-install-to-windows8/)\n1. [关于在64位 Windows 7 中部署中文化的Octopress](http://blog.sprabbit.com/blog/2012/03/23/octopress/)\n","source":"_posts/2013-04-01-using-github-and-octoperss-to-create-a-free-blog.md","raw":"---\nlayout: post\ntitle: \"使用github + Octopress 搭建免费博客\"\ndate: 2013-04-01 15:14\ncomments: true\nshare: true\ncategories: Tools\n---\n### 前提条件\n注册一个github账号。\n\n任何资料，都不如[Octopress](http://octopress.org/docs/) 和[Github Pages](https://help.github.com/categories/20/articles)的官方文档，建议首先阅读官方文档。\n\n### GitHub Pages快速体验\n在GitHub网站上，点击右上角的+号图标，创建一个新的Repo，Repository 的名字必须为 username.github.com。然后点击Settings进入该Repo的设置页面。看到\"Automatic Page Generator\"，说明这个Repo已经启用了GitHub Page。点击按钮进入设置。\n\n在\"Create a GitHub User Page\"填写一些基本信息，点击右下角的\"Continue to Layout\"。布局就用默认的，点击绿色的\"Publish\"按钮。\n\n大功告成，输入\"username.github.com\"，看到一个页面没？这就是你刚刚创建的一个页面。\n\n<!--more-->\n\nGitHub Pages分为两种类型，一种是\"User and Org Pages\"，一种是\"Project Pages\"。前者是用户的主页，一个用户仅有一个。后者是每个项目的主页。见github page官方的文档 [Creating Pages with the automatic generator](https://help.github.com/articles/user-organization-and-project-pages)。\n\n本文创建的是第一种类型。\n\n这篇博客 [搭建一个免费的，无限流量的Blog----github Pages和Jekyll入门 - 阮一峰的网络日志](http://www.ruanyifeng.com/blog/2012/08/blogging_with_jekyll.html)  很通俗易懂，不过它创建的是第二种类型，在一个Repo上新建了一个branch，并命名为gh-pages。\n\n下面正式开始折腾。\n\n### 安装 msysgit并配置\n\n* 下载[msysgit](http://msysgit.github.com/), 然后双击exe文件开始安装。\n* 双击桌面图标Git Bash，启动一个shell，输入如下命令进行配置：\n\n产生公钥ssh key，默认全部回车\n\n``` bash\n    ssh-keygen -C github-account-email -t rsa\n```\n\n\nNote: username@email.com需要更换成你自己的在Github上注册的Email地址。\n这样会在用户目录(C:\\Documents and Settings\\UserName)下产生一个.ssh文件夹，里面为对应的SSH Keys，其中id_rsa.pub是Github需要的SSH公钥文件。\n\n在Github的Account Settings里选择SSH Keys，在其中将id_rsa.pub文件里内容拷贝至 其中的Key里。\n\n这样以后就可以直接使用Git和GitHub了。  \n    \n测试一下\n\n``` bash  \nssh -T git@github.com\n```  \n\n如果出现 hi xxx! You've successfully authenticated, bug GitHub does not povide shell access。说明SSH链接成功。\n\n接下来配置其他信息。\n\n``` bash  \n\tgit config --global user.name github-username  \n\tgit config --global user.email github-account-email  \n\tgit config --global github.user github-username  \n\tgit config --global credential.helper cache  \n\tgit config --global credential.helper 'cache --timeout=3600'\n```\n本节参考了 [msysGit 安装后的配置](http://www.cnblogs.com/kysnail/archive/2012/03/16/2399589.html)。\n\n\n### 安装Octopress\n参考官方文档[setup](http://octopress.org/docs/setup/).  \n**安装Ruby**  \nOctopress 2.0 需要 Ruby 1.9.3，安装其他版本的Ruby可能会行不通。\n\n如果是Linux，使用RVM来安装Ruby，如果是Windows，则使用[RubyInstaller](http://rubyinstaller.org/downloads/)。在这个[下载页面](http://rubyinstaller.org/downloads/)下载Ruby 1.9.3-p392和DevKit(DevKit-tdm-32-4.5.2-20111229-1559-sfx.exe)，双击exe文件进行安装。  \n**安装DevKit**  \n双击DevKit的exe文件，解压到C:\\DevKit，在CMD下执行如下命令\n\n``` bash  \ncd C:\\DevKit\nruby dk.rb init\nruby dk.rb install\ngem install rdiscount --platform=ruby\n```\n  \n**安装Octopress**  \n下载Octopress。\n\n``` bash  \ncd d:\\github  \ngit clone git://github.com/imathis/octopress.git octopress  \ncd octopress  \nruby --version  # Should report Ruby 1.9.3\nrbenv rehash  # 可选，如果安装了rbenv，就需要执行这一步\n```  \n\n**注意**: rubygems.org在中国的下载速度很慢，会导致bundle install这一步下载gems的速度很慢，可能需要等待几个小时。因此需要事先切换到国内的镜像源。\n\n用记事本打开octopress目录下的Gemfile，将第一行修改为\n\n> source \"http://ruby.taobao.org\"\n\n然后可以开始安装依赖的gems了。\n\n``` bash  \nbundle install\n```  \n正常的话应该可以看到一行行的Installing xxx，表示正在安装所需要的gem。\n\n安装默认的Octopress主题。\n\n``` bash  \nrake install\n```  \n如果这一步出现问题，则试一下 bundle update再执行 rake install。\n\n### 部署到GitHub\n将Octopress和自己的Repo关联起来\n\n``` bash  \nrake setup_github_pages\n```  \n编译生成JeKyll所需要的静态文件\n\n``` bash  \nrake generate\n```  \n这个命令主要是根据source目录的内容，编译生成JeKyll所需要的静态文件，存放到public目录下。source 目录对应着git上的source分支。\n\n**UTF-8 编码**  \nWindows预设是Big5编码,所以要想’rake generate’的时候不报编码错误,我们需要设置一下编码! 方法有两个,一个是直接在Git Bash中设置环境:\n\n``` bash  \nset LANG=zh_CN.UTF-8  \nset LC_ALL=zh_CN.UTF-8\n```  \n还有一个是在环境变量中加入这两个变量: 右击电脑->属性，新添加LANG和LC\\_ALL两个环境变量，值为为zh_CN.UTF-8.\n\n然后在Git Bash中做如下设置:\n\n``` bash  \necho \"export LANG LC_ALL\" > ~/.bash_profile\n```\n\n预览\n\n``` bash  \nrake preview\n```\n用浏览器打开 <http://localhost:4000/>，就可以看到效果了。\n\n部署到github\n\n``` bash  \nrake deploy\n```  \n该命令首先清空\\_deploy目录，然后将public目录整个拷贝过来，然后commit到github。\\_deploy 目录对应着master分支。\n\n备份source到github\n\n```\ngit add .\ngit commit -m 'your message'\ngit push origin source\n```\nsource 目录下保存了所有的markdown源文件，是博客的原始数据，以及一些模板文件。因此很有必要备份。用上述命令提交到github，这样就用git管理起来了，再也不用担心数据丢失了。\n\n**终止预览**  \n启用`rake preview`后，直接按`ctrl+c`无法正常终止该进程，老提示`终止批处理操作吗（Y/N）？`，这时候可以另开一个Git Bash窗口，使用`ps aux | grep ruby`命令找出`pid(第一个数值)`，然后执行`kill <pid>`来停止该进程(参考[octopress on heroku (二)](http://linuxabc.heroku.com/blog/octopress-on-heroku-2))。  \n\n  \n### 绑定域名\n参考官方文档[Setting up a custom domain with Pages](https://help.github.com/articles/setting-up-a-custom-domain-with-pages)。\n\n非常简单，在`source`目录下，添加一个文本文件，名字为CNAME，里面的内容就是要绑定的域名，例如本博客CNAME文件的内容是：\n\n> www.yanjiuyanjiu.com\n\n然后去DNSPod，添加一条CNAME，指向 username.github.com。例如我的为：\n\n```\nwww\tCNAME\t默认\tsoulmachine.github.com.\t\t-\t600\n```\n\n很多人喜欢去掉www，用xxx.com的形式来访问，不过大家去试一下，在浏览器输入qq.com, douban.com, baidu.com，发现都会自动跳转到www，也就是说这些大网站，目前也是用www.example.com的域名为主，因此建议大家也这样做。\n\n用www, blog之类的二级域名，还有个好处是方便升级，比如新版本用www1指向，等测试完成后，改成www指向，无缝切换。\n\n如何让example.com 自动变成www.example.com呢？需要用 301重定向，在DNSPod上非常简单，添加一条显性URL即可，例如我的是：\n\n```\n@\t显性URL\t默认\thttp://www.yanjiuyanjiu.com\t-\t600\n```\n\n在使用Octopress的时候，每次`rake generate`, `rake deploy`后，master分支下面的CNAME文件消失了。正确的做法是，把CNAME文件放到在 source 目录下，其余的都删掉，`rake generate` 会自动拷贝到public目录下，`rake deploy`再拷贝public目录内容到\\_deploy目录，并提交到master分支。\n\n\n\n### 参考资料\n1. [【原创】用Github和Octopress搭建博客](http://corey600.github.com/blog/2013/02/28/use-github-and-octopress-create-blog/)\n1. [试用Octopress](http://www.blogjava.net/lishunli/archive/2012/03/18/372115.html)\n1. [windows下安装DevKit](http://rubyer.me/blog/134/)\n1. [在新Windows系统中重新部署Octopress](http://blog.sprabbit.com/blog/2012/12/21/recover-octopress/)\n1. [Windows 8安装Octopress记录](http://hivan.me/octopress-install-to-windows8/)\n1. [关于在64位 Windows 7 中部署中文化的Octopress](http://blog.sprabbit.com/blog/2012/03/23/octopress/)\n","slug":"2013-04-01-using-github-and-octoperss-to-create-a-free-blog","published":1,"updated":"2016-08-18T09:21:04.000Z","photos":[],"link":"","_id":"cis07pf30001001pqcalznrdr","content":"<h3 id=\"前提条件\"><a href=\"#前提条件\" class=\"headerlink\" title=\"前提条件\"></a>前提条件</h3><p>注册一个github账号。</p>\n<p>任何资料，都不如<a href=\"http://octopress.org/docs/\" target=\"_blank\" rel=\"external\">Octopress</a> 和<a href=\"https://help.github.com/categories/20/articles\" target=\"_blank\" rel=\"external\">Github Pages</a>的官方文档，建议首先阅读官方文档。</p>\n<h3 id=\"GitHub-Pages快速体验\"><a href=\"#GitHub-Pages快速体验\" class=\"headerlink\" title=\"GitHub Pages快速体验\"></a>GitHub Pages快速体验</h3><p>在GitHub网站上，点击右上角的+号图标，创建一个新的Repo，Repository 的名字必须为 username.github.com。然后点击Settings进入该Repo的设置页面。看到”Automatic Page Generator”，说明这个Repo已经启用了GitHub Page。点击按钮进入设置。</p>\n<p>在”Create a GitHub User Page”填写一些基本信息，点击右下角的”Continue to Layout”。布局就用默认的，点击绿色的”Publish”按钮。</p>\n<p>大功告成，输入”username.github.com”，看到一个页面没？这就是你刚刚创建的一个页面。</p>\n<a id=\"more\"></a>\n<p>GitHub Pages分为两种类型，一种是”User and Org Pages”，一种是”Project Pages”。前者是用户的主页，一个用户仅有一个。后者是每个项目的主页。见github page官方的文档 <a href=\"https://help.github.com/articles/user-organization-and-project-pages\" target=\"_blank\" rel=\"external\">Creating Pages with the automatic generator</a>。</p>\n<p>本文创建的是第一种类型。</p>\n<p>这篇博客 <a href=\"http://www.ruanyifeng.com/blog/2012/08/blogging_with_jekyll.html\" target=\"_blank\" rel=\"external\">搭建一个免费的，无限流量的Blog—-github Pages和Jekyll入门 - 阮一峰的网络日志</a>  很通俗易懂，不过它创建的是第二种类型，在一个Repo上新建了一个branch，并命名为gh-pages。</p>\n<p>下面正式开始折腾。</p>\n<h3 id=\"安装-msysgit并配置\"><a href=\"#安装-msysgit并配置\" class=\"headerlink\" title=\"安装 msysgit并配置\"></a>安装 msysgit并配置</h3><ul>\n<li>下载<a href=\"http://msysgit.github.com/\" target=\"_blank\" rel=\"external\">msysgit</a>, 然后双击exe文件开始安装。</li>\n<li>双击桌面图标Git Bash，启动一个shell，输入如下命令进行配置：</li>\n</ul>\n<p>产生公钥ssh key，默认全部回车</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">ssh-keygen -C github-account-email -t rsa</div></pre></td></tr></table></figure>\n<p>Note: username@email.com需要更换成你自己的在Github上注册的Email地址。<br>这样会在用户目录(C:\\Documents and Settings\\UserName)下产生一个.ssh文件夹，里面为对应的SSH Keys，其中id_rsa.pub是Github需要的SSH公钥文件。</p>\n<p>在Github的Account Settings里选择SSH Keys，在其中将id_rsa.pub文件里内容拷贝至 其中的Key里。</p>\n<p>这样以后就可以直接使用Git和GitHub了。  </p>\n<p>测试一下</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div></pre></td><td class=\"code\"><pre><div class=\"line\">ssh -T git@github.com</div><div class=\"line\">```  </div><div class=\"line\"></div><div class=\"line\">如果出现 hi xxx! You<span class=\"string\">'ve successfully authenticated, bug GitHub does not povide shell access。说明SSH链接成功。</span></div><div class=\"line\"></div><div class=\"line\">接下来配置其他信息。</div><div class=\"line\"></div><div class=\"line\">``` bash  </div><div class=\"line\">\tgit config --global user.name github-username  </div><div class=\"line\">\tgit config --global user.email github-account-email  </div><div class=\"line\">\tgit config --global github.user github-username  </div><div class=\"line\">\tgit config --global credential.helper cache  </div><div class=\"line\">\tgit config --global credential.helper 'cache --timeout=3600<span class=\"string\">'</span></div></pre></td></tr></table></figure>\n<p>本节参考了 <a href=\"http://www.cnblogs.com/kysnail/archive/2012/03/16/2399589.html\" target=\"_blank\" rel=\"external\">msysGit 安装后的配置</a>。</p>\n<h3 id=\"安装Octopress\"><a href=\"#安装Octopress\" class=\"headerlink\" title=\"安装Octopress\"></a>安装Octopress</h3><p>参考官方文档<a href=\"http://octopress.org/docs/setup/\" target=\"_blank\" rel=\"external\">setup</a>.<br><strong>安装Ruby</strong><br>Octopress 2.0 需要 Ruby 1.9.3，安装其他版本的Ruby可能会行不通。</p>\n<p>如果是Linux，使用RVM来安装Ruby，如果是Windows，则使用<a href=\"http://rubyinstaller.org/downloads/\" target=\"_blank\" rel=\"external\">RubyInstaller</a>。在这个<a href=\"http://rubyinstaller.org/downloads/\" target=\"_blank\" rel=\"external\">下载页面</a>下载Ruby 1.9.3-p392和DevKit(DevKit-tdm-32-4.5.2-20111229-1559-sfx.exe)，双击exe文件进行安装。<br><strong>安装DevKit</strong><br>双击DevKit的exe文件，解压到C:\\DevKit，在CMD下执行如下命令</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"built_in\">cd</span> C:\\DevKit</div><div class=\"line\">ruby dk.rb init</div><div class=\"line\">ruby dk.rb install</div><div class=\"line\">gem install rdiscount --platform=ruby</div></pre></td></tr></table></figure>\n<p><strong>安装Octopress</strong><br>下载Octopress。</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div><div class=\"line\">51</div><div class=\"line\">52</div><div class=\"line\">53</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"built_in\">cd</span> d:\\github  </div><div class=\"line\">git <span class=\"built_in\">clone</span> git://github.com/imathis/octopress.git octopress  </div><div class=\"line\"><span class=\"built_in\">cd</span> octopress  </div><div class=\"line\">ruby --version  <span class=\"comment\"># Should report Ruby 1.9.3</span></div><div class=\"line\">rbenv <span class=\"built_in\">rehash</span>  <span class=\"comment\"># 可选，如果安装了rbenv，就需要执行这一步</span></div><div class=\"line\">```  </div><div class=\"line\"></div><div class=\"line\">**注意**: rubygems.org在中国的下载速度很慢，会导致bundle install这一步下载gems的速度很慢，可能需要等待几个小时。因此需要事先切换到国内的镜像源。</div><div class=\"line\"></div><div class=\"line\">用记事本打开octopress目录下的Gemfile，将第一行修改为</div><div class=\"line\"></div><div class=\"line\">&gt; <span class=\"built_in\">source</span> <span class=\"string\">\"http://ruby.taobao.org\"</span></div><div class=\"line\"></div><div class=\"line\">然后可以开始安装依赖的gems了。</div><div class=\"line\"></div><div class=\"line\">``` bash  </div><div class=\"line\">bundle install</div><div class=\"line\">```  </div><div class=\"line\">正常的话应该可以看到一行行的Installing xxx，表示正在安装所需要的gem。</div><div class=\"line\"></div><div class=\"line\">安装默认的Octopress主题。</div><div class=\"line\"></div><div class=\"line\">``` bash  </div><div class=\"line\">rake install</div><div class=\"line\">```  </div><div class=\"line\">如果这一步出现问题，则试一下 bundle update再执行 rake install。</div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\">### 部署到GitHub</span></div><div class=\"line\">将Octopress和自己的Repo关联起来</div><div class=\"line\"></div><div class=\"line\">``` bash  </div><div class=\"line\">rake setup_github_pages</div><div class=\"line\">```  </div><div class=\"line\">编译生成JeKyll所需要的静态文件</div><div class=\"line\"></div><div class=\"line\">``` bash  </div><div class=\"line\">rake generate</div><div class=\"line\">```  </div><div class=\"line\">这个命令主要是根据<span class=\"built_in\">source</span>目录的内容，编译生成JeKyll所需要的静态文件，存放到public目录下。<span class=\"built_in\">source</span> 目录对应着git上的<span class=\"built_in\">source</span>分支。</div><div class=\"line\"></div><div class=\"line\">**UTF-8 编码**  </div><div class=\"line\">Windows预设是Big5编码,所以要想’rake generate’的时候不报编码错误,我们需要设置一下编码! 方法有两个,一个是直接在Git Bash中设置环境:</div><div class=\"line\"></div><div class=\"line\">``` bash  </div><div class=\"line\"><span class=\"built_in\">set</span> LANG=zh_CN.UTF-8  </div><div class=\"line\"><span class=\"built_in\">set</span> LC_ALL=zh_CN.UTF-8</div><div class=\"line\">```  </div><div class=\"line\">还有一个是在环境变量中加入这两个变量: 右击电脑-&gt;属性，新添加LANG和LC\\_ALL两个环境变量，值为为zh_CN.UTF-8.</div><div class=\"line\"></div><div class=\"line\">然后在Git Bash中做如下设置:</div><div class=\"line\"></div><div class=\"line\">``` bash  </div><div class=\"line\"><span class=\"built_in\">echo</span> <span class=\"string\">\"export LANG LC_ALL\"</span> &gt; ~/.bash_profile</div></pre></td></tr></table></figure>\n<p>预览</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">rake preview</div></pre></td></tr></table></figure>\n<p>用浏览器打开 <a href=\"http://localhost:4000/\" target=\"_blank\" rel=\"external\">http://localhost:4000/</a>，就可以看到效果了。</p>\n<p>部署到github</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\">rake deploy</div><div class=\"line\">```  </div><div class=\"line\">该命令首先清空\\_deploy目录，然后将public目录整个拷贝过来，然后commit到github。\\_deploy 目录对应着master分支。</div><div class=\"line\"></div><div class=\"line\">备份<span class=\"built_in\">source</span>到github</div></pre></td></tr></table></figure>\n<p>git add .<br>git commit -m ‘your message’<br>git push origin source<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div></pre></td><td class=\"code\"><pre><div class=\"line\">source 目录下保存了所有的markdown源文件，是博客的原始数据，以及一些模板文件。因此很有必要备份。用上述命令提交到github，这样就用git管理起来了，再也不用担心数据丢失了。</div><div class=\"line\"></div><div class=\"line\">**终止预览**  </div><div class=\"line\">启用`rake preview`后，直接按`ctrl+c`无法正常终止该进程，老提示`终止批处理操作吗（Y/N）？`，这时候可以另开一个Git Bash窗口，使用`ps aux | grep ruby`命令找出`pid(第一个数值)`，然后执行`kill &lt;pid&gt;`来停止该进程(参考[octopress on heroku (二)](http://linuxabc.heroku.com/blog/octopress-on-heroku-2))。  </div><div class=\"line\"></div><div class=\"line\">  </div><div class=\"line\">### 绑定域名</div><div class=\"line\">参考官方文档[Setting up a custom domain with Pages](https://help.github.com/articles/setting-up-a-custom-domain-with-pages)。</div><div class=\"line\"></div><div class=\"line\">非常简单，在`source`目录下，添加一个文本文件，名字为CNAME，里面的内容就是要绑定的域名，例如本博客CNAME文件的内容是：</div><div class=\"line\"></div><div class=\"line\">&gt; www.yanjiuyanjiu.com</div><div class=\"line\"></div><div class=\"line\">然后去DNSPod，添加一条CNAME，指向 username.github.com。例如我的为：</div></pre></td></tr></table></figure></p>\n<p>www    CNAME    默认    soulmachine.github.com.        -    600<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div></pre></td><td class=\"code\"><pre><div class=\"line\"></div><div class=\"line\">很多人喜欢去掉www，用xxx.com的形式来访问，不过大家去试一下，在浏览器输入qq.com, douban.com, baidu.com，发现都会自动跳转到www，也就是说这些大网站，目前也是用www.example.com的域名为主，因此建议大家也这样做。</div><div class=\"line\"></div><div class=\"line\">用www, blog之类的二级域名，还有个好处是方便升级，比如新版本用www1指向，等测试完成后，改成www指向，无缝切换。</div><div class=\"line\"></div><div class=\"line\">如何让example.com 自动变成www.example.com呢？需要用 301重定向，在DNSPod上非常简单，添加一条显性URL即可，例如我的是：</div></pre></td></tr></table></figure></p>\n<p>@    显性URL    默认    <a href=\"http://www.yanjiuyanjiu.com\" target=\"_blank\" rel=\"external\">http://www.yanjiuyanjiu.com</a>    -    600<br>```</p>\n<p>在使用Octopress的时候，每次<code>rake generate</code>, <code>rake deploy</code>后，master分支下面的CNAME文件消失了。正确的做法是，把CNAME文件放到在 source 目录下，其余的都删掉，<code>rake generate</code> 会自动拷贝到public目录下，<code>rake deploy</code>再拷贝public目录内容到_deploy目录，并提交到master分支。</p>\n<h3 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h3><ol>\n<li><a href=\"http://corey600.github.com/blog/2013/02/28/use-github-and-octopress-create-blog/\" target=\"_blank\" rel=\"external\">【原创】用Github和Octopress搭建博客</a></li>\n<li><a href=\"http://www.blogjava.net/lishunli/archive/2012/03/18/372115.html\" target=\"_blank\" rel=\"external\">试用Octopress</a></li>\n<li><a href=\"http://rubyer.me/blog/134/\" target=\"_blank\" rel=\"external\">windows下安装DevKit</a></li>\n<li><a href=\"http://blog.sprabbit.com/blog/2012/12/21/recover-octopress/\" target=\"_blank\" rel=\"external\">在新Windows系统中重新部署Octopress</a></li>\n<li><a href=\"http://hivan.me/octopress-install-to-windows8/\" target=\"_blank\" rel=\"external\">Windows 8安装Octopress记录</a></li>\n<li><a href=\"http://blog.sprabbit.com/blog/2012/03/23/octopress/\" target=\"_blank\" rel=\"external\">关于在64位 Windows 7 中部署中文化的Octopress</a></li>\n</ol>\n","excerpt":"<h3 id=\"前提条件\"><a href=\"#前提条件\" class=\"headerlink\" title=\"前提条件\"></a>前提条件</h3><p>注册一个github账号。</p>\n<p>任何资料，都不如<a href=\"http://octopress.org/docs/\">Octopress</a> 和<a href=\"https://help.github.com/categories/20/articles\">Github Pages</a>的官方文档，建议首先阅读官方文档。</p>\n<h3 id=\"GitHub-Pages快速体验\"><a href=\"#GitHub-Pages快速体验\" class=\"headerlink\" title=\"GitHub Pages快速体验\"></a>GitHub Pages快速体验</h3><p>在GitHub网站上，点击右上角的+号图标，创建一个新的Repo，Repository 的名字必须为 username.github.com。然后点击Settings进入该Repo的设置页面。看到”Automatic Page Generator”，说明这个Repo已经启用了GitHub Page。点击按钮进入设置。</p>\n<p>在”Create a GitHub User Page”填写一些基本信息，点击右下角的”Continue to Layout”。布局就用默认的，点击绿色的”Publish”按钮。</p>\n<p>大功告成，输入”username.github.com”，看到一个页面没？这就是你刚刚创建的一个页面。</p>","more":"<p>GitHub Pages分为两种类型，一种是”User and Org Pages”，一种是”Project Pages”。前者是用户的主页，一个用户仅有一个。后者是每个项目的主页。见github page官方的文档 <a href=\"https://help.github.com/articles/user-organization-and-project-pages\">Creating Pages with the automatic generator</a>。</p>\n<p>本文创建的是第一种类型。</p>\n<p>这篇博客 <a href=\"http://www.ruanyifeng.com/blog/2012/08/blogging_with_jekyll.html\">搭建一个免费的，无限流量的Blog—-github Pages和Jekyll入门 - 阮一峰的网络日志</a>  很通俗易懂，不过它创建的是第二种类型，在一个Repo上新建了一个branch，并命名为gh-pages。</p>\n<p>下面正式开始折腾。</p>\n<h3 id=\"安装-msysgit并配置\"><a href=\"#安装-msysgit并配置\" class=\"headerlink\" title=\"安装 msysgit并配置\"></a>安装 msysgit并配置</h3><ul>\n<li>下载<a href=\"http://msysgit.github.com/\">msysgit</a>, 然后双击exe文件开始安装。</li>\n<li>双击桌面图标Git Bash，启动一个shell，输入如下命令进行配置：</li>\n</ul>\n<p>产生公钥ssh key，默认全部回车</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">ssh-keygen -C github-account-email -t rsa</div></pre></td></tr></table></figure>\n<p>Note: username@email.com需要更换成你自己的在Github上注册的Email地址。<br>这样会在用户目录(C:\\Documents and Settings\\UserName)下产生一个.ssh文件夹，里面为对应的SSH Keys，其中id_rsa.pub是Github需要的SSH公钥文件。</p>\n<p>在Github的Account Settings里选择SSH Keys，在其中将id_rsa.pub文件里内容拷贝至 其中的Key里。</p>\n<p>这样以后就可以直接使用Git和GitHub了。  </p>\n<p>测试一下</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div></pre></td><td class=\"code\"><pre><div class=\"line\">ssh -T git@github.com</div><div class=\"line\">```  </div><div class=\"line\"></div><div class=\"line\">如果出现 hi xxx! You<span class=\"string\">'ve successfully authenticated, bug GitHub does not povide shell access。说明SSH链接成功。</div><div class=\"line\"></div><div class=\"line\">接下来配置其他信息。</div><div class=\"line\"></div><div class=\"line\">``` bash  </div><div class=\"line\">\tgit config --global user.name github-username  </div><div class=\"line\">\tgit config --global user.email github-account-email  </div><div class=\"line\">\tgit config --global github.user github-username  </div><div class=\"line\">\tgit config --global credential.helper cache  </div><div class=\"line\">\tgit config --global credential.helper '</span>cache --timeout=3600<span class=\"string\">'</span></div></pre></td></tr></table></figure>\n<p>本节参考了 <a href=\"http://www.cnblogs.com/kysnail/archive/2012/03/16/2399589.html\">msysGit 安装后的配置</a>。</p>\n<h3 id=\"安装Octopress\"><a href=\"#安装Octopress\" class=\"headerlink\" title=\"安装Octopress\"></a>安装Octopress</h3><p>参考官方文档<a href=\"http://octopress.org/docs/setup/\">setup</a>.<br><strong>安装Ruby</strong><br>Octopress 2.0 需要 Ruby 1.9.3，安装其他版本的Ruby可能会行不通。</p>\n<p>如果是Linux，使用RVM来安装Ruby，如果是Windows，则使用<a href=\"http://rubyinstaller.org/downloads/\">RubyInstaller</a>。在这个<a href=\"http://rubyinstaller.org/downloads/\">下载页面</a>下载Ruby 1.9.3-p392和DevKit(DevKit-tdm-32-4.5.2-20111229-1559-sfx.exe)，双击exe文件进行安装。<br><strong>安装DevKit</strong><br>双击DevKit的exe文件，解压到C:\\DevKit，在CMD下执行如下命令</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"built_in\">cd</span> C:\\DevKit</div><div class=\"line\">ruby dk.rb init</div><div class=\"line\">ruby dk.rb install</div><div class=\"line\">gem install rdiscount --platform=ruby</div></pre></td></tr></table></figure>\n<p><strong>安装Octopress</strong><br>下载Octopress。</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div><div class=\"line\">51</div><div class=\"line\">52</div><div class=\"line\">53</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"built_in\">cd</span> d:\\github  </div><div class=\"line\">git <span class=\"built_in\">clone</span> git://github.com/imathis/octopress.git octopress  </div><div class=\"line\"><span class=\"built_in\">cd</span> octopress  </div><div class=\"line\">ruby --version  <span class=\"comment\"># Should report Ruby 1.9.3</span></div><div class=\"line\">rbenv <span class=\"built_in\">rehash</span>  <span class=\"comment\"># 可选，如果安装了rbenv，就需要执行这一步</span></div><div class=\"line\">```  </div><div class=\"line\"></div><div class=\"line\">**注意**: rubygems.org在中国的下载速度很慢，会导致bundle install这一步下载gems的速度很慢，可能需要等待几个小时。因此需要事先切换到国内的镜像源。</div><div class=\"line\"></div><div class=\"line\">用记事本打开octopress目录下的Gemfile，将第一行修改为</div><div class=\"line\"></div><div class=\"line\">&gt; <span class=\"built_in\">source</span> <span class=\"string\">\"http://ruby.taobao.org\"</span></div><div class=\"line\"></div><div class=\"line\">然后可以开始安装依赖的gems了。</div><div class=\"line\"></div><div class=\"line\">``` bash  </div><div class=\"line\">bundle install</div><div class=\"line\">```  </div><div class=\"line\">正常的话应该可以看到一行行的Installing xxx，表示正在安装所需要的gem。</div><div class=\"line\"></div><div class=\"line\">安装默认的Octopress主题。</div><div class=\"line\"></div><div class=\"line\">``` bash  </div><div class=\"line\">rake install</div><div class=\"line\">```  </div><div class=\"line\">如果这一步出现问题，则试一下 bundle update再执行 rake install。</div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\">### 部署到GitHub</span></div><div class=\"line\">将Octopress和自己的Repo关联起来</div><div class=\"line\"></div><div class=\"line\">``` bash  </div><div class=\"line\">rake setup_github_pages</div><div class=\"line\">```  </div><div class=\"line\">编译生成JeKyll所需要的静态文件</div><div class=\"line\"></div><div class=\"line\">``` bash  </div><div class=\"line\">rake generate</div><div class=\"line\">```  </div><div class=\"line\">这个命令主要是根据<span class=\"built_in\">source</span>目录的内容，编译生成JeKyll所需要的静态文件，存放到public目录下。<span class=\"built_in\">source</span> 目录对应着git上的<span class=\"built_in\">source</span>分支。</div><div class=\"line\"></div><div class=\"line\">**UTF-8 编码**  </div><div class=\"line\">Windows预设是Big5编码,所以要想’rake generate’的时候不报编码错误,我们需要设置一下编码! 方法有两个,一个是直接在Git Bash中设置环境:</div><div class=\"line\"></div><div class=\"line\">``` bash  </div><div class=\"line\"><span class=\"built_in\">set</span> LANG=zh_CN.UTF-8  </div><div class=\"line\"><span class=\"built_in\">set</span> LC_ALL=zh_CN.UTF-8</div><div class=\"line\">```  </div><div class=\"line\">还有一个是在环境变量中加入这两个变量: 右击电脑-&gt;属性，新添加LANG和LC\\_ALL两个环境变量，值为为zh_CN.UTF-8.</div><div class=\"line\"></div><div class=\"line\">然后在Git Bash中做如下设置:</div><div class=\"line\"></div><div class=\"line\">``` bash  </div><div class=\"line\"><span class=\"built_in\">echo</span> <span class=\"string\">\"export LANG LC_ALL\"</span> &gt; ~/.bash_profile</div></pre></td></tr></table></figure>\n<p>预览</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">rake preview</div></pre></td></tr></table></figure>\n<p>用浏览器打开 <a href=\"http://localhost:4000/\">http://localhost:4000/</a>，就可以看到效果了。</p>\n<p>部署到github</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\">rake deploy</div><div class=\"line\">```  </div><div class=\"line\">该命令首先清空\\_deploy目录，然后将public目录整个拷贝过来，然后commit到github。\\_deploy 目录对应着master分支。</div><div class=\"line\"></div><div class=\"line\">备份<span class=\"built_in\">source</span>到github</div></pre></td></tr></table></figure>\n<p>git add .<br>git commit -m ‘your message’<br>git push origin source<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div></pre></td><td class=\"code\"><pre><div class=\"line\">source 目录下保存了所有的markdown源文件，是博客的原始数据，以及一些模板文件。因此很有必要备份。用上述命令提交到github，这样就用git管理起来了，再也不用担心数据丢失了。</div><div class=\"line\"></div><div class=\"line\">**终止预览**  </div><div class=\"line\">启用`rake preview`后，直接按`ctrl+c`无法正常终止该进程，老提示`终止批处理操作吗（Y/N）？`，这时候可以另开一个Git Bash窗口，使用`ps aux | grep ruby`命令找出`pid(第一个数值)`，然后执行`kill &lt;pid&gt;`来停止该进程(参考[octopress on heroku (二)](http://linuxabc.heroku.com/blog/octopress-on-heroku-2))。  </div><div class=\"line\"></div><div class=\"line\">  </div><div class=\"line\">### 绑定域名</div><div class=\"line\">参考官方文档[Setting up a custom domain with Pages](https://help.github.com/articles/setting-up-a-custom-domain-with-pages)。</div><div class=\"line\"></div><div class=\"line\">非常简单，在`source`目录下，添加一个文本文件，名字为CNAME，里面的内容就是要绑定的域名，例如本博客CNAME文件的内容是：</div><div class=\"line\"></div><div class=\"line\">&gt; www.yanjiuyanjiu.com</div><div class=\"line\"></div><div class=\"line\">然后去DNSPod，添加一条CNAME，指向 username.github.com。例如我的为：</div></pre></td></tr></table></figure></p>\n<p>www    CNAME    默认    soulmachine.github.com.        -    600<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div></pre></td><td class=\"code\"><pre><div class=\"line\"></div><div class=\"line\">很多人喜欢去掉www，用xxx.com的形式来访问，不过大家去试一下，在浏览器输入qq.com, douban.com, baidu.com，发现都会自动跳转到www，也就是说这些大网站，目前也是用www.example.com的域名为主，因此建议大家也这样做。</div><div class=\"line\"></div><div class=\"line\">用www, blog之类的二级域名，还有个好处是方便升级，比如新版本用www1指向，等测试完成后，改成www指向，无缝切换。</div><div class=\"line\"></div><div class=\"line\">如何让example.com 自动变成www.example.com呢？需要用 301重定向，在DNSPod上非常简单，添加一条显性URL即可，例如我的是：</div></pre></td></tr></table></figure></p>\n<p>@    显性URL    默认    <a href=\"http://www.yanjiuyanjiu.com\">http://www.yanjiuyanjiu.com</a>    -    600<br>```</p>\n<p>在使用Octopress的时候，每次<code>rake generate</code>, <code>rake deploy</code>后，master分支下面的CNAME文件消失了。正确的做法是，把CNAME文件放到在 source 目录下，其余的都删掉，<code>rake generate</code> 会自动拷贝到public目录下，<code>rake deploy</code>再拷贝public目录内容到_deploy目录，并提交到master分支。</p>\n<h3 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h3><ol>\n<li><a href=\"http://corey600.github.com/blog/2013/02/28/use-github-and-octopress-create-blog/\">【原创】用Github和Octopress搭建博客</a></li>\n<li><a href=\"http://www.blogjava.net/lishunli/archive/2012/03/18/372115.html\">试用Octopress</a></li>\n<li><a href=\"http://rubyer.me/blog/134/\">windows下安装DevKit</a></li>\n<li><a href=\"http://blog.sprabbit.com/blog/2012/12/21/recover-octopress/\">在新Windows系统中重新部署Octopress</a></li>\n<li><a href=\"http://hivan.me/octopress-install-to-windows8/\">Windows 8安装Octopress记录</a></li>\n<li><a href=\"http://blog.sprabbit.com/blog/2012/03/23/octopress/\">关于在64位 Windows 7 中部署中文化的Octopress</a></li>\n</ol>"},{"layout":"post","title":"我的Octopress配置","date":"2013-04-02T15:35:00.000Z","comments":1,"_content":"## 实时预览\n使用如下命令可以实现实时预览：\n\n``` bash\nrake preview  \n```\n\n`rake preview` 会自动监视文件的变化，重新生成静态页面。因此修改markdown文件后，只需要在浏览器里刷新一下页面，就立刻可以看到效果。不过如果修改了_config.yml的话，则需要Ctrl+C终止，用`rake generate`重新生成，才能看到效果。\n\n## 嵌入代码块\n见官方文档[Sharing Code Snippets](http://octopress.org/docs/blogging/code/)。\n\nOctopress是一款为hacker量身定制的博客系统，当然内置了代码高亮的功能！它的代码高亮功能是通过Pygments实现的，配色方案用的是Solarized，堪称完美。\n\nOctopress支持多种方式嵌入代码，可以直接嵌入代码，也可以引用github上的gist 。\n\n我喜欢用**三个反引号**直接嵌入代码，比 `codeblock`要简洁。\n\n###启用MathJax\n在`source/_includes/custom/footer.html`的第一行加入如下代码：\n\n``` javascript\n<!-- mathjax config similar to math.stackexchange -->\n<script type=\"text/x-mathjax-config\">\nMathJax.Hub.Config({\n  jax: [\"input/TeX\", \"output/HTML-CSS\"],\n  tex2jax: {\n    inlineMath: [ ['$', '$'] ],\n    displayMath: [ ['$$', '$$']],\n    processEscapes: true,\n    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']\n  },\n  messageStyle: \"none\",\n  \"HTML-CSS\": { preferredFont: \"TeX\", availableFonts: [\"STIX\",\"TeX\"] }\n});\n</script>\n<script src=\"http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML\" type=\"text/javascript\"></script>\n```\n\n这样就引入了MathJax的JS包，可以直接在markdown文件里直接写公式了，例如 $\\dfrac {\\pi}{2}$。\n\n上面的代码也可以在`source/_includes/custom/header.html`里添加，不过这样会使得页面的加载速度变慢。还可以在`source/_layouts/default.html`里添加。\n\n<!--more-->\n\n有一个问题，rdiscount这个解析器，对 mathjax 大部分支持，某些细节处理的不好，举个例子，它会在动把公式中的 `^n`转换成`<sup>n</sup>`，例如`$2^n$`会解析成`$2<sup>n</sup>$`，这样就破坏了整个公式，导致公式无法解析。参考[这里](http://christopherpoole.github.io/using-mathjax-on-github-pages/)一段话：\n> as discount for example automatically replaces `x^2` with `x<sup>2</sup>` which interrupts the MathJax rendering.\n\n因此要换一个解析器，[Maruku](http://maruku.rubyforge.org/) 和 [Kramdown](http://kramdown.rubyforge.org/) 都可以，由于Maruku主页PR=4，Kramdown的主页PR=5，我选择了Kramdown。\n\n**用Kramdown代替Rdiscount**  \n修改Gemfile，增加一行：\n\n```\ngem 'kramdown', '~> 0.14'\n```\n很多博客都说要配套安装coderay这个gem，其实是没有必要的，只要代码块以 \\`\\`\\` 开始和结束，自带的pygments就能实现代码高亮。\n\n在Git Bash输入如下命令：\n\n``` bash\nbundle install\n```\n就会自动安装kramdown。\n\n然后在\\_config.yml 文件中，见markdown: rdiscount 修改为  markdown: kramdown。\n\n使用kramdown，感觉它的语法要求比rdiscout严格，例如每个代码块开头，必须有一个空行，否则高亮就会失败，大家可以试试看。每个标题掐面，也必须有一个开头。\n\nkramdown的两种公式，display和inline，都是以`$$`开头和结尾的，display模式时，`$$`要单独占一行。这跟标准的LaTex有点不一样。参考[这里](http://kqueue.org/blog/2012/01/05/hello-world/)。\n\n**右击公式全屏空白**：这时候右击公式，全屏空白。解决这个问题很简单，只需在 `sass/base/_theme.scss`添加\"#main\"即可：\n\n```\nbody {\n  > div#main {\n    background: $sidebar-bg $noise-bg;\n```\n\n本节参考了[Writing Math Equations on Octopress](http://www.idryman.org/blog/2012/03/10/writing-math-equations-on-octopress/) 和 [在Octopress中使用Latex公式](http://jasonllinux.github.com/blog/2012/11/06/write-latex-in-octopress/)。\n\n##kramdown的扩展语法\nkramdown扩展了标准markdown的语法，有很多使用的功能。[语法见官网文档](http://kramdown.rubyforge.org/syntax.html)。这里选一些我常用的。\n\n**脚注(footnote)**  \n脚注定义是：`[^1]:`，数字可以改变，引用语法是`[^1]`。没有被引用到的参考文献，会被忽略掉。\n\n**表格**  \n一下是一个示例：\n\n\t|-----------------+------------+-----------------+----------------|\n\t| Default aligned |Left aligned| Center aligned  | Right aligned  |\n\t|-----------------|:-----------|:---------------:|---------------:|\n\t| First body part |Second cell | Third cell      | fourth cell    |\n\t| Second line     |foo         | **strong**      | baz            |\n\t| Third line      |quux        | baz             | bar            |\n\t|-----------------+------------+-----------------+----------------|\n\n更详细说明见官网。\n\n## 首页只显示部分正文(Excerpts)\nOctopress中，可以使用 `<!--more-->`，这样首页只显示一部分正文，并在每篇文章底下加一个Read on超链接。\n\n## 插入图片\n使用[Image Tag](http://octopress.org/docs/plugins/image-tag/)。\n\n语法\n\n```\n{% img [class names] /path/to/image [width] [height] [title text [alt text]] %}\n```\n\n例子\n\n```\n{% img http://placekitten.com/890/280 %}\n{% img left http://placekitten.com/320/250 Place Kitten #2 %}\n{% img right http://placekitten.com/300/500 150 250 Place Kitten #3 %}\n{% img right http://placekitten.com/300/500 150 250 'Place Kitten #4' 'An image of a very cute kitten' %}\n```\n\n## 添加about me 边栏\n编辑 source\\_includes\\custom\\asides\\about.html，内容如下：\n\n```\n<section>\n  <h1>About Me</h1>\n  <p>一句话自我介绍.</p>\n  <p>新浪微博: <a href=\"http://weibo.com/soulmachine\">@soulmachine</a><br/>\n     Twitter: <a href=\"https://twitter.com/#!/soulmachine\">@soulmachine</a><br/>\n     Other: <a href=\"https://github.com/soulmachine\">Github</a>, <a href=\"https://plus.google.com/103519507226474510310\">Google+</a>, <a href=\"http://www.linkedin.com/in/soulmachine\">LinkedIn</a>, <a href=\"http://www.quora.com/Jason-Day-2\">Quora</a></p>\n  </p>\n</section>\n```\n在 _config.yml 的 default_asides 里添加 custom/asides/about.html。\n\n##添加about页面\n\n```\nrake new_page[about]\n```\n会生成 source/about/index.markdown 文件。\n\n编辑该文件的内容。\n\n然后在头部导航菜单中添加页面的超链接。具体做法是编辑 /source/_includes/custom/navigation.html 文件。\n\n## 社会化分享 \n使用addthis.com的分享按钮，在网站上获取代码，粘贴到`source/_includes/post/sharing.html`中，例如我的代码如下：\n\n``` html\n<div class=\"sharing\">\n  <!-- AddThis Button BEGIN -->\n  <div class=\"addthis_toolbox addthis_default_style addthis_32x32_style\">\n    <a class=\"addthis_button_sinaweibo\"></a>\n    <a class=\"addthis_button_facebook\"></a>\n    <a class=\"addthis_button_twitter\"></a>\n    <a class=\"addthis_button_google_plusone_share\"></a>\n    <a class=\"addthis_button_delicious\"></a>\n    <a class=\"addthis_button_digg\"></a>\n    <a class=\"addthis_button_reddit\"></a>\n    <a class=\"addthis_button_compact\"></a><a class=\"addthis_counter addthis_bubble_style\"></a>\n  </div>\n  <script type=\"text/javascript\" src=\"//s7.addthis.com/js/300/addthis_widget.js#pubid=undefined\"></script>\n  <!-- AddThis Button END -->\n```\n\n在_config.yml 中，将twitter, google+ 和facebook like的按钮设置为false，取消显示，因为 AddThis 已经集成了这三者。\n\n## 社会化评论\n<del>启用Disqus，填入 short name即可。</del>Disqus在国外流行，在国内的加载速度太慢，而且只有twitter, facebook, g+，没有照顾到国内的用户习惯，因此替换成国内的[多说](www.duoshuo.com)。参考这篇博客 [为 Octopress 添加多说评论系统](http://ihavanna.org/Internet/2013-02/add-duoshuo-commemt-system-into-octopress.html)。`source/_includes/post/duoshuo_thread.html`的代码略有不同，添加了`data-title=\"{{ page.title }}\"`，否则侧边栏的最近评论，标题为空白，感谢[碟姐 - 在octopress中添加多说的最近评论](http://yrzhll.com/blog/2012/12/12/comment/)指出了这一点，代码如下：\n\n``` javascript\n<!-- Duoshuo Comment BEGIN -->\n<div class=\"ds-thread\" data-title=\"{{ page.title }}\"></div>\n<script type=\"text/javascript\">\nvar duoshuoQuery = {short_name:\"yanjiuyanjiu\"};\n\t(function() {\n\t\tvar ds = document.createElement('script');\n\t\tds.type = 'text/javascript';ds.async = true;\n\t\tds.src = 'http://static.duoshuo.com/embed.js';\n\t\tds.charset = 'UTF-8';\n\t\t(document.getElementsByTagName('head')[0] \n\t\t|| document.getElementsByTagName('body')[0]).appendChild(ds);\n\t})();\n</script>\n<!-- Duoshuo Comment END -->\n```\n\n_config.yml 中的配置也略有不同： \n\n```\nduoshuo_comments: true\nduoshuo_short_name: yanjiuyanjiu\nduoshuo_asides_num: 5      # 侧边栏评论显示条目数\nduoshuo_asides_avatars: 1   # 侧边栏评论是否显示头像\nduoshuo_asides_time: 1      # 侧边栏评论是否显示时间\nduoshuo_asides_title: 1     # 侧边栏评论是否显示标题\nduoshuo_asides_admin: 0     # 侧边栏评论是否显示作者评论\nduoshuo_asides_length: 32   # 侧边栏评论截取的长度\n```\n\n## 设置固定链接\n在 _config.yml 里，找到 permalink，设置如下：\n\n```\npermalink: /blog/:year:month:day/ \n```\n效果就是`www.example.com/blog/20130403/`。模仿的是豆瓣的URL格式。\n\n参考官方文档[jekyll Permalinks](https://github.com/mojombo/jekyll/wiki/Permalinks)。\n\n## 侧边栏显示分类目录\n使用第三方插件 [octopress-tagcloud](https://github.com/tokkonopapa/octopress-tagcloud)。\n\n##友情链接\n在`source\\_includes\\custom\\asides` 目录下添加一个blogroll.html文件，模仿about.html，添加一些友情链接，例如：\n\n```\n<section>\n  <h1>友情链接</h1>\n  <ul>\n    <li>\n      <a href=\"http://coolshell.cn/\">酷壳CoolShell</a>\n    </li>\n    <li>\n      <a href=\"http://mindhacks.cn/\">刘未鹏MIND HACKS</a>\n    </li>\n    <li>\n      <a href=\"http://blog.codingnow.com/\">云风</a>\n    </li>\n    <li>\n      <a href=\"http://www.cnblogs.com/Solstice/\">陈硕</a>\n    </li>\n  </ul>\n</section>\n```\n然后在 \\_config.yml 文件中，在 default_asides 的数组中添加 `custom/asides/blogroll.html`。\n\n##中文目录\nTODO\n\n##修改字体\nOctopresss默认使用的是 google webfonts，见`source/_includes/custom/head.html`里的两行代码。Google Webfonts是个好东西，但遗憾的是它没有中文字体。所以你用**粗体**，发现并没有变粗，就是这个原因。\n\n首先，将head.html中的两行代码注释掉，省去了加载字体，加快网页加载速度。\n\n```\n<!--Fonts from Google\"s Web font directory at http://google.com/webfonts -->\n<!-- <link href=\"http://fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic\" rel=\"stylesheet\" type=\"text/css\"> -->\n<!-- <link href=\"http://fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic\" rel=\"stylesheet\" type=\"text/css\"> -->\n\n```\n参考 这篇博客 [最佳 Web 中文默认字体](http://lifesinger.wordpress.com/2011/04/06/best-web-default-fonts/)，在`sass/custom/_fonts.scss`中添加如下三行代码：\n\n```\n$heading-font-family: arial, sans-serif;\n$header-title-font-family: arial, sans-serif;\n$header-subtitle-font-family: arial, sans-serif;\n```\n刷新网页，可以看见中文的粗体变黑了。\n\n##一些汉化工作\n在 _config.yml中，把 `Read on` 改为 \"继续阅读\"。\n在 `source/_includes/custom/asides`目录下，将\"Recent Comments\"改为“最新评论”，\"Categories\"改为“分类目录”，将`source/_includes/asides/recent_posts.html`中\"Recent Posts\"改为“最新文章”。\n\n## 添加统计代码\n在_config.yml填入 Google Analytics Tracking ID，例如 `UA-7583537-4`。\n\n##第三方主题和插件\n主题：[3rd Party Octopress Themes](https://github.com/imathis/octopress/wiki/3rd-Party-Octopress-Themes)  \n插件：[3rd party plugins](https://github.com/imathis/octopress/wiki/3rd-party-plugins)\n\n##在一台新电脑上恢复\n如果换了一台电脑，怎样迅速恢复环境呢？参考 [Clone Your Octopress to Blog From Two Places](http://blog.zerosharp.com/clone-your-octopress-to-blog-from-two-places/)。 **注意，在windows上，要首先安装python，否则，虽然所有操作可以成功，不报错误，但是你发现打开后首页一篇空白，我当时百思不得其解，因为没有任何错误信息，最后去看生成的文件，所有index.html都是0字节，就猜测应该是编译出了问题。安装python就好了，linux默认是有Python的，就没有这个问题，windows真是坑爹！以后只在windows下做编辑类的工作，编译和运行都放到Linux下。**\n\n##TODO\n修改字体大小\n\n添加TAG支持\n\n##参考资料\n1. [Octopress主题改造](http://shanewfx.github.com/blog/2012/08/13/improve-blog-theme/)\n1. \n","source":"_posts/2013-04-02-my-octopress-configuration.md","raw":"---\nlayout: post\ntitle: \"我的Octopress配置\"\ndate: 2013-04-02 15:35\ncomments: true\ncategories: Tools\n---\n## 实时预览\n使用如下命令可以实现实时预览：\n\n``` bash\nrake preview  \n```\n\n`rake preview` 会自动监视文件的变化，重新生成静态页面。因此修改markdown文件后，只需要在浏览器里刷新一下页面，就立刻可以看到效果。不过如果修改了_config.yml的话，则需要Ctrl+C终止，用`rake generate`重新生成，才能看到效果。\n\n## 嵌入代码块\n见官方文档[Sharing Code Snippets](http://octopress.org/docs/blogging/code/)。\n\nOctopress是一款为hacker量身定制的博客系统，当然内置了代码高亮的功能！它的代码高亮功能是通过Pygments实现的，配色方案用的是Solarized，堪称完美。\n\nOctopress支持多种方式嵌入代码，可以直接嵌入代码，也可以引用github上的gist 。\n\n我喜欢用**三个反引号**直接嵌入代码，比 `codeblock`要简洁。\n\n###启用MathJax\n在`source/_includes/custom/footer.html`的第一行加入如下代码：\n\n``` javascript\n<!-- mathjax config similar to math.stackexchange -->\n<script type=\"text/x-mathjax-config\">\nMathJax.Hub.Config({\n  jax: [\"input/TeX\", \"output/HTML-CSS\"],\n  tex2jax: {\n    inlineMath: [ ['$', '$'] ],\n    displayMath: [ ['$$', '$$']],\n    processEscapes: true,\n    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']\n  },\n  messageStyle: \"none\",\n  \"HTML-CSS\": { preferredFont: \"TeX\", availableFonts: [\"STIX\",\"TeX\"] }\n});\n</script>\n<script src=\"http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML\" type=\"text/javascript\"></script>\n```\n\n这样就引入了MathJax的JS包，可以直接在markdown文件里直接写公式了，例如 $\\dfrac {\\pi}{2}$。\n\n上面的代码也可以在`source/_includes/custom/header.html`里添加，不过这样会使得页面的加载速度变慢。还可以在`source/_layouts/default.html`里添加。\n\n<!--more-->\n\n有一个问题，rdiscount这个解析器，对 mathjax 大部分支持，某些细节处理的不好，举个例子，它会在动把公式中的 `^n`转换成`<sup>n</sup>`，例如`$2^n$`会解析成`$2<sup>n</sup>$`，这样就破坏了整个公式，导致公式无法解析。参考[这里](http://christopherpoole.github.io/using-mathjax-on-github-pages/)一段话：\n> as discount for example automatically replaces `x^2` with `x<sup>2</sup>` which interrupts the MathJax rendering.\n\n因此要换一个解析器，[Maruku](http://maruku.rubyforge.org/) 和 [Kramdown](http://kramdown.rubyforge.org/) 都可以，由于Maruku主页PR=4，Kramdown的主页PR=5，我选择了Kramdown。\n\n**用Kramdown代替Rdiscount**  \n修改Gemfile，增加一行：\n\n```\ngem 'kramdown', '~> 0.14'\n```\n很多博客都说要配套安装coderay这个gem，其实是没有必要的，只要代码块以 \\`\\`\\` 开始和结束，自带的pygments就能实现代码高亮。\n\n在Git Bash输入如下命令：\n\n``` bash\nbundle install\n```\n就会自动安装kramdown。\n\n然后在\\_config.yml 文件中，见markdown: rdiscount 修改为  markdown: kramdown。\n\n使用kramdown，感觉它的语法要求比rdiscout严格，例如每个代码块开头，必须有一个空行，否则高亮就会失败，大家可以试试看。每个标题掐面，也必须有一个开头。\n\nkramdown的两种公式，display和inline，都是以`$$`开头和结尾的，display模式时，`$$`要单独占一行。这跟标准的LaTex有点不一样。参考[这里](http://kqueue.org/blog/2012/01/05/hello-world/)。\n\n**右击公式全屏空白**：这时候右击公式，全屏空白。解决这个问题很简单，只需在 `sass/base/_theme.scss`添加\"#main\"即可：\n\n```\nbody {\n  > div#main {\n    background: $sidebar-bg $noise-bg;\n```\n\n本节参考了[Writing Math Equations on Octopress](http://www.idryman.org/blog/2012/03/10/writing-math-equations-on-octopress/) 和 [在Octopress中使用Latex公式](http://jasonllinux.github.com/blog/2012/11/06/write-latex-in-octopress/)。\n\n##kramdown的扩展语法\nkramdown扩展了标准markdown的语法，有很多使用的功能。[语法见官网文档](http://kramdown.rubyforge.org/syntax.html)。这里选一些我常用的。\n\n**脚注(footnote)**  \n脚注定义是：`[^1]:`，数字可以改变，引用语法是`[^1]`。没有被引用到的参考文献，会被忽略掉。\n\n**表格**  \n一下是一个示例：\n\n\t|-----------------+------------+-----------------+----------------|\n\t| Default aligned |Left aligned| Center aligned  | Right aligned  |\n\t|-----------------|:-----------|:---------------:|---------------:|\n\t| First body part |Second cell | Third cell      | fourth cell    |\n\t| Second line     |foo         | **strong**      | baz            |\n\t| Third line      |quux        | baz             | bar            |\n\t|-----------------+------------+-----------------+----------------|\n\n更详细说明见官网。\n\n## 首页只显示部分正文(Excerpts)\nOctopress中，可以使用 `<!--more-->`，这样首页只显示一部分正文，并在每篇文章底下加一个Read on超链接。\n\n## 插入图片\n使用[Image Tag](http://octopress.org/docs/plugins/image-tag/)。\n\n语法\n\n```\n{% img [class names] /path/to/image [width] [height] [title text [alt text]] %}\n```\n\n例子\n\n```\n{% img http://placekitten.com/890/280 %}\n{% img left http://placekitten.com/320/250 Place Kitten #2 %}\n{% img right http://placekitten.com/300/500 150 250 Place Kitten #3 %}\n{% img right http://placekitten.com/300/500 150 250 'Place Kitten #4' 'An image of a very cute kitten' %}\n```\n\n## 添加about me 边栏\n编辑 source\\_includes\\custom\\asides\\about.html，内容如下：\n\n```\n<section>\n  <h1>About Me</h1>\n  <p>一句话自我介绍.</p>\n  <p>新浪微博: <a href=\"http://weibo.com/soulmachine\">@soulmachine</a><br/>\n     Twitter: <a href=\"https://twitter.com/#!/soulmachine\">@soulmachine</a><br/>\n     Other: <a href=\"https://github.com/soulmachine\">Github</a>, <a href=\"https://plus.google.com/103519507226474510310\">Google+</a>, <a href=\"http://www.linkedin.com/in/soulmachine\">LinkedIn</a>, <a href=\"http://www.quora.com/Jason-Day-2\">Quora</a></p>\n  </p>\n</section>\n```\n在 _config.yml 的 default_asides 里添加 custom/asides/about.html。\n\n##添加about页面\n\n```\nrake new_page[about]\n```\n会生成 source/about/index.markdown 文件。\n\n编辑该文件的内容。\n\n然后在头部导航菜单中添加页面的超链接。具体做法是编辑 /source/_includes/custom/navigation.html 文件。\n\n## 社会化分享 \n使用addthis.com的分享按钮，在网站上获取代码，粘贴到`source/_includes/post/sharing.html`中，例如我的代码如下：\n\n``` html\n<div class=\"sharing\">\n  <!-- AddThis Button BEGIN -->\n  <div class=\"addthis_toolbox addthis_default_style addthis_32x32_style\">\n    <a class=\"addthis_button_sinaweibo\"></a>\n    <a class=\"addthis_button_facebook\"></a>\n    <a class=\"addthis_button_twitter\"></a>\n    <a class=\"addthis_button_google_plusone_share\"></a>\n    <a class=\"addthis_button_delicious\"></a>\n    <a class=\"addthis_button_digg\"></a>\n    <a class=\"addthis_button_reddit\"></a>\n    <a class=\"addthis_button_compact\"></a><a class=\"addthis_counter addthis_bubble_style\"></a>\n  </div>\n  <script type=\"text/javascript\" src=\"//s7.addthis.com/js/300/addthis_widget.js#pubid=undefined\"></script>\n  <!-- AddThis Button END -->\n```\n\n在_config.yml 中，将twitter, google+ 和facebook like的按钮设置为false，取消显示，因为 AddThis 已经集成了这三者。\n\n## 社会化评论\n<del>启用Disqus，填入 short name即可。</del>Disqus在国外流行，在国内的加载速度太慢，而且只有twitter, facebook, g+，没有照顾到国内的用户习惯，因此替换成国内的[多说](www.duoshuo.com)。参考这篇博客 [为 Octopress 添加多说评论系统](http://ihavanna.org/Internet/2013-02/add-duoshuo-commemt-system-into-octopress.html)。`source/_includes/post/duoshuo_thread.html`的代码略有不同，添加了`data-title=\"{{ page.title }}\"`，否则侧边栏的最近评论，标题为空白，感谢[碟姐 - 在octopress中添加多说的最近评论](http://yrzhll.com/blog/2012/12/12/comment/)指出了这一点，代码如下：\n\n``` javascript\n<!-- Duoshuo Comment BEGIN -->\n<div class=\"ds-thread\" data-title=\"{{ page.title }}\"></div>\n<script type=\"text/javascript\">\nvar duoshuoQuery = {short_name:\"yanjiuyanjiu\"};\n\t(function() {\n\t\tvar ds = document.createElement('script');\n\t\tds.type = 'text/javascript';ds.async = true;\n\t\tds.src = 'http://static.duoshuo.com/embed.js';\n\t\tds.charset = 'UTF-8';\n\t\t(document.getElementsByTagName('head')[0] \n\t\t|| document.getElementsByTagName('body')[0]).appendChild(ds);\n\t})();\n</script>\n<!-- Duoshuo Comment END -->\n```\n\n_config.yml 中的配置也略有不同： \n\n```\nduoshuo_comments: true\nduoshuo_short_name: yanjiuyanjiu\nduoshuo_asides_num: 5      # 侧边栏评论显示条目数\nduoshuo_asides_avatars: 1   # 侧边栏评论是否显示头像\nduoshuo_asides_time: 1      # 侧边栏评论是否显示时间\nduoshuo_asides_title: 1     # 侧边栏评论是否显示标题\nduoshuo_asides_admin: 0     # 侧边栏评论是否显示作者评论\nduoshuo_asides_length: 32   # 侧边栏评论截取的长度\n```\n\n## 设置固定链接\n在 _config.yml 里，找到 permalink，设置如下：\n\n```\npermalink: /blog/:year:month:day/ \n```\n效果就是`www.example.com/blog/20130403/`。模仿的是豆瓣的URL格式。\n\n参考官方文档[jekyll Permalinks](https://github.com/mojombo/jekyll/wiki/Permalinks)。\n\n## 侧边栏显示分类目录\n使用第三方插件 [octopress-tagcloud](https://github.com/tokkonopapa/octopress-tagcloud)。\n\n##友情链接\n在`source\\_includes\\custom\\asides` 目录下添加一个blogroll.html文件，模仿about.html，添加一些友情链接，例如：\n\n```\n<section>\n  <h1>友情链接</h1>\n  <ul>\n    <li>\n      <a href=\"http://coolshell.cn/\">酷壳CoolShell</a>\n    </li>\n    <li>\n      <a href=\"http://mindhacks.cn/\">刘未鹏MIND HACKS</a>\n    </li>\n    <li>\n      <a href=\"http://blog.codingnow.com/\">云风</a>\n    </li>\n    <li>\n      <a href=\"http://www.cnblogs.com/Solstice/\">陈硕</a>\n    </li>\n  </ul>\n</section>\n```\n然后在 \\_config.yml 文件中，在 default_asides 的数组中添加 `custom/asides/blogroll.html`。\n\n##中文目录\nTODO\n\n##修改字体\nOctopresss默认使用的是 google webfonts，见`source/_includes/custom/head.html`里的两行代码。Google Webfonts是个好东西，但遗憾的是它没有中文字体。所以你用**粗体**，发现并没有变粗，就是这个原因。\n\n首先，将head.html中的两行代码注释掉，省去了加载字体，加快网页加载速度。\n\n```\n<!--Fonts from Google\"s Web font directory at http://google.com/webfonts -->\n<!-- <link href=\"http://fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic\" rel=\"stylesheet\" type=\"text/css\"> -->\n<!-- <link href=\"http://fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic\" rel=\"stylesheet\" type=\"text/css\"> -->\n\n```\n参考 这篇博客 [最佳 Web 中文默认字体](http://lifesinger.wordpress.com/2011/04/06/best-web-default-fonts/)，在`sass/custom/_fonts.scss`中添加如下三行代码：\n\n```\n$heading-font-family: arial, sans-serif;\n$header-title-font-family: arial, sans-serif;\n$header-subtitle-font-family: arial, sans-serif;\n```\n刷新网页，可以看见中文的粗体变黑了。\n\n##一些汉化工作\n在 _config.yml中，把 `Read on` 改为 \"继续阅读\"。\n在 `source/_includes/custom/asides`目录下，将\"Recent Comments\"改为“最新评论”，\"Categories\"改为“分类目录”，将`source/_includes/asides/recent_posts.html`中\"Recent Posts\"改为“最新文章”。\n\n## 添加统计代码\n在_config.yml填入 Google Analytics Tracking ID，例如 `UA-7583537-4`。\n\n##第三方主题和插件\n主题：[3rd Party Octopress Themes](https://github.com/imathis/octopress/wiki/3rd-Party-Octopress-Themes)  \n插件：[3rd party plugins](https://github.com/imathis/octopress/wiki/3rd-party-plugins)\n\n##在一台新电脑上恢复\n如果换了一台电脑，怎样迅速恢复环境呢？参考 [Clone Your Octopress to Blog From Two Places](http://blog.zerosharp.com/clone-your-octopress-to-blog-from-two-places/)。 **注意，在windows上，要首先安装python，否则，虽然所有操作可以成功，不报错误，但是你发现打开后首页一篇空白，我当时百思不得其解，因为没有任何错误信息，最后去看生成的文件，所有index.html都是0字节，就猜测应该是编译出了问题。安装python就好了，linux默认是有Python的，就没有这个问题，windows真是坑爹！以后只在windows下做编辑类的工作，编译和运行都放到Linux下。**\n\n##TODO\n修改字体大小\n\n添加TAG支持\n\n##参考资料\n1. [Octopress主题改造](http://shanewfx.github.com/blog/2012/08/13/improve-blog-theme/)\n1. \n","slug":"2013-04-02-my-octopress-configuration","published":1,"updated":"2016-08-18T09:21:04.000Z","photos":[],"link":"","_id":"cis07pf34001201pqa3sdfm28","content":"<h2 id=\"实时预览\"><a href=\"#实时预览\" class=\"headerlink\" title=\"实时预览\"></a>实时预览</h2><p>使用如下命令可以实现实时预览：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">rake preview</div></pre></td></tr></table></figure>\n<p><code>rake preview</code> 会自动监视文件的变化，重新生成静态页面。因此修改markdown文件后，只需要在浏览器里刷新一下页面，就立刻可以看到效果。不过如果修改了_config.yml的话，则需要Ctrl+C终止，用<code>rake generate</code>重新生成，才能看到效果。</p>\n<h2 id=\"嵌入代码块\"><a href=\"#嵌入代码块\" class=\"headerlink\" title=\"嵌入代码块\"></a>嵌入代码块</h2><p>见官方文档<a href=\"http://octopress.org/docs/blogging/code/\" target=\"_blank\" rel=\"external\">Sharing Code Snippets</a>。</p>\n<p>Octopress是一款为hacker量身定制的博客系统，当然内置了代码高亮的功能！它的代码高亮功能是通过Pygments实现的，配色方案用的是Solarized，堪称完美。</p>\n<p>Octopress支持多种方式嵌入代码，可以直接嵌入代码，也可以引用github上的gist 。</p>\n<p>我喜欢用<strong>三个反引号</strong>直接嵌入代码，比 <code>codeblock</code>要简洁。</p>\n<p>###启用MathJax<br>在<code>source/_includes/custom/footer.html</code>的第一行加入如下代码：</p>\n<figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div></pre></td><td class=\"code\"><pre><div class=\"line\">&lt;!-- mathjax config similar to math.stackexchange --&gt;</div><div class=\"line\">&lt;script type=\"text/x-mathjax-config\"&gt;</div><div class=\"line\">MathJax.Hub.Config(&#123;</div><div class=\"line\">  jax: [\"input/TeX\", \"output/HTML-CSS\"],</div><div class=\"line\">  tex2jax: &#123;</div><div class=\"line\">    inlineMath: [ ['$', '$'] ],</div><div class=\"line\">    displayMath: [ ['$$', '$$']],</div><div class=\"line\">    processEscapes: true,</div><div class=\"line\">    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']</div><div class=\"line\">  &#125;,</div><div class=\"line\">  messageStyle: \"none\",</div><div class=\"line\">  \"HTML-CSS\": &#123; preferredFont: \"TeX\", availableFonts: [\"STIX\",\"TeX\"] &#125;</div><div class=\"line\">&#125;);</div><div class=\"line\">&lt;/script&gt;</div><div class=\"line\">&lt;script src=<span class=\"string\">\"http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML\"</span> type=<span class=\"string\">\"text/javascript\"</span>&gt;&lt;/script&gt;</div></pre></td></tr></table></figure>\n<p>这样就引入了MathJax的JS包，可以直接在markdown文件里直接写公式了，例如 $\\dfrac {\\pi}{2}$。</p>\n<p>上面的代码也可以在<code>source/_includes/custom/header.html</code>里添加，不过这样会使得页面的加载速度变慢。还可以在<code>source/_layouts/default.html</code>里添加。</p>\n<a id=\"more\"></a>\n<p>有一个问题，rdiscount这个解析器，对 mathjax 大部分支持，某些细节处理的不好，举个例子，它会在动把公式中的 <code>^n</code>转换成<code>&lt;sup&gt;n&lt;/sup&gt;</code>，例如<code>$2^n$</code>会解析成<code>$2&lt;sup&gt;n&lt;/sup&gt;$</code>，这样就破坏了整个公式，导致公式无法解析。参考<a href=\"http://christopherpoole.github.io/using-mathjax-on-github-pages/\" target=\"_blank\" rel=\"external\">这里</a>一段话：</p>\n<blockquote>\n<p>as discount for example automatically replaces <code>x^2</code> with <code>x&lt;sup&gt;2&lt;/sup&gt;</code> which interrupts the MathJax rendering.</p>\n</blockquote>\n<p>因此要换一个解析器，<a href=\"http://maruku.rubyforge.org/\" target=\"_blank\" rel=\"external\">Maruku</a> 和 <a href=\"http://kramdown.rubyforge.org/\" target=\"_blank\" rel=\"external\">Kramdown</a> 都可以，由于Maruku主页PR=4，Kramdown的主页PR=5，我选择了Kramdown。</p>\n<p><strong>用Kramdown代替Rdiscount</strong><br>修改Gemfile，增加一行：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">gem &apos;kramdown&apos;, &apos;~&gt; 0.14&apos;</div></pre></td></tr></table></figure>\n<p>很多博客都说要配套安装coderay这个gem，其实是没有必要的，只要代码块以 ``` 开始和结束，自带的pygments就能实现代码高亮。</p>\n<p>在Git Bash输入如下命令：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">bundle install</div></pre></td></tr></table></figure>\n<p>就会自动安装kramdown。</p>\n<p>然后在_config.yml 文件中，见markdown: rdiscount 修改为  markdown: kramdown。</p>\n<p>使用kramdown，感觉它的语法要求比rdiscout严格，例如每个代码块开头，必须有一个空行，否则高亮就会失败，大家可以试试看。每个标题掐面，也必须有一个开头。</p>\n<p>kramdown的两种公式，display和inline，都是以<code>$$</code>开头和结尾的，display模式时，<code>$$</code>要单独占一行。这跟标准的LaTex有点不一样。参考<a href=\"http://kqueue.org/blog/2012/01/05/hello-world/\" target=\"_blank\" rel=\"external\">这里</a>。</p>\n<p><strong>右击公式全屏空白</strong>：这时候右击公式，全屏空白。解决这个问题很简单，只需在 <code>sass/base/_theme.scss</code>添加”#main”即可：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">body &#123;</div><div class=\"line\">  &gt; div#main &#123;</div><div class=\"line\">    background: $sidebar-bg $noise-bg;</div></pre></td></tr></table></figure>\n<p>本节参考了<a href=\"http://www.idryman.org/blog/2012/03/10/writing-math-equations-on-octopress/\" target=\"_blank\" rel=\"external\">Writing Math Equations on Octopress</a> 和 <a href=\"http://jasonllinux.github.com/blog/2012/11/06/write-latex-in-octopress/\" target=\"_blank\" rel=\"external\">在Octopress中使用Latex公式</a>。</p>\n<p>##kramdown的扩展语法<br>kramdown扩展了标准markdown的语法，有很多使用的功能。<a href=\"http://kramdown.rubyforge.org/syntax.html\" target=\"_blank\" rel=\"external\">语法见官网文档</a>。这里选一些我常用的。</p>\n<p><strong>脚注(footnote)</strong><br>脚注定义是：<code>[^1]:</code>，数字可以改变，引用语法是<code>[^1]</code>。没有被引用到的参考文献，会被忽略掉。</p>\n<p><strong>表格</strong><br>一下是一个示例：</p>\n<pre><code>|-----------------+------------+-----------------+----------------|\n| Default aligned |Left aligned| Center aligned  | Right aligned  |\n|-----------------|:-----------|:---------------:|---------------:|\n| First body part |Second cell | Third cell      | fourth cell    |\n| Second line     |foo         | **strong**      | baz            |\n| Third line      |quux        | baz             | bar            |\n|-----------------+------------+-----------------+----------------|\n</code></pre><p>更详细说明见官网。</p>\n<h2 id=\"首页只显示部分正文-Excerpts\"><a href=\"#首页只显示部分正文-Excerpts\" class=\"headerlink\" title=\"首页只显示部分正文(Excerpts)\"></a>首页只显示部分正文(Excerpts)</h2><p>Octopress中，可以使用 <code>&lt;!--more--&gt;</code>，这样首页只显示一部分正文，并在每篇文章底下加一个Read on超链接。</p>\n<h2 id=\"插入图片\"><a href=\"#插入图片\" class=\"headerlink\" title=\"插入图片\"></a>插入图片</h2><p>使用<a href=\"http://octopress.org/docs/plugins/image-tag/\" target=\"_blank\" rel=\"external\">Image Tag</a>。</p>\n<p>语法</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">&#123;% img [class names] /path/to/image [width] [height] [title text [alt text]] %&#125;</div></pre></td></tr></table></figure>\n<p>例子</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\">&#123;% img http://placekitten.com/890/280 %&#125;</div><div class=\"line\">&#123;% img left http://placekitten.com/320/250 Place Kitten #2 %&#125;</div><div class=\"line\">&#123;% img right http://placekitten.com/300/500 150 250 Place Kitten #3 %&#125;</div><div class=\"line\">&#123;% img right http://placekitten.com/300/500 150 250 &apos;Place Kitten #4&apos; &apos;An image of a very cute kitten&apos; %&#125;</div></pre></td></tr></table></figure>\n<h2 id=\"添加about-me-边栏\"><a href=\"#添加about-me-边栏\" class=\"headerlink\" title=\"添加about me 边栏\"></a>添加about me 边栏</h2><p>编辑 source_includes\\custom\\asides\\about.html，内容如下：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div></pre></td><td class=\"code\"><pre><div class=\"line\">&lt;section&gt;</div><div class=\"line\">  &lt;h1&gt;About Me&lt;/h1&gt;</div><div class=\"line\">  &lt;p&gt;一句话自我介绍.&lt;/p&gt;</div><div class=\"line\">  &lt;p&gt;新浪微博: &lt;a href=&quot;http://weibo.com/soulmachine&quot;&gt;@soulmachine&lt;/a&gt;&lt;br/&gt;</div><div class=\"line\">     Twitter: &lt;a href=&quot;https://twitter.com/#!/soulmachine&quot;&gt;@soulmachine&lt;/a&gt;&lt;br/&gt;</div><div class=\"line\">     Other: &lt;a href=&quot;https://github.com/soulmachine&quot;&gt;Github&lt;/a&gt;, &lt;a href=&quot;https://plus.google.com/103519507226474510310&quot;&gt;Google+&lt;/a&gt;, &lt;a href=&quot;http://www.linkedin.com/in/soulmachine&quot;&gt;LinkedIn&lt;/a&gt;, &lt;a href=&quot;http://www.quora.com/Jason-Day-2&quot;&gt;Quora&lt;/a&gt;&lt;/p&gt;</div><div class=\"line\">  &lt;/p&gt;</div><div class=\"line\">&lt;/section&gt;</div></pre></td></tr></table></figure>\n<p>在 _config.yml 的 default_asides 里添加 custom/asides/about.html。</p>\n<p>##添加about页面</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">rake new_page[about]</div></pre></td></tr></table></figure>\n<p>会生成 source/about/index.markdown 文件。</p>\n<p>编辑该文件的内容。</p>\n<p>然后在头部导航菜单中添加页面的超链接。具体做法是编辑 /source/_includes/custom/navigation.html 文件。</p>\n<h2 id=\"社会化分享\"><a href=\"#社会化分享\" class=\"headerlink\" title=\"社会化分享\"></a>社会化分享</h2><p>使用addthis.com的分享按钮，在网站上获取代码，粘贴到<code>source/_includes/post/sharing.html</code>中，例如我的代码如下：</p>\n<figure class=\"highlight html\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">div</span> <span class=\"attr\">class</span>=<span class=\"string\">\"sharing\"</span>&gt;</span></div><div class=\"line\">  <span class=\"comment\">&lt;!-- AddThis Button BEGIN --&gt;</span></div><div class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">div</span> <span class=\"attr\">class</span>=<span class=\"string\">\"addthis_toolbox addthis_default_style addthis_32x32_style\"</span>&gt;</span></div><div class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">a</span> <span class=\"attr\">class</span>=<span class=\"string\">\"addthis_button_sinaweibo\"</span>&gt;</span><span class=\"tag\">&lt;/<span class=\"name\">a</span>&gt;</span></div><div class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">a</span> <span class=\"attr\">class</span>=<span class=\"string\">\"addthis_button_facebook\"</span>&gt;</span><span class=\"tag\">&lt;/<span class=\"name\">a</span>&gt;</span></div><div class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">a</span> <span class=\"attr\">class</span>=<span class=\"string\">\"addthis_button_twitter\"</span>&gt;</span><span class=\"tag\">&lt;/<span class=\"name\">a</span>&gt;</span></div><div class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">a</span> <span class=\"attr\">class</span>=<span class=\"string\">\"addthis_button_google_plusone_share\"</span>&gt;</span><span class=\"tag\">&lt;/<span class=\"name\">a</span>&gt;</span></div><div class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">a</span> <span class=\"attr\">class</span>=<span class=\"string\">\"addthis_button_delicious\"</span>&gt;</span><span class=\"tag\">&lt;/<span class=\"name\">a</span>&gt;</span></div><div class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">a</span> <span class=\"attr\">class</span>=<span class=\"string\">\"addthis_button_digg\"</span>&gt;</span><span class=\"tag\">&lt;/<span class=\"name\">a</span>&gt;</span></div><div class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">a</span> <span class=\"attr\">class</span>=<span class=\"string\">\"addthis_button_reddit\"</span>&gt;</span><span class=\"tag\">&lt;/<span class=\"name\">a</span>&gt;</span></div><div class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">a</span> <span class=\"attr\">class</span>=<span class=\"string\">\"addthis_button_compact\"</span>&gt;</span><span class=\"tag\">&lt;/<span class=\"name\">a</span>&gt;</span><span class=\"tag\">&lt;<span class=\"name\">a</span> <span class=\"attr\">class</span>=<span class=\"string\">\"addthis_counter addthis_bubble_style\"</span>&gt;</span><span class=\"tag\">&lt;/<span class=\"name\">a</span>&gt;</span></div><div class=\"line\">  <span class=\"tag\">&lt;/<span class=\"name\">div</span>&gt;</span></div><div class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">script</span> <span class=\"attr\">type</span>=<span class=\"string\">\"text/javascript\"</span> <span class=\"attr\">src</span>=<span class=\"string\">\"//s7.addthis.com/js/300/addthis_widget.js#pubid=undefined\"</span>&gt;</span><span class=\"undefined\"></span><span class=\"tag\">&lt;/<span class=\"name\">script</span>&gt;</span></div><div class=\"line\">  <span class=\"comment\">&lt;!-- AddThis Button END --&gt;</span></div></pre></td></tr></table></figure>\n<p>在_config.yml 中，将twitter, google+ 和facebook like的按钮设置为false，取消显示，因为 AddThis 已经集成了这三者。</p>\n<h2 id=\"社会化评论\"><a href=\"#社会化评论\" class=\"headerlink\" title=\"社会化评论\"></a>社会化评论</h2><p><del>启用Disqus，填入 short name即可。</del>Disqus在国外流行，在国内的加载速度太慢，而且只有twitter, facebook, g+，没有照顾到国内的用户习惯，因此替换成国内的<a href=\"www.duoshuo.com\">多说</a>。参考这篇博客 <a href=\"http://ihavanna.org/Internet/2013-02/add-duoshuo-commemt-system-into-octopress.html\" target=\"_blank\" rel=\"external\">为 Octopress 添加多说评论系统</a>。<code>source/_includes/post/duoshuo_thread.html</code>的代码略有不同，添加了<code>data-title=&quot;&quot;</code>，否则侧边栏的最近评论，标题为空白，感谢<a href=\"http://yrzhll.com/blog/2012/12/12/comment/\" target=\"_blank\" rel=\"external\">碟姐 - 在octopress中添加多说的最近评论</a>指出了这一点，代码如下：</p>\n<figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div></pre></td><td class=\"code\"><pre><div class=\"line\">&lt;!-- Duoshuo Comment BEGIN --&gt;</div><div class=\"line\"><span class=\"xml\"><span class=\"tag\">&lt;<span class=\"name\">div</span> <span class=\"attr\">class</span>=<span class=\"string\">\"ds-thread\"</span> <span class=\"attr\">data-title</span>=<span class=\"string\">\"&#123;&#123; page.title &#125;&#125;\"</span>&gt;</span><span class=\"tag\">&lt;/<span class=\"name\">div</span>&gt;</span></span></div><div class=\"line\">&lt;script type=<span class=\"string\">\"text/javascript\"</span>&gt;</div><div class=\"line\"><span class=\"keyword\">var</span> duoshuoQuery = &#123;short_name:<span class=\"string\">\"yanjiuyanjiu\"</span>&#125;;</div><div class=\"line\">\t(<span class=\"function\"><span class=\"keyword\">function</span>(<span class=\"params\"></span>) </span>&#123;</div><div class=\"line\">\t\t<span class=\"keyword\">var</span> ds = <span class=\"built_in\">document</span>.createElement(<span class=\"string\">'script'</span>);</div><div class=\"line\">\t\tds.type = <span class=\"string\">'text/javascript'</span>;ds.async = <span class=\"literal\">true</span>;</div><div class=\"line\">\t\tds.src = <span class=\"string\">'http://static.duoshuo.com/embed.js'</span>;</div><div class=\"line\">\t\tds.charset = <span class=\"string\">'UTF-8'</span>;</div><div class=\"line\">\t\t(<span class=\"built_in\">document</span>.getElementsByTagName(<span class=\"string\">'head'</span>)[<span class=\"number\">0</span>] </div><div class=\"line\">\t\t|| <span class=\"built_in\">document</span>.getElementsByTagName(<span class=\"string\">'body'</span>)[<span class=\"number\">0</span>]).appendChild(ds);</div><div class=\"line\">\t&#125;)();</div><div class=\"line\"><span class=\"xml\"><span class=\"tag\">&lt;/<span class=\"name\">script</span>&gt;</span></span></div><div class=\"line\">&lt;!-- Duoshuo Comment END --&gt;</div></pre></td></tr></table></figure>\n<p>_config.yml 中的配置也略有不同： </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div></pre></td><td class=\"code\"><pre><div class=\"line\">duoshuo_comments: true</div><div class=\"line\">duoshuo_short_name: yanjiuyanjiu</div><div class=\"line\">duoshuo_asides_num: 5      # 侧边栏评论显示条目数</div><div class=\"line\">duoshuo_asides_avatars: 1   # 侧边栏评论是否显示头像</div><div class=\"line\">duoshuo_asides_time: 1      # 侧边栏评论是否显示时间</div><div class=\"line\">duoshuo_asides_title: 1     # 侧边栏评论是否显示标题</div><div class=\"line\">duoshuo_asides_admin: 0     # 侧边栏评论是否显示作者评论</div><div class=\"line\">duoshuo_asides_length: 32   # 侧边栏评论截取的长度</div></pre></td></tr></table></figure>\n<h2 id=\"设置固定链接\"><a href=\"#设置固定链接\" class=\"headerlink\" title=\"设置固定链接\"></a>设置固定链接</h2><p>在 _config.yml 里，找到 permalink，设置如下：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">permalink: /blog/:year:month:day/</div></pre></td></tr></table></figure>\n<p>效果就是<code>www.example.com/blog/20130403/</code>。模仿的是豆瓣的URL格式。</p>\n<p>参考官方文档<a href=\"https://github.com/mojombo/jekyll/wiki/Permalinks\" target=\"_blank\" rel=\"external\">jekyll Permalinks</a>。</p>\n<h2 id=\"侧边栏显示分类目录\"><a href=\"#侧边栏显示分类目录\" class=\"headerlink\" title=\"侧边栏显示分类目录\"></a>侧边栏显示分类目录</h2><p>使用第三方插件 <a href=\"https://github.com/tokkonopapa/octopress-tagcloud\" target=\"_blank\" rel=\"external\">octopress-tagcloud</a>。</p>\n<p>##友情链接<br>在<code>source\\_includes\\custom\\asides</code> 目录下添加一个blogroll.html文件，模仿about.html，添加一些友情链接，例如：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div></pre></td><td class=\"code\"><pre><div class=\"line\">&lt;section&gt;</div><div class=\"line\">  &lt;h1&gt;友情链接&lt;/h1&gt;</div><div class=\"line\">  &lt;ul&gt;</div><div class=\"line\">    &lt;li&gt;</div><div class=\"line\">      &lt;a href=&quot;http://coolshell.cn/&quot;&gt;酷壳CoolShell&lt;/a&gt;</div><div class=\"line\">    &lt;/li&gt;</div><div class=\"line\">    &lt;li&gt;</div><div class=\"line\">      &lt;a href=&quot;http://mindhacks.cn/&quot;&gt;刘未鹏MIND HACKS&lt;/a&gt;</div><div class=\"line\">    &lt;/li&gt;</div><div class=\"line\">    &lt;li&gt;</div><div class=\"line\">      &lt;a href=&quot;http://blog.codingnow.com/&quot;&gt;云风&lt;/a&gt;</div><div class=\"line\">    &lt;/li&gt;</div><div class=\"line\">    &lt;li&gt;</div><div class=\"line\">      &lt;a href=&quot;http://www.cnblogs.com/Solstice/&quot;&gt;陈硕&lt;/a&gt;</div><div class=\"line\">    &lt;/li&gt;</div><div class=\"line\">  &lt;/ul&gt;</div><div class=\"line\">&lt;/section&gt;</div></pre></td></tr></table></figure>\n<p>然后在 _config.yml 文件中，在 default_asides 的数组中添加 <code>custom/asides/blogroll.html</code>。</p>\n<p>##中文目录<br>TODO</p>\n<p>##修改字体<br>Octopresss默认使用的是 google webfonts，见<code>source/_includes/custom/head.html</code>里的两行代码。Google Webfonts是个好东西，但遗憾的是它没有中文字体。所以你用<strong>粗体</strong>，发现并没有变粗，就是这个原因。</p>\n<p>首先，将head.html中的两行代码注释掉，省去了加载字体，加快网页加载速度。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">&lt;!--Fonts from Google&quot;s Web font directory at http://google.com/webfonts --&gt;</div><div class=\"line\">&lt;!-- &lt;link href=&quot;http://fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic&quot; rel=&quot;stylesheet&quot; type=&quot;text/css&quot;&gt; --&gt;</div><div class=\"line\">&lt;!-- &lt;link href=&quot;http://fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic&quot; rel=&quot;stylesheet&quot; type=&quot;text/css&quot;&gt; --&gt;</div></pre></td></tr></table></figure>\n<p>参考 这篇博客 <a href=\"http://lifesinger.wordpress.com/2011/04/06/best-web-default-fonts/\" target=\"_blank\" rel=\"external\">最佳 Web 中文默认字体</a>，在<code>sass/custom/_fonts.scss</code>中添加如下三行代码：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">$heading-font-family: arial, sans-serif;</div><div class=\"line\">$header-title-font-family: arial, sans-serif;</div><div class=\"line\">$header-subtitle-font-family: arial, sans-serif;</div></pre></td></tr></table></figure>\n<p>刷新网页，可以看见中文的粗体变黑了。</p>\n<p>##一些汉化工作<br>在 _config.yml中，把 <code>Read on</code> 改为 “继续阅读”。<br>在 <code>source/_includes/custom/asides</code>目录下，将”Recent Comments”改为“最新评论”，”Categories”改为“分类目录”，将<code>source/_includes/asides/recent_posts.html</code>中”Recent Posts”改为“最新文章”。</p>\n<h2 id=\"添加统计代码\"><a href=\"#添加统计代码\" class=\"headerlink\" title=\"添加统计代码\"></a>添加统计代码</h2><p>在_config.yml填入 Google Analytics Tracking ID，例如 <code>UA-7583537-4</code>。</p>\n<p>##第三方主题和插件<br>主题：<a href=\"https://github.com/imathis/octopress/wiki/3rd-Party-Octopress-Themes\" target=\"_blank\" rel=\"external\">3rd Party Octopress Themes</a><br>插件：<a href=\"https://github.com/imathis/octopress/wiki/3rd-party-plugins\" target=\"_blank\" rel=\"external\">3rd party plugins</a></p>\n<p>##在一台新电脑上恢复<br>如果换了一台电脑，怎样迅速恢复环境呢？参考 <a href=\"http://blog.zerosharp.com/clone-your-octopress-to-blog-from-two-places/\" target=\"_blank\" rel=\"external\">Clone Your Octopress to Blog From Two Places</a>。 <strong>注意，在windows上，要首先安装python，否则，虽然所有操作可以成功，不报错误，但是你发现打开后首页一篇空白，我当时百思不得其解，因为没有任何错误信息，最后去看生成的文件，所有index.html都是0字节，就猜测应该是编译出了问题。安装python就好了，linux默认是有Python的，就没有这个问题，windows真是坑爹！以后只在windows下做编辑类的工作，编译和运行都放到Linux下。</strong></p>\n<p>##TODO<br>修改字体大小</p>\n<p>添加TAG支持</p>\n<p>##参考资料</p>\n<ol>\n<li><a href=\"http://shanewfx.github.com/blog/2012/08/13/improve-blog-theme/\" target=\"_blank\" rel=\"external\">Octopress主题改造</a></li>\n<li></li>\n</ol>\n","excerpt":"<h2 id=\"实时预览\"><a href=\"#实时预览\" class=\"headerlink\" title=\"实时预览\"></a>实时预览</h2><p>使用如下命令可以实现实时预览：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">rake preview</div></pre></td></tr></table></figure>\n<p><code>rake preview</code> 会自动监视文件的变化，重新生成静态页面。因此修改markdown文件后，只需要在浏览器里刷新一下页面，就立刻可以看到效果。不过如果修改了_config.yml的话，则需要Ctrl+C终止，用<code>rake generate</code>重新生成，才能看到效果。</p>\n<h2 id=\"嵌入代码块\"><a href=\"#嵌入代码块\" class=\"headerlink\" title=\"嵌入代码块\"></a>嵌入代码块</h2><p>见官方文档<a href=\"http://octopress.org/docs/blogging/code/\">Sharing Code Snippets</a>。</p>\n<p>Octopress是一款为hacker量身定制的博客系统，当然内置了代码高亮的功能！它的代码高亮功能是通过Pygments实现的，配色方案用的是Solarized，堪称完美。</p>\n<p>Octopress支持多种方式嵌入代码，可以直接嵌入代码，也可以引用github上的gist 。</p>\n<p>我喜欢用<strong>三个反引号</strong>直接嵌入代码，比 <code>codeblock</code>要简洁。</p>\n<p>###启用MathJax<br>在<code>source/_includes/custom/footer.html</code>的第一行加入如下代码：</p>\n<figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div></pre></td><td class=\"code\"><pre><div class=\"line\">&lt;!-- mathjax config similar to math.stackexchange --&gt;</div><div class=\"line\">&lt;script type=\"text/x-mathjax-config\"&gt;</div><div class=\"line\">MathJax.Hub.Config(&#123;</div><div class=\"line\">  jax: [\"input/TeX\", \"output/HTML-CSS\"],</div><div class=\"line\">  tex2jax: &#123;</div><div class=\"line\">    inlineMath: [ ['$', '$'] ],</div><div class=\"line\">    displayMath: [ ['$$', '$$']],</div><div class=\"line\">    processEscapes: true,</div><div class=\"line\">    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']</div><div class=\"line\">  &#125;,</div><div class=\"line\">  messageStyle: \"none\",</div><div class=\"line\">  \"HTML-CSS\": &#123; preferredFont: \"TeX\", availableFonts: [\"STIX\",\"TeX\"] &#125;</div><div class=\"line\">&#125;);</div><div class=\"line\">&lt;/script&gt;</div><div class=\"line\">&lt;script src=<span class=\"string\">\"http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML\"</span> type=<span class=\"string\">\"text/javascript\"</span>&gt;&lt;/script&gt;</div></pre></td></tr></table></figure>\n<p>这样就引入了MathJax的JS包，可以直接在markdown文件里直接写公式了，例如 $\\dfrac {\\pi}{2}$。</p>\n<p>上面的代码也可以在<code>source/_includes/custom/header.html</code>里添加，不过这样会使得页面的加载速度变慢。还可以在<code>source/_layouts/default.html</code>里添加。</p>","more":"<p>有一个问题，rdiscount这个解析器，对 mathjax 大部分支持，某些细节处理的不好，举个例子，它会在动把公式中的 <code>^n</code>转换成<code>&lt;sup&gt;n&lt;/sup&gt;</code>，例如<code>$2^n$</code>会解析成<code>$2&lt;sup&gt;n&lt;/sup&gt;$</code>，这样就破坏了整个公式，导致公式无法解析。参考<a href=\"http://christopherpoole.github.io/using-mathjax-on-github-pages/\">这里</a>一段话：</p>\n<blockquote>\n<p>as discount for example automatically replaces <code>x^2</code> with <code>x&lt;sup&gt;2&lt;/sup&gt;</code> which interrupts the MathJax rendering.</p>\n</blockquote>\n<p>因此要换一个解析器，<a href=\"http://maruku.rubyforge.org/\">Maruku</a> 和 <a href=\"http://kramdown.rubyforge.org/\">Kramdown</a> 都可以，由于Maruku主页PR=4，Kramdown的主页PR=5，我选择了Kramdown。</p>\n<p><strong>用Kramdown代替Rdiscount</strong><br>修改Gemfile，增加一行：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">gem &apos;kramdown&apos;, &apos;~&gt; 0.14&apos;</div></pre></td></tr></table></figure>\n<p>很多博客都说要配套安装coderay这个gem，其实是没有必要的，只要代码块以 ``` 开始和结束，自带的pygments就能实现代码高亮。</p>\n<p>在Git Bash输入如下命令：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">bundle install</div></pre></td></tr></table></figure>\n<p>就会自动安装kramdown。</p>\n<p>然后在_config.yml 文件中，见markdown: rdiscount 修改为  markdown: kramdown。</p>\n<p>使用kramdown，感觉它的语法要求比rdiscout严格，例如每个代码块开头，必须有一个空行，否则高亮就会失败，大家可以试试看。每个标题掐面，也必须有一个开头。</p>\n<p>kramdown的两种公式，display和inline，都是以<code>$$</code>开头和结尾的，display模式时，<code>$$</code>要单独占一行。这跟标准的LaTex有点不一样。参考<a href=\"http://kqueue.org/blog/2012/01/05/hello-world/\">这里</a>。</p>\n<p><strong>右击公式全屏空白</strong>：这时候右击公式，全屏空白。解决这个问题很简单，只需在 <code>sass/base/_theme.scss</code>添加”#main”即可：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">body &#123;</div><div class=\"line\">  &gt; div#main &#123;</div><div class=\"line\">    background: $sidebar-bg $noise-bg;</div></pre></td></tr></table></figure>\n<p>本节参考了<a href=\"http://www.idryman.org/blog/2012/03/10/writing-math-equations-on-octopress/\">Writing Math Equations on Octopress</a> 和 <a href=\"http://jasonllinux.github.com/blog/2012/11/06/write-latex-in-octopress/\">在Octopress中使用Latex公式</a>。</p>\n<p>##kramdown的扩展语法<br>kramdown扩展了标准markdown的语法，有很多使用的功能。<a href=\"http://kramdown.rubyforge.org/syntax.html\">语法见官网文档</a>。这里选一些我常用的。</p>\n<p><strong>脚注(footnote)</strong><br>脚注定义是：<code>[^1]:</code>，数字可以改变，引用语法是<code>[^1]</code>。没有被引用到的参考文献，会被忽略掉。</p>\n<p><strong>表格</strong><br>一下是一个示例：</p>\n<pre><code>|-----------------+------------+-----------------+----------------|\n| Default aligned |Left aligned| Center aligned  | Right aligned  |\n|-----------------|:-----------|:---------------:|---------------:|\n| First body part |Second cell | Third cell      | fourth cell    |\n| Second line     |foo         | **strong**      | baz            |\n| Third line      |quux        | baz             | bar            |\n|-----------------+------------+-----------------+----------------|\n</code></pre><p>更详细说明见官网。</p>\n<h2 id=\"首页只显示部分正文-Excerpts\"><a href=\"#首页只显示部分正文-Excerpts\" class=\"headerlink\" title=\"首页只显示部分正文(Excerpts)\"></a>首页只显示部分正文(Excerpts)</h2><p>Octopress中，可以使用 <code>&lt;!--more--&gt;</code>，这样首页只显示一部分正文，并在每篇文章底下加一个Read on超链接。</p>\n<h2 id=\"插入图片\"><a href=\"#插入图片\" class=\"headerlink\" title=\"插入图片\"></a>插入图片</h2><p>使用<a href=\"http://octopress.org/docs/plugins/image-tag/\">Image Tag</a>。</p>\n<p>语法</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">&#123;% img [class names] /path/to/image [width] [height] [title text [alt text]] %&#125;</div></pre></td></tr></table></figure>\n<p>例子</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\">&#123;% img http://placekitten.com/890/280 %&#125;</div><div class=\"line\">&#123;% img left http://placekitten.com/320/250 Place Kitten #2 %&#125;</div><div class=\"line\">&#123;% img right http://placekitten.com/300/500 150 250 Place Kitten #3 %&#125;</div><div class=\"line\">&#123;% img right http://placekitten.com/300/500 150 250 &apos;Place Kitten #4&apos; &apos;An image of a very cute kitten&apos; %&#125;</div></pre></td></tr></table></figure>\n<h2 id=\"添加about-me-边栏\"><a href=\"#添加about-me-边栏\" class=\"headerlink\" title=\"添加about me 边栏\"></a>添加about me 边栏</h2><p>编辑 source_includes\\custom\\asides\\about.html，内容如下：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div></pre></td><td class=\"code\"><pre><div class=\"line\">&lt;section&gt;</div><div class=\"line\">  &lt;h1&gt;About Me&lt;/h1&gt;</div><div class=\"line\">  &lt;p&gt;一句话自我介绍.&lt;/p&gt;</div><div class=\"line\">  &lt;p&gt;新浪微博: &lt;a href=&quot;http://weibo.com/soulmachine&quot;&gt;@soulmachine&lt;/a&gt;&lt;br/&gt;</div><div class=\"line\">     Twitter: &lt;a href=&quot;https://twitter.com/#!/soulmachine&quot;&gt;@soulmachine&lt;/a&gt;&lt;br/&gt;</div><div class=\"line\">     Other: &lt;a href=&quot;https://github.com/soulmachine&quot;&gt;Github&lt;/a&gt;, &lt;a href=&quot;https://plus.google.com/103519507226474510310&quot;&gt;Google+&lt;/a&gt;, &lt;a href=&quot;http://www.linkedin.com/in/soulmachine&quot;&gt;LinkedIn&lt;/a&gt;, &lt;a href=&quot;http://www.quora.com/Jason-Day-2&quot;&gt;Quora&lt;/a&gt;&lt;/p&gt;</div><div class=\"line\">  &lt;/p&gt;</div><div class=\"line\">&lt;/section&gt;</div></pre></td></tr></table></figure>\n<p>在 _config.yml 的 default_asides 里添加 custom/asides/about.html。</p>\n<p>##添加about页面</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">rake new_page[about]</div></pre></td></tr></table></figure>\n<p>会生成 source/about/index.markdown 文件。</p>\n<p>编辑该文件的内容。</p>\n<p>然后在头部导航菜单中添加页面的超链接。具体做法是编辑 /source/_includes/custom/navigation.html 文件。</p>\n<h2 id=\"社会化分享\"><a href=\"#社会化分享\" class=\"headerlink\" title=\"社会化分享\"></a>社会化分享</h2><p>使用addthis.com的分享按钮，在网站上获取代码，粘贴到<code>source/_includes/post/sharing.html</code>中，例如我的代码如下：</p>\n<figure class=\"highlight html\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">div</span> <span class=\"attr\">class</span>=<span class=\"string\">\"sharing\"</span>&gt;</span></div><div class=\"line\">  <span class=\"comment\">&lt;!-- AddThis Button BEGIN --&gt;</span></div><div class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">div</span> <span class=\"attr\">class</span>=<span class=\"string\">\"addthis_toolbox addthis_default_style addthis_32x32_style\"</span>&gt;</span></div><div class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">a</span> <span class=\"attr\">class</span>=<span class=\"string\">\"addthis_button_sinaweibo\"</span>&gt;</span><span class=\"tag\">&lt;/<span class=\"name\">a</span>&gt;</span></div><div class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">a</span> <span class=\"attr\">class</span>=<span class=\"string\">\"addthis_button_facebook\"</span>&gt;</span><span class=\"tag\">&lt;/<span class=\"name\">a</span>&gt;</span></div><div class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">a</span> <span class=\"attr\">class</span>=<span class=\"string\">\"addthis_button_twitter\"</span>&gt;</span><span class=\"tag\">&lt;/<span class=\"name\">a</span>&gt;</span></div><div class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">a</span> <span class=\"attr\">class</span>=<span class=\"string\">\"addthis_button_google_plusone_share\"</span>&gt;</span><span class=\"tag\">&lt;/<span class=\"name\">a</span>&gt;</span></div><div class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">a</span> <span class=\"attr\">class</span>=<span class=\"string\">\"addthis_button_delicious\"</span>&gt;</span><span class=\"tag\">&lt;/<span class=\"name\">a</span>&gt;</span></div><div class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">a</span> <span class=\"attr\">class</span>=<span class=\"string\">\"addthis_button_digg\"</span>&gt;</span><span class=\"tag\">&lt;/<span class=\"name\">a</span>&gt;</span></div><div class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">a</span> <span class=\"attr\">class</span>=<span class=\"string\">\"addthis_button_reddit\"</span>&gt;</span><span class=\"tag\">&lt;/<span class=\"name\">a</span>&gt;</span></div><div class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">a</span> <span class=\"attr\">class</span>=<span class=\"string\">\"addthis_button_compact\"</span>&gt;</span><span class=\"tag\">&lt;/<span class=\"name\">a</span>&gt;</span><span class=\"tag\">&lt;<span class=\"name\">a</span> <span class=\"attr\">class</span>=<span class=\"string\">\"addthis_counter addthis_bubble_style\"</span>&gt;</span><span class=\"tag\">&lt;/<span class=\"name\">a</span>&gt;</span></div><div class=\"line\">  <span class=\"tag\">&lt;/<span class=\"name\">div</span>&gt;</span></div><div class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">script</span> <span class=\"attr\">type</span>=<span class=\"string\">\"text/javascript\"</span> <span class=\"attr\">src</span>=<span class=\"string\">\"//s7.addthis.com/js/300/addthis_widget.js#pubid=undefined\"</span>&gt;</span><span class=\"undefined\"></span><span class=\"tag\">&lt;/<span class=\"name\">script</span>&gt;</span></div><div class=\"line\">  <span class=\"comment\">&lt;!-- AddThis Button END --&gt;</span></div></pre></td></tr></table></figure>\n<p>在_config.yml 中，将twitter, google+ 和facebook like的按钮设置为false，取消显示，因为 AddThis 已经集成了这三者。</p>\n<h2 id=\"社会化评论\"><a href=\"#社会化评论\" class=\"headerlink\" title=\"社会化评论\"></a>社会化评论</h2><p><del>启用Disqus，填入 short name即可。</del>Disqus在国外流行，在国内的加载速度太慢，而且只有twitter, facebook, g+，没有照顾到国内的用户习惯，因此替换成国内的<a href=\"www.duoshuo.com\">多说</a>。参考这篇博客 <a href=\"http://ihavanna.org/Internet/2013-02/add-duoshuo-commemt-system-into-octopress.html\">为 Octopress 添加多说评论系统</a>。<code>source/_includes/post/duoshuo_thread.html</code>的代码略有不同，添加了<code>data-title=&quot;&quot;</code>，否则侧边栏的最近评论，标题为空白，感谢<a href=\"http://yrzhll.com/blog/2012/12/12/comment/\">碟姐 - 在octopress中添加多说的最近评论</a>指出了这一点，代码如下：</p>\n<figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div></pre></td><td class=\"code\"><pre><div class=\"line\">&lt;!-- Duoshuo Comment BEGIN --&gt;</div><div class=\"line\"><span class=\"xml\"><span class=\"tag\">&lt;<span class=\"name\">div</span> <span class=\"attr\">class</span>=<span class=\"string\">\"ds-thread\"</span> <span class=\"attr\">data-title</span>=<span class=\"string\">\"&#123;&#123; page.title &#125;&#125;\"</span>&gt;</span><span class=\"tag\">&lt;/<span class=\"name\">div</span>&gt;</span></span></div><div class=\"line\">&lt;script type=<span class=\"string\">\"text/javascript\"</span>&gt;</div><div class=\"line\"><span class=\"keyword\">var</span> duoshuoQuery = &#123;short_name:<span class=\"string\">\"yanjiuyanjiu\"</span>&#125;;</div><div class=\"line\">\t(<span class=\"function\"><span class=\"keyword\">function</span>(<span class=\"params\"></span>) </span>&#123;</div><div class=\"line\">\t\t<span class=\"keyword\">var</span> ds = <span class=\"built_in\">document</span>.createElement(<span class=\"string\">'script'</span>);</div><div class=\"line\">\t\tds.type = <span class=\"string\">'text/javascript'</span>;ds.async = <span class=\"literal\">true</span>;</div><div class=\"line\">\t\tds.src = <span class=\"string\">'http://static.duoshuo.com/embed.js'</span>;</div><div class=\"line\">\t\tds.charset = <span class=\"string\">'UTF-8'</span>;</div><div class=\"line\">\t\t(<span class=\"built_in\">document</span>.getElementsByTagName(<span class=\"string\">'head'</span>)[<span class=\"number\">0</span>] </div><div class=\"line\">\t\t|| <span class=\"built_in\">document</span>.getElementsByTagName(<span class=\"string\">'body'</span>)[<span class=\"number\">0</span>]).appendChild(ds);</div><div class=\"line\">\t&#125;)();</div><div class=\"line\"><span class=\"xml\"><span class=\"tag\">&lt;/<span class=\"name\">script</span>&gt;</span></span></div><div class=\"line\">&lt;!-- Duoshuo Comment END --&gt;</div></pre></td></tr></table></figure>\n<p>_config.yml 中的配置也略有不同： </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div></pre></td><td class=\"code\"><pre><div class=\"line\">duoshuo_comments: true</div><div class=\"line\">duoshuo_short_name: yanjiuyanjiu</div><div class=\"line\">duoshuo_asides_num: 5      # 侧边栏评论显示条目数</div><div class=\"line\">duoshuo_asides_avatars: 1   # 侧边栏评论是否显示头像</div><div class=\"line\">duoshuo_asides_time: 1      # 侧边栏评论是否显示时间</div><div class=\"line\">duoshuo_asides_title: 1     # 侧边栏评论是否显示标题</div><div class=\"line\">duoshuo_asides_admin: 0     # 侧边栏评论是否显示作者评论</div><div class=\"line\">duoshuo_asides_length: 32   # 侧边栏评论截取的长度</div></pre></td></tr></table></figure>\n<h2 id=\"设置固定链接\"><a href=\"#设置固定链接\" class=\"headerlink\" title=\"设置固定链接\"></a>设置固定链接</h2><p>在 _config.yml 里，找到 permalink，设置如下：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">permalink: /blog/:year:month:day/</div></pre></td></tr></table></figure>\n<p>效果就是<code>www.example.com/blog/20130403/</code>。模仿的是豆瓣的URL格式。</p>\n<p>参考官方文档<a href=\"https://github.com/mojombo/jekyll/wiki/Permalinks\">jekyll Permalinks</a>。</p>\n<h2 id=\"侧边栏显示分类目录\"><a href=\"#侧边栏显示分类目录\" class=\"headerlink\" title=\"侧边栏显示分类目录\"></a>侧边栏显示分类目录</h2><p>使用第三方插件 <a href=\"https://github.com/tokkonopapa/octopress-tagcloud\">octopress-tagcloud</a>。</p>\n<p>##友情链接<br>在<code>source\\_includes\\custom\\asides</code> 目录下添加一个blogroll.html文件，模仿about.html，添加一些友情链接，例如：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div></pre></td><td class=\"code\"><pre><div class=\"line\">&lt;section&gt;</div><div class=\"line\">  &lt;h1&gt;友情链接&lt;/h1&gt;</div><div class=\"line\">  &lt;ul&gt;</div><div class=\"line\">    &lt;li&gt;</div><div class=\"line\">      &lt;a href=&quot;http://coolshell.cn/&quot;&gt;酷壳CoolShell&lt;/a&gt;</div><div class=\"line\">    &lt;/li&gt;</div><div class=\"line\">    &lt;li&gt;</div><div class=\"line\">      &lt;a href=&quot;http://mindhacks.cn/&quot;&gt;刘未鹏MIND HACKS&lt;/a&gt;</div><div class=\"line\">    &lt;/li&gt;</div><div class=\"line\">    &lt;li&gt;</div><div class=\"line\">      &lt;a href=&quot;http://blog.codingnow.com/&quot;&gt;云风&lt;/a&gt;</div><div class=\"line\">    &lt;/li&gt;</div><div class=\"line\">    &lt;li&gt;</div><div class=\"line\">      &lt;a href=&quot;http://www.cnblogs.com/Solstice/&quot;&gt;陈硕&lt;/a&gt;</div><div class=\"line\">    &lt;/li&gt;</div><div class=\"line\">  &lt;/ul&gt;</div><div class=\"line\">&lt;/section&gt;</div></pre></td></tr></table></figure>\n<p>然后在 _config.yml 文件中，在 default_asides 的数组中添加 <code>custom/asides/blogroll.html</code>。</p>\n<p>##中文目录<br>TODO</p>\n<p>##修改字体<br>Octopresss默认使用的是 google webfonts，见<code>source/_includes/custom/head.html</code>里的两行代码。Google Webfonts是个好东西，但遗憾的是它没有中文字体。所以你用<strong>粗体</strong>，发现并没有变粗，就是这个原因。</p>\n<p>首先，将head.html中的两行代码注释掉，省去了加载字体，加快网页加载速度。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">&lt;!--Fonts from Google&quot;s Web font directory at http://google.com/webfonts --&gt;</div><div class=\"line\">&lt;!-- &lt;link href=&quot;http://fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic&quot; rel=&quot;stylesheet&quot; type=&quot;text/css&quot;&gt; --&gt;</div><div class=\"line\">&lt;!-- &lt;link href=&quot;http://fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic&quot; rel=&quot;stylesheet&quot; type=&quot;text/css&quot;&gt; --&gt;</div></pre></td></tr></table></figure>\n<p>参考 这篇博客 <a href=\"http://lifesinger.wordpress.com/2011/04/06/best-web-default-fonts/\">最佳 Web 中文默认字体</a>，在<code>sass/custom/_fonts.scss</code>中添加如下三行代码：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">$heading-font-family: arial, sans-serif;</div><div class=\"line\">$header-title-font-family: arial, sans-serif;</div><div class=\"line\">$header-subtitle-font-family: arial, sans-serif;</div></pre></td></tr></table></figure>\n<p>刷新网页，可以看见中文的粗体变黑了。</p>\n<p>##一些汉化工作<br>在 _config.yml中，把 <code>Read on</code> 改为 “继续阅读”。<br>在 <code>source/_includes/custom/asides</code>目录下，将”Recent Comments”改为“最新评论”，”Categories”改为“分类目录”，将<code>source/_includes/asides/recent_posts.html</code>中”Recent Posts”改为“最新文章”。</p>\n<h2 id=\"添加统计代码\"><a href=\"#添加统计代码\" class=\"headerlink\" title=\"添加统计代码\"></a>添加统计代码</h2><p>在_config.yml填入 Google Analytics Tracking ID，例如 <code>UA-7583537-4</code>。</p>\n<p>##第三方主题和插件<br>主题：<a href=\"https://github.com/imathis/octopress/wiki/3rd-Party-Octopress-Themes\">3rd Party Octopress Themes</a><br>插件：<a href=\"https://github.com/imathis/octopress/wiki/3rd-party-plugins\">3rd party plugins</a></p>\n<p>##在一台新电脑上恢复<br>如果换了一台电脑，怎样迅速恢复环境呢？参考 <a href=\"http://blog.zerosharp.com/clone-your-octopress-to-blog-from-two-places/\">Clone Your Octopress to Blog From Two Places</a>。 <strong>注意，在windows上，要首先安装python，否则，虽然所有操作可以成功，不报错误，但是你发现打开后首页一篇空白，我当时百思不得其解，因为没有任何错误信息，最后去看生成的文件，所有index.html都是0字节，就猜测应该是编译出了问题。安装python就好了，linux默认是有Python的，就没有这个问题，windows真是坑爹！以后只在windows下做编辑类的工作，编译和运行都放到Linux下。</strong></p>\n<p>##TODO<br>修改字体大小</p>\n<p>添加TAG支持</p>\n<p>##参考资料</p>\n<ol>\n<li><a href=\"http://shanewfx.github.com/blog/2012/08/13/improve-blog-theme/\">Octopress主题改造</a></li>\n<li></li>\n</ol>"},{"layout":"post","title":"LaTeX的各种发行版和编辑器的比较","date":"2013-04-12T11:01:00.000Z","comments":1,"_content":"##发行版(distribution)\nTeX类似于Linux，有很多不同的发行版(distribution)。\n\n先看看各个发行版的流行程度。\n \n|----------+-------------------------------+--------+-----------+------------------+-----------+-----------|  \n| **名字** |            **官网**           | **PR** | **Alexa** |   **最后更新**   | **weibo** | **quora** |  \n|:--------:|:-----------------------------:|:------:|:---------:|:----------------:|:---------:|:--------:|  \n| TeX Live |     <http://www.tug.org/texlive/>    |    7   |    N/A    |    2012-07-01    |     43    |    N/A    |  \n|  MiKTeX  |     <http://miktex.org/>      |    7   |  188,485  | 1.3.2 2012-09-24 |     54    |    N/A    |  \n|   CTeX   |     <http://www.ctex.org/>    |    6   |  252,657  | 2.9.2 2012-03-30 |     344   |    N/A    |  \n|  proTeXt | <http://www.tug.org/protext/> |    7   |    N/A    | 3.1.1 2012-07-23 |     10    |    N/A    |  \n|----------+-------------------------------+--------+-----------+------------------+-----------+-----------|   \n\n其中CTeX和proTeXt都是基于MiKTeX的，再次进行了打包。国内估计用CTeX比较多。\n\n##编辑器(editor)\n编辑器大概分为两种，一种为WYSIWYG，所见即所得，实时预览，类似于Word，另一种是纯文本编辑器，有语法高亮，没有预览功能，需要另外安装一个发行版，编译成PDF后才能预览。\n\n先看看各个编辑器的流行程度。\n\n|--------------+-------------------------------------+--------+-----------+--------------+--------------------------+-----------+-----------|  \n|   **名字**   |                 **官网**            | **PR** | **Alexa** | **预览类型** |      **最后更新**        | **weibo** | **quora** |  \n|:------------:|:-----------------------------------:|:------:|:---------:|:------------:|:------------------------:|:---------:|:---------:|  \n|   TeXmaker   | <http://www.xm1math.net/texmaker/>  |    6   |  289,311  |    无预览    |      4.0.1 2013-03-16    |     60    |    N/A    |  \n|   TeXworks   |   <http://www.tug.org/texworks/>    |    5   |  90,230   |    无预览    |      0.4.4  2012-04      |     23    |    N/A    |  \n|   TeXstudio  | <http://texstudio.sourceforge.net/> |    6   |    N/A    |    无预览    |      2.5.2 2013-01-08    |     15    |    N/A    |  \n| TeXnicCenter |   <http://www.texniccenter.org/>    |    7   |  884,570  |    无预览    |  v2.0 beta1 2012-11-03   |     10    |    N/A    |  \n|     Lyx      |       <http://www.lyx.org/>         |    6   |  261,649  |   实时预览   |    2.0.5.1 2013-01-08    |     56    |     42    |  \n|    Bakoma    |   <http://www.bakoma-tex.com/>      |    5   | 1,327,901 |   实时预览   |     10.10 2013-01-13     |      3    |    N/A    |  \n|   TeXmacs    |     <http://www.texmacs.org>        |    6   | 1,525,373 |   实时预览   |   1.0.7.19 2013-03-27    |     27    |    N/A    |  \n|     LEd      |   <http://www.latexeditor.org/>     |    6   |  624,564  |   实时预览   |     0.53 2009-10-09      |     0    |    N/A    |  \n|--------------+-------------------------------------+--------+-----------+--------------+--------------------------+-----------+-----------|  \n\n<!--more-->\n\n##跨平台\n下面看看各个发行版和编辑器的跨平台支持程度。\n\n|--------------+---------+-----+-------|  \n|   **名字**   | Windows | Mac | Linux |  \n|:------------:|:-------:|:---:|:-----:|  \n|    编辑器     |         |     |       |  \n|   TeXmaker   |    √    |  √  |   √   |  \n|   TeXworks   |    √    |  √  |   √   |  \n|   TeXstudio  |    √    |  √  |   √   |   \n| TeXnicCenter |    √    |  ×  |   ×   |  \n|   WYSIWYG    |         |     |       |  \n|     Lyx      |    √    |  √  |   √   |  \n|    Bakoma    |    √    |  √  |   √   |  \n|   TeXmacs    |    √    |  √  |   √   |  \n|     LEd      |    √    |  ×  |   ×   |  \n|     发行版    |         |     |       |  \n|     MiKTeX   |     √   |  ×  |   ×   |  \n|    TeX Live  |    √    |  √  |   √   |  \n|     CTeX     |     √   |  ×  |   ×   |  \n|     proTeXt  |     √   |  ×  |   ×   |  \n|--------------+---------+-----+-------| \n\nTex Live在Mac上，叫做MacTex，见[官网的一段话](http://www.tug.org/mactex/newfeatures.html)：\n\n> MacTeX-2012 installs a completely unmodified copy of the full TeX Live 2012 distribution. This is exactly the same distribution that runs on OS X, Windows, GNU/Linux, various BSD Unix systems, and other systems.\n\n##如何选择\n四个发新版，只有 Tex Live 是跨平台的，故使用Tex Live，其他发行版抛弃。\n\nTeXmaker, TeXstudio, TeXworks 来进行比较  \n中文支持的程度，打开.tex文件是否有乱码\n\n|-----------+--------------------------+------------------------|  \n|  **名字** | **打开GB18030的tex文件** | **打开UTF8编码的文件** |  \n|:---------:|:------------------------:|:----------------------:|  \n| TeXworks  |         有乱码           |          无乱码        |  \n| TeXmaker  |         无乱码           |          无乱码        |  \n| TeXstudio |         有乱码           |          无乱码        |  \n|-----------+--------------------------+------------------------|  \n\nTeXmaker 界面丑陋，且中文支持不好，功能没有多，抛弃之。\nTeXmaker 和 TeXstudio 界面比较美观，而且二者界面风格很类似。因为TeXstudio是在TeXmaker的基础上而来的，[见wikipedia的描述](http://en.wikipedia.org/wiki/TeXstudio)：\n\n> Originally called TexMakerX, TeXstudio was started as a fork of Texmaker that tried to extend it with additional features while keeping its look and feel.\n\nTeXnicCenter 安装时不会自动探测，第一次运行时会要求你指定 latex.exe 的路径。TeXnicCenter 界面风格是office的风格，很现代化。TeXnicCenter 只有 windows版，故放弃。\n\nLyX 安装时会自动探测到TeX Live。这点比较方便，无需配置。  \nLyX可以导入.tex文件，导入后，不能直接修改.tex源码，只能在上方的可视化区域直接输入内容，即LyX强迫你用类似word的方式来输入内容。因此抛弃LyX。\n\nBakoma 是商业软件，30天试用期，网上搜了一下，没有破解版，故放弃。\n\nTeXmacs 1.0.7.19 在windows上安装完成后，双击后启动界面会闪退，完全没法用，换了1.0.7.18，可以启动了，目前发现两个问题：1. 打开（使用文件-->打开或导入）一个含有中文的.tex文件会崩溃；2. 关闭程序管不了，需要用任务管理器杀掉才行，可见TeXmacs 还很不完善，其次TeXmacs 有着自己的语法，不是一个标准的TeX发行版，因此放弃 TeXmacs 。\n\nLEd已经很久不更新，且只有windows版，放弃。\n\n大牛陈硕用的是Tex Live，他的书使用Tex Live来排版的。  \n![](http://yanjiuyanjiu-wordpress.stor.sinaapp.com/uploads/2013/04/chenshuo_texlive.png)\n\n##安装和配置\n在windows下安装 Tex Live 2012，先下载DVD ISO，然后安装即可。假设安装到`D:\\texlive`。\n\n安装完后，将`D:\\texlive\\2012\\bin\\win32`添加到PATH环境变量。这样Texmaker，Texstudio就不用配置了，安装后即可正常编译。如果没有添加到PATH环境变量，则在Texmaker，Texstudio中指定一些exe文件的绝对路径。\n\n","source":"_posts/2013-04-12-latex-distributions-and-editors.md","raw":"---\nlayout: post\ntitle: \"LaTeX的各种发行版和编辑器的比较\"\ndate: 2013-04-12 11:01\ncomments: true\ncategories: Tools\n---\n##发行版(distribution)\nTeX类似于Linux，有很多不同的发行版(distribution)。\n\n先看看各个发行版的流行程度。\n \n|----------+-------------------------------+--------+-----------+------------------+-----------+-----------|  \n| **名字** |            **官网**           | **PR** | **Alexa** |   **最后更新**   | **weibo** | **quora** |  \n|:--------:|:-----------------------------:|:------:|:---------:|:----------------:|:---------:|:--------:|  \n| TeX Live |     <http://www.tug.org/texlive/>    |    7   |    N/A    |    2012-07-01    |     43    |    N/A    |  \n|  MiKTeX  |     <http://miktex.org/>      |    7   |  188,485  | 1.3.2 2012-09-24 |     54    |    N/A    |  \n|   CTeX   |     <http://www.ctex.org/>    |    6   |  252,657  | 2.9.2 2012-03-30 |     344   |    N/A    |  \n|  proTeXt | <http://www.tug.org/protext/> |    7   |    N/A    | 3.1.1 2012-07-23 |     10    |    N/A    |  \n|----------+-------------------------------+--------+-----------+------------------+-----------+-----------|   \n\n其中CTeX和proTeXt都是基于MiKTeX的，再次进行了打包。国内估计用CTeX比较多。\n\n##编辑器(editor)\n编辑器大概分为两种，一种为WYSIWYG，所见即所得，实时预览，类似于Word，另一种是纯文本编辑器，有语法高亮，没有预览功能，需要另外安装一个发行版，编译成PDF后才能预览。\n\n先看看各个编辑器的流行程度。\n\n|--------------+-------------------------------------+--------+-----------+--------------+--------------------------+-----------+-----------|  \n|   **名字**   |                 **官网**            | **PR** | **Alexa** | **预览类型** |      **最后更新**        | **weibo** | **quora** |  \n|:------------:|:-----------------------------------:|:------:|:---------:|:------------:|:------------------------:|:---------:|:---------:|  \n|   TeXmaker   | <http://www.xm1math.net/texmaker/>  |    6   |  289,311  |    无预览    |      4.0.1 2013-03-16    |     60    |    N/A    |  \n|   TeXworks   |   <http://www.tug.org/texworks/>    |    5   |  90,230   |    无预览    |      0.4.4  2012-04      |     23    |    N/A    |  \n|   TeXstudio  | <http://texstudio.sourceforge.net/> |    6   |    N/A    |    无预览    |      2.5.2 2013-01-08    |     15    |    N/A    |  \n| TeXnicCenter |   <http://www.texniccenter.org/>    |    7   |  884,570  |    无预览    |  v2.0 beta1 2012-11-03   |     10    |    N/A    |  \n|     Lyx      |       <http://www.lyx.org/>         |    6   |  261,649  |   实时预览   |    2.0.5.1 2013-01-08    |     56    |     42    |  \n|    Bakoma    |   <http://www.bakoma-tex.com/>      |    5   | 1,327,901 |   实时预览   |     10.10 2013-01-13     |      3    |    N/A    |  \n|   TeXmacs    |     <http://www.texmacs.org>        |    6   | 1,525,373 |   实时预览   |   1.0.7.19 2013-03-27    |     27    |    N/A    |  \n|     LEd      |   <http://www.latexeditor.org/>     |    6   |  624,564  |   实时预览   |     0.53 2009-10-09      |     0    |    N/A    |  \n|--------------+-------------------------------------+--------+-----------+--------------+--------------------------+-----------+-----------|  \n\n<!--more-->\n\n##跨平台\n下面看看各个发行版和编辑器的跨平台支持程度。\n\n|--------------+---------+-----+-------|  \n|   **名字**   | Windows | Mac | Linux |  \n|:------------:|:-------:|:---:|:-----:|  \n|    编辑器     |         |     |       |  \n|   TeXmaker   |    √    |  √  |   √   |  \n|   TeXworks   |    √    |  √  |   √   |  \n|   TeXstudio  |    √    |  √  |   √   |   \n| TeXnicCenter |    √    |  ×  |   ×   |  \n|   WYSIWYG    |         |     |       |  \n|     Lyx      |    √    |  √  |   √   |  \n|    Bakoma    |    √    |  √  |   √   |  \n|   TeXmacs    |    √    |  √  |   √   |  \n|     LEd      |    √    |  ×  |   ×   |  \n|     发行版    |         |     |       |  \n|     MiKTeX   |     √   |  ×  |   ×   |  \n|    TeX Live  |    √    |  √  |   √   |  \n|     CTeX     |     √   |  ×  |   ×   |  \n|     proTeXt  |     √   |  ×  |   ×   |  \n|--------------+---------+-----+-------| \n\nTex Live在Mac上，叫做MacTex，见[官网的一段话](http://www.tug.org/mactex/newfeatures.html)：\n\n> MacTeX-2012 installs a completely unmodified copy of the full TeX Live 2012 distribution. This is exactly the same distribution that runs on OS X, Windows, GNU/Linux, various BSD Unix systems, and other systems.\n\n##如何选择\n四个发新版，只有 Tex Live 是跨平台的，故使用Tex Live，其他发行版抛弃。\n\nTeXmaker, TeXstudio, TeXworks 来进行比较  \n中文支持的程度，打开.tex文件是否有乱码\n\n|-----------+--------------------------+------------------------|  \n|  **名字** | **打开GB18030的tex文件** | **打开UTF8编码的文件** |  \n|:---------:|:------------------------:|:----------------------:|  \n| TeXworks  |         有乱码           |          无乱码        |  \n| TeXmaker  |         无乱码           |          无乱码        |  \n| TeXstudio |         有乱码           |          无乱码        |  \n|-----------+--------------------------+------------------------|  \n\nTeXmaker 界面丑陋，且中文支持不好，功能没有多，抛弃之。\nTeXmaker 和 TeXstudio 界面比较美观，而且二者界面风格很类似。因为TeXstudio是在TeXmaker的基础上而来的，[见wikipedia的描述](http://en.wikipedia.org/wiki/TeXstudio)：\n\n> Originally called TexMakerX, TeXstudio was started as a fork of Texmaker that tried to extend it with additional features while keeping its look and feel.\n\nTeXnicCenter 安装时不会自动探测，第一次运行时会要求你指定 latex.exe 的路径。TeXnicCenter 界面风格是office的风格，很现代化。TeXnicCenter 只有 windows版，故放弃。\n\nLyX 安装时会自动探测到TeX Live。这点比较方便，无需配置。  \nLyX可以导入.tex文件，导入后，不能直接修改.tex源码，只能在上方的可视化区域直接输入内容，即LyX强迫你用类似word的方式来输入内容。因此抛弃LyX。\n\nBakoma 是商业软件，30天试用期，网上搜了一下，没有破解版，故放弃。\n\nTeXmacs 1.0.7.19 在windows上安装完成后，双击后启动界面会闪退，完全没法用，换了1.0.7.18，可以启动了，目前发现两个问题：1. 打开（使用文件-->打开或导入）一个含有中文的.tex文件会崩溃；2. 关闭程序管不了，需要用任务管理器杀掉才行，可见TeXmacs 还很不完善，其次TeXmacs 有着自己的语法，不是一个标准的TeX发行版，因此放弃 TeXmacs 。\n\nLEd已经很久不更新，且只有windows版，放弃。\n\n大牛陈硕用的是Tex Live，他的书使用Tex Live来排版的。  \n![](http://yanjiuyanjiu-wordpress.stor.sinaapp.com/uploads/2013/04/chenshuo_texlive.png)\n\n##安装和配置\n在windows下安装 Tex Live 2012，先下载DVD ISO，然后安装即可。假设安装到`D:\\texlive`。\n\n安装完后，将`D:\\texlive\\2012\\bin\\win32`添加到PATH环境变量。这样Texmaker，Texstudio就不用配置了，安装后即可正常编译。如果没有添加到PATH环境变量，则在Texmaker，Texstudio中指定一些exe文件的绝对路径。\n\n","slug":"2013-04-12-latex-distributions-and-editors","published":1,"updated":"2016-08-18T09:21:04.000Z","photos":[],"link":"","_id":"cis07pf35001501pqehzwkx74","content":"<p>##发行版(distribution)<br>TeX类似于Linux，有很多不同的发行版(distribution)。</p>\n<p>先看看各个发行版的流行程度。</p>\n<p>|———-+——————————-+——–+———–+——————+———–+———–|<br>| <strong>名字</strong> |            <strong>官网</strong>           | <strong>PR</strong> | <strong>Alexa</strong> |   <strong>最后更新</strong>   | <strong>weibo</strong> | <strong>quora</strong> |<br>|:——–:|:—————————–:|:——:|:———:|:—————-:|:———:|:——–:|<br>| TeX Live |     <a href=\"http://www.tug.org/texlive/\" target=\"_blank\" rel=\"external\">http://www.tug.org/texlive/</a>    |    7   |    N/A    |    2012-07-01    |     43    |    N/A    |<br>|  MiKTeX  |     <a href=\"http://miktex.org/\" target=\"_blank\" rel=\"external\">http://miktex.org/</a>      |    7   |  188,485  | 1.3.2 2012-09-24 |     54    |    N/A    |<br>|   CTeX   |     <a href=\"http://www.ctex.org/\" target=\"_blank\" rel=\"external\">http://www.ctex.org/</a>    |    6   |  252,657  | 2.9.2 2012-03-30 |     344   |    N/A    |<br>|  proTeXt | <a href=\"http://www.tug.org/protext/\" target=\"_blank\" rel=\"external\">http://www.tug.org/protext/</a> |    7   |    N/A    | 3.1.1 2012-07-23 |     10    |    N/A    |<br>|———-+——————————-+——–+———–+——————+———–+———–|   </p>\n<p>其中CTeX和proTeXt都是基于MiKTeX的，再次进行了打包。国内估计用CTeX比较多。</p>\n<p>##编辑器(editor)<br>编辑器大概分为两种，一种为WYSIWYG，所见即所得，实时预览，类似于Word，另一种是纯文本编辑器，有语法高亮，没有预览功能，需要另外安装一个发行版，编译成PDF后才能预览。</p>\n<p>先看看各个编辑器的流行程度。</p>\n<p>|————–+————————————-+——–+———–+————–+————————–+———–+———–|<br>|   <strong>名字</strong>   |                 <strong>官网</strong>            | <strong>PR</strong> | <strong>Alexa</strong> | <strong>预览类型</strong> |      <strong>最后更新</strong>        | <strong>weibo</strong> | <strong>quora</strong> |<br>|:————:|:———————————–:|:——:|:———:|:————:|:————————:|:———:|:———:|<br>|   TeXmaker   | <a href=\"http://www.xm1math.net/texmaker/\" target=\"_blank\" rel=\"external\">http://www.xm1math.net/texmaker/</a>  |    6   |  289,311  |    无预览    |      4.0.1 2013-03-16    |     60    |    N/A    |<br>|   TeXworks   |   <a href=\"http://www.tug.org/texworks/\" target=\"_blank\" rel=\"external\">http://www.tug.org/texworks/</a>    |    5   |  90,230   |    无预览    |      0.4.4  2012-04      |     23    |    N/A    |<br>|   TeXstudio  | <a href=\"http://texstudio.sourceforge.net/\" target=\"_blank\" rel=\"external\">http://texstudio.sourceforge.net/</a> |    6   |    N/A    |    无预览    |      2.5.2 2013-01-08    |     15    |    N/A    |<br>| TeXnicCenter |   <a href=\"http://www.texniccenter.org/\" target=\"_blank\" rel=\"external\">http://www.texniccenter.org/</a>    |    7   |  884,570  |    无预览    |  v2.0 beta1 2012-11-03   |     10    |    N/A    |<br>|     Lyx      |       <a href=\"http://www.lyx.org/\" target=\"_blank\" rel=\"external\">http://www.lyx.org/</a>         |    6   |  261,649  |   实时预览   |    2.0.5.1 2013-01-08    |     56    |     42    |<br>|    Bakoma    |   <a href=\"http://www.bakoma-tex.com/\" target=\"_blank\" rel=\"external\">http://www.bakoma-tex.com/</a>      |    5   | 1,327,901 |   实时预览   |     10.10 2013-01-13     |      3    |    N/A    |<br>|   TeXmacs    |     <a href=\"http://www.texmacs.org\" target=\"_blank\" rel=\"external\">http://www.texmacs.org</a>        |    6   | 1,525,373 |   实时预览   |   1.0.7.19 2013-03-27    |     27    |    N/A    |<br>|     LEd      |   <a href=\"http://www.latexeditor.org/\" target=\"_blank\" rel=\"external\">http://www.latexeditor.org/</a>     |    6   |  624,564  |   实时预览   |     0.53 2009-10-09      |     0    |    N/A    |<br>|————–+————————————-+——–+———–+————–+————————–+———–+———–|  </p>\n<a id=\"more\"></a>\n<p>##跨平台<br>下面看看各个发行版和编辑器的跨平台支持程度。</p>\n<p>|————–+———+—–+——-|<br>|   <strong>名字</strong>   | Windows | Mac | Linux |<br>|:————:|:——-:|:—:|:—–:|<br>|    编辑器     |         |     |       |<br>|   TeXmaker   |    √    |  √  |   √   |<br>|   TeXworks   |    √    |  √  |   √   |<br>|   TeXstudio  |    √    |  √  |   √   |<br>| TeXnicCenter |    √    |  ×  |   ×   |<br>|   WYSIWYG    |         |     |       |<br>|     Lyx      |    √    |  √  |   √   |<br>|    Bakoma    |    √    |  √  |   √   |<br>|   TeXmacs    |    √    |  √  |   √   |<br>|     LEd      |    √    |  ×  |   ×   |<br>|     发行版    |         |     |       |<br>|     MiKTeX   |     √   |  ×  |   ×   |<br>|    TeX Live  |    √    |  √  |   √   |<br>|     CTeX     |     √   |  ×  |   ×   |<br>|     proTeXt  |     √   |  ×  |   ×   |<br>|————–+———+—–+——-| </p>\n<p>Tex Live在Mac上，叫做MacTex，见<a href=\"http://www.tug.org/mactex/newfeatures.html\" target=\"_blank\" rel=\"external\">官网的一段话</a>：</p>\n<blockquote>\n<p>MacTeX-2012 installs a completely unmodified copy of the full TeX Live 2012 distribution. This is exactly the same distribution that runs on OS X, Windows, GNU/Linux, various BSD Unix systems, and other systems.</p>\n</blockquote>\n<p>##如何选择<br>四个发新版，只有 Tex Live 是跨平台的，故使用Tex Live，其他发行版抛弃。</p>\n<p>TeXmaker, TeXstudio, TeXworks 来进行比较<br>中文支持的程度，打开.tex文件是否有乱码</p>\n<p>|———–+————————–+————————|<br>|  <strong>名字</strong> | <strong>打开GB18030的tex文件</strong> | <strong>打开UTF8编码的文件</strong> |<br>|:———:|:————————:|:———————-:|<br>| TeXworks  |         有乱码           |          无乱码        |<br>| TeXmaker  |         无乱码           |          无乱码        |<br>| TeXstudio |         有乱码           |          无乱码        |<br>|———–+————————–+————————|  </p>\n<p>TeXmaker 界面丑陋，且中文支持不好，功能没有多，抛弃之。<br>TeXmaker 和 TeXstudio 界面比较美观，而且二者界面风格很类似。因为TeXstudio是在TeXmaker的基础上而来的，<a href=\"http://en.wikipedia.org/wiki/TeXstudio\" target=\"_blank\" rel=\"external\">见wikipedia的描述</a>：</p>\n<blockquote>\n<p>Originally called TexMakerX, TeXstudio was started as a fork of Texmaker that tried to extend it with additional features while keeping its look and feel.</p>\n</blockquote>\n<p>TeXnicCenter 安装时不会自动探测，第一次运行时会要求你指定 latex.exe 的路径。TeXnicCenter 界面风格是office的风格，很现代化。TeXnicCenter 只有 windows版，故放弃。</p>\n<p>LyX 安装时会自动探测到TeX Live。这点比较方便，无需配置。<br>LyX可以导入.tex文件，导入后，不能直接修改.tex源码，只能在上方的可视化区域直接输入内容，即LyX强迫你用类似word的方式来输入内容。因此抛弃LyX。</p>\n<p>Bakoma 是商业软件，30天试用期，网上搜了一下，没有破解版，故放弃。</p>\n<p>TeXmacs 1.0.7.19 在windows上安装完成后，双击后启动界面会闪退，完全没法用，换了1.0.7.18，可以启动了，目前发现两个问题：1. 打开（使用文件–&gt;打开或导入）一个含有中文的.tex文件会崩溃；2. 关闭程序管不了，需要用任务管理器杀掉才行，可见TeXmacs 还很不完善，其次TeXmacs 有着自己的语法，不是一个标准的TeX发行版，因此放弃 TeXmacs 。</p>\n<p>LEd已经很久不更新，且只有windows版，放弃。</p>\n<p>大牛陈硕用的是Tex Live，他的书使用Tex Live来排版的。<br><img src=\"http://yanjiuyanjiu-wordpress.stor.sinaapp.com/uploads/2013/04/chenshuo_texlive.png\" alt=\"\"></p>\n<p>##安装和配置<br>在windows下安装 Tex Live 2012，先下载DVD ISO，然后安装即可。假设安装到<code>D:\\texlive</code>。</p>\n<p>安装完后，将<code>D:\\texlive\\2012\\bin\\win32</code>添加到PATH环境变量。这样Texmaker，Texstudio就不用配置了，安装后即可正常编译。如果没有添加到PATH环境变量，则在Texmaker，Texstudio中指定一些exe文件的绝对路径。</p>\n","excerpt":"<p>##发行版(distribution)<br>TeX类似于Linux，有很多不同的发行版(distribution)。</p>\n<p>先看看各个发行版的流行程度。</p>\n<p>|———-+——————————-+——–+———–+——————+———–+———–|<br>| <strong>名字</strong> |            <strong>官网</strong>           | <strong>PR</strong> | <strong>Alexa</strong> |   <strong>最后更新</strong>   | <strong>weibo</strong> | <strong>quora</strong> |<br>|:——–:|:—————————–:|:——:|:———:|:—————-:|:———:|:——–:|<br>| TeX Live |     <a href=\"http://www.tug.org/texlive/\">http://www.tug.org/texlive/</a>    |    7   |    N/A    |    2012-07-01    |     43    |    N/A    |<br>|  MiKTeX  |     <a href=\"http://miktex.org/\">http://miktex.org/</a>      |    7   |  188,485  | 1.3.2 2012-09-24 |     54    |    N/A    |<br>|   CTeX   |     <a href=\"http://www.ctex.org/\">http://www.ctex.org/</a>    |    6   |  252,657  | 2.9.2 2012-03-30 |     344   |    N/A    |<br>|  proTeXt | <a href=\"http://www.tug.org/protext/\">http://www.tug.org/protext/</a> |    7   |    N/A    | 3.1.1 2012-07-23 |     10    |    N/A    |<br>|———-+——————————-+——–+———–+——————+———–+———–|   </p>\n<p>其中CTeX和proTeXt都是基于MiKTeX的，再次进行了打包。国内估计用CTeX比较多。</p>\n<p>##编辑器(editor)<br>编辑器大概分为两种，一种为WYSIWYG，所见即所得，实时预览，类似于Word，另一种是纯文本编辑器，有语法高亮，没有预览功能，需要另外安装一个发行版，编译成PDF后才能预览。</p>\n<p>先看看各个编辑器的流行程度。</p>\n<p>|————–+————————————-+——–+———–+————–+————————–+———–+———–|<br>|   <strong>名字</strong>   |                 <strong>官网</strong>            | <strong>PR</strong> | <strong>Alexa</strong> | <strong>预览类型</strong> |      <strong>最后更新</strong>        | <strong>weibo</strong> | <strong>quora</strong> |<br>|:————:|:———————————–:|:——:|:———:|:————:|:————————:|:———:|:———:|<br>|   TeXmaker   | <a href=\"http://www.xm1math.net/texmaker/\">http://www.xm1math.net/texmaker/</a>  |    6   |  289,311  |    无预览    |      4.0.1 2013-03-16    |     60    |    N/A    |<br>|   TeXworks   |   <a href=\"http://www.tug.org/texworks/\">http://www.tug.org/texworks/</a>    |    5   |  90,230   |    无预览    |      0.4.4  2012-04      |     23    |    N/A    |<br>|   TeXstudio  | <a href=\"http://texstudio.sourceforge.net/\">http://texstudio.sourceforge.net/</a> |    6   |    N/A    |    无预览    |      2.5.2 2013-01-08    |     15    |    N/A    |<br>| TeXnicCenter |   <a href=\"http://www.texniccenter.org/\">http://www.texniccenter.org/</a>    |    7   |  884,570  |    无预览    |  v2.0 beta1 2012-11-03   |     10    |    N/A    |<br>|     Lyx      |       <a href=\"http://www.lyx.org/\">http://www.lyx.org/</a>         |    6   |  261,649  |   实时预览   |    2.0.5.1 2013-01-08    |     56    |     42    |<br>|    Bakoma    |   <a href=\"http://www.bakoma-tex.com/\">http://www.bakoma-tex.com/</a>      |    5   | 1,327,901 |   实时预览   |     10.10 2013-01-13     |      3    |    N/A    |<br>|   TeXmacs    |     <a href=\"http://www.texmacs.org\">http://www.texmacs.org</a>        |    6   | 1,525,373 |   实时预览   |   1.0.7.19 2013-03-27    |     27    |    N/A    |<br>|     LEd      |   <a href=\"http://www.latexeditor.org/\">http://www.latexeditor.org/</a>     |    6   |  624,564  |   实时预览   |     0.53 2009-10-09      |     0    |    N/A    |<br>|————–+————————————-+——–+———–+————–+————————–+———–+———–|  </p>","more":"<p>##跨平台<br>下面看看各个发行版和编辑器的跨平台支持程度。</p>\n<p>|————–+———+—–+——-|<br>|   <strong>名字</strong>   | Windows | Mac | Linux |<br>|:————:|:——-:|:—:|:—–:|<br>|    编辑器     |         |     |       |<br>|   TeXmaker   |    √    |  √  |   √   |<br>|   TeXworks   |    √    |  √  |   √   |<br>|   TeXstudio  |    √    |  √  |   √   |<br>| TeXnicCenter |    √    |  ×  |   ×   |<br>|   WYSIWYG    |         |     |       |<br>|     Lyx      |    √    |  √  |   √   |<br>|    Bakoma    |    √    |  √  |   √   |<br>|   TeXmacs    |    √    |  √  |   √   |<br>|     LEd      |    √    |  ×  |   ×   |<br>|     发行版    |         |     |       |<br>|     MiKTeX   |     √   |  ×  |   ×   |<br>|    TeX Live  |    √    |  √  |   √   |<br>|     CTeX     |     √   |  ×  |   ×   |<br>|     proTeXt  |     √   |  ×  |   ×   |<br>|————–+———+—–+——-| </p>\n<p>Tex Live在Mac上，叫做MacTex，见<a href=\"http://www.tug.org/mactex/newfeatures.html\">官网的一段话</a>：</p>\n<blockquote>\n<p>MacTeX-2012 installs a completely unmodified copy of the full TeX Live 2012 distribution. This is exactly the same distribution that runs on OS X, Windows, GNU/Linux, various BSD Unix systems, and other systems.</p>\n</blockquote>\n<p>##如何选择<br>四个发新版，只有 Tex Live 是跨平台的，故使用Tex Live，其他发行版抛弃。</p>\n<p>TeXmaker, TeXstudio, TeXworks 来进行比较<br>中文支持的程度，打开.tex文件是否有乱码</p>\n<p>|———–+————————–+————————|<br>|  <strong>名字</strong> | <strong>打开GB18030的tex文件</strong> | <strong>打开UTF8编码的文件</strong> |<br>|:———:|:————————:|:———————-:|<br>| TeXworks  |         有乱码           |          无乱码        |<br>| TeXmaker  |         无乱码           |          无乱码        |<br>| TeXstudio |         有乱码           |          无乱码        |<br>|———–+————————–+————————|  </p>\n<p>TeXmaker 界面丑陋，且中文支持不好，功能没有多，抛弃之。<br>TeXmaker 和 TeXstudio 界面比较美观，而且二者界面风格很类似。因为TeXstudio是在TeXmaker的基础上而来的，<a href=\"http://en.wikipedia.org/wiki/TeXstudio\">见wikipedia的描述</a>：</p>\n<blockquote>\n<p>Originally called TexMakerX, TeXstudio was started as a fork of Texmaker that tried to extend it with additional features while keeping its look and feel.</p>\n</blockquote>\n<p>TeXnicCenter 安装时不会自动探测，第一次运行时会要求你指定 latex.exe 的路径。TeXnicCenter 界面风格是office的风格，很现代化。TeXnicCenter 只有 windows版，故放弃。</p>\n<p>LyX 安装时会自动探测到TeX Live。这点比较方便，无需配置。<br>LyX可以导入.tex文件，导入后，不能直接修改.tex源码，只能在上方的可视化区域直接输入内容，即LyX强迫你用类似word的方式来输入内容。因此抛弃LyX。</p>\n<p>Bakoma 是商业软件，30天试用期，网上搜了一下，没有破解版，故放弃。</p>\n<p>TeXmacs 1.0.7.19 在windows上安装完成后，双击后启动界面会闪退，完全没法用，换了1.0.7.18，可以启动了，目前发现两个问题：1. 打开（使用文件–&gt;打开或导入）一个含有中文的.tex文件会崩溃；2. 关闭程序管不了，需要用任务管理器杀掉才行，可见TeXmacs 还很不完善，其次TeXmacs 有着自己的语法，不是一个标准的TeX发行版，因此放弃 TeXmacs 。</p>\n<p>LEd已经很久不更新，且只有windows版，放弃。</p>\n<p>大牛陈硕用的是Tex Live，他的书使用Tex Live来排版的。<br><img src=\"http://yanjiuyanjiu-wordpress.stor.sinaapp.com/uploads/2013/04/chenshuo_texlive.png\" alt=\"\"></p>\n<p>##安装和配置<br>在windows下安装 Tex Live 2012，先下载DVD ISO，然后安装即可。假设安装到<code>D:\\texlive</code>。</p>\n<p>安装完后，将<code>D:\\texlive\\2012\\bin\\win32</code>添加到PATH环境变量。这样Texmaker，Texstudio就不用配置了，安装后即可正常编译。如果没有添加到PATH环境变量，则在Texmaker，Texstudio中指定一些exe文件的绝对路径。</p>"},{"layout":"post","title":"使用Scala IDE 阅读spark源码 -- 将sbt项目转化为eclipse项目","date":"2013-06-11T11:48:00.000Z","comments":1,"_content":"阅读Spark源代码，最简单的方式是下载源码包，解压后用纯文本方式来阅读源码。这样效率不高，可以用sbteclipse这个插件，将sbt项目文件转化为eclipse项目文件，然后导入到Scala IDE，用eclipse来阅读源码，效率大大提高。\n\n**环境**：Windows 7, JDK 1.6\n\n1. 安装 scala。去官网 <http://www.scala-lang.org/> ，下载MSI，安装，按默认设置即可。\n2. 安装 sbt。去官网 <http://www.scala-sbt.org/> ， 下载MSI，安装，按默认设置即可。\nLinux下可以省略以上两步，spark源码自带了一个sbt，且启动sbt时它会自动下载对应的scala编译器。\n\n3. 安装 Scala IDE。 去官网 <http://scala-ide.org/>，点击\"Get the SDK\"绿色按钮，下载。这个IDE的好处是，自带了scala编译器，解压即可使用。\n\n4. 下载spark源码。 去官网 <http://spark-project.org/> 下载源码，当前版本是 0.7.2, source package 大约4M左右。解压源码，例如 解压到 d:spark-0.7.0\\\n\n5. 添加 sbteclipse 插件依赖。spark已经添加了依赖，这一步什么也不需要做。\n\n\t这个插件的作用，就是能够读取sbt的配置文件，生成一个eclipse的工程文件。有了eclipse工程文件，就可以导入到eclipse了。\n\n    spark已经添加了依赖，见 d:\\spark-0.7.2\\project\\plugins.sbt，有一行\n\n    addSbtPlugin(\"com.typesafe.sbteclipse\" % \"sbteclipse-plugin\" % \"2.1.1\")\n\n\n6. 启动cmd，启动sbt。\n\n    > cd  d:\\spark-0.7.0  \n    sbt\n\n    Linux下则是\n\n    > cd  d:\\spark-0.7.0  \n\tsbt/sbt\n\n    开始下载各种依赖包，需要等待很长时间。\n\n7. **翻@\\_@墙。见本文最后一段。**\n\n    <!--more-->\n\n8. 等sbt提升符>出现后，输入eclipse命令，开始生成eclipse工程文件，需要耐心等待一段时间\n\n\n    > \\>eclipse  \n    [info] About to create Eclipse project files for your project(s).  \n    [info] Successfully created Eclipse project files for project(s):  \n    [info] spark-examples    \n    [info] spark-streaming   \n    [info] spark-repl  \n    [info] spark-bagel  \n    [info] spark-core  \n\n\n    这样就生成成功了，去core, bagel, streaming, repl, examples 五个文件夹下，可以看到有一个.project和.classpath文件。从这里也可以看出，spark源码由五个项目组成。\n\n9. 用 Scala IDE 导入这5个工程，选择 d:\\spark-0.7.2 文件夹，可以一次性导入5个项目。\n项目图标上有红色感叹号，是因为jar包的路径不对，右击某个项目，选择 “Build Path -> Configure Build Path” ，删除所有的jar，点击 \"Add external jars\"，浏览到 d:\\spark-0.7.2\\lib_managed\\jars，添加所有的jar，这是红色感叹号就消失了。每个项目都如此操作一番。\n\n\n**注意：第8步在国内是无法成功的，因为一些maven仓库被墙，例如 twitter4j.org这个仓库就被墙了。因此需要翻@\\_@墙。**\n\n我平时用goagent翻@\\_@墙，不过goagent只能让浏览器翻@\\_@墙，如何让goagent变成全局代理呢？即所有http协议都经过goagent。可以用 Proxifier，它可以把goagent变成操作系统全局的http代理。\n\n不过 spark 在访问maven仓库时，用的是https网址，即https协议，虽然goagent可以用来访问https页面，但 goagent 和 Proxifier 使用时，https协议总是链接不通（参考 <https://code.google.com/p/goagent/issues/detail?id=5210>）。\n\n于是我又想到了另一个方法，用SSH翻@\\_@墙。去网上找一个免费的ssh，安装 Bitvise SSH Client，然后在\"Services\"标签页面，勾选\"SOCKS/HTTP Proxy Forwarding\"，这样来翻@\\_@墙，Proxifier  使用  Bitvise SSH Client 提供的代理。\n\n翻@\\_@墙成功后，再输入 eclipse，当到达 twitter4j.org 时，会发现 SUCCESS了。耐心等待，最后会成功生成.project文件。\n\n用Scala IDE 导入项目，就可以开始阅读spark 源码了 :)\n\n如果不想折腾，可以下载我已经生成好的项目, [spark-0.7.2.zip](http://pan.baidu.com/share/link?shareid=534521368&uk=2466605404)。解压，启动Scala IDE，选择菜单`File->Import->General->Existing projects into workspace`，浏览到 spark-0.7.2目录，批量导入5个项目。导入后项目图标有红色感叹号，这是因为你的电脑上路径和我的路径不一样，找不到引用的jar了。右击项目，选择`Build Path->Configure Build Path`，选择`Libraries`标签，这时可以看到所有jar都有红叉叉，全选，删除，然后点击`Add External Jars`，浏览到`spark-0.7.2\\lib_managed\\jars`，把所有jar都导入，导入后红色感叹号就消失了。对每个项目都执行上述操作。\n\n**2013-07-27 更新**：eclipse项目上有红色小叉叉图标，之前一直没解决，今天解决了，主要原因是，**Scala IDE 版本不对！** scala-ide.org 官网最新的的3.0.1只支持scala 2.10，不再支持2.9.3。由于Spark目前使用scala 2.9.3写的，所以我们要下载支持 scala 2.9.3 版，scala ide 3.0.0是支持 2.9.3的，不过首选要下载 eclipse JUNO，不要使用新版的eclipse，例如eclipse Indigo, Kepler都不行。\n\n因此，正确的做法是，先下载 eclipse juno，然后下载 3.0.0 的zip包，解压，然后启动eclipse，点击菜单\"help->Install New Software\"，浏览到刚刚解压的`site`文件夹，就可以安装scala ide插件了。\n","source":"_posts/2013-06-11-read-spark-source-code-using-scala-ide.md","raw":"---\nlayout: post\ntitle: \"使用Scala IDE 阅读spark源码 -- 将sbt项目转化为eclipse项目\"\ndate: 2013-06-11 11:48\ncomments: true\ncategories: Spark\ntags: [scala, spark]\n---\n阅读Spark源代码，最简单的方式是下载源码包，解压后用纯文本方式来阅读源码。这样效率不高，可以用sbteclipse这个插件，将sbt项目文件转化为eclipse项目文件，然后导入到Scala IDE，用eclipse来阅读源码，效率大大提高。\n\n**环境**：Windows 7, JDK 1.6\n\n1. 安装 scala。去官网 <http://www.scala-lang.org/> ，下载MSI，安装，按默认设置即可。\n2. 安装 sbt。去官网 <http://www.scala-sbt.org/> ， 下载MSI，安装，按默认设置即可。\nLinux下可以省略以上两步，spark源码自带了一个sbt，且启动sbt时它会自动下载对应的scala编译器。\n\n3. 安装 Scala IDE。 去官网 <http://scala-ide.org/>，点击\"Get the SDK\"绿色按钮，下载。这个IDE的好处是，自带了scala编译器，解压即可使用。\n\n4. 下载spark源码。 去官网 <http://spark-project.org/> 下载源码，当前版本是 0.7.2, source package 大约4M左右。解压源码，例如 解压到 d:spark-0.7.0\\\n\n5. 添加 sbteclipse 插件依赖。spark已经添加了依赖，这一步什么也不需要做。\n\n\t这个插件的作用，就是能够读取sbt的配置文件，生成一个eclipse的工程文件。有了eclipse工程文件，就可以导入到eclipse了。\n\n    spark已经添加了依赖，见 d:\\spark-0.7.2\\project\\plugins.sbt，有一行\n\n    addSbtPlugin(\"com.typesafe.sbteclipse\" % \"sbteclipse-plugin\" % \"2.1.1\")\n\n\n6. 启动cmd，启动sbt。\n\n    > cd  d:\\spark-0.7.0  \n    sbt\n\n    Linux下则是\n\n    > cd  d:\\spark-0.7.0  \n\tsbt/sbt\n\n    开始下载各种依赖包，需要等待很长时间。\n\n7. **翻@\\_@墙。见本文最后一段。**\n\n    <!--more-->\n\n8. 等sbt提升符>出现后，输入eclipse命令，开始生成eclipse工程文件，需要耐心等待一段时间\n\n\n    > \\>eclipse  \n    [info] About to create Eclipse project files for your project(s).  \n    [info] Successfully created Eclipse project files for project(s):  \n    [info] spark-examples    \n    [info] spark-streaming   \n    [info] spark-repl  \n    [info] spark-bagel  \n    [info] spark-core  \n\n\n    这样就生成成功了，去core, bagel, streaming, repl, examples 五个文件夹下，可以看到有一个.project和.classpath文件。从这里也可以看出，spark源码由五个项目组成。\n\n9. 用 Scala IDE 导入这5个工程，选择 d:\\spark-0.7.2 文件夹，可以一次性导入5个项目。\n项目图标上有红色感叹号，是因为jar包的路径不对，右击某个项目，选择 “Build Path -> Configure Build Path” ，删除所有的jar，点击 \"Add external jars\"，浏览到 d:\\spark-0.7.2\\lib_managed\\jars，添加所有的jar，这是红色感叹号就消失了。每个项目都如此操作一番。\n\n\n**注意：第8步在国内是无法成功的，因为一些maven仓库被墙，例如 twitter4j.org这个仓库就被墙了。因此需要翻@\\_@墙。**\n\n我平时用goagent翻@\\_@墙，不过goagent只能让浏览器翻@\\_@墙，如何让goagent变成全局代理呢？即所有http协议都经过goagent。可以用 Proxifier，它可以把goagent变成操作系统全局的http代理。\n\n不过 spark 在访问maven仓库时，用的是https网址，即https协议，虽然goagent可以用来访问https页面，但 goagent 和 Proxifier 使用时，https协议总是链接不通（参考 <https://code.google.com/p/goagent/issues/detail?id=5210>）。\n\n于是我又想到了另一个方法，用SSH翻@\\_@墙。去网上找一个免费的ssh，安装 Bitvise SSH Client，然后在\"Services\"标签页面，勾选\"SOCKS/HTTP Proxy Forwarding\"，这样来翻@\\_@墙，Proxifier  使用  Bitvise SSH Client 提供的代理。\n\n翻@\\_@墙成功后，再输入 eclipse，当到达 twitter4j.org 时，会发现 SUCCESS了。耐心等待，最后会成功生成.project文件。\n\n用Scala IDE 导入项目，就可以开始阅读spark 源码了 :)\n\n如果不想折腾，可以下载我已经生成好的项目, [spark-0.7.2.zip](http://pan.baidu.com/share/link?shareid=534521368&uk=2466605404)。解压，启动Scala IDE，选择菜单`File->Import->General->Existing projects into workspace`，浏览到 spark-0.7.2目录，批量导入5个项目。导入后项目图标有红色感叹号，这是因为你的电脑上路径和我的路径不一样，找不到引用的jar了。右击项目，选择`Build Path->Configure Build Path`，选择`Libraries`标签，这时可以看到所有jar都有红叉叉，全选，删除，然后点击`Add External Jars`，浏览到`spark-0.7.2\\lib_managed\\jars`，把所有jar都导入，导入后红色感叹号就消失了。对每个项目都执行上述操作。\n\n**2013-07-27 更新**：eclipse项目上有红色小叉叉图标，之前一直没解决，今天解决了，主要原因是，**Scala IDE 版本不对！** scala-ide.org 官网最新的的3.0.1只支持scala 2.10，不再支持2.9.3。由于Spark目前使用scala 2.9.3写的，所以我们要下载支持 scala 2.9.3 版，scala ide 3.0.0是支持 2.9.3的，不过首选要下载 eclipse JUNO，不要使用新版的eclipse，例如eclipse Indigo, Kepler都不行。\n\n因此，正确的做法是，先下载 eclipse juno，然后下载 3.0.0 的zip包，解压，然后启动eclipse，点击菜单\"help->Install New Software\"，浏览到刚刚解压的`site`文件夹，就可以安装scala ide插件了。\n","slug":"2013-06-11-read-spark-source-code-using-scala-ide","published":1,"updated":"2016-08-18T09:21:04.000Z","photos":[],"link":"","_id":"cis07pf37001701pqf0p2omkn","content":"<p>阅读Spark源代码，最简单的方式是下载源码包，解压后用纯文本方式来阅读源码。这样效率不高，可以用sbteclipse这个插件，将sbt项目文件转化为eclipse项目文件，然后导入到Scala IDE，用eclipse来阅读源码，效率大大提高。</p>\n<p><strong>环境</strong>：Windows 7, JDK 1.6</p>\n<ol>\n<li>安装 scala。去官网 <a href=\"http://www.scala-lang.org/\" target=\"_blank\" rel=\"external\">http://www.scala-lang.org/</a> ，下载MSI，安装，按默认设置即可。</li>\n<li><p>安装 sbt。去官网 <a href=\"http://www.scala-sbt.org/\" target=\"_blank\" rel=\"external\">http://www.scala-sbt.org/</a> ， 下载MSI，安装，按默认设置即可。<br>Linux下可以省略以上两步，spark源码自带了一个sbt，且启动sbt时它会自动下载对应的scala编译器。</p>\n</li>\n<li><p>安装 Scala IDE。 去官网 <a href=\"http://scala-ide.org/\" target=\"_blank\" rel=\"external\">http://scala-ide.org/</a>，点击”Get the SDK”绿色按钮，下载。这个IDE的好处是，自带了scala编译器，解压即可使用。</p>\n</li>\n<li><p>下载spark源码。 去官网 <a href=\"http://spark-project.org/\" target=\"_blank\" rel=\"external\">http://spark-project.org/</a> 下载源码，当前版本是 0.7.2, source package 大约4M左右。解压源码，例如 解压到 d:spark-0.7.0\\</p>\n</li>\n<li><p>添加 sbteclipse 插件依赖。spark已经添加了依赖，这一步什么也不需要做。</p>\n<p> 这个插件的作用，就是能够读取sbt的配置文件，生成一个eclipse的工程文件。有了eclipse工程文件，就可以导入到eclipse了。</p>\n<p> spark已经添加了依赖，见 d:\\spark-0.7.2\\project\\plugins.sbt，有一行</p>\n<p> addSbtPlugin(“com.typesafe.sbteclipse” % “sbteclipse-plugin” % “2.1.1”)</p>\n</li>\n</ol>\n<ol>\n<li><p>启动cmd，启动sbt。</p>\n<blockquote>\n<p>cd  d:\\spark-0.7.0<br> sbt</p>\n</blockquote>\n<p> Linux下则是</p>\n<blockquote>\n<p>cd  d:\\spark-0.7.0<br> sbt/sbt</p>\n</blockquote>\n<p> 开始下载各种依赖包，需要等待很长时间。</p>\n</li>\n<li><p><strong>翻@_@墙。见本文最后一段。</strong></p>\n <a id=\"more\"></a>\n</li>\n<li><p>等sbt提升符&gt;出现后，输入eclipse命令，开始生成eclipse工程文件，需要耐心等待一段时间</p>\n</li>\n</ol>\n<pre><code>&gt; \\&gt;eclipse  \n[info] About to create Eclipse project files for your project(s).  \n[info] Successfully created Eclipse project files for project(s):  \n[info] spark-examples    \n[info] spark-streaming   \n[info] spark-repl  \n[info] spark-bagel  \n[info] spark-core  \n\n\n这样就生成成功了，去core, bagel, streaming, repl, examples 五个文件夹下，可以看到有一个.project和.classpath文件。从这里也可以看出，spark源码由五个项目组成。\n</code></pre><ol>\n<li>用 Scala IDE 导入这5个工程，选择 d:\\spark-0.7.2 文件夹，可以一次性导入5个项目。<br>项目图标上有红色感叹号，是因为jar包的路径不对，右击某个项目，选择 “Build Path -&gt; Configure Build Path” ，删除所有的jar，点击 “Add external jars”，浏览到 d:\\spark-0.7.2\\lib_managed\\jars，添加所有的jar，这是红色感叹号就消失了。每个项目都如此操作一番。</li>\n</ol>\n<p><strong>注意：第8步在国内是无法成功的，因为一些maven仓库被墙，例如 twitter4j.org这个仓库就被墙了。因此需要翻@_@墙。</strong></p>\n<p>我平时用goagent翻@_@墙，不过goagent只能让浏览器翻@_@墙，如何让goagent变成全局代理呢？即所有http协议都经过goagent。可以用 Proxifier，它可以把goagent变成操作系统全局的http代理。</p>\n<p>不过 spark 在访问maven仓库时，用的是https网址，即https协议，虽然goagent可以用来访问https页面，但 goagent 和 Proxifier 使用时，https协议总是链接不通（参考 <a href=\"https://code.google.com/p/goagent/issues/detail?id=5210\" target=\"_blank\" rel=\"external\">https://code.google.com/p/goagent/issues/detail?id=5210</a>）。</p>\n<p>于是我又想到了另一个方法，用SSH翻@_@墙。去网上找一个免费的ssh，安装 Bitvise SSH Client，然后在”Services”标签页面，勾选”SOCKS/HTTP Proxy Forwarding”，这样来翻@_@墙，Proxifier  使用  Bitvise SSH Client 提供的代理。</p>\n<p>翻@_@墙成功后，再输入 eclipse，当到达 twitter4j.org 时，会发现 SUCCESS了。耐心等待，最后会成功生成.project文件。</p>\n<p>用Scala IDE 导入项目，就可以开始阅读spark 源码了 :)</p>\n<p>如果不想折腾，可以下载我已经生成好的项目, <a href=\"http://pan.baidu.com/share/link?shareid=534521368&amp;uk=2466605404\" target=\"_blank\" rel=\"external\">spark-0.7.2.zip</a>。解压，启动Scala IDE，选择菜单<code>File-&gt;Import-&gt;General-&gt;Existing projects into workspace</code>，浏览到 spark-0.7.2目录，批量导入5个项目。导入后项目图标有红色感叹号，这是因为你的电脑上路径和我的路径不一样，找不到引用的jar了。右击项目，选择<code>Build Path-&gt;Configure Build Path</code>，选择<code>Libraries</code>标签，这时可以看到所有jar都有红叉叉，全选，删除，然后点击<code>Add External Jars</code>，浏览到<code>spark-0.7.2\\lib_managed\\jars</code>，把所有jar都导入，导入后红色感叹号就消失了。对每个项目都执行上述操作。</p>\n<p><strong>2013-07-27 更新</strong>：eclipse项目上有红色小叉叉图标，之前一直没解决，今天解决了，主要原因是，<strong>Scala IDE 版本不对！</strong> scala-ide.org 官网最新的的3.0.1只支持scala 2.10，不再支持2.9.3。由于Spark目前使用scala 2.9.3写的，所以我们要下载支持 scala 2.9.3 版，scala ide 3.0.0是支持 2.9.3的，不过首选要下载 eclipse JUNO，不要使用新版的eclipse，例如eclipse Indigo, Kepler都不行。</p>\n<p>因此，正确的做法是，先下载 eclipse juno，然后下载 3.0.0 的zip包，解压，然后启动eclipse，点击菜单”help-&gt;Install New Software”，浏览到刚刚解压的<code>site</code>文件夹，就可以安装scala ide插件了。</p>\n","excerpt":"<p>阅读Spark源代码，最简单的方式是下载源码包，解压后用纯文本方式来阅读源码。这样效率不高，可以用sbteclipse这个插件，将sbt项目文件转化为eclipse项目文件，然后导入到Scala IDE，用eclipse来阅读源码，效率大大提高。</p>\n<p><strong>环境</strong>：Windows 7, JDK 1.6</p>\n<ol>\n<li>安装 scala。去官网 <a href=\"http://www.scala-lang.org/\">http://www.scala-lang.org/</a> ，下载MSI，安装，按默认设置即可。</li>\n<li><p>安装 sbt。去官网 <a href=\"http://www.scala-sbt.org/\">http://www.scala-sbt.org/</a> ， 下载MSI，安装，按默认设置即可。<br>Linux下可以省略以上两步，spark源码自带了一个sbt，且启动sbt时它会自动下载对应的scala编译器。</p>\n</li>\n<li><p>安装 Scala IDE。 去官网 <a href=\"http://scala-ide.org/\">http://scala-ide.org/</a>，点击”Get the SDK”绿色按钮，下载。这个IDE的好处是，自带了scala编译器，解压即可使用。</p>\n</li>\n<li><p>下载spark源码。 去官网 <a href=\"http://spark-project.org/\">http://spark-project.org/</a> 下载源码，当前版本是 0.7.2, source package 大约4M左右。解压源码，例如 解压到 d:spark-0.7.0\\</p>\n</li>\n<li><p>添加 sbteclipse 插件依赖。spark已经添加了依赖，这一步什么也不需要做。</p>\n<p> 这个插件的作用，就是能够读取sbt的配置文件，生成一个eclipse的工程文件。有了eclipse工程文件，就可以导入到eclipse了。</p>\n<p> spark已经添加了依赖，见 d:\\spark-0.7.2\\project\\plugins.sbt，有一行</p>\n<p> addSbtPlugin(“com.typesafe.sbteclipse” % “sbteclipse-plugin” % “2.1.1”)</p>\n</li>\n</ol>\n<ol>\n<li><p>启动cmd，启动sbt。</p>\n<blockquote>\n<p>cd  d:\\spark-0.7.0<br> sbt</p>\n</blockquote>\n<p> Linux下则是</p>\n<blockquote>\n<p>cd  d:\\spark-0.7.0<br> sbt/sbt</p>\n</blockquote>\n<p> 开始下载各种依赖包，需要等待很长时间。</p>\n</li>\n<li><p><strong>翻@_@墙。见本文最后一段。</strong></p>","more":"</li>\n<li><p>等sbt提升符&gt;出现后，输入eclipse命令，开始生成eclipse工程文件，需要耐心等待一段时间</p>\n</li>\n</ol>\n<pre><code>&gt; \\&gt;eclipse  \n[info] About to create Eclipse project files for your project(s).  \n[info] Successfully created Eclipse project files for project(s):  \n[info] spark-examples    \n[info] spark-streaming   \n[info] spark-repl  \n[info] spark-bagel  \n[info] spark-core  \n\n\n这样就生成成功了，去core, bagel, streaming, repl, examples 五个文件夹下，可以看到有一个.project和.classpath文件。从这里也可以看出，spark源码由五个项目组成。\n</code></pre><ol>\n<li>用 Scala IDE 导入这5个工程，选择 d:\\spark-0.7.2 文件夹，可以一次性导入5个项目。<br>项目图标上有红色感叹号，是因为jar包的路径不对，右击某个项目，选择 “Build Path -&gt; Configure Build Path” ，删除所有的jar，点击 “Add external jars”，浏览到 d:\\spark-0.7.2\\lib_managed\\jars，添加所有的jar，这是红色感叹号就消失了。每个项目都如此操作一番。</li>\n</ol>\n<p><strong>注意：第8步在国内是无法成功的，因为一些maven仓库被墙，例如 twitter4j.org这个仓库就被墙了。因此需要翻@_@墙。</strong></p>\n<p>我平时用goagent翻@_@墙，不过goagent只能让浏览器翻@_@墙，如何让goagent变成全局代理呢？即所有http协议都经过goagent。可以用 Proxifier，它可以把goagent变成操作系统全局的http代理。</p>\n<p>不过 spark 在访问maven仓库时，用的是https网址，即https协议，虽然goagent可以用来访问https页面，但 goagent 和 Proxifier 使用时，https协议总是链接不通（参考 <a href=\"https://code.google.com/p/goagent/issues/detail?id=5210\">https://code.google.com/p/goagent/issues/detail?id=5210</a>）。</p>\n<p>于是我又想到了另一个方法，用SSH翻@_@墙。去网上找一个免费的ssh，安装 Bitvise SSH Client，然后在”Services”标签页面，勾选”SOCKS/HTTP Proxy Forwarding”，这样来翻@_@墙，Proxifier  使用  Bitvise SSH Client 提供的代理。</p>\n<p>翻@_@墙成功后，再输入 eclipse，当到达 twitter4j.org 时，会发现 SUCCESS了。耐心等待，最后会成功生成.project文件。</p>\n<p>用Scala IDE 导入项目，就可以开始阅读spark 源码了 :)</p>\n<p>如果不想折腾，可以下载我已经生成好的项目, <a href=\"http://pan.baidu.com/share/link?shareid=534521368&amp;uk=2466605404\">spark-0.7.2.zip</a>。解压，启动Scala IDE，选择菜单<code>File-&gt;Import-&gt;General-&gt;Existing projects into workspace</code>，浏览到 spark-0.7.2目录，批量导入5个项目。导入后项目图标有红色感叹号，这是因为你的电脑上路径和我的路径不一样，找不到引用的jar了。右击项目，选择<code>Build Path-&gt;Configure Build Path</code>，选择<code>Libraries</code>标签，这时可以看到所有jar都有红叉叉，全选，删除，然后点击<code>Add External Jars</code>，浏览到<code>spark-0.7.2\\lib_managed\\jars</code>，把所有jar都导入，导入后红色感叹号就消失了。对每个项目都执行上述操作。</p>\n<p><strong>2013-07-27 更新</strong>：eclipse项目上有红色小叉叉图标，之前一直没解决，今天解决了，主要原因是，<strong>Scala IDE 版本不对！</strong> scala-ide.org 官网最新的的3.0.1只支持scala 2.10，不再支持2.9.3。由于Spark目前使用scala 2.9.3写的，所以我们要下载支持 scala 2.9.3 版，scala ide 3.0.0是支持 2.9.3的，不过首选要下载 eclipse JUNO，不要使用新版的eclipse，例如eclipse Indigo, Kepler都不行。</p>\n<p>因此，正确的做法是，先下载 eclipse juno，然后下载 3.0.0 的zip包，解压，然后启动eclipse，点击菜单”help-&gt;Install New Software”，浏览到刚刚解压的<code>site</code>文件夹，就可以安装scala ide插件了。</p>"},{"layout":"post","title":"简洁的Scala","date":"2013-08-29T21:38:00.000Z","comments":1,"_content":"Scala语言是很注重一致性(consistency)的，Scala的简洁性(concision)都是由其一致性带来的。\n\nScala的看上去很复杂，但是它在概念上是非常一致的。弄清了几个概念后，也就不觉得复杂了，反倒是比Java的简单。\n\n# 1. OO + FP\n\n## 1.1 一切都是对象\n\n更精确地说，应该是“一切值都是对象”。\n\n* 整数, 浮点数等基本类型(primitive type)是对象  \n\n\t\t123.toByte\n\t\t3.14.toInt\n\n\t在Java中，primitive type不是对象，打破了一致性。\n\n* 函数是对象\n\n\t\tval compare = (x: Int, y: Int) => x > y\n\t\tcompare(1, 2)\n\n* 不再有静态方法(static method)和静态属性(static field)。Java中的静态方法(static method)和静态属性(static field)，有点打破了面向对象，因为它们不属于一个实例，而是属于类。在Scala中，静态方法和静态属性也属于对象，具体来说，属于Scala中的单例object。这样，静态成员和普通成员统一了起来，都附属于某个实例(instance)。\n\n\t\tobject Dog {\n\t\t  val sound = \"wang wang\" //static field\n\t\t}\n\n\n## 1.2 函数是值\n\n函数是一等公民，跟普通的值没区别\n\n* 可以当作参数传递\n\n\t\tval  compare = (x: Int , y: Int ) => x >  y\n\t\tlist sortWith compare\n\n* 不管它是实例的方法\n\n\t\tclass AComparator  {\n\t\t  def  compare(x: Int , y: Int ) = x >  y\n\t\t}\n\t\tlist sortWith ( new  AComparator ).compare\n\n* 还是匿名子句\n\n\t\tobject  annonymous extends scala.Function2[Int , Int , Boolean] {\n\t\t  override  def  apply(x: Int , y: Int ) = x >  y\n\t\t}\n\t\tlist sortWith annonymous \n\n\n## 1.3 一切操作都是函数调用\n<!-- more -->\n\n* 运算符是函数调用\n\n\t\t1 +  1\n\t\t1.+(1)\n\t\t1.>(0)\n\t\t1 >  0\n\t\t(1 >  0).&(2 >  1)\n\t\t(1 >  0) & 2 >  1\n\t\tstack.push(10)\n\t\tstack push  10\n\t\tstack.pop\n\t\tstack pop\n\n\t注意，上述代码中，只有一个参数或零个参数的方法在调用时可以省略”.” 和”()”。\n\n* 更多的符号需要用作方法名\n\n\t\tdef  !@#%^&*\\-<=>?|~:/ = println(\"noop\" )\n\t\tdef  √(x: Double ) = Math.sqrt( x)\n\t\tval  Π =  Math.Pi\n\t\tval  r =  √( 9*Π)\n\n\n* ‘<’, ‘>’ 更适合作方法名，所以用’[’ 和‘]’ 来表示类型参数\n\n* for语句是函数调用\n\n\t\tfor  (i <- List(1, 2)) {\n\t\t  println(i)\n\t\t}\n\t\tList(1, 2) foreach { i => println(i)}\n\t\tfor  (i <- List(1, 2))  yield {\n\t\t  i +  10\n\t\t}\n\t\tList(1, 2) map {i => i +  10}\n\n* 更多的例子\n\n\t\t// synchronized is function call instead of keyword\n\t\tdef  check = synchronized {\n\t\t  // isInstanceOf is function call instead of keyword\n\t\t  100.isInstanceOf[ String ] \n\t\t}\n\n* 额外的好处：自左向右顺序书写语句\n\n\t\tstack.pop.asInstanceOf[ Int ] // (Integer) stack.pop() in Java\n\n\n## 1.4 一切操作都有返回值\n\n* 默认返回最后一条语句的值，也可以用return 显式返回\n\n\t\tval  r1 = { // return 3\n\t\t  val  a =  1\n\t\t  val  b =  2\n\t\t  a +  b\n\t\t}\n\t\tval  r2 =  if (true) 1 else 2\n\t\tval  r3 =  // return (): Unit\n\t\t  for  (i <- List(1, 2)) {\n\t\t    println(i)\n\t\t  }\n\t\tval  r4 =  // return List(11, 12)\n\t\t  for  (i <- List(1, 2))  yield {\n\t\t     i +  10\n\t\t  }\n\t\tval  r5 =  // return java.io.File\n\t\ttry  {\n\t\t   val  f =  new  File(\"afile\")\n\t\t   f\n\t\t}  catch {\n\t\t   case ex: IOException  => null\n\t\t}\n\nScala里不再像C/C++, Java，区分语句(statement)和表达式(expression)。Scala里没有statement，只有expression，因此一切操作都是表达式，都有返回值。Scala可以说是**expression-oriented**。\n\n关于语句和表达式的区别，可以看\"Scala in depth\"一书中的比较:\n\n> **Statement Versus Expression** A statement is something that execute; an expression is something that evaluates to a value.\n\n## 1.5 总结：一切都是对象+数据即操作，操作即数据 = OO + FP\n\n\n# 2. 一致的类型系统(type system)\n\n## 2.1 scala class hierarchy\n\n{% img http://www.scala-lang.org/old/sites/default/files/images/classhierarchy.png %}\n\n## 2.2 根类 Any\n\nScala 上有一个共同的根类**Any**。Any统一了基本类型和引用类型。\n\n## 2.3 两个尾类Null和Nothing。\n\nJVM上的null是Null类，它是所有AnyRef的子类。\n\nNothing是所有类型（包括AnyVal和AnyRef）的子类。它没有值（实例），用于处理一些特殊情况，例如出错时返回该类型。\n\n## 2.4 Invariant, Covariant, Contravariant\n\n## 2.5 类型参数(type parameter) VS. 抽象类型成员(abstract type member)\n\n\ttrait Pair[K, V] {\n\t  def get(key: K): V\n\t  def set(key: K, value: V)\n\t}\n\tclass PairImpl extends Pair[Dog, Fox] {\n\t  def get(key: Dog): Fox\n\t  def put(key: Dog, value: Fox)\n\t}\n\n类型参数的名字会发散到所有子类和引用的类，因此改变类型名字时需要修改很多地方\n\n\ttrait Pair{\n\t  type K // deferred type\n\t  type V // deferred type\n\t  defget(key: K): V\n\t  defset(key: K, value: V)\n\t}\n\tclass PairImpl extends Pair{\n\t  type K= Dog\n\t  type V= Fox\n\t  defget(key: K): V\n\t  defset(key: K, value: V)\n\t}\n\n抽象类型成员，改变类型名字时，只需要修改一处地方\n\n\n# 4. 一些牛人的讨论\n\n[2 楼 dcaoyuan 2009-10-25](http://dcaoyuan.iteye.com/blog/502730)  \n\n> 这次会上讲PPT时间有点不够，但这个PPT中提到的每句话都是仔细想过的，强调的是Scala中一些概念的一致性，比如，有关Scala的文章中常提到“值都是对象”，准确地说，应该是“值都是对象的实例”，还有，“操作、函数、参数可以互相转化，都是值，都是实例的对象”，这其实是Scala可以扩展的关键，也是OO+FP能够比较好地在Scala中结合的关键。 \n> \n> 还有就是Scala的类型体系，看上去复杂，其实是为了修正Java中类型体系的一些问题，并且带了了一个JVM上的完整一致的类型体系。弄清了几个概念后，也就不觉得复杂了，反倒是比Java的简单。 \n> \n> 总之，我看到的Scala的简单性都是由其一致性带来的，虽然设计者为了开发人员的习惯作了一点点妥协，但还是非常坚持他的设计理念。 \n> \n> Martin不是一个简单的人，为了在JVM上实现他的设计理念，其后台的具体实现其实是相当复杂和困难的，但他坚持并不断实践，有时候甚至不惜把原来的实现推倒重来，终于在2.6以后有了我们现在看到的相当理想的结果。\n\n#参考资料\n\n1. [2009. 邓草原. 对Java的修正和超越](http://www.slideshare.net/dcaoyuan/scalajava)\n","source":"_posts/2013-04-05-concise-scala.md","raw":"---\nlayout: post\ntitle: \"简洁的Scala\"\ndate: 2013-08-29 21:38\ncomments: true\ncategories: Language\n---\nScala语言是很注重一致性(consistency)的，Scala的简洁性(concision)都是由其一致性带来的。\n\nScala的看上去很复杂，但是它在概念上是非常一致的。弄清了几个概念后，也就不觉得复杂了，反倒是比Java的简单。\n\n# 1. OO + FP\n\n## 1.1 一切都是对象\n\n更精确地说，应该是“一切值都是对象”。\n\n* 整数, 浮点数等基本类型(primitive type)是对象  \n\n\t\t123.toByte\n\t\t3.14.toInt\n\n\t在Java中，primitive type不是对象，打破了一致性。\n\n* 函数是对象\n\n\t\tval compare = (x: Int, y: Int) => x > y\n\t\tcompare(1, 2)\n\n* 不再有静态方法(static method)和静态属性(static field)。Java中的静态方法(static method)和静态属性(static field)，有点打破了面向对象，因为它们不属于一个实例，而是属于类。在Scala中，静态方法和静态属性也属于对象，具体来说，属于Scala中的单例object。这样，静态成员和普通成员统一了起来，都附属于某个实例(instance)。\n\n\t\tobject Dog {\n\t\t  val sound = \"wang wang\" //static field\n\t\t}\n\n\n## 1.2 函数是值\n\n函数是一等公民，跟普通的值没区别\n\n* 可以当作参数传递\n\n\t\tval  compare = (x: Int , y: Int ) => x >  y\n\t\tlist sortWith compare\n\n* 不管它是实例的方法\n\n\t\tclass AComparator  {\n\t\t  def  compare(x: Int , y: Int ) = x >  y\n\t\t}\n\t\tlist sortWith ( new  AComparator ).compare\n\n* 还是匿名子句\n\n\t\tobject  annonymous extends scala.Function2[Int , Int , Boolean] {\n\t\t  override  def  apply(x: Int , y: Int ) = x >  y\n\t\t}\n\t\tlist sortWith annonymous \n\n\n## 1.3 一切操作都是函数调用\n<!-- more -->\n\n* 运算符是函数调用\n\n\t\t1 +  1\n\t\t1.+(1)\n\t\t1.>(0)\n\t\t1 >  0\n\t\t(1 >  0).&(2 >  1)\n\t\t(1 >  0) & 2 >  1\n\t\tstack.push(10)\n\t\tstack push  10\n\t\tstack.pop\n\t\tstack pop\n\n\t注意，上述代码中，只有一个参数或零个参数的方法在调用时可以省略”.” 和”()”。\n\n* 更多的符号需要用作方法名\n\n\t\tdef  !@#%^&*\\-<=>?|~:/ = println(\"noop\" )\n\t\tdef  √(x: Double ) = Math.sqrt( x)\n\t\tval  Π =  Math.Pi\n\t\tval  r =  √( 9*Π)\n\n\n* ‘<’, ‘>’ 更适合作方法名，所以用’[’ 和‘]’ 来表示类型参数\n\n* for语句是函数调用\n\n\t\tfor  (i <- List(1, 2)) {\n\t\t  println(i)\n\t\t}\n\t\tList(1, 2) foreach { i => println(i)}\n\t\tfor  (i <- List(1, 2))  yield {\n\t\t  i +  10\n\t\t}\n\t\tList(1, 2) map {i => i +  10}\n\n* 更多的例子\n\n\t\t// synchronized is function call instead of keyword\n\t\tdef  check = synchronized {\n\t\t  // isInstanceOf is function call instead of keyword\n\t\t  100.isInstanceOf[ String ] \n\t\t}\n\n* 额外的好处：自左向右顺序书写语句\n\n\t\tstack.pop.asInstanceOf[ Int ] // (Integer) stack.pop() in Java\n\n\n## 1.4 一切操作都有返回值\n\n* 默认返回最后一条语句的值，也可以用return 显式返回\n\n\t\tval  r1 = { // return 3\n\t\t  val  a =  1\n\t\t  val  b =  2\n\t\t  a +  b\n\t\t}\n\t\tval  r2 =  if (true) 1 else 2\n\t\tval  r3 =  // return (): Unit\n\t\t  for  (i <- List(1, 2)) {\n\t\t    println(i)\n\t\t  }\n\t\tval  r4 =  // return List(11, 12)\n\t\t  for  (i <- List(1, 2))  yield {\n\t\t     i +  10\n\t\t  }\n\t\tval  r5 =  // return java.io.File\n\t\ttry  {\n\t\t   val  f =  new  File(\"afile\")\n\t\t   f\n\t\t}  catch {\n\t\t   case ex: IOException  => null\n\t\t}\n\nScala里不再像C/C++, Java，区分语句(statement)和表达式(expression)。Scala里没有statement，只有expression，因此一切操作都是表达式，都有返回值。Scala可以说是**expression-oriented**。\n\n关于语句和表达式的区别，可以看\"Scala in depth\"一书中的比较:\n\n> **Statement Versus Expression** A statement is something that execute; an expression is something that evaluates to a value.\n\n## 1.5 总结：一切都是对象+数据即操作，操作即数据 = OO + FP\n\n\n# 2. 一致的类型系统(type system)\n\n## 2.1 scala class hierarchy\n\n{% img http://www.scala-lang.org/old/sites/default/files/images/classhierarchy.png %}\n\n## 2.2 根类 Any\n\nScala 上有一个共同的根类**Any**。Any统一了基本类型和引用类型。\n\n## 2.3 两个尾类Null和Nothing。\n\nJVM上的null是Null类，它是所有AnyRef的子类。\n\nNothing是所有类型（包括AnyVal和AnyRef）的子类。它没有值（实例），用于处理一些特殊情况，例如出错时返回该类型。\n\n## 2.4 Invariant, Covariant, Contravariant\n\n## 2.5 类型参数(type parameter) VS. 抽象类型成员(abstract type member)\n\n\ttrait Pair[K, V] {\n\t  def get(key: K): V\n\t  def set(key: K, value: V)\n\t}\n\tclass PairImpl extends Pair[Dog, Fox] {\n\t  def get(key: Dog): Fox\n\t  def put(key: Dog, value: Fox)\n\t}\n\n类型参数的名字会发散到所有子类和引用的类，因此改变类型名字时需要修改很多地方\n\n\ttrait Pair{\n\t  type K // deferred type\n\t  type V // deferred type\n\t  defget(key: K): V\n\t  defset(key: K, value: V)\n\t}\n\tclass PairImpl extends Pair{\n\t  type K= Dog\n\t  type V= Fox\n\t  defget(key: K): V\n\t  defset(key: K, value: V)\n\t}\n\n抽象类型成员，改变类型名字时，只需要修改一处地方\n\n\n# 4. 一些牛人的讨论\n\n[2 楼 dcaoyuan 2009-10-25](http://dcaoyuan.iteye.com/blog/502730)  \n\n> 这次会上讲PPT时间有点不够，但这个PPT中提到的每句话都是仔细想过的，强调的是Scala中一些概念的一致性，比如，有关Scala的文章中常提到“值都是对象”，准确地说，应该是“值都是对象的实例”，还有，“操作、函数、参数可以互相转化，都是值，都是实例的对象”，这其实是Scala可以扩展的关键，也是OO+FP能够比较好地在Scala中结合的关键。 \n> \n> 还有就是Scala的类型体系，看上去复杂，其实是为了修正Java中类型体系的一些问题，并且带了了一个JVM上的完整一致的类型体系。弄清了几个概念后，也就不觉得复杂了，反倒是比Java的简单。 \n> \n> 总之，我看到的Scala的简单性都是由其一致性带来的，虽然设计者为了开发人员的习惯作了一点点妥协，但还是非常坚持他的设计理念。 \n> \n> Martin不是一个简单的人，为了在JVM上实现他的设计理念，其后台的具体实现其实是相当复杂和困难的，但他坚持并不断实践，有时候甚至不惜把原来的实现推倒重来，终于在2.6以后有了我们现在看到的相当理想的结果。\n\n#参考资料\n\n1. [2009. 邓草原. 对Java的修正和超越](http://www.slideshare.net/dcaoyuan/scalajava)\n","slug":"2013-04-05-concise-scala","published":1,"updated":"2016-08-18T09:21:04.000Z","photos":[],"link":"","_id":"cis07pf39001901pq4t6gp8fj","content":"<p>Scala语言是很注重一致性(consistency)的，Scala的简洁性(concision)都是由其一致性带来的。</p>\n<p>Scala的看上去很复杂，但是它在概念上是非常一致的。弄清了几个概念后，也就不觉得复杂了，反倒是比Java的简单。</p>\n<h1 id=\"1-OO-FP\"><a href=\"#1-OO-FP\" class=\"headerlink\" title=\"1. OO + FP\"></a>1. OO + FP</h1><h2 id=\"1-1-一切都是对象\"><a href=\"#1-1-一切都是对象\" class=\"headerlink\" title=\"1.1 一切都是对象\"></a>1.1 一切都是对象</h2><p>更精确地说，应该是“一切值都是对象”。</p>\n<ul>\n<li><p>整数, 浮点数等基本类型(primitive type)是对象  </p>\n<pre><code>123.toByte\n3.14.toInt\n</code></pre><p>  在Java中，primitive type不是对象，打破了一致性。</p>\n</li>\n<li><p>函数是对象</p>\n<pre><code>val compare = (x: Int, y: Int) =&gt; x &gt; y\ncompare(1, 2)\n</code></pre></li>\n<li><p>不再有静态方法(static method)和静态属性(static field)。Java中的静态方法(static method)和静态属性(static field)，有点打破了面向对象，因为它们不属于一个实例，而是属于类。在Scala中，静态方法和静态属性也属于对象，具体来说，属于Scala中的单例object。这样，静态成员和普通成员统一了起来，都附属于某个实例(instance)。</p>\n<pre><code>object Dog {\n  val sound = &quot;wang wang&quot; //static field\n}\n</code></pre></li>\n</ul>\n<h2 id=\"1-2-函数是值\"><a href=\"#1-2-函数是值\" class=\"headerlink\" title=\"1.2 函数是值\"></a>1.2 函数是值</h2><p>函数是一等公民，跟普通的值没区别</p>\n<ul>\n<li><p>可以当作参数传递</p>\n<pre><code>val  compare = (x: Int , y: Int ) =&gt; x &gt;  y\nlist sortWith compare\n</code></pre></li>\n<li><p>不管它是实例的方法</p>\n<pre><code>class AComparator  {\n  def  compare(x: Int , y: Int ) = x &gt;  y\n}\nlist sortWith ( new  AComparator ).compare\n</code></pre></li>\n<li><p>还是匿名子句</p>\n<pre><code>object  annonymous extends scala.Function2[Int , Int , Boolean] {\n  override  def  apply(x: Int , y: Int ) = x &gt;  y\n}\nlist sortWith annonymous \n</code></pre></li>\n</ul>\n<h2 id=\"1-3-一切操作都是函数调用\"><a href=\"#1-3-一切操作都是函数调用\" class=\"headerlink\" title=\"1.3 一切操作都是函数调用\"></a>1.3 一切操作都是函数调用</h2><a id=\"more\"></a>\n<ul>\n<li><p>运算符是函数调用</p>\n<pre><code>1 +  1\n1.+(1)\n1.&gt;(0)\n1 &gt;  0\n(1 &gt;  0).&amp;(2 &gt;  1)\n(1 &gt;  0) &amp; 2 &gt;  1\nstack.push(10)\nstack push  10\nstack.pop\nstack pop\n</code></pre><p>  注意，上述代码中，只有一个参数或零个参数的方法在调用时可以省略”.” 和”()”。</p>\n</li>\n<li><p>更多的符号需要用作方法名</p>\n<pre><code>def  !@#%^&amp;*\\-&lt;=&gt;?|~:/ = println(&quot;noop&quot; )\ndef  √(x: Double ) = Math.sqrt( x)\nval  Π =  Math.Pi\nval  r =  √( 9*Π)\n</code></pre></li>\n</ul>\n<ul>\n<li><p>‘&lt;’, ‘&gt;’ 更适合作方法名，所以用’[’ 和‘]’ 来表示类型参数</p>\n</li>\n<li><p>for语句是函数调用</p>\n<pre><code>for  (i &lt;- List(1, 2)) {\n  println(i)\n}\nList(1, 2) foreach { i =&gt; println(i)}\nfor  (i &lt;- List(1, 2))  yield {\n  i +  10\n}\nList(1, 2) map {i =&gt; i +  10}\n</code></pre></li>\n<li><p>更多的例子</p>\n<pre><code>// synchronized is function call instead of keyword\ndef  check = synchronized {\n  // isInstanceOf is function call instead of keyword\n  100.isInstanceOf[ String ] \n}\n</code></pre></li>\n<li><p>额外的好处：自左向右顺序书写语句</p>\n<pre><code>stack.pop.asInstanceOf[ Int ] // (Integer) stack.pop() in Java\n</code></pre></li>\n</ul>\n<h2 id=\"1-4-一切操作都有返回值\"><a href=\"#1-4-一切操作都有返回值\" class=\"headerlink\" title=\"1.4 一切操作都有返回值\"></a>1.4 一切操作都有返回值</h2><ul>\n<li><p>默认返回最后一条语句的值，也可以用return 显式返回</p>\n<pre><code>val  r1 = { // return 3\n  val  a =  1\n  val  b =  2\n  a +  b\n}\nval  r2 =  if (true) 1 else 2\nval  r3 =  // return (): Unit\n  for  (i &lt;- List(1, 2)) {\n    println(i)\n  }\nval  r4 =  // return List(11, 12)\n  for  (i &lt;- List(1, 2))  yield {\n     i +  10\n  }\nval  r5 =  // return java.io.File\ntry  {\n   val  f =  new  File(&quot;afile&quot;)\n   f\n}  catch {\n   case ex: IOException  =&gt; null\n}\n</code></pre></li>\n</ul>\n<p>Scala里不再像C/C++, Java，区分语句(statement)和表达式(expression)。Scala里没有statement，只有expression，因此一切操作都是表达式，都有返回值。Scala可以说是<strong>expression-oriented</strong>。</p>\n<p>关于语句和表达式的区别，可以看”Scala in depth”一书中的比较:</p>\n<blockquote>\n<p><strong>Statement Versus Expression</strong> A statement is something that execute; an expression is something that evaluates to a value.</p>\n</blockquote>\n<h2 id=\"1-5-总结：一切都是对象-数据即操作，操作即数据-OO-FP\"><a href=\"#1-5-总结：一切都是对象-数据即操作，操作即数据-OO-FP\" class=\"headerlink\" title=\"1.5 总结：一切都是对象+数据即操作，操作即数据 = OO + FP\"></a>1.5 总结：一切都是对象+数据即操作，操作即数据 = OO + FP</h2><h1 id=\"2-一致的类型系统-type-system\"><a href=\"#2-一致的类型系统-type-system\" class=\"headerlink\" title=\"2. 一致的类型系统(type system)\"></a>2. 一致的类型系统(type system)</h1><h2 id=\"2-1-scala-class-hierarchy\"><a href=\"#2-1-scala-class-hierarchy\" class=\"headerlink\" title=\"2.1 scala class hierarchy\"></a>2.1 scala class hierarchy</h2><img src=\"http://www.scala-lang.org/old/sites/default/files/images/classhierarchy.png\">\n<h2 id=\"2-2-根类-Any\"><a href=\"#2-2-根类-Any\" class=\"headerlink\" title=\"2.2 根类 Any\"></a>2.2 根类 Any</h2><p>Scala 上有一个共同的根类<strong>Any</strong>。Any统一了基本类型和引用类型。</p>\n<h2 id=\"2-3-两个尾类Null和Nothing。\"><a href=\"#2-3-两个尾类Null和Nothing。\" class=\"headerlink\" title=\"2.3 两个尾类Null和Nothing。\"></a>2.3 两个尾类Null和Nothing。</h2><p>JVM上的null是Null类，它是所有AnyRef的子类。</p>\n<p>Nothing是所有类型（包括AnyVal和AnyRef）的子类。它没有值（实例），用于处理一些特殊情况，例如出错时返回该类型。</p>\n<h2 id=\"2-4-Invariant-Covariant-Contravariant\"><a href=\"#2-4-Invariant-Covariant-Contravariant\" class=\"headerlink\" title=\"2.4 Invariant, Covariant, Contravariant\"></a>2.4 Invariant, Covariant, Contravariant</h2><h2 id=\"2-5-类型参数-type-parameter-VS-抽象类型成员-abstract-type-member\"><a href=\"#2-5-类型参数-type-parameter-VS-抽象类型成员-abstract-type-member\" class=\"headerlink\" title=\"2.5 类型参数(type parameter) VS. 抽象类型成员(abstract type member)\"></a>2.5 类型参数(type parameter) VS. 抽象类型成员(abstract type member)</h2><pre><code>trait Pair[K, V] {\n  def get(key: K): V\n  def set(key: K, value: V)\n}\nclass PairImpl extends Pair[Dog, Fox] {\n  def get(key: Dog): Fox\n  def put(key: Dog, value: Fox)\n}\n</code></pre><p>类型参数的名字会发散到所有子类和引用的类，因此改变类型名字时需要修改很多地方</p>\n<pre><code>trait Pair{\n  type K // deferred type\n  type V // deferred type\n  defget(key: K): V\n  defset(key: K, value: V)\n}\nclass PairImpl extends Pair{\n  type K= Dog\n  type V= Fox\n  defget(key: K): V\n  defset(key: K, value: V)\n}\n</code></pre><p>抽象类型成员，改变类型名字时，只需要修改一处地方</p>\n<h1 id=\"4-一些牛人的讨论\"><a href=\"#4-一些牛人的讨论\" class=\"headerlink\" title=\"4. 一些牛人的讨论\"></a>4. 一些牛人的讨论</h1><p><a href=\"http://dcaoyuan.iteye.com/blog/502730\" target=\"_blank\" rel=\"external\">2 楼 dcaoyuan 2009-10-25</a>  </p>\n<blockquote>\n<p>这次会上讲PPT时间有点不够，但这个PPT中提到的每句话都是仔细想过的，强调的是Scala中一些概念的一致性，比如，有关Scala的文章中常提到“值都是对象”，准确地说，应该是“值都是对象的实例”，还有，“操作、函数、参数可以互相转化，都是值，都是实例的对象”，这其实是Scala可以扩展的关键，也是OO+FP能够比较好地在Scala中结合的关键。 </p>\n<p>还有就是Scala的类型体系，看上去复杂，其实是为了修正Java中类型体系的一些问题，并且带了了一个JVM上的完整一致的类型体系。弄清了几个概念后，也就不觉得复杂了，反倒是比Java的简单。 </p>\n<p>总之，我看到的Scala的简单性都是由其一致性带来的，虽然设计者为了开发人员的习惯作了一点点妥协，但还是非常坚持他的设计理念。 </p>\n<p>Martin不是一个简单的人，为了在JVM上实现他的设计理念，其后台的具体实现其实是相当复杂和困难的，但他坚持并不断实践，有时候甚至不惜把原来的实现推倒重来，终于在2.6以后有了我们现在看到的相当理想的结果。</p>\n</blockquote>\n<p>#参考资料</p>\n<ol>\n<li><a href=\"http://www.slideshare.net/dcaoyuan/scalajava\" target=\"_blank\" rel=\"external\">2009. 邓草原. 对Java的修正和超越</a></li>\n</ol>\n","excerpt":"<p>Scala语言是很注重一致性(consistency)的，Scala的简洁性(concision)都是由其一致性带来的。</p>\n<p>Scala的看上去很复杂，但是它在概念上是非常一致的。弄清了几个概念后，也就不觉得复杂了，反倒是比Java的简单。</p>\n<h1 id=\"1-OO-FP\"><a href=\"#1-OO-FP\" class=\"headerlink\" title=\"1. OO + FP\"></a>1. OO + FP</h1><h2 id=\"1-1-一切都是对象\"><a href=\"#1-1-一切都是对象\" class=\"headerlink\" title=\"1.1 一切都是对象\"></a>1.1 一切都是对象</h2><p>更精确地说，应该是“一切值都是对象”。</p>\n<ul>\n<li><p>整数, 浮点数等基本类型(primitive type)是对象  </p>\n<pre><code>123.toByte\n3.14.toInt\n</code></pre><p>  在Java中，primitive type不是对象，打破了一致性。</p>\n</li>\n<li><p>函数是对象</p>\n<pre><code>val compare = (x: Int, y: Int) =&gt; x &gt; y\ncompare(1, 2)\n</code></pre></li>\n<li><p>不再有静态方法(static method)和静态属性(static field)。Java中的静态方法(static method)和静态属性(static field)，有点打破了面向对象，因为它们不属于一个实例，而是属于类。在Scala中，静态方法和静态属性也属于对象，具体来说，属于Scala中的单例object。这样，静态成员和普通成员统一了起来，都附属于某个实例(instance)。</p>\n<pre><code>object Dog {\n  val sound = &quot;wang wang&quot; //static field\n}\n</code></pre></li>\n</ul>\n<h2 id=\"1-2-函数是值\"><a href=\"#1-2-函数是值\" class=\"headerlink\" title=\"1.2 函数是值\"></a>1.2 函数是值</h2><p>函数是一等公民，跟普通的值没区别</p>\n<ul>\n<li><p>可以当作参数传递</p>\n<pre><code>val  compare = (x: Int , y: Int ) =&gt; x &gt;  y\nlist sortWith compare\n</code></pre></li>\n<li><p>不管它是实例的方法</p>\n<pre><code>class AComparator  {\n  def  compare(x: Int , y: Int ) = x &gt;  y\n}\nlist sortWith ( new  AComparator ).compare\n</code></pre></li>\n<li><p>还是匿名子句</p>\n<pre><code>object  annonymous extends scala.Function2[Int , Int , Boolean] {\n  override  def  apply(x: Int , y: Int ) = x &gt;  y\n}\nlist sortWith annonymous \n</code></pre></li>\n</ul>\n<h2 id=\"1-3-一切操作都是函数调用\"><a href=\"#1-3-一切操作都是函数调用\" class=\"headerlink\" title=\"1.3 一切操作都是函数调用\"></a>1.3 一切操作都是函数调用</h2>","more":"<ul>\n<li><p>运算符是函数调用</p>\n<pre><code>1 +  1\n1.+(1)\n1.&gt;(0)\n1 &gt;  0\n(1 &gt;  0).&amp;(2 &gt;  1)\n(1 &gt;  0) &amp; 2 &gt;  1\nstack.push(10)\nstack push  10\nstack.pop\nstack pop\n</code></pre><p>  注意，上述代码中，只有一个参数或零个参数的方法在调用时可以省略”.” 和”()”。</p>\n</li>\n<li><p>更多的符号需要用作方法名</p>\n<pre><code>def  !@#%^&amp;*\\-&lt;=&gt;?|~:/ = println(&quot;noop&quot; )\ndef  √(x: Double ) = Math.sqrt( x)\nval  Π =  Math.Pi\nval  r =  √( 9*Π)\n</code></pre></li>\n</ul>\n<ul>\n<li><p>‘&lt;’, ‘&gt;’ 更适合作方法名，所以用’[’ 和‘]’ 来表示类型参数</p>\n</li>\n<li><p>for语句是函数调用</p>\n<pre><code>for  (i &lt;- List(1, 2)) {\n  println(i)\n}\nList(1, 2) foreach { i =&gt; println(i)}\nfor  (i &lt;- List(1, 2))  yield {\n  i +  10\n}\nList(1, 2) map {i =&gt; i +  10}\n</code></pre></li>\n<li><p>更多的例子</p>\n<pre><code>// synchronized is function call instead of keyword\ndef  check = synchronized {\n  // isInstanceOf is function call instead of keyword\n  100.isInstanceOf[ String ] \n}\n</code></pre></li>\n<li><p>额外的好处：自左向右顺序书写语句</p>\n<pre><code>stack.pop.asInstanceOf[ Int ] // (Integer) stack.pop() in Java\n</code></pre></li>\n</ul>\n<h2 id=\"1-4-一切操作都有返回值\"><a href=\"#1-4-一切操作都有返回值\" class=\"headerlink\" title=\"1.4 一切操作都有返回值\"></a>1.4 一切操作都有返回值</h2><ul>\n<li><p>默认返回最后一条语句的值，也可以用return 显式返回</p>\n<pre><code>val  r1 = { // return 3\n  val  a =  1\n  val  b =  2\n  a +  b\n}\nval  r2 =  if (true) 1 else 2\nval  r3 =  // return (): Unit\n  for  (i &lt;- List(1, 2)) {\n    println(i)\n  }\nval  r4 =  // return List(11, 12)\n  for  (i &lt;- List(1, 2))  yield {\n     i +  10\n  }\nval  r5 =  // return java.io.File\ntry  {\n   val  f =  new  File(&quot;afile&quot;)\n   f\n}  catch {\n   case ex: IOException  =&gt; null\n}\n</code></pre></li>\n</ul>\n<p>Scala里不再像C/C++, Java，区分语句(statement)和表达式(expression)。Scala里没有statement，只有expression，因此一切操作都是表达式，都有返回值。Scala可以说是<strong>expression-oriented</strong>。</p>\n<p>关于语句和表达式的区别，可以看”Scala in depth”一书中的比较:</p>\n<blockquote>\n<p><strong>Statement Versus Expression</strong> A statement is something that execute; an expression is something that evaluates to a value.</p>\n</blockquote>\n<h2 id=\"1-5-总结：一切都是对象-数据即操作，操作即数据-OO-FP\"><a href=\"#1-5-总结：一切都是对象-数据即操作，操作即数据-OO-FP\" class=\"headerlink\" title=\"1.5 总结：一切都是对象+数据即操作，操作即数据 = OO + FP\"></a>1.5 总结：一切都是对象+数据即操作，操作即数据 = OO + FP</h2><h1 id=\"2-一致的类型系统-type-system\"><a href=\"#2-一致的类型系统-type-system\" class=\"headerlink\" title=\"2. 一致的类型系统(type system)\"></a>2. 一致的类型系统(type system)</h1><h2 id=\"2-1-scala-class-hierarchy\"><a href=\"#2-1-scala-class-hierarchy\" class=\"headerlink\" title=\"2.1 scala class hierarchy\"></a>2.1 scala class hierarchy</h2><img src=\"http://www.scala-lang.org/old/sites/default/files/images/classhierarchy.png\">\n<h2 id=\"2-2-根类-Any\"><a href=\"#2-2-根类-Any\" class=\"headerlink\" title=\"2.2 根类 Any\"></a>2.2 根类 Any</h2><p>Scala 上有一个共同的根类<strong>Any</strong>。Any统一了基本类型和引用类型。</p>\n<h2 id=\"2-3-两个尾类Null和Nothing。\"><a href=\"#2-3-两个尾类Null和Nothing。\" class=\"headerlink\" title=\"2.3 两个尾类Null和Nothing。\"></a>2.3 两个尾类Null和Nothing。</h2><p>JVM上的null是Null类，它是所有AnyRef的子类。</p>\n<p>Nothing是所有类型（包括AnyVal和AnyRef）的子类。它没有值（实例），用于处理一些特殊情况，例如出错时返回该类型。</p>\n<h2 id=\"2-4-Invariant-Covariant-Contravariant\"><a href=\"#2-4-Invariant-Covariant-Contravariant\" class=\"headerlink\" title=\"2.4 Invariant, Covariant, Contravariant\"></a>2.4 Invariant, Covariant, Contravariant</h2><h2 id=\"2-5-类型参数-type-parameter-VS-抽象类型成员-abstract-type-member\"><a href=\"#2-5-类型参数-type-parameter-VS-抽象类型成员-abstract-type-member\" class=\"headerlink\" title=\"2.5 类型参数(type parameter) VS. 抽象类型成员(abstract type member)\"></a>2.5 类型参数(type parameter) VS. 抽象类型成员(abstract type member)</h2><pre><code>trait Pair[K, V] {\n  def get(key: K): V\n  def set(key: K, value: V)\n}\nclass PairImpl extends Pair[Dog, Fox] {\n  def get(key: Dog): Fox\n  def put(key: Dog, value: Fox)\n}\n</code></pre><p>类型参数的名字会发散到所有子类和引用的类，因此改变类型名字时需要修改很多地方</p>\n<pre><code>trait Pair{\n  type K // deferred type\n  type V // deferred type\n  defget(key: K): V\n  defset(key: K, value: V)\n}\nclass PairImpl extends Pair{\n  type K= Dog\n  type V= Fox\n  defget(key: K): V\n  defset(key: K, value: V)\n}\n</code></pre><p>抽象类型成员，改变类型名字时，只需要修改一处地方</p>\n<h1 id=\"4-一些牛人的讨论\"><a href=\"#4-一些牛人的讨论\" class=\"headerlink\" title=\"4. 一些牛人的讨论\"></a>4. 一些牛人的讨论</h1><p><a href=\"http://dcaoyuan.iteye.com/blog/502730\">2 楼 dcaoyuan 2009-10-25</a>  </p>\n<blockquote>\n<p>这次会上讲PPT时间有点不够，但这个PPT中提到的每句话都是仔细想过的，强调的是Scala中一些概念的一致性，比如，有关Scala的文章中常提到“值都是对象”，准确地说，应该是“值都是对象的实例”，还有，“操作、函数、参数可以互相转化，都是值，都是实例的对象”，这其实是Scala可以扩展的关键，也是OO+FP能够比较好地在Scala中结合的关键。 </p>\n<p>还有就是Scala的类型体系，看上去复杂，其实是为了修正Java中类型体系的一些问题，并且带了了一个JVM上的完整一致的类型体系。弄清了几个概念后，也就不觉得复杂了，反倒是比Java的简单。 </p>\n<p>总之，我看到的Scala的简单性都是由其一致性带来的，虽然设计者为了开发人员的习惯作了一点点妥协，但还是非常坚持他的设计理念。 </p>\n<p>Martin不是一个简单的人，为了在JVM上实现他的设计理念，其后台的具体实现其实是相当复杂和困难的，但他坚持并不断实践，有时候甚至不惜把原来的实现推倒重来，终于在2.6以后有了我们现在看到的相当理想的结果。</p>\n</blockquote>\n<p>#参考资料</p>\n<ol>\n<li><a href=\"http://www.slideshare.net/dcaoyuan/scalajava\">2009. 邓草原. 对Java的修正和超越</a></li>\n</ol>"},{"layout":"post","title":"Installing Spark on CentOS","date":"2013-06-14T19:06:00.000Z","comments":1,"_content":"**Environment**:CentOS 6.4, Hadoop 1.1.2, JDK 1.7, Spark 0.7.2, Scala 2.9.3\n\nAfter a few days hacking , I have found that installing a Spark cluster is exteremely easy :)\n\n#1. Install JDK 1.7\n\tyum search openjdk-devel\n\tsudo yum install java-1.7.0-openjdk-devel.x86_64\n\t/usr/sbin/alternatives --config java\n\t/usr/sbin/alternatives --config javac\n\tsudo vim /etc/profile\n\t# add the following lines at the end\n\texport JAVA_HOME=/usr/lib/jvm/java-1.7.0-openjdk-1.7.0.19.x86_64\n\texport JRE_HOME=$JAVA_HOME/jre\n\texport PATH=$PATH:$JAVA_HOME/bin\n\texport CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar\n\t# save and exit vim\n\t# make the bash profile take effect immediately\n\t$ source /etc/profile\n\t# test\n\t$ java -version\n\n#2. Install Scala 2.9.3\nSpark 0.7.2 depends on Scala 2.9.3, So we must install Scala of version 2.9.3.\n\nDownload [scala-2.9.3.tgz](http://www.scala-lang.org/downloads/distrib/files/scala-2.9.3.tgz) and save it to home directory.\n\n\t$ tar -zxf scala-2.9.3.tgz\n\t$ sudo mv scala-2.9.3 /usr/lib\n\t$ sudo vim /etc/profile\n\t# add the following lines at the end\n\texport SCALA_HOME=/usr/lib/scala-2.9.3\n\texport PATH=$PATH:$SCALA_HOME/bin\n\t# save and exit vim\n\t# make the bash profile take effect immediately\n\tsource /etc/profile\n\t# test\n\t$ scala -version\n\n#3. Download prebuilt packages\nDownload prebuilt packages, [spark-0.7.2-prebuilt-hadoop1.tgz](http://www.spark-project.org/download-spark-0.7.2-prebuilt-hadoop1). \n\nIf you want to compile it from scratch, download the source package, but I don’t recommend this way, because in Chinese Mainland the GFW has blocked one of maven repositories, twitter4j.org, which makes the compilation an impossible mission unless you can conquer GFW.\n\n#4. Local Mode\n\n##4.1 Untar the tarball\n\n\t$ tar -zxf spark-0.7.2-prebuilt-hadoop1.tgz\n\n##4.2 Set the SPARK\\_EXAMPLES\\_JAR environment variable\n\t$ vim ~/.bash_profile\n\t# add the following lines at the end\n\texport SPARK_EXAMPLES_JAR=$HOME/spark-0.7.2/examples/target/scala-2.9.3/spark-examples_2.9.3-0.7.2.jar\n\t# save and exit vim\n\t# make the bash profile take effect immediately\n\t$ source /etc/profile\n\nThis is the most important step that must be done , but unfortunately the official docs and most web blogs haven’t mentioned this. I found this step when I bumped into these posts, [Running SparkPi](https://groups.google.com/forum/?fromgroups#!topic/spark-users/nQ6wB2lcFN8), [Null pointer exception when running ./run spark.examples.SparkPi local](https://groups.google.com/forum/#!msg/spark-users/x5UczgI-Xm8/wzMm3Mb77-oJ).\n\n##4.3 (Optional)Set SPARK\\_HOME and add SPARK\\_HOME/bin to PATH\n\n\t$ vim ~/.bash_profile\n\t# add the following lines at the end\n\texport SPARK_HOME=$HOME/spark-0.7.2\n\texport PATH=$PATH:$SPARK_HOME/bin\n\t# save and exit vim\n\t# make the bash profile take effect immediately\n\t$ source /etc/profile\n\n##4.4 Now you can run SparkPi.\n\n\t$ cd ~/spark-0.7.2\n\t$ ./run spark.examples.SparkPi local \n\n#5. Cluster Mode\n\n<!-- more -->\n\n##5.1 Install hadoop\nUse VMware Workstation to create three CentOS virtual machines, which's hostnames are master, slave01, slave02, setup password-less ssh to the slaves, install hadoop on the three machines and start up the hadoop cluster. For more details please read another blog of mine, [在CentOS上安装Hadoop](http://www.yanjiuyanjiu.com/blog/20130612).\n\n##5.2 Install JDK and Scala\nInstall JDK 1.7 and Scala 2.9.3 on the three machines, according to section 1 and section 2.\n\n##5.3 Install and configure Spark on master\nUntar\n\n\t$ tar -zxf spark-0.7.2-prebuilt-hadoop1.tgz\n\nSet the SPARK\\_EXAMPLES\\_JAR environment variable\n\n\t$ vim ~/.bash_profile\n\t# add the following lines at the end\n\texport SPARK_EXAMPLES_JAR=$HOME/spark-0.7.2/examples/target/scala-2.9.3/spark-examples_2.9.3-0.7.2.jar\n\t# save and exit vim\n\t# make the bash profile take effect immediately\n\t$ source /etc/profile\n\nSet `SCALA_HOME` in `conf/spark-env.sh`\n\n\t$ cd ~/spark-0.7.2/conf\n\t$ mv spark-env.sh.template spark-env.sh\n\t$ vim spark-env.sh\n\t# add the following line\n\texport SCALA_HOME=/usr/lib/scala-2.9.3\n\t# save and exit\n\nIn`conf/slaves`, add hostnames of Spark workers, one per line.\n\n\t$ vim slaves\n\tslave01\n\tslave02\n\t# save and exit\n\n(Optional)Set SPARK\\_HOME and add SPARK\\_HOME/bin to PATH\n\n\t$ vim ~/.bash_profile\n\t# add the following lines at the end\n\texport SPARK_HOME=$HOME/spark-0.7.2\n\texport PATH=$PATH:$SPARK_HOME/bin\n\t# save and exit vim\n\t# make the bash profile take effect immediately\n\t$ source /etc/profile\n\n##5.4 Install and configure Spark on workers\nCopy the spark directory to all slaves. **Remark，the spark directories must locat at the the same path on all machines，because the master will login to work to execute spark commands, it assumes that workers have the same path as itself**\n\n\t$ cd\n\t$ scp -r spark-0.7.2 dev@slave01:~\n\t$ scp -r spark-0.7.2 dev@slave02:~\n\nSet `SPARK_EXAMPLES_JAR`  on all slaves as section 5.3. There is no need to edit configuration files because they are copied from master, which are already well configured.\n\n##5.5 Start Spark cluster\nOn master\n\n\t$ cd ~/spark-0.7.2\n\t$ bin/start-all.sh\n\nCheck whether the processes have been started.\n\n\t$ jps\n\t11055 Jps\n\t2313 SecondaryNameNode\n\t2409 JobTracker\n\t2152 NameNode\n\t4822 Master\n\nLook at the master’s web UI (<http://localhost:8080> by default). You should see the new node listed there, along with its number of CPUs and memory (minus one gigabyte left for the OS).\n\n##5.6 run the SparkPi example in cluster mode\n\n\t$ cd ~/spark-0.7.2\n\t$ ./run spark.examples.SparkPi spark://master:7077\n\n(Optional)Run built-in examples, SparkLR and SparkKMeans.\n\t\n\t#Logistic Regression\n\t#./run spark.examples.SparkLR spark://master:7077\n\t#kmeans\n\t$ ./run spark.examples.SparkKMeans spark://master:7077 ./kmeans_data.txt 2 1\n\n##5.7 read files from HDFS and run WordCount\n\n\t$ cd ~/spark-0.7.2\n\t$ hadoop fs -put README.md .\n\t$ MASTER=spark://master:7077 ./spark-shell\n\tscala> val file = sc.textFile(\"hdfs://master:9000/user/dev/README.md\")\n\tscala> val count = file.flatMap(line => line.split(\" \")).map(word => (word, 1)).reduceByKey(_+_)\n\tscala> count.collect()\n\n##5.8 Stop Spark cluster\n\n\t$ cd ~/spark-0.7.2\n\t$ bin/stop-all.sh\n\n#References\n1. [Spark Standalone Mode](http://spark-project.org/docs/latest/spark-standalone.html)\n1. [Running A Spark Standalone Cluster](https://github.com/mesos/spark/wiki/Running-A-Spark-Standalone-Cluster)\n1. [Lightning-Fast WordCount using Spark Alongside Hadoop](http://sprism.blogspot.com/2012/11/lightning-fast-wordcount-using-spark.html)\n\nThe following posts are outdated.\n\n1. [Installing Spark on Fedora 18](http://chapeau.freevariable.com/2013/04/installing-spark-on-fedora-18.html)\n1. [Spark随谈（二）—— 安装攻略](http://rdc.taobao.com/team/jm/archives/1823)\n1. [Spark安装与学习](http://www.cnblogs.com/jerrylead/archive/2012/08/13/2636115.html)\n","source":"_posts/2013-06-14-installing-spark-on-centos.md","raw":"---\nlayout: post\ntitle: \"Installing Spark on CentOS\"\ndate: 2013-06-14 19:06\ncomments: true\ncategories: Spark\n---\n**Environment**:CentOS 6.4, Hadoop 1.1.2, JDK 1.7, Spark 0.7.2, Scala 2.9.3\n\nAfter a few days hacking , I have found that installing a Spark cluster is exteremely easy :)\n\n#1. Install JDK 1.7\n\tyum search openjdk-devel\n\tsudo yum install java-1.7.0-openjdk-devel.x86_64\n\t/usr/sbin/alternatives --config java\n\t/usr/sbin/alternatives --config javac\n\tsudo vim /etc/profile\n\t# add the following lines at the end\n\texport JAVA_HOME=/usr/lib/jvm/java-1.7.0-openjdk-1.7.0.19.x86_64\n\texport JRE_HOME=$JAVA_HOME/jre\n\texport PATH=$PATH:$JAVA_HOME/bin\n\texport CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar\n\t# save and exit vim\n\t# make the bash profile take effect immediately\n\t$ source /etc/profile\n\t# test\n\t$ java -version\n\n#2. Install Scala 2.9.3\nSpark 0.7.2 depends on Scala 2.9.3, So we must install Scala of version 2.9.3.\n\nDownload [scala-2.9.3.tgz](http://www.scala-lang.org/downloads/distrib/files/scala-2.9.3.tgz) and save it to home directory.\n\n\t$ tar -zxf scala-2.9.3.tgz\n\t$ sudo mv scala-2.9.3 /usr/lib\n\t$ sudo vim /etc/profile\n\t# add the following lines at the end\n\texport SCALA_HOME=/usr/lib/scala-2.9.3\n\texport PATH=$PATH:$SCALA_HOME/bin\n\t# save and exit vim\n\t# make the bash profile take effect immediately\n\tsource /etc/profile\n\t# test\n\t$ scala -version\n\n#3. Download prebuilt packages\nDownload prebuilt packages, [spark-0.7.2-prebuilt-hadoop1.tgz](http://www.spark-project.org/download-spark-0.7.2-prebuilt-hadoop1). \n\nIf you want to compile it from scratch, download the source package, but I don’t recommend this way, because in Chinese Mainland the GFW has blocked one of maven repositories, twitter4j.org, which makes the compilation an impossible mission unless you can conquer GFW.\n\n#4. Local Mode\n\n##4.1 Untar the tarball\n\n\t$ tar -zxf spark-0.7.2-prebuilt-hadoop1.tgz\n\n##4.2 Set the SPARK\\_EXAMPLES\\_JAR environment variable\n\t$ vim ~/.bash_profile\n\t# add the following lines at the end\n\texport SPARK_EXAMPLES_JAR=$HOME/spark-0.7.2/examples/target/scala-2.9.3/spark-examples_2.9.3-0.7.2.jar\n\t# save and exit vim\n\t# make the bash profile take effect immediately\n\t$ source /etc/profile\n\nThis is the most important step that must be done , but unfortunately the official docs and most web blogs haven’t mentioned this. I found this step when I bumped into these posts, [Running SparkPi](https://groups.google.com/forum/?fromgroups#!topic/spark-users/nQ6wB2lcFN8), [Null pointer exception when running ./run spark.examples.SparkPi local](https://groups.google.com/forum/#!msg/spark-users/x5UczgI-Xm8/wzMm3Mb77-oJ).\n\n##4.3 (Optional)Set SPARK\\_HOME and add SPARK\\_HOME/bin to PATH\n\n\t$ vim ~/.bash_profile\n\t# add the following lines at the end\n\texport SPARK_HOME=$HOME/spark-0.7.2\n\texport PATH=$PATH:$SPARK_HOME/bin\n\t# save and exit vim\n\t# make the bash profile take effect immediately\n\t$ source /etc/profile\n\n##4.4 Now you can run SparkPi.\n\n\t$ cd ~/spark-0.7.2\n\t$ ./run spark.examples.SparkPi local \n\n#5. Cluster Mode\n\n<!-- more -->\n\n##5.1 Install hadoop\nUse VMware Workstation to create three CentOS virtual machines, which's hostnames are master, slave01, slave02, setup password-less ssh to the slaves, install hadoop on the three machines and start up the hadoop cluster. For more details please read another blog of mine, [在CentOS上安装Hadoop](http://www.yanjiuyanjiu.com/blog/20130612).\n\n##5.2 Install JDK and Scala\nInstall JDK 1.7 and Scala 2.9.3 on the three machines, according to section 1 and section 2.\n\n##5.3 Install and configure Spark on master\nUntar\n\n\t$ tar -zxf spark-0.7.2-prebuilt-hadoop1.tgz\n\nSet the SPARK\\_EXAMPLES\\_JAR environment variable\n\n\t$ vim ~/.bash_profile\n\t# add the following lines at the end\n\texport SPARK_EXAMPLES_JAR=$HOME/spark-0.7.2/examples/target/scala-2.9.3/spark-examples_2.9.3-0.7.2.jar\n\t# save and exit vim\n\t# make the bash profile take effect immediately\n\t$ source /etc/profile\n\nSet `SCALA_HOME` in `conf/spark-env.sh`\n\n\t$ cd ~/spark-0.7.2/conf\n\t$ mv spark-env.sh.template spark-env.sh\n\t$ vim spark-env.sh\n\t# add the following line\n\texport SCALA_HOME=/usr/lib/scala-2.9.3\n\t# save and exit\n\nIn`conf/slaves`, add hostnames of Spark workers, one per line.\n\n\t$ vim slaves\n\tslave01\n\tslave02\n\t# save and exit\n\n(Optional)Set SPARK\\_HOME and add SPARK\\_HOME/bin to PATH\n\n\t$ vim ~/.bash_profile\n\t# add the following lines at the end\n\texport SPARK_HOME=$HOME/spark-0.7.2\n\texport PATH=$PATH:$SPARK_HOME/bin\n\t# save and exit vim\n\t# make the bash profile take effect immediately\n\t$ source /etc/profile\n\n##5.4 Install and configure Spark on workers\nCopy the spark directory to all slaves. **Remark，the spark directories must locat at the the same path on all machines，because the master will login to work to execute spark commands, it assumes that workers have the same path as itself**\n\n\t$ cd\n\t$ scp -r spark-0.7.2 dev@slave01:~\n\t$ scp -r spark-0.7.2 dev@slave02:~\n\nSet `SPARK_EXAMPLES_JAR`  on all slaves as section 5.3. There is no need to edit configuration files because they are copied from master, which are already well configured.\n\n##5.5 Start Spark cluster\nOn master\n\n\t$ cd ~/spark-0.7.2\n\t$ bin/start-all.sh\n\nCheck whether the processes have been started.\n\n\t$ jps\n\t11055 Jps\n\t2313 SecondaryNameNode\n\t2409 JobTracker\n\t2152 NameNode\n\t4822 Master\n\nLook at the master’s web UI (<http://localhost:8080> by default). You should see the new node listed there, along with its number of CPUs and memory (minus one gigabyte left for the OS).\n\n##5.6 run the SparkPi example in cluster mode\n\n\t$ cd ~/spark-0.7.2\n\t$ ./run spark.examples.SparkPi spark://master:7077\n\n(Optional)Run built-in examples, SparkLR and SparkKMeans.\n\t\n\t#Logistic Regression\n\t#./run spark.examples.SparkLR spark://master:7077\n\t#kmeans\n\t$ ./run spark.examples.SparkKMeans spark://master:7077 ./kmeans_data.txt 2 1\n\n##5.7 read files from HDFS and run WordCount\n\n\t$ cd ~/spark-0.7.2\n\t$ hadoop fs -put README.md .\n\t$ MASTER=spark://master:7077 ./spark-shell\n\tscala> val file = sc.textFile(\"hdfs://master:9000/user/dev/README.md\")\n\tscala> val count = file.flatMap(line => line.split(\" \")).map(word => (word, 1)).reduceByKey(_+_)\n\tscala> count.collect()\n\n##5.8 Stop Spark cluster\n\n\t$ cd ~/spark-0.7.2\n\t$ bin/stop-all.sh\n\n#References\n1. [Spark Standalone Mode](http://spark-project.org/docs/latest/spark-standalone.html)\n1. [Running A Spark Standalone Cluster](https://github.com/mesos/spark/wiki/Running-A-Spark-Standalone-Cluster)\n1. [Lightning-Fast WordCount using Spark Alongside Hadoop](http://sprism.blogspot.com/2012/11/lightning-fast-wordcount-using-spark.html)\n\nThe following posts are outdated.\n\n1. [Installing Spark on Fedora 18](http://chapeau.freevariable.com/2013/04/installing-spark-on-fedora-18.html)\n1. [Spark随谈（二）—— 安装攻略](http://rdc.taobao.com/team/jm/archives/1823)\n1. [Spark安装与学习](http://www.cnblogs.com/jerrylead/archive/2012/08/13/2636115.html)\n","slug":"2013-06-14-installing-spark-on-centos","published":1,"updated":"2016-08-18T09:21:04.000Z","photos":[],"link":"","_id":"cis07pf3b001d01pqbbvmrs7t","content":"<p><strong>Environment</strong>:CentOS 6.4, Hadoop 1.1.2, JDK 1.7, Spark 0.7.2, Scala 2.9.3</p>\n<p>After a few days hacking , I have found that installing a Spark cluster is exteremely easy :)</p>\n<p>#1. Install JDK 1.7<br>    yum search openjdk-devel<br>    sudo yum install java-1.7.0-openjdk-devel.x86_64<br>    /usr/sbin/alternatives –config java<br>    /usr/sbin/alternatives –config javac<br>    sudo vim /etc/profile</p>\n<pre><code># add the following lines at the end\nexport JAVA_HOME=/usr/lib/jvm/java-1.7.0-openjdk-1.7.0.19.x86_64\nexport JRE_HOME=$JAVA_HOME/jre\nexport PATH=$PATH:$JAVA_HOME/bin\nexport CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar\n# save and exit vim\n# make the bash profile take effect immediately\n$ source /etc/profile\n# test\n$ java -version\n</code></pre><p>#2. Install Scala 2.9.3<br>Spark 0.7.2 depends on Scala 2.9.3, So we must install Scala of version 2.9.3.</p>\n<p>Download <a href=\"http://www.scala-lang.org/downloads/distrib/files/scala-2.9.3.tgz\" target=\"_blank\" rel=\"external\">scala-2.9.3.tgz</a> and save it to home directory.</p>\n<pre><code>$ tar -zxf scala-2.9.3.tgz\n$ sudo mv scala-2.9.3 /usr/lib\n$ sudo vim /etc/profile\n# add the following lines at the end\nexport SCALA_HOME=/usr/lib/scala-2.9.3\nexport PATH=$PATH:$SCALA_HOME/bin\n# save and exit vim\n# make the bash profile take effect immediately\nsource /etc/profile\n# test\n$ scala -version\n</code></pre><p>#3. Download prebuilt packages<br>Download prebuilt packages, <a href=\"http://www.spark-project.org/download-spark-0.7.2-prebuilt-hadoop1\" target=\"_blank\" rel=\"external\">spark-0.7.2-prebuilt-hadoop1.tgz</a>. </p>\n<p>If you want to compile it from scratch, download the source package, but I don’t recommend this way, because in Chinese Mainland the GFW has blocked one of maven repositories, twitter4j.org, which makes the compilation an impossible mission unless you can conquer GFW.</p>\n<p>#4. Local Mode</p>\n<p>##4.1 Untar the tarball</p>\n<pre><code>$ tar -zxf spark-0.7.2-prebuilt-hadoop1.tgz\n</code></pre><p>##4.2 Set the SPARK_EXAMPLES_JAR environment variable<br>    $ vim ~/.bash_profile</p>\n<pre><code># add the following lines at the end\nexport SPARK_EXAMPLES_JAR=$HOME/spark-0.7.2/examples/target/scala-2.9.3/spark-examples_2.9.3-0.7.2.jar\n# save and exit vim\n# make the bash profile take effect immediately\n$ source /etc/profile\n</code></pre><p>This is the most important step that must be done , but unfortunately the official docs and most web blogs haven’t mentioned this. I found this step when I bumped into these posts, <a href=\"https://groups.google.com/forum/?fromgroups#!topic/spark-users/nQ6wB2lcFN8\" target=\"_blank\" rel=\"external\">Running SparkPi</a>, <a href=\"https://groups.google.com/forum/#!msg/spark-users/x5UczgI-Xm8/wzMm3Mb77-oJ\" target=\"_blank\" rel=\"external\">Null pointer exception when running ./run spark.examples.SparkPi local</a>.</p>\n<p>##4.3 (Optional)Set SPARK_HOME and add SPARK_HOME/bin to PATH</p>\n<pre><code>$ vim ~/.bash_profile\n# add the following lines at the end\nexport SPARK_HOME=$HOME/spark-0.7.2\nexport PATH=$PATH:$SPARK_HOME/bin\n# save and exit vim\n# make the bash profile take effect immediately\n$ source /etc/profile\n</code></pre><p>##4.4 Now you can run SparkPi.</p>\n<pre><code>$ cd ~/spark-0.7.2\n$ ./run spark.examples.SparkPi local \n</code></pre><p>#5. Cluster Mode</p>\n<a id=\"more\"></a>\n<p>##5.1 Install hadoop<br>Use VMware Workstation to create three CentOS virtual machines, which’s hostnames are master, slave01, slave02, setup password-less ssh to the slaves, install hadoop on the three machines and start up the hadoop cluster. For more details please read another blog of mine, <a href=\"http://www.yanjiuyanjiu.com/blog/20130612\" target=\"_blank\" rel=\"external\">在CentOS上安装Hadoop</a>.</p>\n<p>##5.2 Install JDK and Scala<br>Install JDK 1.7 and Scala 2.9.3 on the three machines, according to section 1 and section 2.</p>\n<p>##5.3 Install and configure Spark on master<br>Untar</p>\n<pre><code>$ tar -zxf spark-0.7.2-prebuilt-hadoop1.tgz\n</code></pre><p>Set the SPARK_EXAMPLES_JAR environment variable</p>\n<pre><code>$ vim ~/.bash_profile\n# add the following lines at the end\nexport SPARK_EXAMPLES_JAR=$HOME/spark-0.7.2/examples/target/scala-2.9.3/spark-examples_2.9.3-0.7.2.jar\n# save and exit vim\n# make the bash profile take effect immediately\n$ source /etc/profile\n</code></pre><p>Set <code>SCALA_HOME</code> in <code>conf/spark-env.sh</code></p>\n<pre><code>$ cd ~/spark-0.7.2/conf\n$ mv spark-env.sh.template spark-env.sh\n$ vim spark-env.sh\n# add the following line\nexport SCALA_HOME=/usr/lib/scala-2.9.3\n# save and exit\n</code></pre><p>In<code>conf/slaves</code>, add hostnames of Spark workers, one per line.</p>\n<pre><code>$ vim slaves\nslave01\nslave02\n# save and exit\n</code></pre><p>(Optional)Set SPARK_HOME and add SPARK_HOME/bin to PATH</p>\n<pre><code>$ vim ~/.bash_profile\n# add the following lines at the end\nexport SPARK_HOME=$HOME/spark-0.7.2\nexport PATH=$PATH:$SPARK_HOME/bin\n# save and exit vim\n# make the bash profile take effect immediately\n$ source /etc/profile\n</code></pre><p>##5.4 Install and configure Spark on workers<br>Copy the spark directory to all slaves. <strong>Remark，the spark directories must locat at the the same path on all machines，because the master will login to work to execute spark commands, it assumes that workers have the same path as itself</strong></p>\n<pre><code>$ cd\n$ scp -r spark-0.7.2 dev@slave01:~\n$ scp -r spark-0.7.2 dev@slave02:~\n</code></pre><p>Set <code>SPARK_EXAMPLES_JAR</code>  on all slaves as section 5.3. There is no need to edit configuration files because they are copied from master, which are already well configured.</p>\n<p>##5.5 Start Spark cluster<br>On master</p>\n<pre><code>$ cd ~/spark-0.7.2\n$ bin/start-all.sh\n</code></pre><p>Check whether the processes have been started.</p>\n<pre><code>$ jps\n11055 Jps\n2313 SecondaryNameNode\n2409 JobTracker\n2152 NameNode\n4822 Master\n</code></pre><p>Look at the master’s web UI (<a href=\"http://localhost:8080\" target=\"_blank\" rel=\"external\">http://localhost:8080</a> by default). You should see the new node listed there, along with its number of CPUs and memory (minus one gigabyte left for the OS).</p>\n<p>##5.6 run the SparkPi example in cluster mode</p>\n<pre><code>$ cd ~/spark-0.7.2\n$ ./run spark.examples.SparkPi spark://master:7077\n</code></pre><p>(Optional)Run built-in examples, SparkLR and SparkKMeans.</p>\n<pre><code>#Logistic Regression\n#./run spark.examples.SparkLR spark://master:7077\n#kmeans\n$ ./run spark.examples.SparkKMeans spark://master:7077 ./kmeans_data.txt 2 1\n</code></pre><p>##5.7 read files from HDFS and run WordCount</p>\n<pre><code>$ cd ~/spark-0.7.2\n$ hadoop fs -put README.md .\n$ MASTER=spark://master:7077 ./spark-shell\nscala&gt; val file = sc.textFile(&quot;hdfs://master:9000/user/dev/README.md&quot;)\nscala&gt; val count = file.flatMap(line =&gt; line.split(&quot; &quot;)).map(word =&gt; (word, 1)).reduceByKey(_+_)\nscala&gt; count.collect()\n</code></pre><p>##5.8 Stop Spark cluster</p>\n<pre><code>$ cd ~/spark-0.7.2\n$ bin/stop-all.sh\n</code></pre><p>#References</p>\n<ol>\n<li><a href=\"http://spark-project.org/docs/latest/spark-standalone.html\" target=\"_blank\" rel=\"external\">Spark Standalone Mode</a></li>\n<li><a href=\"https://github.com/mesos/spark/wiki/Running-A-Spark-Standalone-Cluster\" target=\"_blank\" rel=\"external\">Running A Spark Standalone Cluster</a></li>\n<li><a href=\"http://sprism.blogspot.com/2012/11/lightning-fast-wordcount-using-spark.html\" target=\"_blank\" rel=\"external\">Lightning-Fast WordCount using Spark Alongside Hadoop</a></li>\n</ol>\n<p>The following posts are outdated.</p>\n<ol>\n<li><a href=\"http://chapeau.freevariable.com/2013/04/installing-spark-on-fedora-18.html\" target=\"_blank\" rel=\"external\">Installing Spark on Fedora 18</a></li>\n<li><a href=\"http://rdc.taobao.com/team/jm/archives/1823\" target=\"_blank\" rel=\"external\">Spark随谈（二）—— 安装攻略</a></li>\n<li><a href=\"http://www.cnblogs.com/jerrylead/archive/2012/08/13/2636115.html\" target=\"_blank\" rel=\"external\">Spark安装与学习</a></li>\n</ol>\n","excerpt":"<p><strong>Environment</strong>:CentOS 6.4, Hadoop 1.1.2, JDK 1.7, Spark 0.7.2, Scala 2.9.3</p>\n<p>After a few days hacking , I have found that installing a Spark cluster is exteremely easy :)</p>\n<p>#1. Install JDK 1.7<br>    yum search openjdk-devel<br>    sudo yum install java-1.7.0-openjdk-devel.x86_64<br>    /usr/sbin/alternatives –config java<br>    /usr/sbin/alternatives –config javac<br>    sudo vim /etc/profile</p>\n<pre><code># add the following lines at the end\nexport JAVA_HOME=/usr/lib/jvm/java-1.7.0-openjdk-1.7.0.19.x86_64\nexport JRE_HOME=$JAVA_HOME/jre\nexport PATH=$PATH:$JAVA_HOME/bin\nexport CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar\n# save and exit vim\n# make the bash profile take effect immediately\n$ source /etc/profile\n# test\n$ java -version\n</code></pre><p>#2. Install Scala 2.9.3<br>Spark 0.7.2 depends on Scala 2.9.3, So we must install Scala of version 2.9.3.</p>\n<p>Download <a href=\"http://www.scala-lang.org/downloads/distrib/files/scala-2.9.3.tgz\">scala-2.9.3.tgz</a> and save it to home directory.</p>\n<pre><code>$ tar -zxf scala-2.9.3.tgz\n$ sudo mv scala-2.9.3 /usr/lib\n$ sudo vim /etc/profile\n# add the following lines at the end\nexport SCALA_HOME=/usr/lib/scala-2.9.3\nexport PATH=$PATH:$SCALA_HOME/bin\n# save and exit vim\n# make the bash profile take effect immediately\nsource /etc/profile\n# test\n$ scala -version\n</code></pre><p>#3. Download prebuilt packages<br>Download prebuilt packages, <a href=\"http://www.spark-project.org/download-spark-0.7.2-prebuilt-hadoop1\">spark-0.7.2-prebuilt-hadoop1.tgz</a>. </p>\n<p>If you want to compile it from scratch, download the source package, but I don’t recommend this way, because in Chinese Mainland the GFW has blocked one of maven repositories, twitter4j.org, which makes the compilation an impossible mission unless you can conquer GFW.</p>\n<p>#4. Local Mode</p>\n<p>##4.1 Untar the tarball</p>\n<pre><code>$ tar -zxf spark-0.7.2-prebuilt-hadoop1.tgz\n</code></pre><p>##4.2 Set the SPARK_EXAMPLES_JAR environment variable<br>    $ vim ~/.bash_profile</p>\n<pre><code># add the following lines at the end\nexport SPARK_EXAMPLES_JAR=$HOME/spark-0.7.2/examples/target/scala-2.9.3/spark-examples_2.9.3-0.7.2.jar\n# save and exit vim\n# make the bash profile take effect immediately\n$ source /etc/profile\n</code></pre><p>This is the most important step that must be done , but unfortunately the official docs and most web blogs haven’t mentioned this. I found this step when I bumped into these posts, <a href=\"https://groups.google.com/forum/?fromgroups#!topic/spark-users/nQ6wB2lcFN8\">Running SparkPi</a>, <a href=\"https://groups.google.com/forum/#!msg/spark-users/x5UczgI-Xm8/wzMm3Mb77-oJ\">Null pointer exception when running ./run spark.examples.SparkPi local</a>.</p>\n<p>##4.3 (Optional)Set SPARK_HOME and add SPARK_HOME/bin to PATH</p>\n<pre><code>$ vim ~/.bash_profile\n# add the following lines at the end\nexport SPARK_HOME=$HOME/spark-0.7.2\nexport PATH=$PATH:$SPARK_HOME/bin\n# save and exit vim\n# make the bash profile take effect immediately\n$ source /etc/profile\n</code></pre><p>##4.4 Now you can run SparkPi.</p>\n<pre><code>$ cd ~/spark-0.7.2\n$ ./run spark.examples.SparkPi local \n</code></pre><p>#5. Cluster Mode</p>","more":"<p>##5.1 Install hadoop<br>Use VMware Workstation to create three CentOS virtual machines, which’s hostnames are master, slave01, slave02, setup password-less ssh to the slaves, install hadoop on the three machines and start up the hadoop cluster. For more details please read another blog of mine, <a href=\"http://www.yanjiuyanjiu.com/blog/20130612\">在CentOS上安装Hadoop</a>.</p>\n<p>##5.2 Install JDK and Scala<br>Install JDK 1.7 and Scala 2.9.3 on the three machines, according to section 1 and section 2.</p>\n<p>##5.3 Install and configure Spark on master<br>Untar</p>\n<pre><code>$ tar -zxf spark-0.7.2-prebuilt-hadoop1.tgz\n</code></pre><p>Set the SPARK_EXAMPLES_JAR environment variable</p>\n<pre><code>$ vim ~/.bash_profile\n# add the following lines at the end\nexport SPARK_EXAMPLES_JAR=$HOME/spark-0.7.2/examples/target/scala-2.9.3/spark-examples_2.9.3-0.7.2.jar\n# save and exit vim\n# make the bash profile take effect immediately\n$ source /etc/profile\n</code></pre><p>Set <code>SCALA_HOME</code> in <code>conf/spark-env.sh</code></p>\n<pre><code>$ cd ~/spark-0.7.2/conf\n$ mv spark-env.sh.template spark-env.sh\n$ vim spark-env.sh\n# add the following line\nexport SCALA_HOME=/usr/lib/scala-2.9.3\n# save and exit\n</code></pre><p>In<code>conf/slaves</code>, add hostnames of Spark workers, one per line.</p>\n<pre><code>$ vim slaves\nslave01\nslave02\n# save and exit\n</code></pre><p>(Optional)Set SPARK_HOME and add SPARK_HOME/bin to PATH</p>\n<pre><code>$ vim ~/.bash_profile\n# add the following lines at the end\nexport SPARK_HOME=$HOME/spark-0.7.2\nexport PATH=$PATH:$SPARK_HOME/bin\n# save and exit vim\n# make the bash profile take effect immediately\n$ source /etc/profile\n</code></pre><p>##5.4 Install and configure Spark on workers<br>Copy the spark directory to all slaves. <strong>Remark，the spark directories must locat at the the same path on all machines，because the master will login to work to execute spark commands, it assumes that workers have the same path as itself</strong></p>\n<pre><code>$ cd\n$ scp -r spark-0.7.2 dev@slave01:~\n$ scp -r spark-0.7.2 dev@slave02:~\n</code></pre><p>Set <code>SPARK_EXAMPLES_JAR</code>  on all slaves as section 5.3. There is no need to edit configuration files because they are copied from master, which are already well configured.</p>\n<p>##5.5 Start Spark cluster<br>On master</p>\n<pre><code>$ cd ~/spark-0.7.2\n$ bin/start-all.sh\n</code></pre><p>Check whether the processes have been started.</p>\n<pre><code>$ jps\n11055 Jps\n2313 SecondaryNameNode\n2409 JobTracker\n2152 NameNode\n4822 Master\n</code></pre><p>Look at the master’s web UI (<a href=\"http://localhost:8080\">http://localhost:8080</a> by default). You should see the new node listed there, along with its number of CPUs and memory (minus one gigabyte left for the OS).</p>\n<p>##5.6 run the SparkPi example in cluster mode</p>\n<pre><code>$ cd ~/spark-0.7.2\n$ ./run spark.examples.SparkPi spark://master:7077\n</code></pre><p>(Optional)Run built-in examples, SparkLR and SparkKMeans.</p>\n<pre><code>#Logistic Regression\n#./run spark.examples.SparkLR spark://master:7077\n#kmeans\n$ ./run spark.examples.SparkKMeans spark://master:7077 ./kmeans_data.txt 2 1\n</code></pre><p>##5.7 read files from HDFS and run WordCount</p>\n<pre><code>$ cd ~/spark-0.7.2\n$ hadoop fs -put README.md .\n$ MASTER=spark://master:7077 ./spark-shell\nscala&gt; val file = sc.textFile(&quot;hdfs://master:9000/user/dev/README.md&quot;)\nscala&gt; val count = file.flatMap(line =&gt; line.split(&quot; &quot;)).map(word =&gt; (word, 1)).reduceByKey(_+_)\nscala&gt; count.collect()\n</code></pre><p>##5.8 Stop Spark cluster</p>\n<pre><code>$ cd ~/spark-0.7.2\n$ bin/stop-all.sh\n</code></pre><p>#References</p>\n<ol>\n<li><a href=\"http://spark-project.org/docs/latest/spark-standalone.html\">Spark Standalone Mode</a></li>\n<li><a href=\"https://github.com/mesos/spark/wiki/Running-A-Spark-Standalone-Cluster\">Running A Spark Standalone Cluster</a></li>\n<li><a href=\"http://sprism.blogspot.com/2012/11/lightning-fast-wordcount-using-spark.html\">Lightning-Fast WordCount using Spark Alongside Hadoop</a></li>\n</ol>\n<p>The following posts are outdated.</p>\n<ol>\n<li><a href=\"http://chapeau.freevariable.com/2013/04/installing-spark-on-fedora-18.html\">Installing Spark on Fedora 18</a></li>\n<li><a href=\"http://rdc.taobao.com/team/jm/archives/1823\">Spark随谈（二）—— 安装攻略</a></li>\n<li><a href=\"http://www.cnblogs.com/jerrylead/archive/2012/08/13/2636115.html\">Spark安装与学习</a></li>\n</ol>"},{"layout":"post","title":"安装Spark集群(在CentOS上)","date":"2013-06-17T22:16:00.000Z","comments":1,"_content":"**环境**:CentOS 6.4, Hadoop 1.1.2, JDK 1.7, Spark 0.7.2, Scala 2.9.3\n\n折腾了几天，终于把Spark 集群安装成功了，其实比hadoop要简单很多，由于网上搜索到的博客大部分都还停留在需要依赖mesos的版本，走了不少弯路。\n\n\n#1. 安装 JDK 1.7\n\tyum search openjdk-devel\n\tsudo yum install java-1.7.0-openjdk-devel.x86_64\n\t/usr/sbin/alternatives --config java\n\t/usr/sbin/alternatives --config javac\n\tsudo vim /etc/profile\n\t# add the following lines at the end\n\texport JAVA_HOME=/usr/lib/jvm/java-1.7.0-openjdk-1.7.0.19.x86_64\n\texport JRE_HOME=$JAVA_HOME/jre\n\texport PATH=$PATH:$JAVA_HOME/bin\n\texport CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar\n\t# save and exit vim\n\t# make the bash profile take effect immediately\n\t$ source /etc/profile\n\t# test\n\t$ java -version\n\n参考我的另一篇博客，[安装和配置CentOS服务器的详细步骤](http://www.yanjiuyanjiu.com/blog/20120423/)。\n\n#2. 安装 Scala 2.9.3\nSpark 0.7.2 依赖 Scala 2.9.3, 我们必须要安装Scala 2.9.3.\n\n下载 [scala-2.9.3.tgz](http://www.scala-lang.org/downloads/distrib/files/scala-2.9.3.tgz) 并 保存到home目录.\n\n\t$ tar -zxf scala-2.9.3.tgz\n\t$ sudo mv scala-2.9.3 /usr/lib\n\t$ sudo vim /etc/profile\n\t# add the following lines at the end\n\texport SCALA_HOME=/usr/lib/scala-2.9.3\n\texport PATH=$PATH:$SCALA_HOME/bin\n\t# save and exit vim\n\t#make the bash profile take effect immediately\n\tsource /etc/profile\n\t# test\n\t$ scala -version\n\n#3. 下载预编译好的Spark\n下载预编译好的Spark, [spark-0.7.2-prebuilt-hadoop1.tgz](http://www.spark-project.org/download-spark-0.7.2-prebuilt-hadoop1). \n\n如果你想从零开始编译，则下载源码包，但是我不建议你这么做，因为有一个Maven仓库，twitter4j.org, 被墙了，导致编译时需要翻墙，非常麻烦。如果你有DIY精神，并能顺利翻墙，则可以试试这种方式。\n\n#4. 本地模式\n\n##4.1 解压\n\n\t$ tar -zxf spark-0.7.2-prebuilt-hadoop1.tgz\n\t\n##4.2 设置SPARK\\_EXAMPLES\\_JAR 环境变量\n\n\t$ vim ~/.bash_profile\n\t# add the following lines at the end\n\texport SPARK_EXAMPLES_JAR=$HOME/spark-0.7.2/examples/target/scala-2.9.3/spark-examples_2.9.3-0.7.2.jar\n\t# save and exit vim\n\t#make the bash profile take effect immediately\n\t$ source /etc/profile\n\n这一步其实最关键，很不幸的是，官方文档和网上的博客，都没有提及这一点。我是偶然看到了这两篇帖子，[Running SparkPi](https://groups.google.com/forum/?fromgroups#!topic/spark-users/nQ6wB2lcFN8), [Null pointer exception when running ./run spark.examples.SparkPi local](https://groups.google.com/forum/#!msg/spark-users/x5UczgI-Xm8/wzMm3Mb77-oJ)，才补上了这一步，之前死活都无法运行SparkPi。\n\n##4.3 （可选）设置 SPARK\\_HOME环境变量，并将SPARK\\_HOME/bin加入PATH\n\t$ vim ~/.bash_profile\n\t# add the following lines at the end\n\texport SPARK_HOME=$HOME/spark-0.7.2\n\texport PATH=$PATH:$SPARK_HOME/bin\n\t# save and exit vim\n\t#make the bash profile take effect immediately\n\t$ source /etc/profile\n\n##4.4 现在可以运行SparkPi了\n\n\t$ cd ~/spark-0.7.2\n\t$ ./run spark.examples.SparkPi local \n\n#5. 集群模式\n\n<!-- more -->\n\n##5.1 安装Hadoop\n用VMware Workstation 创建三台CentOS 虚拟机，hostname分别设置为 master, slave01, slave02，设置SSH无密码登陆，安装hadoop，然后启动hadoop集群。参考我的这篇博客，[在CentOS上安装Hadoop](http://www.yanjiuyanjiu.com/blog/20130612). \n\n##5.2 Scala\n在三台机器上都要安装 Scala 2.9.3 , 按照第2节的步骤。JDK在安装Hadoop时已经安装了。\n\n##5.3 在master上安装并配置Spark\n解压\n\n\t$ tar -zxf spark-0.7.2-prebuilt-hadoop1.tgz\n\n设置SPARK\\_EXAMPLES\\_JAR 环境变量\n\n\t$ vim ~/.bash_profile\n\t# add the following lines at the end\n\texport SPARK_EXAMPLES_JAR=$HOME/spark-0.7.2/examples/target/scala-2.9.3/spark-examples_2.9.3-0.7.2.jar\n\t# save and exit vim\n\t#make the bash profile take effect immediately\n\t$ source /etc/profile\n\n在 in `conf/spark-env.sh` 中设置`SCALA_HOME`\n\n\t$ cd ~/spark-0.7.2/conf\n\t$ mv spark-env.sh.template spark-env.sh\n\t$ vim spark-env.sh\n\t# add the following line\n\texport SCALA_HOME=/usr/lib/scala-2.9.3\n\t# save and exit\n\n在`conf/slaves`, 添加Spark worker的hostname, 一行一个。\n\n\t$ vim slaves\n\tslave01\n\tslave02\n\t# save and exit\n\n（可选）设置 SPARK\\_HOME环境变量，并将SPARK\\_HOME/bin加入PATH\n\n\t$ vim ~/.bash_profile\n\t# add the following lines at the end\n\texport SPARK_HOME=$HOME/spark-0.7.2\n\texport PATH=$PATH:$SPARK_HOME/bin\n\t# save and exit vim\n\t#make the bash profile take effect immediately\n\t$ source /etc/profile\n\n##5.4 在所有worker上安装并配置Spark\n既然master上的这个文件件已经配置好了，把它拷贝到所有的worker。**注意，三台机器spark所在目录必须一致，因为master会登陆到worker上执行命令，master认为worker的spark路径与自己一样。**\n\t\n\t$ cd\n\t$ scp -r spark-0.7.2 dev@slave01:~\n\t$ scp -r spark-0.7.2 dev@slave02:~\n\n按照第5.3节设置`SPARK_EXAMPLES_JAR`环境变量，配置文件不用配置了，因为是直接从master复制过来的，已经配置好了。\n\n\n##5.5 启动 Spark 集群\n在master上执行\n\n\t$ cd ~/spark-0.7.2\n\t$ bin/start-all.sh\n\n检测进程是否启动\n\n\t$ jps\n\t11055 Jps\n\t2313 SecondaryNameNode\n\t2409 JobTracker\n\t2152 NameNode\n\t4822 Master\n\n浏览master的web UI(默认<http://localhost:8080>). 这是你应该可以看到所有的word节点，以及他们的CPU个数和内存等信息。\n##5.6 运行SparkPi例子\n\n\t$ cd ~/spark-0.7.2\n\t$ ./run spark.examples.SparkPi spark://master:7077\n\n（可选）运行自带的例子，SparkLR 和 SparkKMeans.\n\t\n\t#Logistic Regression\n\t#./run spark.examples.SparkLR spark://master:7077\n\t#kmeans\n\t$ ./run spark.examples.SparkKMeans spark://master:7077 ./kmeans_data.txt 2 1\n\t\n\n##5.7 从HDFS读取文件并运行WordCount\n\n\t$ cd ~/spark-0.7.2\n\t$ hadoop fs -put README.md .\n\t$ MASTER=spark://master:7077 ./spark-shell\n\tscala> val file = sc.textFile(\"hdfs://master:9000/user/dev/README.md\")\n\tscala> val count = file.flatMap(line => line.split(\" \")).map(word => (word, 1)).reduceByKey(_+_)\n\tscala> count.collect()\n\n##5.8 停止 Spark 集群\n\n\t$ cd ~/spark-0.7.2\n\t$ bin/stop-all.sh\n\n#参考资料\n1. [Spark Standalone Mode](http://spark-project.org/docs/latest/spark-standalone.html)\n1. [Running A Spark Standalone Cluster](https://github.com/mesos/spark/wiki/Running-A-Spark-Standalone-Cluster)\n1. [Lightning-Fast WordCount using Spark Alongside Hadoop](http://sprism.blogspot.com/2012/11/lightning-fast-wordcount-using-spark.html)\n\n以下博客都已经过时了：\n\n1. [Installing Spark on Fedora 18](http://chapeau.freevariable.com/2013/04/installing-spark-on-fedora-18.html)\n1. [Spark随谈（二）—— 安装攻略](http://rdc.taobao.com/team/jm/archives/1823)\n1. [Spark安装与学习](http://www.cnblogs.com/jerrylead/archive/2012/08/13/2636115.html)\n","source":"_posts/2013-06-17-installing-spark-on-centos-cn.md","raw":"---\nlayout: post\ntitle: \"安装Spark集群(在CentOS上)\"\ndate: 2013-06-17 22:16\ncomments: true\ncategories: Spark\n---\n**环境**:CentOS 6.4, Hadoop 1.1.2, JDK 1.7, Spark 0.7.2, Scala 2.9.3\n\n折腾了几天，终于把Spark 集群安装成功了，其实比hadoop要简单很多，由于网上搜索到的博客大部分都还停留在需要依赖mesos的版本，走了不少弯路。\n\n\n#1. 安装 JDK 1.7\n\tyum search openjdk-devel\n\tsudo yum install java-1.7.0-openjdk-devel.x86_64\n\t/usr/sbin/alternatives --config java\n\t/usr/sbin/alternatives --config javac\n\tsudo vim /etc/profile\n\t# add the following lines at the end\n\texport JAVA_HOME=/usr/lib/jvm/java-1.7.0-openjdk-1.7.0.19.x86_64\n\texport JRE_HOME=$JAVA_HOME/jre\n\texport PATH=$PATH:$JAVA_HOME/bin\n\texport CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar\n\t# save and exit vim\n\t# make the bash profile take effect immediately\n\t$ source /etc/profile\n\t# test\n\t$ java -version\n\n参考我的另一篇博客，[安装和配置CentOS服务器的详细步骤](http://www.yanjiuyanjiu.com/blog/20120423/)。\n\n#2. 安装 Scala 2.9.3\nSpark 0.7.2 依赖 Scala 2.9.3, 我们必须要安装Scala 2.9.3.\n\n下载 [scala-2.9.3.tgz](http://www.scala-lang.org/downloads/distrib/files/scala-2.9.3.tgz) 并 保存到home目录.\n\n\t$ tar -zxf scala-2.9.3.tgz\n\t$ sudo mv scala-2.9.3 /usr/lib\n\t$ sudo vim /etc/profile\n\t# add the following lines at the end\n\texport SCALA_HOME=/usr/lib/scala-2.9.3\n\texport PATH=$PATH:$SCALA_HOME/bin\n\t# save and exit vim\n\t#make the bash profile take effect immediately\n\tsource /etc/profile\n\t# test\n\t$ scala -version\n\n#3. 下载预编译好的Spark\n下载预编译好的Spark, [spark-0.7.2-prebuilt-hadoop1.tgz](http://www.spark-project.org/download-spark-0.7.2-prebuilt-hadoop1). \n\n如果你想从零开始编译，则下载源码包，但是我不建议你这么做，因为有一个Maven仓库，twitter4j.org, 被墙了，导致编译时需要翻墙，非常麻烦。如果你有DIY精神，并能顺利翻墙，则可以试试这种方式。\n\n#4. 本地模式\n\n##4.1 解压\n\n\t$ tar -zxf spark-0.7.2-prebuilt-hadoop1.tgz\n\t\n##4.2 设置SPARK\\_EXAMPLES\\_JAR 环境变量\n\n\t$ vim ~/.bash_profile\n\t# add the following lines at the end\n\texport SPARK_EXAMPLES_JAR=$HOME/spark-0.7.2/examples/target/scala-2.9.3/spark-examples_2.9.3-0.7.2.jar\n\t# save and exit vim\n\t#make the bash profile take effect immediately\n\t$ source /etc/profile\n\n这一步其实最关键，很不幸的是，官方文档和网上的博客，都没有提及这一点。我是偶然看到了这两篇帖子，[Running SparkPi](https://groups.google.com/forum/?fromgroups#!topic/spark-users/nQ6wB2lcFN8), [Null pointer exception when running ./run spark.examples.SparkPi local](https://groups.google.com/forum/#!msg/spark-users/x5UczgI-Xm8/wzMm3Mb77-oJ)，才补上了这一步，之前死活都无法运行SparkPi。\n\n##4.3 （可选）设置 SPARK\\_HOME环境变量，并将SPARK\\_HOME/bin加入PATH\n\t$ vim ~/.bash_profile\n\t# add the following lines at the end\n\texport SPARK_HOME=$HOME/spark-0.7.2\n\texport PATH=$PATH:$SPARK_HOME/bin\n\t# save and exit vim\n\t#make the bash profile take effect immediately\n\t$ source /etc/profile\n\n##4.4 现在可以运行SparkPi了\n\n\t$ cd ~/spark-0.7.2\n\t$ ./run spark.examples.SparkPi local \n\n#5. 集群模式\n\n<!-- more -->\n\n##5.1 安装Hadoop\n用VMware Workstation 创建三台CentOS 虚拟机，hostname分别设置为 master, slave01, slave02，设置SSH无密码登陆，安装hadoop，然后启动hadoop集群。参考我的这篇博客，[在CentOS上安装Hadoop](http://www.yanjiuyanjiu.com/blog/20130612). \n\n##5.2 Scala\n在三台机器上都要安装 Scala 2.9.3 , 按照第2节的步骤。JDK在安装Hadoop时已经安装了。\n\n##5.3 在master上安装并配置Spark\n解压\n\n\t$ tar -zxf spark-0.7.2-prebuilt-hadoop1.tgz\n\n设置SPARK\\_EXAMPLES\\_JAR 环境变量\n\n\t$ vim ~/.bash_profile\n\t# add the following lines at the end\n\texport SPARK_EXAMPLES_JAR=$HOME/spark-0.7.2/examples/target/scala-2.9.3/spark-examples_2.9.3-0.7.2.jar\n\t# save and exit vim\n\t#make the bash profile take effect immediately\n\t$ source /etc/profile\n\n在 in `conf/spark-env.sh` 中设置`SCALA_HOME`\n\n\t$ cd ~/spark-0.7.2/conf\n\t$ mv spark-env.sh.template spark-env.sh\n\t$ vim spark-env.sh\n\t# add the following line\n\texport SCALA_HOME=/usr/lib/scala-2.9.3\n\t# save and exit\n\n在`conf/slaves`, 添加Spark worker的hostname, 一行一个。\n\n\t$ vim slaves\n\tslave01\n\tslave02\n\t# save and exit\n\n（可选）设置 SPARK\\_HOME环境变量，并将SPARK\\_HOME/bin加入PATH\n\n\t$ vim ~/.bash_profile\n\t# add the following lines at the end\n\texport SPARK_HOME=$HOME/spark-0.7.2\n\texport PATH=$PATH:$SPARK_HOME/bin\n\t# save and exit vim\n\t#make the bash profile take effect immediately\n\t$ source /etc/profile\n\n##5.4 在所有worker上安装并配置Spark\n既然master上的这个文件件已经配置好了，把它拷贝到所有的worker。**注意，三台机器spark所在目录必须一致，因为master会登陆到worker上执行命令，master认为worker的spark路径与自己一样。**\n\t\n\t$ cd\n\t$ scp -r spark-0.7.2 dev@slave01:~\n\t$ scp -r spark-0.7.2 dev@slave02:~\n\n按照第5.3节设置`SPARK_EXAMPLES_JAR`环境变量，配置文件不用配置了，因为是直接从master复制过来的，已经配置好了。\n\n\n##5.5 启动 Spark 集群\n在master上执行\n\n\t$ cd ~/spark-0.7.2\n\t$ bin/start-all.sh\n\n检测进程是否启动\n\n\t$ jps\n\t11055 Jps\n\t2313 SecondaryNameNode\n\t2409 JobTracker\n\t2152 NameNode\n\t4822 Master\n\n浏览master的web UI(默认<http://localhost:8080>). 这是你应该可以看到所有的word节点，以及他们的CPU个数和内存等信息。\n##5.6 运行SparkPi例子\n\n\t$ cd ~/spark-0.7.2\n\t$ ./run spark.examples.SparkPi spark://master:7077\n\n（可选）运行自带的例子，SparkLR 和 SparkKMeans.\n\t\n\t#Logistic Regression\n\t#./run spark.examples.SparkLR spark://master:7077\n\t#kmeans\n\t$ ./run spark.examples.SparkKMeans spark://master:7077 ./kmeans_data.txt 2 1\n\t\n\n##5.7 从HDFS读取文件并运行WordCount\n\n\t$ cd ~/spark-0.7.2\n\t$ hadoop fs -put README.md .\n\t$ MASTER=spark://master:7077 ./spark-shell\n\tscala> val file = sc.textFile(\"hdfs://master:9000/user/dev/README.md\")\n\tscala> val count = file.flatMap(line => line.split(\" \")).map(word => (word, 1)).reduceByKey(_+_)\n\tscala> count.collect()\n\n##5.8 停止 Spark 集群\n\n\t$ cd ~/spark-0.7.2\n\t$ bin/stop-all.sh\n\n#参考资料\n1. [Spark Standalone Mode](http://spark-project.org/docs/latest/spark-standalone.html)\n1. [Running A Spark Standalone Cluster](https://github.com/mesos/spark/wiki/Running-A-Spark-Standalone-Cluster)\n1. [Lightning-Fast WordCount using Spark Alongside Hadoop](http://sprism.blogspot.com/2012/11/lightning-fast-wordcount-using-spark.html)\n\n以下博客都已经过时了：\n\n1. [Installing Spark on Fedora 18](http://chapeau.freevariable.com/2013/04/installing-spark-on-fedora-18.html)\n1. [Spark随谈（二）—— 安装攻略](http://rdc.taobao.com/team/jm/archives/1823)\n1. [Spark安装与学习](http://www.cnblogs.com/jerrylead/archive/2012/08/13/2636115.html)\n","slug":"2013-06-17-installing-spark-on-centos-cn","published":1,"updated":"2016-08-18T09:21:04.000Z","photos":[],"link":"","_id":"cis07pf3d001f01pqvhet8up1","content":"<p><strong>环境</strong>:CentOS 6.4, Hadoop 1.1.2, JDK 1.7, Spark 0.7.2, Scala 2.9.3</p>\n<p>折腾了几天，终于把Spark 集群安装成功了，其实比hadoop要简单很多，由于网上搜索到的博客大部分都还停留在需要依赖mesos的版本，走了不少弯路。</p>\n<p>#1. 安装 JDK 1.7<br>    yum search openjdk-devel<br>    sudo yum install java-1.7.0-openjdk-devel.x86_64<br>    /usr/sbin/alternatives –config java<br>    /usr/sbin/alternatives –config javac<br>    sudo vim /etc/profile</p>\n<pre><code># add the following lines at the end\nexport JAVA_HOME=/usr/lib/jvm/java-1.7.0-openjdk-1.7.0.19.x86_64\nexport JRE_HOME=$JAVA_HOME/jre\nexport PATH=$PATH:$JAVA_HOME/bin\nexport CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar\n# save and exit vim\n# make the bash profile take effect immediately\n$ source /etc/profile\n# test\n$ java -version\n</code></pre><p>参考我的另一篇博客，<a href=\"http://www.yanjiuyanjiu.com/blog/20120423/\" target=\"_blank\" rel=\"external\">安装和配置CentOS服务器的详细步骤</a>。</p>\n<p>#2. 安装 Scala 2.9.3<br>Spark 0.7.2 依赖 Scala 2.9.3, 我们必须要安装Scala 2.9.3.</p>\n<p>下载 <a href=\"http://www.scala-lang.org/downloads/distrib/files/scala-2.9.3.tgz\" target=\"_blank\" rel=\"external\">scala-2.9.3.tgz</a> 并 保存到home目录.</p>\n<pre><code>$ tar -zxf scala-2.9.3.tgz\n$ sudo mv scala-2.9.3 /usr/lib\n$ sudo vim /etc/profile\n# add the following lines at the end\nexport SCALA_HOME=/usr/lib/scala-2.9.3\nexport PATH=$PATH:$SCALA_HOME/bin\n# save and exit vim\n#make the bash profile take effect immediately\nsource /etc/profile\n# test\n$ scala -version\n</code></pre><p>#3. 下载预编译好的Spark<br>下载预编译好的Spark, <a href=\"http://www.spark-project.org/download-spark-0.7.2-prebuilt-hadoop1\" target=\"_blank\" rel=\"external\">spark-0.7.2-prebuilt-hadoop1.tgz</a>. </p>\n<p>如果你想从零开始编译，则下载源码包，但是我不建议你这么做，因为有一个Maven仓库，twitter4j.org, 被墙了，导致编译时需要翻墙，非常麻烦。如果你有DIY精神，并能顺利翻墙，则可以试试这种方式。</p>\n<p>#4. 本地模式</p>\n<p>##4.1 解压</p>\n<pre><code>$ tar -zxf spark-0.7.2-prebuilt-hadoop1.tgz\n</code></pre><p>##4.2 设置SPARK_EXAMPLES_JAR 环境变量</p>\n<pre><code>$ vim ~/.bash_profile\n# add the following lines at the end\nexport SPARK_EXAMPLES_JAR=$HOME/spark-0.7.2/examples/target/scala-2.9.3/spark-examples_2.9.3-0.7.2.jar\n# save and exit vim\n#make the bash profile take effect immediately\n$ source /etc/profile\n</code></pre><p>这一步其实最关键，很不幸的是，官方文档和网上的博客，都没有提及这一点。我是偶然看到了这两篇帖子，<a href=\"https://groups.google.com/forum/?fromgroups#!topic/spark-users/nQ6wB2lcFN8\" target=\"_blank\" rel=\"external\">Running SparkPi</a>, <a href=\"https://groups.google.com/forum/#!msg/spark-users/x5UczgI-Xm8/wzMm3Mb77-oJ\" target=\"_blank\" rel=\"external\">Null pointer exception when running ./run spark.examples.SparkPi local</a>，才补上了这一步，之前死活都无法运行SparkPi。</p>\n<p>##4.3 （可选）设置 SPARK_HOME环境变量，并将SPARK_HOME/bin加入PATH<br>    $ vim ~/.bash_profile</p>\n<pre><code># add the following lines at the end\nexport SPARK_HOME=$HOME/spark-0.7.2\nexport PATH=$PATH:$SPARK_HOME/bin\n# save and exit vim\n#make the bash profile take effect immediately\n$ source /etc/profile\n</code></pre><p>##4.4 现在可以运行SparkPi了</p>\n<pre><code>$ cd ~/spark-0.7.2\n$ ./run spark.examples.SparkPi local \n</code></pre><p>#5. 集群模式</p>\n<a id=\"more\"></a>\n<p>##5.1 安装Hadoop<br>用VMware Workstation 创建三台CentOS 虚拟机，hostname分别设置为 master, slave01, slave02，设置SSH无密码登陆，安装hadoop，然后启动hadoop集群。参考我的这篇博客，<a href=\"http://www.yanjiuyanjiu.com/blog/20130612\" target=\"_blank\" rel=\"external\">在CentOS上安装Hadoop</a>. </p>\n<p>##5.2 Scala<br>在三台机器上都要安装 Scala 2.9.3 , 按照第2节的步骤。JDK在安装Hadoop时已经安装了。</p>\n<p>##5.3 在master上安装并配置Spark<br>解压</p>\n<pre><code>$ tar -zxf spark-0.7.2-prebuilt-hadoop1.tgz\n</code></pre><p>设置SPARK_EXAMPLES_JAR 环境变量</p>\n<pre><code>$ vim ~/.bash_profile\n# add the following lines at the end\nexport SPARK_EXAMPLES_JAR=$HOME/spark-0.7.2/examples/target/scala-2.9.3/spark-examples_2.9.3-0.7.2.jar\n# save and exit vim\n#make the bash profile take effect immediately\n$ source /etc/profile\n</code></pre><p>在 in <code>conf/spark-env.sh</code> 中设置<code>SCALA_HOME</code></p>\n<pre><code>$ cd ~/spark-0.7.2/conf\n$ mv spark-env.sh.template spark-env.sh\n$ vim spark-env.sh\n# add the following line\nexport SCALA_HOME=/usr/lib/scala-2.9.3\n# save and exit\n</code></pre><p>在<code>conf/slaves</code>, 添加Spark worker的hostname, 一行一个。</p>\n<pre><code>$ vim slaves\nslave01\nslave02\n# save and exit\n</code></pre><p>（可选）设置 SPARK_HOME环境变量，并将SPARK_HOME/bin加入PATH</p>\n<pre><code>$ vim ~/.bash_profile\n# add the following lines at the end\nexport SPARK_HOME=$HOME/spark-0.7.2\nexport PATH=$PATH:$SPARK_HOME/bin\n# save and exit vim\n#make the bash profile take effect immediately\n$ source /etc/profile\n</code></pre><p>##5.4 在所有worker上安装并配置Spark<br>既然master上的这个文件件已经配置好了，把它拷贝到所有的worker。<strong>注意，三台机器spark所在目录必须一致，因为master会登陆到worker上执行命令，master认为worker的spark路径与自己一样。</strong></p>\n<pre><code>$ cd\n$ scp -r spark-0.7.2 dev@slave01:~\n$ scp -r spark-0.7.2 dev@slave02:~\n</code></pre><p>按照第5.3节设置<code>SPARK_EXAMPLES_JAR</code>环境变量，配置文件不用配置了，因为是直接从master复制过来的，已经配置好了。</p>\n<p>##5.5 启动 Spark 集群<br>在master上执行</p>\n<pre><code>$ cd ~/spark-0.7.2\n$ bin/start-all.sh\n</code></pre><p>检测进程是否启动</p>\n<pre><code>$ jps\n11055 Jps\n2313 SecondaryNameNode\n2409 JobTracker\n2152 NameNode\n4822 Master\n</code></pre><p>浏览master的web UI(默认<a href=\"http://localhost:8080\" target=\"_blank\" rel=\"external\">http://localhost:8080</a>). 这是你应该可以看到所有的word节点，以及他们的CPU个数和内存等信息。</p>\n<p>##5.6 运行SparkPi例子</p>\n<pre><code>$ cd ~/spark-0.7.2\n$ ./run spark.examples.SparkPi spark://master:7077\n</code></pre><p>（可选）运行自带的例子，SparkLR 和 SparkKMeans.</p>\n<pre><code>#Logistic Regression\n#./run spark.examples.SparkLR spark://master:7077\n#kmeans\n$ ./run spark.examples.SparkKMeans spark://master:7077 ./kmeans_data.txt 2 1\n</code></pre><p>##5.7 从HDFS读取文件并运行WordCount</p>\n<pre><code>$ cd ~/spark-0.7.2\n$ hadoop fs -put README.md .\n$ MASTER=spark://master:7077 ./spark-shell\nscala&gt; val file = sc.textFile(&quot;hdfs://master:9000/user/dev/README.md&quot;)\nscala&gt; val count = file.flatMap(line =&gt; line.split(&quot; &quot;)).map(word =&gt; (word, 1)).reduceByKey(_+_)\nscala&gt; count.collect()\n</code></pre><p>##5.8 停止 Spark 集群</p>\n<pre><code>$ cd ~/spark-0.7.2\n$ bin/stop-all.sh\n</code></pre><p>#参考资料</p>\n<ol>\n<li><a href=\"http://spark-project.org/docs/latest/spark-standalone.html\" target=\"_blank\" rel=\"external\">Spark Standalone Mode</a></li>\n<li><a href=\"https://github.com/mesos/spark/wiki/Running-A-Spark-Standalone-Cluster\" target=\"_blank\" rel=\"external\">Running A Spark Standalone Cluster</a></li>\n<li><a href=\"http://sprism.blogspot.com/2012/11/lightning-fast-wordcount-using-spark.html\" target=\"_blank\" rel=\"external\">Lightning-Fast WordCount using Spark Alongside Hadoop</a></li>\n</ol>\n<p>以下博客都已经过时了：</p>\n<ol>\n<li><a href=\"http://chapeau.freevariable.com/2013/04/installing-spark-on-fedora-18.html\" target=\"_blank\" rel=\"external\">Installing Spark on Fedora 18</a></li>\n<li><a href=\"http://rdc.taobao.com/team/jm/archives/1823\" target=\"_blank\" rel=\"external\">Spark随谈（二）—— 安装攻略</a></li>\n<li><a href=\"http://www.cnblogs.com/jerrylead/archive/2012/08/13/2636115.html\" target=\"_blank\" rel=\"external\">Spark安装与学习</a></li>\n</ol>\n","excerpt":"<p><strong>环境</strong>:CentOS 6.4, Hadoop 1.1.2, JDK 1.7, Spark 0.7.2, Scala 2.9.3</p>\n<p>折腾了几天，终于把Spark 集群安装成功了，其实比hadoop要简单很多，由于网上搜索到的博客大部分都还停留在需要依赖mesos的版本，走了不少弯路。</p>\n<p>#1. 安装 JDK 1.7<br>    yum search openjdk-devel<br>    sudo yum install java-1.7.0-openjdk-devel.x86_64<br>    /usr/sbin/alternatives –config java<br>    /usr/sbin/alternatives –config javac<br>    sudo vim /etc/profile</p>\n<pre><code># add the following lines at the end\nexport JAVA_HOME=/usr/lib/jvm/java-1.7.0-openjdk-1.7.0.19.x86_64\nexport JRE_HOME=$JAVA_HOME/jre\nexport PATH=$PATH:$JAVA_HOME/bin\nexport CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar\n# save and exit vim\n# make the bash profile take effect immediately\n$ source /etc/profile\n# test\n$ java -version\n</code></pre><p>参考我的另一篇博客，<a href=\"http://www.yanjiuyanjiu.com/blog/20120423/\">安装和配置CentOS服务器的详细步骤</a>。</p>\n<p>#2. 安装 Scala 2.9.3<br>Spark 0.7.2 依赖 Scala 2.9.3, 我们必须要安装Scala 2.9.3.</p>\n<p>下载 <a href=\"http://www.scala-lang.org/downloads/distrib/files/scala-2.9.3.tgz\">scala-2.9.3.tgz</a> 并 保存到home目录.</p>\n<pre><code>$ tar -zxf scala-2.9.3.tgz\n$ sudo mv scala-2.9.3 /usr/lib\n$ sudo vim /etc/profile\n# add the following lines at the end\nexport SCALA_HOME=/usr/lib/scala-2.9.3\nexport PATH=$PATH:$SCALA_HOME/bin\n# save and exit vim\n#make the bash profile take effect immediately\nsource /etc/profile\n# test\n$ scala -version\n</code></pre><p>#3. 下载预编译好的Spark<br>下载预编译好的Spark, <a href=\"http://www.spark-project.org/download-spark-0.7.2-prebuilt-hadoop1\">spark-0.7.2-prebuilt-hadoop1.tgz</a>. </p>\n<p>如果你想从零开始编译，则下载源码包，但是我不建议你这么做，因为有一个Maven仓库，twitter4j.org, 被墙了，导致编译时需要翻墙，非常麻烦。如果你有DIY精神，并能顺利翻墙，则可以试试这种方式。</p>\n<p>#4. 本地模式</p>\n<p>##4.1 解压</p>\n<pre><code>$ tar -zxf spark-0.7.2-prebuilt-hadoop1.tgz\n</code></pre><p>##4.2 设置SPARK_EXAMPLES_JAR 环境变量</p>\n<pre><code>$ vim ~/.bash_profile\n# add the following lines at the end\nexport SPARK_EXAMPLES_JAR=$HOME/spark-0.7.2/examples/target/scala-2.9.3/spark-examples_2.9.3-0.7.2.jar\n# save and exit vim\n#make the bash profile take effect immediately\n$ source /etc/profile\n</code></pre><p>这一步其实最关键，很不幸的是，官方文档和网上的博客，都没有提及这一点。我是偶然看到了这两篇帖子，<a href=\"https://groups.google.com/forum/?fromgroups#!topic/spark-users/nQ6wB2lcFN8\">Running SparkPi</a>, <a href=\"https://groups.google.com/forum/#!msg/spark-users/x5UczgI-Xm8/wzMm3Mb77-oJ\">Null pointer exception when running ./run spark.examples.SparkPi local</a>，才补上了这一步，之前死活都无法运行SparkPi。</p>\n<p>##4.3 （可选）设置 SPARK_HOME环境变量，并将SPARK_HOME/bin加入PATH<br>    $ vim ~/.bash_profile</p>\n<pre><code># add the following lines at the end\nexport SPARK_HOME=$HOME/spark-0.7.2\nexport PATH=$PATH:$SPARK_HOME/bin\n# save and exit vim\n#make the bash profile take effect immediately\n$ source /etc/profile\n</code></pre><p>##4.4 现在可以运行SparkPi了</p>\n<pre><code>$ cd ~/spark-0.7.2\n$ ./run spark.examples.SparkPi local \n</code></pre><p>#5. 集群模式</p>","more":"<p>##5.1 安装Hadoop<br>用VMware Workstation 创建三台CentOS 虚拟机，hostname分别设置为 master, slave01, slave02，设置SSH无密码登陆，安装hadoop，然后启动hadoop集群。参考我的这篇博客，<a href=\"http://www.yanjiuyanjiu.com/blog/20130612\">在CentOS上安装Hadoop</a>. </p>\n<p>##5.2 Scala<br>在三台机器上都要安装 Scala 2.9.3 , 按照第2节的步骤。JDK在安装Hadoop时已经安装了。</p>\n<p>##5.3 在master上安装并配置Spark<br>解压</p>\n<pre><code>$ tar -zxf spark-0.7.2-prebuilt-hadoop1.tgz\n</code></pre><p>设置SPARK_EXAMPLES_JAR 环境变量</p>\n<pre><code>$ vim ~/.bash_profile\n# add the following lines at the end\nexport SPARK_EXAMPLES_JAR=$HOME/spark-0.7.2/examples/target/scala-2.9.3/spark-examples_2.9.3-0.7.2.jar\n# save and exit vim\n#make the bash profile take effect immediately\n$ source /etc/profile\n</code></pre><p>在 in <code>conf/spark-env.sh</code> 中设置<code>SCALA_HOME</code></p>\n<pre><code>$ cd ~/spark-0.7.2/conf\n$ mv spark-env.sh.template spark-env.sh\n$ vim spark-env.sh\n# add the following line\nexport SCALA_HOME=/usr/lib/scala-2.9.3\n# save and exit\n</code></pre><p>在<code>conf/slaves</code>, 添加Spark worker的hostname, 一行一个。</p>\n<pre><code>$ vim slaves\nslave01\nslave02\n# save and exit\n</code></pre><p>（可选）设置 SPARK_HOME环境变量，并将SPARK_HOME/bin加入PATH</p>\n<pre><code>$ vim ~/.bash_profile\n# add the following lines at the end\nexport SPARK_HOME=$HOME/spark-0.7.2\nexport PATH=$PATH:$SPARK_HOME/bin\n# save and exit vim\n#make the bash profile take effect immediately\n$ source /etc/profile\n</code></pre><p>##5.4 在所有worker上安装并配置Spark<br>既然master上的这个文件件已经配置好了，把它拷贝到所有的worker。<strong>注意，三台机器spark所在目录必须一致，因为master会登陆到worker上执行命令，master认为worker的spark路径与自己一样。</strong></p>\n<pre><code>$ cd\n$ scp -r spark-0.7.2 dev@slave01:~\n$ scp -r spark-0.7.2 dev@slave02:~\n</code></pre><p>按照第5.3节设置<code>SPARK_EXAMPLES_JAR</code>环境变量，配置文件不用配置了，因为是直接从master复制过来的，已经配置好了。</p>\n<p>##5.5 启动 Spark 集群<br>在master上执行</p>\n<pre><code>$ cd ~/spark-0.7.2\n$ bin/start-all.sh\n</code></pre><p>检测进程是否启动</p>\n<pre><code>$ jps\n11055 Jps\n2313 SecondaryNameNode\n2409 JobTracker\n2152 NameNode\n4822 Master\n</code></pre><p>浏览master的web UI(默认<a href=\"http://localhost:8080\">http://localhost:8080</a>). 这是你应该可以看到所有的word节点，以及他们的CPU个数和内存等信息。</p>\n<p>##5.6 运行SparkPi例子</p>\n<pre><code>$ cd ~/spark-0.7.2\n$ ./run spark.examples.SparkPi spark://master:7077\n</code></pre><p>（可选）运行自带的例子，SparkLR 和 SparkKMeans.</p>\n<pre><code>#Logistic Regression\n#./run spark.examples.SparkLR spark://master:7077\n#kmeans\n$ ./run spark.examples.SparkKMeans spark://master:7077 ./kmeans_data.txt 2 1\n</code></pre><p>##5.7 从HDFS读取文件并运行WordCount</p>\n<pre><code>$ cd ~/spark-0.7.2\n$ hadoop fs -put README.md .\n$ MASTER=spark://master:7077 ./spark-shell\nscala&gt; val file = sc.textFile(&quot;hdfs://master:9000/user/dev/README.md&quot;)\nscala&gt; val count = file.flatMap(line =&gt; line.split(&quot; &quot;)).map(word =&gt; (word, 1)).reduceByKey(_+_)\nscala&gt; count.collect()\n</code></pre><p>##5.8 停止 Spark 集群</p>\n<pre><code>$ cd ~/spark-0.7.2\n$ bin/stop-all.sh\n</code></pre><p>#参考资料</p>\n<ol>\n<li><a href=\"http://spark-project.org/docs/latest/spark-standalone.html\">Spark Standalone Mode</a></li>\n<li><a href=\"https://github.com/mesos/spark/wiki/Running-A-Spark-Standalone-Cluster\">Running A Spark Standalone Cluster</a></li>\n<li><a href=\"http://sprism.blogspot.com/2012/11/lightning-fast-wordcount-using-spark.html\">Lightning-Fast WordCount using Spark Alongside Hadoop</a></li>\n</ol>\n<p>以下博客都已经过时了：</p>\n<ol>\n<li><a href=\"http://chapeau.freevariable.com/2013/04/installing-spark-on-fedora-18.html\">Installing Spark on Fedora 18</a></li>\n<li><a href=\"http://rdc.taobao.com/team/jm/archives/1823\">Spark随谈（二）—— 安装攻略</a></li>\n<li><a href=\"http://www.cnblogs.com/jerrylead/archive/2012/08/13/2636115.html\">Spark安装与学习</a></li>\n</ol>"},{"layout":"post","title":"安装Spark 0.8 集群(在CentOS上)","date":"2013-10-17T11:58:00.000Z","comments":1,"_content":"**环境**:CentOS 6.4, Hadoop 1.1.2, JDK 1.7, Spark 0.8.0, Scala 2.9.3\n\nSpark 0.7.2 的安装请看之前的一篇博客，[安装Spark集群(在CentOS上)](http://www.yanjiuyanjiu.com/blog/20130617/) 。\n\nSpark的安装很简单，总结起来一句话：下载，解压，然后拷贝到所有机器，完毕，无需任何配置。\n\n\n#1. 安装 JDK 1.7\n\tyum search openjdk-devel\n\tsudo yum install java-1.7.0-openjdk-devel.x86_64\n\t/usr/sbin/alternatives --config java\n\t/usr/sbin/alternatives --config javac\n\tsudo vim /etc/profile\n\t# add the following lines at the end\n\texport JAVA_HOME=/usr/lib/jvm/java-1.7.0-openjdk-1.7.0.19.x86_64\n\texport JRE_HOME=$JAVA_HOME/jre\n\texport PATH=$PATH:$JAVA_HOME/bin\n\texport CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar\n\t# save and exit vim\n\t# make the bash profile take effect immediately\n\t$ source /etc/profile\n\t# test\n\t$ java -version\n\n参考我的另一篇博客，[安装和配置CentOS服务器的详细步骤](http://www.yanjiuyanjiu.com/blog/20120423/)。\n\n#2. 安装 Scala 2.9.3\nSpark 0.8.0 依赖 Scala 2.9.3, 我们必须要安装Scala 2.9.3.\n\n下载 [scala-2.9.3.tgz](http://www.scala-lang.org/downloads/distrib/files/scala-2.9.3.tgz) 并 保存到home目录.\n\n\t$ tar -zxf scala-2.9.3.tgz\n\t$ sudo mv scala-2.9.3 /usr/lib\n\t$ sudo vim /etc/profile\n\t# add the following lines at the end\n\texport SCALA_HOME=/usr/lib/scala-2.9.3\n\texport PATH=$PATH:$SCALA_HOME/bin\n\t# save and exit vim\n\t#make the bash profile take effect immediately\n\tsource /etc/profile\n\t# test\n\t$ scala -version\n\n#3. 下载预编译好的Spark\n下载预编译好的Spark, [spark-0.8.0-incubating-bin-hadoop1.tgz](http://spark-project.org/download/spark-0.8.0-incubating-bin-hadoop1.tgz). \n\n如果你想从零开始编译，则下载源码包，但是我不建议你这么做，因为有一个Maven仓库，twitter4j.org, 被墙了，导致编译时需要翻墙，非常麻烦。如果你有DIY精神，并能顺利翻墙，则可以试试这种方式。\n\n#4. Local模式\n\n##4.1 解压\n\n\t$ tar -zxf spark-0.8.0-incubating-bin-hadoop1.tgz\n\n##4.2 （可选）设置 SPARK\\_HOME环境变量\n\n\t$ vim ~/.bash_profile\n\t# add the following lines at the end\n\texport SPARK_HOME=$HOME/spark-0.8.0\n\t# save and exit vim\n\t#make the bash profile take effect immediately\n\t$ source /etc/profile\n\n##4.3 现在可以运行SparkPi了\n\n\t$ cd $SPARK_HOME\n\t$ ./run-example org.apache.spark.examples.SparkPi local\n\n#5. Cluster模式\n\n<!-- more -->\n\n##5.1 安装Hadoop\n用VMware Workstation 创建三台CentOS 虚拟机，hostname分别设置为 master, slave01, slave02，设置SSH无密码登陆，安装hadoop，然后启动hadoop集群。参考我的这篇博客，[在CentOS上安装Hadoop](http://www.yanjiuyanjiu.com/blog/20130612). \n\n##5.2 Scala\n在三台机器上都要安装 Scala 2.9.3 , 按照第2节的步骤。JDK在安装Hadoop时已经安装了。\n\n##5.3 在master上安装并配置Spark\n解压\n\n\t$ tar -zxf spark-0.8.0-incubating-bin-hadoop1.tgz.tgz\n\n在 in `conf/spark-env.sh` 中设置`SCALA_HOME`\n\n\t$ cd ~/spark-0.8.0/conf\n\t$ mv spark-env.sh.template spark-env.sh\n\t$ vim spark-env.sh\n\t# add the following line\n\texport SCALA_HOME=/usr/lib/scala-2.9.3\n\t# save and exit\n\n在`conf/slaves`, 添加Spark worker的hostname, 一行一个。\n\n\t$ vim slaves\n\tslave01\n\tslave02\n\t# save and exit\n\n（可选）设置 SPARK\\_HOME环境变量，并将SPARK\\_HOME/bin加入PATH\n\n\t$ vim ~/.bash_profile\n\t# add the following lines at the end\n\texport SPARK_HOME=$HOME/spark-0.8.0\n\texport PATH=$PATH:$SPARK_HOME/bin\n\t# save and exit vim\n\t#make the bash profile take effect immediately\n\t$ source /etc/profile\n\n##5.4 在所有worker上安装并配置Spark\n既然master上的这个文件件已经配置好了，把它拷贝到所有的worker即可。**注意，三台机器spark所在目录必须一致，因为master会登陆到worker上执行命令，master认为worker的spark路径与自己一样。**\n\t\n\t$ cd\n\t$ scp -r spark-0.8.0 dev@slave01:~\n\t$ scp -r spark-0.8.0 dev@slave02:~\n\n\n##5.5 启动 Spark 集群\n在master上执行\n\n\t$ cd ~/spark-0.8.0\n\t$ bin/start-all.sh\n\n检测进程是否启动\n\n\t$ jps\n\t11055 Jps\n\t2313 SecondaryNameNode\n\t2409 JobTracker\n\t2152 NameNode\n\t4822 Master\n\n浏览master的web UI(默认<http://localhost:8080>). 这是你应该可以看到所有的word节点，以及他们的CPU个数和内存等信息。\n\n##5.6 运行Spark自带的例子\n\n运行SparkPi\n\n\t$ cd ~/spark-0.8.0\n\t$ ./run-example org.apache.spark.examples.SparkPi spark://master:7077\n\n运行 SparkLR\n\t\n\t#Logistic Regression\n\t#./run-example org.apache.spark.examples.SparkLR spark://master:7077\n\n运行 SparkKMeans\n\n\t#kmeans\n\t$ ./run-example org.apache.spark.examples.SparkKMeans spark://master:7077 ./kmeans_data.txt 2 1\n\t\n\n##5.7 从HDFS读取文件并运行WordCount\n\n\t$ cd ~/spark-0.8.0\n\t$ hadoop fs -put README.md .\n\t$ MASTER=spark://master:7077 ./spark-shell\n\tscala> val file = sc.textFile(\"hdfs://master:9000/user/dev/README.md\")\n\tscala> val count = file.flatMap(line => line.split(\" \")).map(word => (word, 1)).reduceByKey(_+_)\n\tscala> count.collect()\n\n##5.8 停止 Spark 集群\n\n\t$ cd ~/spark-0.8.0\n\t$ bin/stop-all.sh\n\n#参考资料\n1. [Spark Standalone Mode](http://spark-project.org/docs/latest/spark-standalone.html)\n1. [Running A Spark Standalone Cluster](https://github.com/mesos/spark/wiki/Running-A-Spark-Standalone-Cluster)\n1. [Lightning-Fast WordCount using Spark Alongside Hadoop](http://sprism.blogspot.com/2012/11/lightning-fast-wordcount-using-spark.html)\n\n以下博客都已经过时了：\n\n1. [Installing Spark on Fedora 18](http://chapeau.freevariable.com/2013/04/installing-spark-on-fedora-18.html)\n1. [Spark随谈（二）—— 安装攻略](http://rdc.taobao.com/team/jm/archives/1823)\n1. [Spark安装与学习](http://www.cnblogs.com/jerrylead/archive/2012/08/13/2636115.html)\n","source":"_posts/2013-10-17-installing-spark-on-centos-cn.md","raw":"---\nlayout: post\ntitle: \"安装Spark 0.8 集群(在CentOS上)\"\ndate: 2013-10-17 11:58\ncomments: true\ncategories: Spark\n---\n**环境**:CentOS 6.4, Hadoop 1.1.2, JDK 1.7, Spark 0.8.0, Scala 2.9.3\n\nSpark 0.7.2 的安装请看之前的一篇博客，[安装Spark集群(在CentOS上)](http://www.yanjiuyanjiu.com/blog/20130617/) 。\n\nSpark的安装很简单，总结起来一句话：下载，解压，然后拷贝到所有机器，完毕，无需任何配置。\n\n\n#1. 安装 JDK 1.7\n\tyum search openjdk-devel\n\tsudo yum install java-1.7.0-openjdk-devel.x86_64\n\t/usr/sbin/alternatives --config java\n\t/usr/sbin/alternatives --config javac\n\tsudo vim /etc/profile\n\t# add the following lines at the end\n\texport JAVA_HOME=/usr/lib/jvm/java-1.7.0-openjdk-1.7.0.19.x86_64\n\texport JRE_HOME=$JAVA_HOME/jre\n\texport PATH=$PATH:$JAVA_HOME/bin\n\texport CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar\n\t# save and exit vim\n\t# make the bash profile take effect immediately\n\t$ source /etc/profile\n\t# test\n\t$ java -version\n\n参考我的另一篇博客，[安装和配置CentOS服务器的详细步骤](http://www.yanjiuyanjiu.com/blog/20120423/)。\n\n#2. 安装 Scala 2.9.3\nSpark 0.8.0 依赖 Scala 2.9.3, 我们必须要安装Scala 2.9.3.\n\n下载 [scala-2.9.3.tgz](http://www.scala-lang.org/downloads/distrib/files/scala-2.9.3.tgz) 并 保存到home目录.\n\n\t$ tar -zxf scala-2.9.3.tgz\n\t$ sudo mv scala-2.9.3 /usr/lib\n\t$ sudo vim /etc/profile\n\t# add the following lines at the end\n\texport SCALA_HOME=/usr/lib/scala-2.9.3\n\texport PATH=$PATH:$SCALA_HOME/bin\n\t# save and exit vim\n\t#make the bash profile take effect immediately\n\tsource /etc/profile\n\t# test\n\t$ scala -version\n\n#3. 下载预编译好的Spark\n下载预编译好的Spark, [spark-0.8.0-incubating-bin-hadoop1.tgz](http://spark-project.org/download/spark-0.8.0-incubating-bin-hadoop1.tgz). \n\n如果你想从零开始编译，则下载源码包，但是我不建议你这么做，因为有一个Maven仓库，twitter4j.org, 被墙了，导致编译时需要翻墙，非常麻烦。如果你有DIY精神，并能顺利翻墙，则可以试试这种方式。\n\n#4. Local模式\n\n##4.1 解压\n\n\t$ tar -zxf spark-0.8.0-incubating-bin-hadoop1.tgz\n\n##4.2 （可选）设置 SPARK\\_HOME环境变量\n\n\t$ vim ~/.bash_profile\n\t# add the following lines at the end\n\texport SPARK_HOME=$HOME/spark-0.8.0\n\t# save and exit vim\n\t#make the bash profile take effect immediately\n\t$ source /etc/profile\n\n##4.3 现在可以运行SparkPi了\n\n\t$ cd $SPARK_HOME\n\t$ ./run-example org.apache.spark.examples.SparkPi local\n\n#5. Cluster模式\n\n<!-- more -->\n\n##5.1 安装Hadoop\n用VMware Workstation 创建三台CentOS 虚拟机，hostname分别设置为 master, slave01, slave02，设置SSH无密码登陆，安装hadoop，然后启动hadoop集群。参考我的这篇博客，[在CentOS上安装Hadoop](http://www.yanjiuyanjiu.com/blog/20130612). \n\n##5.2 Scala\n在三台机器上都要安装 Scala 2.9.3 , 按照第2节的步骤。JDK在安装Hadoop时已经安装了。\n\n##5.3 在master上安装并配置Spark\n解压\n\n\t$ tar -zxf spark-0.8.0-incubating-bin-hadoop1.tgz.tgz\n\n在 in `conf/spark-env.sh` 中设置`SCALA_HOME`\n\n\t$ cd ~/spark-0.8.0/conf\n\t$ mv spark-env.sh.template spark-env.sh\n\t$ vim spark-env.sh\n\t# add the following line\n\texport SCALA_HOME=/usr/lib/scala-2.9.3\n\t# save and exit\n\n在`conf/slaves`, 添加Spark worker的hostname, 一行一个。\n\n\t$ vim slaves\n\tslave01\n\tslave02\n\t# save and exit\n\n（可选）设置 SPARK\\_HOME环境变量，并将SPARK\\_HOME/bin加入PATH\n\n\t$ vim ~/.bash_profile\n\t# add the following lines at the end\n\texport SPARK_HOME=$HOME/spark-0.8.0\n\texport PATH=$PATH:$SPARK_HOME/bin\n\t# save and exit vim\n\t#make the bash profile take effect immediately\n\t$ source /etc/profile\n\n##5.4 在所有worker上安装并配置Spark\n既然master上的这个文件件已经配置好了，把它拷贝到所有的worker即可。**注意，三台机器spark所在目录必须一致，因为master会登陆到worker上执行命令，master认为worker的spark路径与自己一样。**\n\t\n\t$ cd\n\t$ scp -r spark-0.8.0 dev@slave01:~\n\t$ scp -r spark-0.8.0 dev@slave02:~\n\n\n##5.5 启动 Spark 集群\n在master上执行\n\n\t$ cd ~/spark-0.8.0\n\t$ bin/start-all.sh\n\n检测进程是否启动\n\n\t$ jps\n\t11055 Jps\n\t2313 SecondaryNameNode\n\t2409 JobTracker\n\t2152 NameNode\n\t4822 Master\n\n浏览master的web UI(默认<http://localhost:8080>). 这是你应该可以看到所有的word节点，以及他们的CPU个数和内存等信息。\n\n##5.6 运行Spark自带的例子\n\n运行SparkPi\n\n\t$ cd ~/spark-0.8.0\n\t$ ./run-example org.apache.spark.examples.SparkPi spark://master:7077\n\n运行 SparkLR\n\t\n\t#Logistic Regression\n\t#./run-example org.apache.spark.examples.SparkLR spark://master:7077\n\n运行 SparkKMeans\n\n\t#kmeans\n\t$ ./run-example org.apache.spark.examples.SparkKMeans spark://master:7077 ./kmeans_data.txt 2 1\n\t\n\n##5.7 从HDFS读取文件并运行WordCount\n\n\t$ cd ~/spark-0.8.0\n\t$ hadoop fs -put README.md .\n\t$ MASTER=spark://master:7077 ./spark-shell\n\tscala> val file = sc.textFile(\"hdfs://master:9000/user/dev/README.md\")\n\tscala> val count = file.flatMap(line => line.split(\" \")).map(word => (word, 1)).reduceByKey(_+_)\n\tscala> count.collect()\n\n##5.8 停止 Spark 集群\n\n\t$ cd ~/spark-0.8.0\n\t$ bin/stop-all.sh\n\n#参考资料\n1. [Spark Standalone Mode](http://spark-project.org/docs/latest/spark-standalone.html)\n1. [Running A Spark Standalone Cluster](https://github.com/mesos/spark/wiki/Running-A-Spark-Standalone-Cluster)\n1. [Lightning-Fast WordCount using Spark Alongside Hadoop](http://sprism.blogspot.com/2012/11/lightning-fast-wordcount-using-spark.html)\n\n以下博客都已经过时了：\n\n1. [Installing Spark on Fedora 18](http://chapeau.freevariable.com/2013/04/installing-spark-on-fedora-18.html)\n1. [Spark随谈（二）—— 安装攻略](http://rdc.taobao.com/team/jm/archives/1823)\n1. [Spark安装与学习](http://www.cnblogs.com/jerrylead/archive/2012/08/13/2636115.html)\n","slug":"2013-10-17-installing-spark-on-centos-cn","published":1,"updated":"2016-08-18T09:21:04.000Z","photos":[],"link":"","_id":"cis07pf3e001i01pqxb6u0uj5","content":"<p><strong>环境</strong>:CentOS 6.4, Hadoop 1.1.2, JDK 1.7, Spark 0.8.0, Scala 2.9.3</p>\n<p>Spark 0.7.2 的安装请看之前的一篇博客，<a href=\"http://www.yanjiuyanjiu.com/blog/20130617/\" target=\"_blank\" rel=\"external\">安装Spark集群(在CentOS上)</a> 。</p>\n<p>Spark的安装很简单，总结起来一句话：下载，解压，然后拷贝到所有机器，完毕，无需任何配置。</p>\n<p>#1. 安装 JDK 1.7<br>    yum search openjdk-devel<br>    sudo yum install java-1.7.0-openjdk-devel.x86_64<br>    /usr/sbin/alternatives –config java<br>    /usr/sbin/alternatives –config javac<br>    sudo vim /etc/profile</p>\n<pre><code># add the following lines at the end\nexport JAVA_HOME=/usr/lib/jvm/java-1.7.0-openjdk-1.7.0.19.x86_64\nexport JRE_HOME=$JAVA_HOME/jre\nexport PATH=$PATH:$JAVA_HOME/bin\nexport CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar\n# save and exit vim\n# make the bash profile take effect immediately\n$ source /etc/profile\n# test\n$ java -version\n</code></pre><p>参考我的另一篇博客，<a href=\"http://www.yanjiuyanjiu.com/blog/20120423/\" target=\"_blank\" rel=\"external\">安装和配置CentOS服务器的详细步骤</a>。</p>\n<p>#2. 安装 Scala 2.9.3<br>Spark 0.8.0 依赖 Scala 2.9.3, 我们必须要安装Scala 2.9.3.</p>\n<p>下载 <a href=\"http://www.scala-lang.org/downloads/distrib/files/scala-2.9.3.tgz\" target=\"_blank\" rel=\"external\">scala-2.9.3.tgz</a> 并 保存到home目录.</p>\n<pre><code>$ tar -zxf scala-2.9.3.tgz\n$ sudo mv scala-2.9.3 /usr/lib\n$ sudo vim /etc/profile\n# add the following lines at the end\nexport SCALA_HOME=/usr/lib/scala-2.9.3\nexport PATH=$PATH:$SCALA_HOME/bin\n# save and exit vim\n#make the bash profile take effect immediately\nsource /etc/profile\n# test\n$ scala -version\n</code></pre><p>#3. 下载预编译好的Spark<br>下载预编译好的Spark, <a href=\"http://spark-project.org/download/spark-0.8.0-incubating-bin-hadoop1.tgz\" target=\"_blank\" rel=\"external\">spark-0.8.0-incubating-bin-hadoop1.tgz</a>. </p>\n<p>如果你想从零开始编译，则下载源码包，但是我不建议你这么做，因为有一个Maven仓库，twitter4j.org, 被墙了，导致编译时需要翻墙，非常麻烦。如果你有DIY精神，并能顺利翻墙，则可以试试这种方式。</p>\n<p>#4. Local模式</p>\n<p>##4.1 解压</p>\n<pre><code>$ tar -zxf spark-0.8.0-incubating-bin-hadoop1.tgz\n</code></pre><p>##4.2 （可选）设置 SPARK_HOME环境变量</p>\n<pre><code>$ vim ~/.bash_profile\n# add the following lines at the end\nexport SPARK_HOME=$HOME/spark-0.8.0\n# save and exit vim\n#make the bash profile take effect immediately\n$ source /etc/profile\n</code></pre><p>##4.3 现在可以运行SparkPi了</p>\n<pre><code>$ cd $SPARK_HOME\n$ ./run-example org.apache.spark.examples.SparkPi local\n</code></pre><p>#5. Cluster模式</p>\n<a id=\"more\"></a>\n<p>##5.1 安装Hadoop<br>用VMware Workstation 创建三台CentOS 虚拟机，hostname分别设置为 master, slave01, slave02，设置SSH无密码登陆，安装hadoop，然后启动hadoop集群。参考我的这篇博客，<a href=\"http://www.yanjiuyanjiu.com/blog/20130612\" target=\"_blank\" rel=\"external\">在CentOS上安装Hadoop</a>. </p>\n<p>##5.2 Scala<br>在三台机器上都要安装 Scala 2.9.3 , 按照第2节的步骤。JDK在安装Hadoop时已经安装了。</p>\n<p>##5.3 在master上安装并配置Spark<br>解压</p>\n<pre><code>$ tar -zxf spark-0.8.0-incubating-bin-hadoop1.tgz.tgz\n</code></pre><p>在 in <code>conf/spark-env.sh</code> 中设置<code>SCALA_HOME</code></p>\n<pre><code>$ cd ~/spark-0.8.0/conf\n$ mv spark-env.sh.template spark-env.sh\n$ vim spark-env.sh\n# add the following line\nexport SCALA_HOME=/usr/lib/scala-2.9.3\n# save and exit\n</code></pre><p>在<code>conf/slaves</code>, 添加Spark worker的hostname, 一行一个。</p>\n<pre><code>$ vim slaves\nslave01\nslave02\n# save and exit\n</code></pre><p>（可选）设置 SPARK_HOME环境变量，并将SPARK_HOME/bin加入PATH</p>\n<pre><code>$ vim ~/.bash_profile\n# add the following lines at the end\nexport SPARK_HOME=$HOME/spark-0.8.0\nexport PATH=$PATH:$SPARK_HOME/bin\n# save and exit vim\n#make the bash profile take effect immediately\n$ source /etc/profile\n</code></pre><p>##5.4 在所有worker上安装并配置Spark<br>既然master上的这个文件件已经配置好了，把它拷贝到所有的worker即可。<strong>注意，三台机器spark所在目录必须一致，因为master会登陆到worker上执行命令，master认为worker的spark路径与自己一样。</strong></p>\n<pre><code>$ cd\n$ scp -r spark-0.8.0 dev@slave01:~\n$ scp -r spark-0.8.0 dev@slave02:~\n</code></pre><p>##5.5 启动 Spark 集群<br>在master上执行</p>\n<pre><code>$ cd ~/spark-0.8.0\n$ bin/start-all.sh\n</code></pre><p>检测进程是否启动</p>\n<pre><code>$ jps\n11055 Jps\n2313 SecondaryNameNode\n2409 JobTracker\n2152 NameNode\n4822 Master\n</code></pre><p>浏览master的web UI(默认<a href=\"http://localhost:8080\" target=\"_blank\" rel=\"external\">http://localhost:8080</a>). 这是你应该可以看到所有的word节点，以及他们的CPU个数和内存等信息。</p>\n<p>##5.6 运行Spark自带的例子</p>\n<p>运行SparkPi</p>\n<pre><code>$ cd ~/spark-0.8.0\n$ ./run-example org.apache.spark.examples.SparkPi spark://master:7077\n</code></pre><p>运行 SparkLR</p>\n<pre><code>#Logistic Regression\n#./run-example org.apache.spark.examples.SparkLR spark://master:7077\n</code></pre><p>运行 SparkKMeans</p>\n<pre><code>#kmeans\n$ ./run-example org.apache.spark.examples.SparkKMeans spark://master:7077 ./kmeans_data.txt 2 1\n</code></pre><p>##5.7 从HDFS读取文件并运行WordCount</p>\n<pre><code>$ cd ~/spark-0.8.0\n$ hadoop fs -put README.md .\n$ MASTER=spark://master:7077 ./spark-shell\nscala&gt; val file = sc.textFile(&quot;hdfs://master:9000/user/dev/README.md&quot;)\nscala&gt; val count = file.flatMap(line =&gt; line.split(&quot; &quot;)).map(word =&gt; (word, 1)).reduceByKey(_+_)\nscala&gt; count.collect()\n</code></pre><p>##5.8 停止 Spark 集群</p>\n<pre><code>$ cd ~/spark-0.8.0\n$ bin/stop-all.sh\n</code></pre><p>#参考资料</p>\n<ol>\n<li><a href=\"http://spark-project.org/docs/latest/spark-standalone.html\" target=\"_blank\" rel=\"external\">Spark Standalone Mode</a></li>\n<li><a href=\"https://github.com/mesos/spark/wiki/Running-A-Spark-Standalone-Cluster\" target=\"_blank\" rel=\"external\">Running A Spark Standalone Cluster</a></li>\n<li><a href=\"http://sprism.blogspot.com/2012/11/lightning-fast-wordcount-using-spark.html\" target=\"_blank\" rel=\"external\">Lightning-Fast WordCount using Spark Alongside Hadoop</a></li>\n</ol>\n<p>以下博客都已经过时了：</p>\n<ol>\n<li><a href=\"http://chapeau.freevariable.com/2013/04/installing-spark-on-fedora-18.html\" target=\"_blank\" rel=\"external\">Installing Spark on Fedora 18</a></li>\n<li><a href=\"http://rdc.taobao.com/team/jm/archives/1823\" target=\"_blank\" rel=\"external\">Spark随谈（二）—— 安装攻略</a></li>\n<li><a href=\"http://www.cnblogs.com/jerrylead/archive/2012/08/13/2636115.html\" target=\"_blank\" rel=\"external\">Spark安装与学习</a></li>\n</ol>\n","excerpt":"<p><strong>环境</strong>:CentOS 6.4, Hadoop 1.1.2, JDK 1.7, Spark 0.8.0, Scala 2.9.3</p>\n<p>Spark 0.7.2 的安装请看之前的一篇博客，<a href=\"http://www.yanjiuyanjiu.com/blog/20130617/\">安装Spark集群(在CentOS上)</a> 。</p>\n<p>Spark的安装很简单，总结起来一句话：下载，解压，然后拷贝到所有机器，完毕，无需任何配置。</p>\n<p>#1. 安装 JDK 1.7<br>    yum search openjdk-devel<br>    sudo yum install java-1.7.0-openjdk-devel.x86_64<br>    /usr/sbin/alternatives –config java<br>    /usr/sbin/alternatives –config javac<br>    sudo vim /etc/profile</p>\n<pre><code># add the following lines at the end\nexport JAVA_HOME=/usr/lib/jvm/java-1.7.0-openjdk-1.7.0.19.x86_64\nexport JRE_HOME=$JAVA_HOME/jre\nexport PATH=$PATH:$JAVA_HOME/bin\nexport CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar\n# save and exit vim\n# make the bash profile take effect immediately\n$ source /etc/profile\n# test\n$ java -version\n</code></pre><p>参考我的另一篇博客，<a href=\"http://www.yanjiuyanjiu.com/blog/20120423/\">安装和配置CentOS服务器的详细步骤</a>。</p>\n<p>#2. 安装 Scala 2.9.3<br>Spark 0.8.0 依赖 Scala 2.9.3, 我们必须要安装Scala 2.9.3.</p>\n<p>下载 <a href=\"http://www.scala-lang.org/downloads/distrib/files/scala-2.9.3.tgz\">scala-2.9.3.tgz</a> 并 保存到home目录.</p>\n<pre><code>$ tar -zxf scala-2.9.3.tgz\n$ sudo mv scala-2.9.3 /usr/lib\n$ sudo vim /etc/profile\n# add the following lines at the end\nexport SCALA_HOME=/usr/lib/scala-2.9.3\nexport PATH=$PATH:$SCALA_HOME/bin\n# save and exit vim\n#make the bash profile take effect immediately\nsource /etc/profile\n# test\n$ scala -version\n</code></pre><p>#3. 下载预编译好的Spark<br>下载预编译好的Spark, <a href=\"http://spark-project.org/download/spark-0.8.0-incubating-bin-hadoop1.tgz\">spark-0.8.0-incubating-bin-hadoop1.tgz</a>. </p>\n<p>如果你想从零开始编译，则下载源码包，但是我不建议你这么做，因为有一个Maven仓库，twitter4j.org, 被墙了，导致编译时需要翻墙，非常麻烦。如果你有DIY精神，并能顺利翻墙，则可以试试这种方式。</p>\n<p>#4. Local模式</p>\n<p>##4.1 解压</p>\n<pre><code>$ tar -zxf spark-0.8.0-incubating-bin-hadoop1.tgz\n</code></pre><p>##4.2 （可选）设置 SPARK_HOME环境变量</p>\n<pre><code>$ vim ~/.bash_profile\n# add the following lines at the end\nexport SPARK_HOME=$HOME/spark-0.8.0\n# save and exit vim\n#make the bash profile take effect immediately\n$ source /etc/profile\n</code></pre><p>##4.3 现在可以运行SparkPi了</p>\n<pre><code>$ cd $SPARK_HOME\n$ ./run-example org.apache.spark.examples.SparkPi local\n</code></pre><p>#5. Cluster模式</p>","more":"<p>##5.1 安装Hadoop<br>用VMware Workstation 创建三台CentOS 虚拟机，hostname分别设置为 master, slave01, slave02，设置SSH无密码登陆，安装hadoop，然后启动hadoop集群。参考我的这篇博客，<a href=\"http://www.yanjiuyanjiu.com/blog/20130612\">在CentOS上安装Hadoop</a>. </p>\n<p>##5.2 Scala<br>在三台机器上都要安装 Scala 2.9.3 , 按照第2节的步骤。JDK在安装Hadoop时已经安装了。</p>\n<p>##5.3 在master上安装并配置Spark<br>解压</p>\n<pre><code>$ tar -zxf spark-0.8.0-incubating-bin-hadoop1.tgz.tgz\n</code></pre><p>在 in <code>conf/spark-env.sh</code> 中设置<code>SCALA_HOME</code></p>\n<pre><code>$ cd ~/spark-0.8.0/conf\n$ mv spark-env.sh.template spark-env.sh\n$ vim spark-env.sh\n# add the following line\nexport SCALA_HOME=/usr/lib/scala-2.9.3\n# save and exit\n</code></pre><p>在<code>conf/slaves</code>, 添加Spark worker的hostname, 一行一个。</p>\n<pre><code>$ vim slaves\nslave01\nslave02\n# save and exit\n</code></pre><p>（可选）设置 SPARK_HOME环境变量，并将SPARK_HOME/bin加入PATH</p>\n<pre><code>$ vim ~/.bash_profile\n# add the following lines at the end\nexport SPARK_HOME=$HOME/spark-0.8.0\nexport PATH=$PATH:$SPARK_HOME/bin\n# save and exit vim\n#make the bash profile take effect immediately\n$ source /etc/profile\n</code></pre><p>##5.4 在所有worker上安装并配置Spark<br>既然master上的这个文件件已经配置好了，把它拷贝到所有的worker即可。<strong>注意，三台机器spark所在目录必须一致，因为master会登陆到worker上执行命令，master认为worker的spark路径与自己一样。</strong></p>\n<pre><code>$ cd\n$ scp -r spark-0.8.0 dev@slave01:~\n$ scp -r spark-0.8.0 dev@slave02:~\n</code></pre><p>##5.5 启动 Spark 集群<br>在master上执行</p>\n<pre><code>$ cd ~/spark-0.8.0\n$ bin/start-all.sh\n</code></pre><p>检测进程是否启动</p>\n<pre><code>$ jps\n11055 Jps\n2313 SecondaryNameNode\n2409 JobTracker\n2152 NameNode\n4822 Master\n</code></pre><p>浏览master的web UI(默认<a href=\"http://localhost:8080\">http://localhost:8080</a>). 这是你应该可以看到所有的word节点，以及他们的CPU个数和内存等信息。</p>\n<p>##5.6 运行Spark自带的例子</p>\n<p>运行SparkPi</p>\n<pre><code>$ cd ~/spark-0.8.0\n$ ./run-example org.apache.spark.examples.SparkPi spark://master:7077\n</code></pre><p>运行 SparkLR</p>\n<pre><code>#Logistic Regression\n#./run-example org.apache.spark.examples.SparkLR spark://master:7077\n</code></pre><p>运行 SparkKMeans</p>\n<pre><code>#kmeans\n$ ./run-example org.apache.spark.examples.SparkKMeans spark://master:7077 ./kmeans_data.txt 2 1\n</code></pre><p>##5.7 从HDFS读取文件并运行WordCount</p>\n<pre><code>$ cd ~/spark-0.8.0\n$ hadoop fs -put README.md .\n$ MASTER=spark://master:7077 ./spark-shell\nscala&gt; val file = sc.textFile(&quot;hdfs://master:9000/user/dev/README.md&quot;)\nscala&gt; val count = file.flatMap(line =&gt; line.split(&quot; &quot;)).map(word =&gt; (word, 1)).reduceByKey(_+_)\nscala&gt; count.collect()\n</code></pre><p>##5.8 停止 Spark 集群</p>\n<pre><code>$ cd ~/spark-0.8.0\n$ bin/stop-all.sh\n</code></pre><p>#参考资料</p>\n<ol>\n<li><a href=\"http://spark-project.org/docs/latest/spark-standalone.html\">Spark Standalone Mode</a></li>\n<li><a href=\"https://github.com/mesos/spark/wiki/Running-A-Spark-Standalone-Cluster\">Running A Spark Standalone Cluster</a></li>\n<li><a href=\"http://sprism.blogspot.com/2012/11/lightning-fast-wordcount-using-spark.html\">Lightning-Fast WordCount using Spark Alongside Hadoop</a></li>\n</ol>\n<p>以下博客都已经过时了：</p>\n<ol>\n<li><a href=\"http://chapeau.freevariable.com/2013/04/installing-spark-on-fedora-18.html\">Installing Spark on Fedora 18</a></li>\n<li><a href=\"http://rdc.taobao.com/team/jm/archives/1823\">Spark随谈（二）—— 安装攻略</a></li>\n<li><a href=\"http://www.cnblogs.com/jerrylead/archive/2012/08/13/2636115.html\">Spark安装与学习</a></li>\n</ol>"},{"layout":"post","title":"Mhout KMeans 结果分析","date":"2013-07-07T17:04:00.000Z","comments":1,"published":0,"_content":"\n# 运行KMeans示例\n运行KMeans示例有三种方法，参考前篇一篇博客，[安装mahout]()。\n\n通过阅读`examples\\src\\main\\java\\org\\apache\\mahout\\clustering\\syntheticcontrol\\kmeans\\Job.java`和`integration\\src\\main\\java\\org\\apache\\mahout\\clustering\\conversion\\InputDriver.java`的代码，运行KMeans示例还有第4种方法\n\n利用`InputDriver`将文本格式的向量转化为Mahout能识别的向量，\n\n\t$ hadoop jar ~/mahout-distribution-0.7/mahout-examples-0.7-job.jar org.apache.mahout.clustering.conversion.InputDriver -i testdata -o vector\n\n利用 mahout 自带的命令行工具，\n\n\t$ mahout kmeans -i vector -o output -dm org.apache.mahout.common.distance.EuclideanDistanceMeasure -c centroids -k 6 -cd 0.5 -x 10 -ow \n\n# 分析聚类结果\n\n## 查看结果\n\n\t$ hadoop fs -lsr output\n\t$ mahout seqdumper -i output/clusteredPoints -o clusteredPoints\n\t$ vim clusteredPoints\n\t$ mahout clusterdump -i output/clusters-9-final -o clusters --pointsDir output/clusteredPoints\n\t$ vim clusters\n\n## 分析结果\n\n# 参考资料\n1. [Clustering of synthetic control data](https://cwiki.apache.org/confluence/display/MAHOUT/Clustering+of+synthetic+control+data)\n1. [mahout中的kmeans结果分析](http://blog.csdn.net/aidayei/article/details/6665530)","source":"_posts/2013-07-07-mahout-kmeans-results-analysis.md","raw":"---\nlayout: post\ntitle: \"Mhout KMeans 结果分析\"\ndate: 2013-07-07 17:04\ncomments: true\ncategories: mahout\npublished: false\n---\n\n# 运行KMeans示例\n运行KMeans示例有三种方法，参考前篇一篇博客，[安装mahout]()。\n\n通过阅读`examples\\src\\main\\java\\org\\apache\\mahout\\clustering\\syntheticcontrol\\kmeans\\Job.java`和`integration\\src\\main\\java\\org\\apache\\mahout\\clustering\\conversion\\InputDriver.java`的代码，运行KMeans示例还有第4种方法\n\n利用`InputDriver`将文本格式的向量转化为Mahout能识别的向量，\n\n\t$ hadoop jar ~/mahout-distribution-0.7/mahout-examples-0.7-job.jar org.apache.mahout.clustering.conversion.InputDriver -i testdata -o vector\n\n利用 mahout 自带的命令行工具，\n\n\t$ mahout kmeans -i vector -o output -dm org.apache.mahout.common.distance.EuclideanDistanceMeasure -c centroids -k 6 -cd 0.5 -x 10 -ow \n\n# 分析聚类结果\n\n## 查看结果\n\n\t$ hadoop fs -lsr output\n\t$ mahout seqdumper -i output/clusteredPoints -o clusteredPoints\n\t$ vim clusteredPoints\n\t$ mahout clusterdump -i output/clusters-9-final -o clusters --pointsDir output/clusteredPoints\n\t$ vim clusters\n\n## 分析结果\n\n# 参考资料\n1. [Clustering of synthetic control data](https://cwiki.apache.org/confluence/display/MAHOUT/Clustering+of+synthetic+control+data)\n1. [mahout中的kmeans结果分析](http://blog.csdn.net/aidayei/article/details/6665530)","slug":"2013-07-07-mahout-kmeans-results-analysis","updated":"2016-08-18T09:21:04.000Z","photos":[],"link":"","_id":"cis07pf3g001l01pqoqnmlc5z","content":"<h1 id=\"运行KMeans示例\"><a href=\"#运行KMeans示例\" class=\"headerlink\" title=\"运行KMeans示例\"></a>运行KMeans示例</h1><p>运行KMeans示例有三种方法，参考前篇一篇博客，<a href=\"\">安装mahout</a>。</p>\n<p>通过阅读<code>examples\\src\\main\\java\\org\\apache\\mahout\\clustering\\syntheticcontrol\\kmeans\\Job.java</code>和<code>integration\\src\\main\\java\\org\\apache\\mahout\\clustering\\conversion\\InputDriver.java</code>的代码，运行KMeans示例还有第4种方法</p>\n<p>利用<code>InputDriver</code>将文本格式的向量转化为Mahout能识别的向量，</p>\n<pre><code>$ hadoop jar ~/mahout-distribution-0.7/mahout-examples-0.7-job.jar org.apache.mahout.clustering.conversion.InputDriver -i testdata -o vector\n</code></pre><p>利用 mahout 自带的命令行工具，</p>\n<pre><code>$ mahout kmeans -i vector -o output -dm org.apache.mahout.common.distance.EuclideanDistanceMeasure -c centroids -k 6 -cd 0.5 -x 10 -ow \n</code></pre><h1 id=\"分析聚类结果\"><a href=\"#分析聚类结果\" class=\"headerlink\" title=\"分析聚类结果\"></a>分析聚类结果</h1><h2 id=\"查看结果\"><a href=\"#查看结果\" class=\"headerlink\" title=\"查看结果\"></a>查看结果</h2><pre><code>$ hadoop fs -lsr output\n$ mahout seqdumper -i output/clusteredPoints -o clusteredPoints\n$ vim clusteredPoints\n$ mahout clusterdump -i output/clusters-9-final -o clusters --pointsDir output/clusteredPoints\n$ vim clusters\n</code></pre><h2 id=\"分析结果\"><a href=\"#分析结果\" class=\"headerlink\" title=\"分析结果\"></a>分析结果</h2><h1 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h1><ol>\n<li><a href=\"https://cwiki.apache.org/confluence/display/MAHOUT/Clustering+of+synthetic+control+data\" target=\"_blank\" rel=\"external\">Clustering of synthetic control data</a></li>\n<li><a href=\"http://blog.csdn.net/aidayei/article/details/6665530\" target=\"_blank\" rel=\"external\">mahout中的kmeans结果分析</a></li>\n</ol>\n","excerpt":"","more":"<h1 id=\"运行KMeans示例\"><a href=\"#运行KMeans示例\" class=\"headerlink\" title=\"运行KMeans示例\"></a>运行KMeans示例</h1><p>运行KMeans示例有三种方法，参考前篇一篇博客，<a href=\"\">安装mahout</a>。</p>\n<p>通过阅读<code>examples\\src\\main\\java\\org\\apache\\mahout\\clustering\\syntheticcontrol\\kmeans\\Job.java</code>和<code>integration\\src\\main\\java\\org\\apache\\mahout\\clustering\\conversion\\InputDriver.java</code>的代码，运行KMeans示例还有第4种方法</p>\n<p>利用<code>InputDriver</code>将文本格式的向量转化为Mahout能识别的向量，</p>\n<pre><code>$ hadoop jar ~/mahout-distribution-0.7/mahout-examples-0.7-job.jar org.apache.mahout.clustering.conversion.InputDriver -i testdata -o vector\n</code></pre><p>利用 mahout 自带的命令行工具，</p>\n<pre><code>$ mahout kmeans -i vector -o output -dm org.apache.mahout.common.distance.EuclideanDistanceMeasure -c centroids -k 6 -cd 0.5 -x 10 -ow \n</code></pre><h1 id=\"分析聚类结果\"><a href=\"#分析聚类结果\" class=\"headerlink\" title=\"分析聚类结果\"></a>分析聚类结果</h1><h2 id=\"查看结果\"><a href=\"#查看结果\" class=\"headerlink\" title=\"查看结果\"></a>查看结果</h2><pre><code>$ hadoop fs -lsr output\n$ mahout seqdumper -i output/clusteredPoints -o clusteredPoints\n$ vim clusteredPoints\n$ mahout clusterdump -i output/clusters-9-final -o clusters --pointsDir output/clusteredPoints\n$ vim clusters\n</code></pre><h2 id=\"分析结果\"><a href=\"#分析结果\" class=\"headerlink\" title=\"分析结果\"></a>分析结果</h2><h1 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h1><ol>\n<li><a href=\"https://cwiki.apache.org/confluence/display/MAHOUT/Clustering+of+synthetic+control+data\">Clustering of synthetic control data</a></li>\n<li><a href=\"http://blog.csdn.net/aidayei/article/details/6665530\">mahout中的kmeans结果分析</a></li>\n</ol>\n"},{"layout":"post","title":"安装 mahout","date":"2013-07-04T15:47:00.000Z","comments":1,"published":0,"_content":"\n**前提条件**：已经安装好Hadoop集群，并启动。参考我的博客，[在CentOS上安装Hadoop](http://www.yanjiuyanjiu.com/blog/20130612)，[在Ubuntu上安装Hadoop](http://www.yanjiuyanjiu.com/blog/20120103)。\n\n## 编译源码进行安装\n\n见官网文档， [Installation/Setup](https://cwiki.apache.org/confluence/display/MAHOUT/Mahout+Wiki#MahoutWiki-Installation%2FSetup)\n\n不推荐这个方式，太繁琐。\n\n## 下载预编译好的压缩包进行安装\n\n这种方法最简单。\n\n### 下载\n\n在首页点击右侧的\"Download Mahout\"按钮，下载预编译好的二进制包。我下载的是mahout-distribution-0.7.tar.gz。\n\n### 解压\n\n解压到$HOME目录\n\n\t$ tar -zxf mahout-distribution-0.7.tar.gz\n\t$ cd mahout-distribution-0.7\n\n### 配置\n\n只需要在Master这台机器上配置即可。\n\n设置 HADOOP_PREFIX 环境变量，把Hadoop的安装位置告诉Mahout。或者设置HADOOP_HOME环境变量，不过HADOOP_HOME已经是derecated了，不建议使用。\n\n设置 HADOOP_CONF_DIR，把Hadoop配置文件的位置告诉Mahout。\n\n[可选]为了方便，将mahout命令加入PATH。\n\n将Mahout的jar加入CLASSPATH，在编译代码时需要。\n\n\t$ vim ~/.bash_profile\n\texport HADOOP_PREFIX=$HOME/hadoop-1.1.2\n\texport HADOOP_CONF_DIR=$HADOOP_PREFIX/conf\n\texport PATH=$PATH:$HOME/mahout-distribution-0.7/bin\n\texport CLASSPATH=$CLASSPATH:$HOME/mahout-distribution-0.7/mahout-core-0.7.jar\n\t$ source  ~/.bash_profile\n\n以上配置都是通过阅读 mahout这个脚本才知道的。\n\n\t$ vim mahout-distribution-0.7/bin/mahout\n\n打开这个脚本，可以看到所有配置，一目了然。\n\n\n## 运行自带的 KMeans 例子\n\n主要参考官网文档，[Clustering of synthetic control data](https://cwiki.apache.org/confluence/display/MAHOUT/Clustering+of+synthetic+control+data)。\n\n### 下载数据\n\n下载地址：[synthetic_control.data](http://archive.ics.uci.edu/ml/databases/synthetic_control/synthetic_control.data)  \n[数据格式说明](http://archive.ics.uci.edu/ml/databases/synthetic_control/synthetic_control.data.html)\n\n### 上传到HDFS\n\n\t$ hadoop fs -mkdir testdata\n\t$ hadoop fs -put ./synthetic_control.data testdata\n\nMahout自带的mahout-examples-0.7-job.jar 默认从 testdata目录读取数据，所以目录必须命名为testdata\n\n### 运行自带的kmeans算法\n\n\t$ mahout org.apache.mahout.clustering.syntheticcontrol.kmeans.Job\n\n或者\n\n\t$ hadoop jar ~/mahout-distribution-0.7/mahout-examples-0.7-job.jar org.apache.mahout.clustering.syntheticcontrol.kmeans.Job\n\n或者\n\n\t$ mahout jar ~/mahout-distribution-0.7/mahout-examples-0.7-job.jar org.apache.mahout.clustering.syntheticcontrol.kmeans.Job\n\n三者是等价的。感兴趣的话去阅读 `bin/mahout` 这个脚本，看看最后几行，包含 `exec` 的那几行代码。\n\n### 查看结果\n\n\t$ hadoop fs -lsr output\n\n如果看到以下结果，说明算法运行成功，Mahout的安装也就成功了。\n\n\tclusteredPoints  clusters-0  clusters-1  clusters-10  clusters-2  clusters-3  clusters-4 clusters-5  clusters-6  clusters-7  clusters-8  clusters-9  data\n\n## 参考资料\n1. [Installation/Setup](https://cwiki.apache.org/confluence/display/MAHOUT/Mahout+Wiki#MahoutWiki-Installation%2FSetup)\n1. [Mahout安装与配置](http://www.cnblogs.com/linjiqin/archive/2013/03/15/2961649.html)","source":"_posts/2013-07-04-installing-mahout.md","raw":"---\nlayout: post\ntitle: \"安装 mahout\"\ndate: 2013-07-04 15:47\ncomments: true\ncategories: mahout\npublished: false\n---\n\n**前提条件**：已经安装好Hadoop集群，并启动。参考我的博客，[在CentOS上安装Hadoop](http://www.yanjiuyanjiu.com/blog/20130612)，[在Ubuntu上安装Hadoop](http://www.yanjiuyanjiu.com/blog/20120103)。\n\n## 编译源码进行安装\n\n见官网文档， [Installation/Setup](https://cwiki.apache.org/confluence/display/MAHOUT/Mahout+Wiki#MahoutWiki-Installation%2FSetup)\n\n不推荐这个方式，太繁琐。\n\n## 下载预编译好的压缩包进行安装\n\n这种方法最简单。\n\n### 下载\n\n在首页点击右侧的\"Download Mahout\"按钮，下载预编译好的二进制包。我下载的是mahout-distribution-0.7.tar.gz。\n\n### 解压\n\n解压到$HOME目录\n\n\t$ tar -zxf mahout-distribution-0.7.tar.gz\n\t$ cd mahout-distribution-0.7\n\n### 配置\n\n只需要在Master这台机器上配置即可。\n\n设置 HADOOP_PREFIX 环境变量，把Hadoop的安装位置告诉Mahout。或者设置HADOOP_HOME环境变量，不过HADOOP_HOME已经是derecated了，不建议使用。\n\n设置 HADOOP_CONF_DIR，把Hadoop配置文件的位置告诉Mahout。\n\n[可选]为了方便，将mahout命令加入PATH。\n\n将Mahout的jar加入CLASSPATH，在编译代码时需要。\n\n\t$ vim ~/.bash_profile\n\texport HADOOP_PREFIX=$HOME/hadoop-1.1.2\n\texport HADOOP_CONF_DIR=$HADOOP_PREFIX/conf\n\texport PATH=$PATH:$HOME/mahout-distribution-0.7/bin\n\texport CLASSPATH=$CLASSPATH:$HOME/mahout-distribution-0.7/mahout-core-0.7.jar\n\t$ source  ~/.bash_profile\n\n以上配置都是通过阅读 mahout这个脚本才知道的。\n\n\t$ vim mahout-distribution-0.7/bin/mahout\n\n打开这个脚本，可以看到所有配置，一目了然。\n\n\n## 运行自带的 KMeans 例子\n\n主要参考官网文档，[Clustering of synthetic control data](https://cwiki.apache.org/confluence/display/MAHOUT/Clustering+of+synthetic+control+data)。\n\n### 下载数据\n\n下载地址：[synthetic_control.data](http://archive.ics.uci.edu/ml/databases/synthetic_control/synthetic_control.data)  \n[数据格式说明](http://archive.ics.uci.edu/ml/databases/synthetic_control/synthetic_control.data.html)\n\n### 上传到HDFS\n\n\t$ hadoop fs -mkdir testdata\n\t$ hadoop fs -put ./synthetic_control.data testdata\n\nMahout自带的mahout-examples-0.7-job.jar 默认从 testdata目录读取数据，所以目录必须命名为testdata\n\n### 运行自带的kmeans算法\n\n\t$ mahout org.apache.mahout.clustering.syntheticcontrol.kmeans.Job\n\n或者\n\n\t$ hadoop jar ~/mahout-distribution-0.7/mahout-examples-0.7-job.jar org.apache.mahout.clustering.syntheticcontrol.kmeans.Job\n\n或者\n\n\t$ mahout jar ~/mahout-distribution-0.7/mahout-examples-0.7-job.jar org.apache.mahout.clustering.syntheticcontrol.kmeans.Job\n\n三者是等价的。感兴趣的话去阅读 `bin/mahout` 这个脚本，看看最后几行，包含 `exec` 的那几行代码。\n\n### 查看结果\n\n\t$ hadoop fs -lsr output\n\n如果看到以下结果，说明算法运行成功，Mahout的安装也就成功了。\n\n\tclusteredPoints  clusters-0  clusters-1  clusters-10  clusters-2  clusters-3  clusters-4 clusters-5  clusters-6  clusters-7  clusters-8  clusters-9  data\n\n## 参考资料\n1. [Installation/Setup](https://cwiki.apache.org/confluence/display/MAHOUT/Mahout+Wiki#MahoutWiki-Installation%2FSetup)\n1. [Mahout安装与配置](http://www.cnblogs.com/linjiqin/archive/2013/03/15/2961649.html)","slug":"2013-07-04-installing-mahout","updated":"2016-08-18T09:21:04.000Z","photos":[],"link":"","_id":"cis07pf3i001n01pqs5rnprl7","content":"<p><strong>前提条件</strong>：已经安装好Hadoop集群，并启动。参考我的博客，<a href=\"http://www.yanjiuyanjiu.com/blog/20130612\" target=\"_blank\" rel=\"external\">在CentOS上安装Hadoop</a>，<a href=\"http://www.yanjiuyanjiu.com/blog/20120103\" target=\"_blank\" rel=\"external\">在Ubuntu上安装Hadoop</a>。</p>\n<h2 id=\"编译源码进行安装\"><a href=\"#编译源码进行安装\" class=\"headerlink\" title=\"编译源码进行安装\"></a>编译源码进行安装</h2><p>见官网文档， <a href=\"https://cwiki.apache.org/confluence/display/MAHOUT/Mahout+Wiki#MahoutWiki-Installation%2FSetup\" target=\"_blank\" rel=\"external\">Installation/Setup</a></p>\n<p>不推荐这个方式，太繁琐。</p>\n<h2 id=\"下载预编译好的压缩包进行安装\"><a href=\"#下载预编译好的压缩包进行安装\" class=\"headerlink\" title=\"下载预编译好的压缩包进行安装\"></a>下载预编译好的压缩包进行安装</h2><p>这种方法最简单。</p>\n<h3 id=\"下载\"><a href=\"#下载\" class=\"headerlink\" title=\"下载\"></a>下载</h3><p>在首页点击右侧的”Download Mahout”按钮，下载预编译好的二进制包。我下载的是mahout-distribution-0.7.tar.gz。</p>\n<h3 id=\"解压\"><a href=\"#解压\" class=\"headerlink\" title=\"解压\"></a>解压</h3><p>解压到$HOME目录</p>\n<pre><code>$ tar -zxf mahout-distribution-0.7.tar.gz\n$ cd mahout-distribution-0.7\n</code></pre><h3 id=\"配置\"><a href=\"#配置\" class=\"headerlink\" title=\"配置\"></a>配置</h3><p>只需要在Master这台机器上配置即可。</p>\n<p>设置 HADOOP_PREFIX 环境变量，把Hadoop的安装位置告诉Mahout。或者设置HADOOP_HOME环境变量，不过HADOOP_HOME已经是derecated了，不建议使用。</p>\n<p>设置 HADOOP_CONF_DIR，把Hadoop配置文件的位置告诉Mahout。</p>\n<p>[可选]为了方便，将mahout命令加入PATH。</p>\n<p>将Mahout的jar加入CLASSPATH，在编译代码时需要。</p>\n<pre><code>$ vim ~/.bash_profile\nexport HADOOP_PREFIX=$HOME/hadoop-1.1.2\nexport HADOOP_CONF_DIR=$HADOOP_PREFIX/conf\nexport PATH=$PATH:$HOME/mahout-distribution-0.7/bin\nexport CLASSPATH=$CLASSPATH:$HOME/mahout-distribution-0.7/mahout-core-0.7.jar\n$ source  ~/.bash_profile\n</code></pre><p>以上配置都是通过阅读 mahout这个脚本才知道的。</p>\n<pre><code>$ vim mahout-distribution-0.7/bin/mahout\n</code></pre><p>打开这个脚本，可以看到所有配置，一目了然。</p>\n<h2 id=\"运行自带的-KMeans-例子\"><a href=\"#运行自带的-KMeans-例子\" class=\"headerlink\" title=\"运行自带的 KMeans 例子\"></a>运行自带的 KMeans 例子</h2><p>主要参考官网文档，<a href=\"https://cwiki.apache.org/confluence/display/MAHOUT/Clustering+of+synthetic+control+data\" target=\"_blank\" rel=\"external\">Clustering of synthetic control data</a>。</p>\n<h3 id=\"下载数据\"><a href=\"#下载数据\" class=\"headerlink\" title=\"下载数据\"></a>下载数据</h3><p>下载地址：<a href=\"http://archive.ics.uci.edu/ml/databases/synthetic_control/synthetic_control.data\" target=\"_blank\" rel=\"external\">synthetic_control.data</a><br><a href=\"http://archive.ics.uci.edu/ml/databases/synthetic_control/synthetic_control.data.html\" target=\"_blank\" rel=\"external\">数据格式说明</a></p>\n<h3 id=\"上传到HDFS\"><a href=\"#上传到HDFS\" class=\"headerlink\" title=\"上传到HDFS\"></a>上传到HDFS</h3><pre><code>$ hadoop fs -mkdir testdata\n$ hadoop fs -put ./synthetic_control.data testdata\n</code></pre><p>Mahout自带的mahout-examples-0.7-job.jar 默认从 testdata目录读取数据，所以目录必须命名为testdata</p>\n<h3 id=\"运行自带的kmeans算法\"><a href=\"#运行自带的kmeans算法\" class=\"headerlink\" title=\"运行自带的kmeans算法\"></a>运行自带的kmeans算法</h3><pre><code>$ mahout org.apache.mahout.clustering.syntheticcontrol.kmeans.Job\n</code></pre><p>或者</p>\n<pre><code>$ hadoop jar ~/mahout-distribution-0.7/mahout-examples-0.7-job.jar org.apache.mahout.clustering.syntheticcontrol.kmeans.Job\n</code></pre><p>或者</p>\n<pre><code>$ mahout jar ~/mahout-distribution-0.7/mahout-examples-0.7-job.jar org.apache.mahout.clustering.syntheticcontrol.kmeans.Job\n</code></pre><p>三者是等价的。感兴趣的话去阅读 <code>bin/mahout</code> 这个脚本，看看最后几行，包含 <code>exec</code> 的那几行代码。</p>\n<h3 id=\"查看结果\"><a href=\"#查看结果\" class=\"headerlink\" title=\"查看结果\"></a>查看结果</h3><pre><code>$ hadoop fs -lsr output\n</code></pre><p>如果看到以下结果，说明算法运行成功，Mahout的安装也就成功了。</p>\n<pre><code>clusteredPoints  clusters-0  clusters-1  clusters-10  clusters-2  clusters-3  clusters-4 clusters-5  clusters-6  clusters-7  clusters-8  clusters-9  data\n</code></pre><h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><ol>\n<li><a href=\"https://cwiki.apache.org/confluence/display/MAHOUT/Mahout+Wiki#MahoutWiki-Installation%2FSetup\" target=\"_blank\" rel=\"external\">Installation/Setup</a></li>\n<li><a href=\"http://www.cnblogs.com/linjiqin/archive/2013/03/15/2961649.html\" target=\"_blank\" rel=\"external\">Mahout安装与配置</a></li>\n</ol>\n","excerpt":"","more":"<p><strong>前提条件</strong>：已经安装好Hadoop集群，并启动。参考我的博客，<a href=\"http://www.yanjiuyanjiu.com/blog/20130612\">在CentOS上安装Hadoop</a>，<a href=\"http://www.yanjiuyanjiu.com/blog/20120103\">在Ubuntu上安装Hadoop</a>。</p>\n<h2 id=\"编译源码进行安装\"><a href=\"#编译源码进行安装\" class=\"headerlink\" title=\"编译源码进行安装\"></a>编译源码进行安装</h2><p>见官网文档， <a href=\"https://cwiki.apache.org/confluence/display/MAHOUT/Mahout+Wiki#MahoutWiki-Installation%2FSetup\">Installation/Setup</a></p>\n<p>不推荐这个方式，太繁琐。</p>\n<h2 id=\"下载预编译好的压缩包进行安装\"><a href=\"#下载预编译好的压缩包进行安装\" class=\"headerlink\" title=\"下载预编译好的压缩包进行安装\"></a>下载预编译好的压缩包进行安装</h2><p>这种方法最简单。</p>\n<h3 id=\"下载\"><a href=\"#下载\" class=\"headerlink\" title=\"下载\"></a>下载</h3><p>在首页点击右侧的”Download Mahout”按钮，下载预编译好的二进制包。我下载的是mahout-distribution-0.7.tar.gz。</p>\n<h3 id=\"解压\"><a href=\"#解压\" class=\"headerlink\" title=\"解压\"></a>解压</h3><p>解压到$HOME目录</p>\n<pre><code>$ tar -zxf mahout-distribution-0.7.tar.gz\n$ cd mahout-distribution-0.7\n</code></pre><h3 id=\"配置\"><a href=\"#配置\" class=\"headerlink\" title=\"配置\"></a>配置</h3><p>只需要在Master这台机器上配置即可。</p>\n<p>设置 HADOOP_PREFIX 环境变量，把Hadoop的安装位置告诉Mahout。或者设置HADOOP_HOME环境变量，不过HADOOP_HOME已经是derecated了，不建议使用。</p>\n<p>设置 HADOOP_CONF_DIR，把Hadoop配置文件的位置告诉Mahout。</p>\n<p>[可选]为了方便，将mahout命令加入PATH。</p>\n<p>将Mahout的jar加入CLASSPATH，在编译代码时需要。</p>\n<pre><code>$ vim ~/.bash_profile\nexport HADOOP_PREFIX=$HOME/hadoop-1.1.2\nexport HADOOP_CONF_DIR=$HADOOP_PREFIX/conf\nexport PATH=$PATH:$HOME/mahout-distribution-0.7/bin\nexport CLASSPATH=$CLASSPATH:$HOME/mahout-distribution-0.7/mahout-core-0.7.jar\n$ source  ~/.bash_profile\n</code></pre><p>以上配置都是通过阅读 mahout这个脚本才知道的。</p>\n<pre><code>$ vim mahout-distribution-0.7/bin/mahout\n</code></pre><p>打开这个脚本，可以看到所有配置，一目了然。</p>\n<h2 id=\"运行自带的-KMeans-例子\"><a href=\"#运行自带的-KMeans-例子\" class=\"headerlink\" title=\"运行自带的 KMeans 例子\"></a>运行自带的 KMeans 例子</h2><p>主要参考官网文档，<a href=\"https://cwiki.apache.org/confluence/display/MAHOUT/Clustering+of+synthetic+control+data\">Clustering of synthetic control data</a>。</p>\n<h3 id=\"下载数据\"><a href=\"#下载数据\" class=\"headerlink\" title=\"下载数据\"></a>下载数据</h3><p>下载地址：<a href=\"http://archive.ics.uci.edu/ml/databases/synthetic_control/synthetic_control.data\">synthetic_control.data</a><br><a href=\"http://archive.ics.uci.edu/ml/databases/synthetic_control/synthetic_control.data.html\">数据格式说明</a></p>\n<h3 id=\"上传到HDFS\"><a href=\"#上传到HDFS\" class=\"headerlink\" title=\"上传到HDFS\"></a>上传到HDFS</h3><pre><code>$ hadoop fs -mkdir testdata\n$ hadoop fs -put ./synthetic_control.data testdata\n</code></pre><p>Mahout自带的mahout-examples-0.7-job.jar 默认从 testdata目录读取数据，所以目录必须命名为testdata</p>\n<h3 id=\"运行自带的kmeans算法\"><a href=\"#运行自带的kmeans算法\" class=\"headerlink\" title=\"运行自带的kmeans算法\"></a>运行自带的kmeans算法</h3><pre><code>$ mahout org.apache.mahout.clustering.syntheticcontrol.kmeans.Job\n</code></pre><p>或者</p>\n<pre><code>$ hadoop jar ~/mahout-distribution-0.7/mahout-examples-0.7-job.jar org.apache.mahout.clustering.syntheticcontrol.kmeans.Job\n</code></pre><p>或者</p>\n<pre><code>$ mahout jar ~/mahout-distribution-0.7/mahout-examples-0.7-job.jar org.apache.mahout.clustering.syntheticcontrol.kmeans.Job\n</code></pre><p>三者是等价的。感兴趣的话去阅读 <code>bin/mahout</code> 这个脚本，看看最后几行，包含 <code>exec</code> 的那几行代码。</p>\n<h3 id=\"查看结果\"><a href=\"#查看结果\" class=\"headerlink\" title=\"查看结果\"></a>查看结果</h3><pre><code>$ hadoop fs -lsr output\n</code></pre><p>如果看到以下结果，说明算法运行成功，Mahout的安装也就成功了。</p>\n<pre><code>clusteredPoints  clusters-0  clusters-1  clusters-10  clusters-2  clusters-3  clusters-4 clusters-5  clusters-6  clusters-7  clusters-8  clusters-9  data\n</code></pre><h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><ol>\n<li><a href=\"https://cwiki.apache.org/confluence/display/MAHOUT/Mahout+Wiki#MahoutWiki-Installation%2FSetup\">Installation/Setup</a></li>\n<li><a href=\"http://www.cnblogs.com/linjiqin/archive/2013/03/15/2961649.html\">Mahout安装与配置</a></li>\n</ol>\n"},{"layout":"post","title":"docker安装","date":"2013-10-25T23:41:00.000Z","comments":1,"_content":"\n## 1 在 CentOS 6.4 上安装 docker\n\ndocker当前官方只支持Ubuntu，所以在 CentOS 安装Docker比较麻烦([Issue #172](https://github.com/dotcloud/docker/issues/172))。\n\ndocker官方文档说要求Linux kernel至少3.8以上，CentOS 6.4是2.6的内核，于是我哼哧哼哧的[编译安装了最新的kernel 3.11.6](http://www.yanjiuyanjiu.com/blog/20131024)，重启后运行docker还是失败，最后找到原因，是因为编译时忘记集成aufs模块了。aufs 需要和 kernel 一起编译，很麻烦。\n\n不过不需要这么麻烦，有强人已经编译好了带aufs模块的内核，见这里[Installing docker.io on centos 6.4 (64-bit)](http://nareshv.blogspot.com/2013/08/installing-dockerio-on-centos-64-64-bit.html)\n\n### 1.1 取消selinux，因为它会干扰lxc的正常功能\n\n\tsudo vim /etc/selinux/config \n\tSELINUX=disabled\n\tSELINUXTYPE=targeted\n\n### 1.2 安装 Fedora EPEL \n\n\tsudo yum install http://ftp.riken.jp/Linux/fedora/epel/6/x86_64/epel-release-6-8.noarch.rpm\n\n### 1.3 添加 hop5 repo地址\n\n\tcd /etc/yum.repos.d\n\tsudo wget http://www.hop5.in/yum/el6/hop5.repo\n\n### 1.4 安装 docker-io\n\n\tsudo yum install docker-io\n\n会自动安装带aufs模块的3.10内核，以及docker-io包。\n\n### 1.5 将 cgroup 文件系统添加到 `/etc/fstab` , 只有这样docker才能正常工作\n\n\tsudo echo \"none                    /sys/fs/cgroup          cgroup  defaults        0 0\" >> /etc/fstab\n\n### 1.6 修改grub引导顺序\n\n\tsudo vim /etc/grub.conf\n\tdefault=0\n\n设置default为新安装的内核的位置，一般是0\n\n### 1.7 重启\n\n\tsudo reboot\n\n### 1.8 检查新内核是否引导成功\n\n重启后，检查一下新内核是否引导起来了\n\n\tuname -r\n\t3.10.5-3.el6.x86_64\n\n说明成功了\n\n看一下 aufs是否存在\n\n\tgrep aufs /proc/filesystems \n\tnodev   aufs\n\n说明存在\n\n### 1.9 启动 docker daemon 进程\n\n\tsudo docker -d &\n\n如果你在公司，且公司内部都是通过代理上网，则可以把代理服务器告诉docker，用如下命令(参考[这里](https://github.com/dotcloud/docker/issues/402))：\n\n\tsudo HTTP_PROXY=http://xxx:port docker -d &\n\n### 1.10 下载 ubuntu 镜像\n\n\tsudo docker pull ubuntu\n\n### 1.11 运行 hello world\n\n<!--more-->\n\n\tsudo docker run ubuntu /bin/echo hello world\n\thello world\n\n安装成功了！！\n\n\n## 2 在 Ubuntu 上安装 docker\n\n见官方文档，[Ubuntu Linux](http://docs.docker.io/en/latest/installation/ubuntulinux/)\n","source":"_posts/2013-10-25-docker-installation.md","raw":"---\nlayout: post\ntitle: \"docker安装\"\ndate: 2013-10-25 23:41\ncomments: true\ncategories: Docker\n---\n\n## 1 在 CentOS 6.4 上安装 docker\n\ndocker当前官方只支持Ubuntu，所以在 CentOS 安装Docker比较麻烦([Issue #172](https://github.com/dotcloud/docker/issues/172))。\n\ndocker官方文档说要求Linux kernel至少3.8以上，CentOS 6.4是2.6的内核，于是我哼哧哼哧的[编译安装了最新的kernel 3.11.6](http://www.yanjiuyanjiu.com/blog/20131024)，重启后运行docker还是失败，最后找到原因，是因为编译时忘记集成aufs模块了。aufs 需要和 kernel 一起编译，很麻烦。\n\n不过不需要这么麻烦，有强人已经编译好了带aufs模块的内核，见这里[Installing docker.io on centos 6.4 (64-bit)](http://nareshv.blogspot.com/2013/08/installing-dockerio-on-centos-64-64-bit.html)\n\n### 1.1 取消selinux，因为它会干扰lxc的正常功能\n\n\tsudo vim /etc/selinux/config \n\tSELINUX=disabled\n\tSELINUXTYPE=targeted\n\n### 1.2 安装 Fedora EPEL \n\n\tsudo yum install http://ftp.riken.jp/Linux/fedora/epel/6/x86_64/epel-release-6-8.noarch.rpm\n\n### 1.3 添加 hop5 repo地址\n\n\tcd /etc/yum.repos.d\n\tsudo wget http://www.hop5.in/yum/el6/hop5.repo\n\n### 1.4 安装 docker-io\n\n\tsudo yum install docker-io\n\n会自动安装带aufs模块的3.10内核，以及docker-io包。\n\n### 1.5 将 cgroup 文件系统添加到 `/etc/fstab` , 只有这样docker才能正常工作\n\n\tsudo echo \"none                    /sys/fs/cgroup          cgroup  defaults        0 0\" >> /etc/fstab\n\n### 1.6 修改grub引导顺序\n\n\tsudo vim /etc/grub.conf\n\tdefault=0\n\n设置default为新安装的内核的位置，一般是0\n\n### 1.7 重启\n\n\tsudo reboot\n\n### 1.8 检查新内核是否引导成功\n\n重启后，检查一下新内核是否引导起来了\n\n\tuname -r\n\t3.10.5-3.el6.x86_64\n\n说明成功了\n\n看一下 aufs是否存在\n\n\tgrep aufs /proc/filesystems \n\tnodev   aufs\n\n说明存在\n\n### 1.9 启动 docker daemon 进程\n\n\tsudo docker -d &\n\n如果你在公司，且公司内部都是通过代理上网，则可以把代理服务器告诉docker，用如下命令(参考[这里](https://github.com/dotcloud/docker/issues/402))：\n\n\tsudo HTTP_PROXY=http://xxx:port docker -d &\n\n### 1.10 下载 ubuntu 镜像\n\n\tsudo docker pull ubuntu\n\n### 1.11 运行 hello world\n\n<!--more-->\n\n\tsudo docker run ubuntu /bin/echo hello world\n\thello world\n\n安装成功了！！\n\n\n## 2 在 Ubuntu 上安装 docker\n\n见官方文档，[Ubuntu Linux](http://docs.docker.io/en/latest/installation/ubuntulinux/)\n","slug":"2013-10-25-docker-installation","published":1,"updated":"2016-08-18T09:21:04.000Z","photos":[],"link":"","_id":"cis07pf3k001r01pqkh9wfsxz","content":"<h2 id=\"1-在-CentOS-6-4-上安装-docker\"><a href=\"#1-在-CentOS-6-4-上安装-docker\" class=\"headerlink\" title=\"1 在 CentOS 6.4 上安装 docker\"></a>1 在 CentOS 6.4 上安装 docker</h2><p>docker当前官方只支持Ubuntu，所以在 CentOS 安装Docker比较麻烦(<a href=\"https://github.com/dotcloud/docker/issues/172\" target=\"_blank\" rel=\"external\">Issue #172</a>)。</p>\n<p>docker官方文档说要求Linux kernel至少3.8以上，CentOS 6.4是2.6的内核，于是我哼哧哼哧的<a href=\"http://www.yanjiuyanjiu.com/blog/20131024\" target=\"_blank\" rel=\"external\">编译安装了最新的kernel 3.11.6</a>，重启后运行docker还是失败，最后找到原因，是因为编译时忘记集成aufs模块了。aufs 需要和 kernel 一起编译，很麻烦。</p>\n<p>不过不需要这么麻烦，有强人已经编译好了带aufs模块的内核，见这里<a href=\"http://nareshv.blogspot.com/2013/08/installing-dockerio-on-centos-64-64-bit.html\" target=\"_blank\" rel=\"external\">Installing docker.io on centos 6.4 (64-bit)</a></p>\n<h3 id=\"1-1-取消selinux，因为它会干扰lxc的正常功能\"><a href=\"#1-1-取消selinux，因为它会干扰lxc的正常功能\" class=\"headerlink\" title=\"1.1 取消selinux，因为它会干扰lxc的正常功能\"></a>1.1 取消selinux，因为它会干扰lxc的正常功能</h3><pre><code>sudo vim /etc/selinux/config \nSELINUX=disabled\nSELINUXTYPE=targeted\n</code></pre><h3 id=\"1-2-安装-Fedora-EPEL\"><a href=\"#1-2-安装-Fedora-EPEL\" class=\"headerlink\" title=\"1.2 安装 Fedora EPEL\"></a>1.2 安装 Fedora EPEL</h3><pre><code>sudo yum install http://ftp.riken.jp/Linux/fedora/epel/6/x86_64/epel-release-6-8.noarch.rpm\n</code></pre><h3 id=\"1-3-添加-hop5-repo地址\"><a href=\"#1-3-添加-hop5-repo地址\" class=\"headerlink\" title=\"1.3 添加 hop5 repo地址\"></a>1.3 添加 hop5 repo地址</h3><pre><code>cd /etc/yum.repos.d\nsudo wget http://www.hop5.in/yum/el6/hop5.repo\n</code></pre><h3 id=\"1-4-安装-docker-io\"><a href=\"#1-4-安装-docker-io\" class=\"headerlink\" title=\"1.4 安装 docker-io\"></a>1.4 安装 docker-io</h3><pre><code>sudo yum install docker-io\n</code></pre><p>会自动安装带aufs模块的3.10内核，以及docker-io包。</p>\n<h3 id=\"1-5-将-cgroup-文件系统添加到-etc-fstab-只有这样docker才能正常工作\"><a href=\"#1-5-将-cgroup-文件系统添加到-etc-fstab-只有这样docker才能正常工作\" class=\"headerlink\" title=\"1.5 将 cgroup 文件系统添加到 /etc/fstab , 只有这样docker才能正常工作\"></a>1.5 将 cgroup 文件系统添加到 <code>/etc/fstab</code> , 只有这样docker才能正常工作</h3><pre><code>sudo echo &quot;none                    /sys/fs/cgroup          cgroup  defaults        0 0&quot; &gt;&gt; /etc/fstab\n</code></pre><h3 id=\"1-6-修改grub引导顺序\"><a href=\"#1-6-修改grub引导顺序\" class=\"headerlink\" title=\"1.6 修改grub引导顺序\"></a>1.6 修改grub引导顺序</h3><pre><code>sudo vim /etc/grub.conf\ndefault=0\n</code></pre><p>设置default为新安装的内核的位置，一般是0</p>\n<h3 id=\"1-7-重启\"><a href=\"#1-7-重启\" class=\"headerlink\" title=\"1.7 重启\"></a>1.7 重启</h3><pre><code>sudo reboot\n</code></pre><h3 id=\"1-8-检查新内核是否引导成功\"><a href=\"#1-8-检查新内核是否引导成功\" class=\"headerlink\" title=\"1.8 检查新内核是否引导成功\"></a>1.8 检查新内核是否引导成功</h3><p>重启后，检查一下新内核是否引导起来了</p>\n<pre><code>uname -r\n3.10.5-3.el6.x86_64\n</code></pre><p>说明成功了</p>\n<p>看一下 aufs是否存在</p>\n<pre><code>grep aufs /proc/filesystems \nnodev   aufs\n</code></pre><p>说明存在</p>\n<h3 id=\"1-9-启动-docker-daemon-进程\"><a href=\"#1-9-启动-docker-daemon-进程\" class=\"headerlink\" title=\"1.9 启动 docker daemon 进程\"></a>1.9 启动 docker daemon 进程</h3><pre><code>sudo docker -d &amp;\n</code></pre><p>如果你在公司，且公司内部都是通过代理上网，则可以把代理服务器告诉docker，用如下命令(参考<a href=\"https://github.com/dotcloud/docker/issues/402\" target=\"_blank\" rel=\"external\">这里</a>)：</p>\n<pre><code>sudo HTTP_PROXY=http://xxx:port docker -d &amp;\n</code></pre><h3 id=\"1-10-下载-ubuntu-镜像\"><a href=\"#1-10-下载-ubuntu-镜像\" class=\"headerlink\" title=\"1.10 下载 ubuntu 镜像\"></a>1.10 下载 ubuntu 镜像</h3><pre><code>sudo docker pull ubuntu\n</code></pre><h3 id=\"1-11-运行-hello-world\"><a href=\"#1-11-运行-hello-world\" class=\"headerlink\" title=\"1.11 运行 hello world\"></a>1.11 运行 hello world</h3><a id=\"more\"></a>\n<pre><code>sudo docker run ubuntu /bin/echo hello world\nhello world\n</code></pre><p>安装成功了！！</p>\n<h2 id=\"2-在-Ubuntu-上安装-docker\"><a href=\"#2-在-Ubuntu-上安装-docker\" class=\"headerlink\" title=\"2 在 Ubuntu 上安装 docker\"></a>2 在 Ubuntu 上安装 docker</h2><p>见官方文档，<a href=\"http://docs.docker.io/en/latest/installation/ubuntulinux/\" target=\"_blank\" rel=\"external\">Ubuntu Linux</a></p>\n","excerpt":"<h2 id=\"1-在-CentOS-6-4-上安装-docker\"><a href=\"#1-在-CentOS-6-4-上安装-docker\" class=\"headerlink\" title=\"1 在 CentOS 6.4 上安装 docker\"></a>1 在 CentOS 6.4 上安装 docker</h2><p>docker当前官方只支持Ubuntu，所以在 CentOS 安装Docker比较麻烦(<a href=\"https://github.com/dotcloud/docker/issues/172\">Issue #172</a>)。</p>\n<p>docker官方文档说要求Linux kernel至少3.8以上，CentOS 6.4是2.6的内核，于是我哼哧哼哧的<a href=\"http://www.yanjiuyanjiu.com/blog/20131024\">编译安装了最新的kernel 3.11.6</a>，重启后运行docker还是失败，最后找到原因，是因为编译时忘记集成aufs模块了。aufs 需要和 kernel 一起编译，很麻烦。</p>\n<p>不过不需要这么麻烦，有强人已经编译好了带aufs模块的内核，见这里<a href=\"http://nareshv.blogspot.com/2013/08/installing-dockerio-on-centos-64-64-bit.html\">Installing docker.io on centos 6.4 (64-bit)</a></p>\n<h3 id=\"1-1-取消selinux，因为它会干扰lxc的正常功能\"><a href=\"#1-1-取消selinux，因为它会干扰lxc的正常功能\" class=\"headerlink\" title=\"1.1 取消selinux，因为它会干扰lxc的正常功能\"></a>1.1 取消selinux，因为它会干扰lxc的正常功能</h3><pre><code>sudo vim /etc/selinux/config \nSELINUX=disabled\nSELINUXTYPE=targeted\n</code></pre><h3 id=\"1-2-安装-Fedora-EPEL\"><a href=\"#1-2-安装-Fedora-EPEL\" class=\"headerlink\" title=\"1.2 安装 Fedora EPEL\"></a>1.2 安装 Fedora EPEL</h3><pre><code>sudo yum install http://ftp.riken.jp/Linux/fedora/epel/6/x86_64/epel-release-6-8.noarch.rpm\n</code></pre><h3 id=\"1-3-添加-hop5-repo地址\"><a href=\"#1-3-添加-hop5-repo地址\" class=\"headerlink\" title=\"1.3 添加 hop5 repo地址\"></a>1.3 添加 hop5 repo地址</h3><pre><code>cd /etc/yum.repos.d\nsudo wget http://www.hop5.in/yum/el6/hop5.repo\n</code></pre><h3 id=\"1-4-安装-docker-io\"><a href=\"#1-4-安装-docker-io\" class=\"headerlink\" title=\"1.4 安装 docker-io\"></a>1.4 安装 docker-io</h3><pre><code>sudo yum install docker-io\n</code></pre><p>会自动安装带aufs模块的3.10内核，以及docker-io包。</p>\n<h3 id=\"1-5-将-cgroup-文件系统添加到-etc-fstab-只有这样docker才能正常工作\"><a href=\"#1-5-将-cgroup-文件系统添加到-etc-fstab-只有这样docker才能正常工作\" class=\"headerlink\" title=\"1.5 将 cgroup 文件系统添加到 /etc/fstab , 只有这样docker才能正常工作\"></a>1.5 将 cgroup 文件系统添加到 <code>/etc/fstab</code> , 只有这样docker才能正常工作</h3><pre><code>sudo echo &quot;none                    /sys/fs/cgroup          cgroup  defaults        0 0&quot; &gt;&gt; /etc/fstab\n</code></pre><h3 id=\"1-6-修改grub引导顺序\"><a href=\"#1-6-修改grub引导顺序\" class=\"headerlink\" title=\"1.6 修改grub引导顺序\"></a>1.6 修改grub引导顺序</h3><pre><code>sudo vim /etc/grub.conf\ndefault=0\n</code></pre><p>设置default为新安装的内核的位置，一般是0</p>\n<h3 id=\"1-7-重启\"><a href=\"#1-7-重启\" class=\"headerlink\" title=\"1.7 重启\"></a>1.7 重启</h3><pre><code>sudo reboot\n</code></pre><h3 id=\"1-8-检查新内核是否引导成功\"><a href=\"#1-8-检查新内核是否引导成功\" class=\"headerlink\" title=\"1.8 检查新内核是否引导成功\"></a>1.8 检查新内核是否引导成功</h3><p>重启后，检查一下新内核是否引导起来了</p>\n<pre><code>uname -r\n3.10.5-3.el6.x86_64\n</code></pre><p>说明成功了</p>\n<p>看一下 aufs是否存在</p>\n<pre><code>grep aufs /proc/filesystems \nnodev   aufs\n</code></pre><p>说明存在</p>\n<h3 id=\"1-9-启动-docker-daemon-进程\"><a href=\"#1-9-启动-docker-daemon-进程\" class=\"headerlink\" title=\"1.9 启动 docker daemon 进程\"></a>1.9 启动 docker daemon 进程</h3><pre><code>sudo docker -d &amp;\n</code></pre><p>如果你在公司，且公司内部都是通过代理上网，则可以把代理服务器告诉docker，用如下命令(参考<a href=\"https://github.com/dotcloud/docker/issues/402\">这里</a>)：</p>\n<pre><code>sudo HTTP_PROXY=http://xxx:port docker -d &amp;\n</code></pre><h3 id=\"1-10-下载-ubuntu-镜像\"><a href=\"#1-10-下载-ubuntu-镜像\" class=\"headerlink\" title=\"1.10 下载 ubuntu 镜像\"></a>1.10 下载 ubuntu 镜像</h3><pre><code>sudo docker pull ubuntu\n</code></pre><h3 id=\"1-11-运行-hello-world\"><a href=\"#1-11-运行-hello-world\" class=\"headerlink\" title=\"1.11 运行 hello world\"></a>1.11 运行 hello world</h3>","more":"<pre><code>sudo docker run ubuntu /bin/echo hello world\nhello world\n</code></pre><p>安装成功了！！</p>\n<h2 id=\"2-在-Ubuntu-上安装-docker\"><a href=\"#2-在-Ubuntu-上安装-docker\" class=\"headerlink\" title=\"2 在 Ubuntu 上安装 docker\"></a>2 在 Ubuntu 上安装 docker</h2><p>见官方文档，<a href=\"http://docs.docker.io/en/latest/installation/ubuntulinux/\">Ubuntu Linux</a></p>"},{"layout":"post","title":"Ansible快速入门","date":"2013-10-16T16:53:00.000Z","comments":1,"published":0,"_content":"Ansible 是一个新工具，比Puppet,Chef要轻量很多。只需要在一台机器上安装，slave机器不需要安装。有点像一个增强版的pssh。\n\n本文主要参考官方文档 [docs](http://www.ansibleworks.com/docs/)\n\n环境：CentOS 6.4\n\n## 安装 ansible\n选一台机器作为master，在上面安装Ansible。\n\n\tsudo yum install ansible\n\n## 配置SSH无密码登陆\n要让master能够无密码登陆所有的slave机器。参考我另一篇博客，[在CentOS上安装Hadoop](http://www.yanjiuyanjiu.com/blog/20130612/)，里面的“配置 master 无密码登陆到所有机”这节。\n\n## 测试一下\n\n\tansible all -a \"/bin/echo hello\"\n\n如果hosts文件里的所有机器都返回了结果，说明安装成功了。\n\n\n","source":"_posts/2013-10-16-ansible-tutorial.md","raw":"---\nlayout: post\ntitle: \"Ansible快速入门\"\ndate: 2013-10-16 16:53\ncomments: true\ncategories: DevOps\npublished: false\n---\nAnsible 是一个新工具，比Puppet,Chef要轻量很多。只需要在一台机器上安装，slave机器不需要安装。有点像一个增强版的pssh。\n\n本文主要参考官方文档 [docs](http://www.ansibleworks.com/docs/)\n\n环境：CentOS 6.4\n\n## 安装 ansible\n选一台机器作为master，在上面安装Ansible。\n\n\tsudo yum install ansible\n\n## 配置SSH无密码登陆\n要让master能够无密码登陆所有的slave机器。参考我另一篇博客，[在CentOS上安装Hadoop](http://www.yanjiuyanjiu.com/blog/20130612/)，里面的“配置 master 无密码登陆到所有机”这节。\n\n## 测试一下\n\n\tansible all -a \"/bin/echo hello\"\n\n如果hosts文件里的所有机器都返回了结果，说明安装成功了。\n\n\n","slug":"2013-10-16-ansible-tutorial","updated":"2016-08-18T09:21:04.000Z","photos":[],"link":"","_id":"cis07pf3m001u01pqn52pmfc2","content":"<p>Ansible 是一个新工具，比Puppet,Chef要轻量很多。只需要在一台机器上安装，slave机器不需要安装。有点像一个增强版的pssh。</p>\n<p>本文主要参考官方文档 <a href=\"http://www.ansibleworks.com/docs/\" target=\"_blank\" rel=\"external\">docs</a></p>\n<p>环境：CentOS 6.4</p>\n<h2 id=\"安装-ansible\"><a href=\"#安装-ansible\" class=\"headerlink\" title=\"安装 ansible\"></a>安装 ansible</h2><p>选一台机器作为master，在上面安装Ansible。</p>\n<pre><code>sudo yum install ansible\n</code></pre><h2 id=\"配置SSH无密码登陆\"><a href=\"#配置SSH无密码登陆\" class=\"headerlink\" title=\"配置SSH无密码登陆\"></a>配置SSH无密码登陆</h2><p>要让master能够无密码登陆所有的slave机器。参考我另一篇博客，<a href=\"http://www.yanjiuyanjiu.com/blog/20130612/\" target=\"_blank\" rel=\"external\">在CentOS上安装Hadoop</a>，里面的“配置 master 无密码登陆到所有机”这节。</p>\n<h2 id=\"测试一下\"><a href=\"#测试一下\" class=\"headerlink\" title=\"测试一下\"></a>测试一下</h2><pre><code>ansible all -a &quot;/bin/echo hello&quot;\n</code></pre><p>如果hosts文件里的所有机器都返回了结果，说明安装成功了。</p>\n","excerpt":"","more":"<p>Ansible 是一个新工具，比Puppet,Chef要轻量很多。只需要在一台机器上安装，slave机器不需要安装。有点像一个增强版的pssh。</p>\n<p>本文主要参考官方文档 <a href=\"http://www.ansibleworks.com/docs/\">docs</a></p>\n<p>环境：CentOS 6.4</p>\n<h2 id=\"安装-ansible\"><a href=\"#安装-ansible\" class=\"headerlink\" title=\"安装 ansible\"></a>安装 ansible</h2><p>选一台机器作为master，在上面安装Ansible。</p>\n<pre><code>sudo yum install ansible\n</code></pre><h2 id=\"配置SSH无密码登陆\"><a href=\"#配置SSH无密码登陆\" class=\"headerlink\" title=\"配置SSH无密码登陆\"></a>配置SSH无密码登陆</h2><p>要让master能够无密码登陆所有的slave机器。参考我另一篇博客，<a href=\"http://www.yanjiuyanjiu.com/blog/20130612/\">在CentOS上安装Hadoop</a>，里面的“配置 master 无密码登陆到所有机”这节。</p>\n<h2 id=\"测试一下\"><a href=\"#测试一下\" class=\"headerlink\" title=\"测试一下\"></a>测试一下</h2><pre><code>ansible all -a &quot;/bin/echo hello&quot;\n</code></pre><p>如果hosts文件里的所有机器都返回了结果，说明安装成功了。</p>\n"},{"layout":"post","title":"在Eclipse里运行Nutch","date":"2014-01-20T04:11:00.000Z","comments":1,"_content":"\n环境：Ubuntu Desktop 12.04，JDK 1.7, Nutch 1.7\n\n本文主要参考[Running Nutch in Eclipse](http://wiki.apache.org/nutch/RunNutchInEclipse)\n\n##前提\n\n* 机器上安装了Ant, Eclipse\n* Eclipse安装了subclipse, update site 是 <http://subclipse.tigris.org/update_1.10.x>\n* Eclipse安装了IvyDE, update site 是 <http://www.apache.org/dist/ant/ivyde/updatesite>\n* Eclipse安装了m2e插件，update site 是 <http://download.eclipse.org/technology/m2e/releases>\n\n##1 下载源码\n有两种方法，\n\n1. 去官网首页下载apache-nutch-1.7-src.tar.gz\n1. 用svn checkout\n\n        $ svn co https://svn.apache.org/repos/asf/nutch/tags/release-1.7\n\n推荐用第2种方法，因为用SVN checkout出来的有`pom.xml`文件，即maven文件，但是压缩包里没有，只有ant的`build.xml`文件。\n\n##2 配置\n把 conf/ 下的 `nutch-site.xml.template`复制一份，命名为`nutch-site.xml`，在里面添加如下配置：\n\n    <property>\n      <name>http.agent.name</name>\n      <value>My Nutch Spider</value>\n    </property>\n    <property>\n      <name>plugin.folders</name>\n      <value>$NUTCH_HOME/build/plugins</value>\n    </property>\n\n`$NUTCH_HOME`是指nutch源码的根目录，例如我的是`/home/soulmachine/local/opt/apache-nutch-1.7`.\n\n##3 生成Eclipse项目文件，即.project文件\n\n    $ ant eclipse\n\n<!--more-->\n\n如果发现一直卡在 `ivy:resolve .....`这里，原因很有可能是 <http://repo1.maven.org>被墙，参考[这里](http://blog.csdn.net/majian_1987/article/details/17004531)，这时候要设置HTTP代理，\n\n    $ Ctrl+C\n    $ export HTTP_PROXY=localhost:8087    #我用的goagent\n    $ ant runtime\n\n##4 加载到Eclipse\n启动Eclipse，点击\"File->Import->General->Existing projects into workspace\"，浏览到`$NUTCH_DIR`，点击\"Finish\"。\n\n![](http://wiki.apache.org/nutch/RunNutchInEclipse?action=AttachFile&do=get&target=importproject.png)\n\n请等待一会儿，让Eclipse解析该项目，可以在右下角看到状态。\n\n##5 把conf/目录加入到class folder\n在Package Explorer里右击项目，选择\"Build Path->Configure Build Path->Order and Export\"，下拉滚动条，找到conf/目录，打上勾，点击\"Top\"按钮。\n\n![](http://wiki.apache.org/nutch/RunNutchInEclipse?action=AttachFile&do=get&target=order_and_export.png)\n\n##6 在Eclipse里运行org.apache.nutch.crawl.Crawl来抓取网页\n在Package Explorer里找到`org.apache.nutch.crawl.Crawl`，右击，选择\"Run as -> Java Application\"，发现输出如下：\n\n    Usage: Crawl <urlDir> -solr <solrURL> [-dir d] [-threads n] [-depth i] [-topN N]\n\n因为我们没有给main()函数提供必要的参数。\n\n###6.1 添加种子URL\n\n    $ cd PROJECT_DIR\n    $ mkdir urls\n    $ vim ./urls/seed.txt\n    http://movie.douban.com/subject/5323968/\n\n###6.2 设置URL过滤规则\n如果只想抓取某种类型的URL，可以在 `conf/regex-urlfilter.txt`设置正则表达式，于是，只有匹配这些正则表达式的URL才会被抓取。\n\n例如，我只想抓取豆瓣电影的数据，可以这样设置：\n\n    #注释掉这一行\n    # skip URLs containing certain characters as probable queries, etc.\n    #-[?*!@=]\n    # accept anything else\n    #注释掉这行\n    #+.\n    +^http:\\/\\/movie\\.douban\\.com\\/subject\\/[0-9]+\\/(\\?.+)?$\n\n**注意**，每次修改了conf目录中的配置文件，必须重新编译，修改才能生效，原因是ant里有拷贝文件的任务，将conf/下的xml文件拷贝到`runtie/local/conf`和`runtime/deploy/conf`下。\n\n这里，我们不再使用命令行编译，而是在eclipse里右击build.xml，选择`Run as -> Ant Build`.\n\n###6.3 安装Solr\n见我的这篇文章，[Nutch 快速入门(Nutch 1.7)](http://www.yanjiuyanjiu.com/blog/20140121/) 第6节。\n\n###6.4 给main()函数提供参数\n右击`org.apache.nutch.crawl.Crawl`，选择\"Run as -> Run Configurations\"，在`Program arguments`里填写：\n\n    urls -solr http://localhost:8983/solr/ -dir TestCrawl -depth 2 -topN 5\n\n在\"VM Arguments\"里填写`-Dhadoop.log.dir=logs -Dhadoop.log.file=hadoop.log`\n\n###6.5 运行\n最后点击\"Apply\", \"Run\"，就开始抓取了。\n\n###6.6 查看结果\n\n####6.6.1 查看segments目录\n右击`org.apache.nutch.segment.SegmentReader`，选择\"Run as -> Run Configurations\"，在`Program arguments`里填写：\n\n    -dump TestCrawl/segments/* TestCrawl/segments/dump\n\n然后点击\"Run\"。\n\n用文本编辑器打开文件 `TestCrawl/segments/dump/dump`查看segments中存储的信息。\n\n####6.6.2 查看crawldb目录\n右击`org.apache.nutch.crawl.CrawlDbReader`，选择\"Run as -> Run Configurations\"，在`Program arguments`里填写：\n\n    TestCrawl/crawldb -stats\n\n然后点击\"Run\"，控制台会输出 crawldb统计信息。\n\n####6.6.3 查看linkdb目录\n右击`org.apache.nutch.crawl.LinkDbReader`，选择\"Run as -> Run Configurations\"，在`Program arguments`里填写：\n\n    TestCrawl/linkdb -dump TestCrawl/linkdb_dump\n\n然后点击\"Run\"。\n\n用文本编辑器打开文件 `TestCrawl/linkdb_dump/part-00000`查看linkdb中存储的信息\n\n\n###6.7 每个nutch命令对应的java类\n怎么知道每个nutch命令对应的java类呢？打开`src/bin/nutch`并滚动到底部，就会找到每个命令对应的java类。\n\n##7 在Eclipse里单步调试\n以上费了这么大劲，为的是什么？就是为了利用Eclipse这个强大的IDE，能够进行单步调试。写代码其实不花时间，调试才是最花时间的，因此一定要有好的调试工具，磨刀不误砍柴功。\n\n如果想调试某一个类的代码，在Eclipse里下断点，然后\"Debug as ...\"就可以了。\n\n由于有Hadoop job的关系，比较难以难以在哪些地方下断点好。下面给出了Nutch 1.x 的代码中，一些比较好的断点位置：\n\n* Fetcher [line: 1115] - run\n* Fetcher [line: 530] - fetch\n* Fetcher$FetcherThread [line: 560] - run()\n* Generator [line: 443] - generate\n* Generator$Selector [line: 108] - map\n* OutlinkExtractor [line: 71 & 74] - getOutlinks\n\n\n##相关文章\n[Nutch 快速入门(Nutch 1.7)](http://www.yanjiuyanjiu.com/blog/20140121/)\n\n[Nutch 快速入门(Nutch 2.2.1)](http://www.yanjiuyanjiu.com/blog/20140201/)\n\n","source":"_posts/2014-01-20-Running-Nutch-in-Eclipse.md","raw":"---\nlayout: post\ntitle: \"在Eclipse里运行Nutch\"\ndate: 2014-01-20 04:11\ncomments: true\ncategories: Search-Engine\n---\n\n环境：Ubuntu Desktop 12.04，JDK 1.7, Nutch 1.7\n\n本文主要参考[Running Nutch in Eclipse](http://wiki.apache.org/nutch/RunNutchInEclipse)\n\n##前提\n\n* 机器上安装了Ant, Eclipse\n* Eclipse安装了subclipse, update site 是 <http://subclipse.tigris.org/update_1.10.x>\n* Eclipse安装了IvyDE, update site 是 <http://www.apache.org/dist/ant/ivyde/updatesite>\n* Eclipse安装了m2e插件，update site 是 <http://download.eclipse.org/technology/m2e/releases>\n\n##1 下载源码\n有两种方法，\n\n1. 去官网首页下载apache-nutch-1.7-src.tar.gz\n1. 用svn checkout\n\n        $ svn co https://svn.apache.org/repos/asf/nutch/tags/release-1.7\n\n推荐用第2种方法，因为用SVN checkout出来的有`pom.xml`文件，即maven文件，但是压缩包里没有，只有ant的`build.xml`文件。\n\n##2 配置\n把 conf/ 下的 `nutch-site.xml.template`复制一份，命名为`nutch-site.xml`，在里面添加如下配置：\n\n    <property>\n      <name>http.agent.name</name>\n      <value>My Nutch Spider</value>\n    </property>\n    <property>\n      <name>plugin.folders</name>\n      <value>$NUTCH_HOME/build/plugins</value>\n    </property>\n\n`$NUTCH_HOME`是指nutch源码的根目录，例如我的是`/home/soulmachine/local/opt/apache-nutch-1.7`.\n\n##3 生成Eclipse项目文件，即.project文件\n\n    $ ant eclipse\n\n<!--more-->\n\n如果发现一直卡在 `ivy:resolve .....`这里，原因很有可能是 <http://repo1.maven.org>被墙，参考[这里](http://blog.csdn.net/majian_1987/article/details/17004531)，这时候要设置HTTP代理，\n\n    $ Ctrl+C\n    $ export HTTP_PROXY=localhost:8087    #我用的goagent\n    $ ant runtime\n\n##4 加载到Eclipse\n启动Eclipse，点击\"File->Import->General->Existing projects into workspace\"，浏览到`$NUTCH_DIR`，点击\"Finish\"。\n\n![](http://wiki.apache.org/nutch/RunNutchInEclipse?action=AttachFile&do=get&target=importproject.png)\n\n请等待一会儿，让Eclipse解析该项目，可以在右下角看到状态。\n\n##5 把conf/目录加入到class folder\n在Package Explorer里右击项目，选择\"Build Path->Configure Build Path->Order and Export\"，下拉滚动条，找到conf/目录，打上勾，点击\"Top\"按钮。\n\n![](http://wiki.apache.org/nutch/RunNutchInEclipse?action=AttachFile&do=get&target=order_and_export.png)\n\n##6 在Eclipse里运行org.apache.nutch.crawl.Crawl来抓取网页\n在Package Explorer里找到`org.apache.nutch.crawl.Crawl`，右击，选择\"Run as -> Java Application\"，发现输出如下：\n\n    Usage: Crawl <urlDir> -solr <solrURL> [-dir d] [-threads n] [-depth i] [-topN N]\n\n因为我们没有给main()函数提供必要的参数。\n\n###6.1 添加种子URL\n\n    $ cd PROJECT_DIR\n    $ mkdir urls\n    $ vim ./urls/seed.txt\n    http://movie.douban.com/subject/5323968/\n\n###6.2 设置URL过滤规则\n如果只想抓取某种类型的URL，可以在 `conf/regex-urlfilter.txt`设置正则表达式，于是，只有匹配这些正则表达式的URL才会被抓取。\n\n例如，我只想抓取豆瓣电影的数据，可以这样设置：\n\n    #注释掉这一行\n    # skip URLs containing certain characters as probable queries, etc.\n    #-[?*!@=]\n    # accept anything else\n    #注释掉这行\n    #+.\n    +^http:\\/\\/movie\\.douban\\.com\\/subject\\/[0-9]+\\/(\\?.+)?$\n\n**注意**，每次修改了conf目录中的配置文件，必须重新编译，修改才能生效，原因是ant里有拷贝文件的任务，将conf/下的xml文件拷贝到`runtie/local/conf`和`runtime/deploy/conf`下。\n\n这里，我们不再使用命令行编译，而是在eclipse里右击build.xml，选择`Run as -> Ant Build`.\n\n###6.3 安装Solr\n见我的这篇文章，[Nutch 快速入门(Nutch 1.7)](http://www.yanjiuyanjiu.com/blog/20140121/) 第6节。\n\n###6.4 给main()函数提供参数\n右击`org.apache.nutch.crawl.Crawl`，选择\"Run as -> Run Configurations\"，在`Program arguments`里填写：\n\n    urls -solr http://localhost:8983/solr/ -dir TestCrawl -depth 2 -topN 5\n\n在\"VM Arguments\"里填写`-Dhadoop.log.dir=logs -Dhadoop.log.file=hadoop.log`\n\n###6.5 运行\n最后点击\"Apply\", \"Run\"，就开始抓取了。\n\n###6.6 查看结果\n\n####6.6.1 查看segments目录\n右击`org.apache.nutch.segment.SegmentReader`，选择\"Run as -> Run Configurations\"，在`Program arguments`里填写：\n\n    -dump TestCrawl/segments/* TestCrawl/segments/dump\n\n然后点击\"Run\"。\n\n用文本编辑器打开文件 `TestCrawl/segments/dump/dump`查看segments中存储的信息。\n\n####6.6.2 查看crawldb目录\n右击`org.apache.nutch.crawl.CrawlDbReader`，选择\"Run as -> Run Configurations\"，在`Program arguments`里填写：\n\n    TestCrawl/crawldb -stats\n\n然后点击\"Run\"，控制台会输出 crawldb统计信息。\n\n####6.6.3 查看linkdb目录\n右击`org.apache.nutch.crawl.LinkDbReader`，选择\"Run as -> Run Configurations\"，在`Program arguments`里填写：\n\n    TestCrawl/linkdb -dump TestCrawl/linkdb_dump\n\n然后点击\"Run\"。\n\n用文本编辑器打开文件 `TestCrawl/linkdb_dump/part-00000`查看linkdb中存储的信息\n\n\n###6.7 每个nutch命令对应的java类\n怎么知道每个nutch命令对应的java类呢？打开`src/bin/nutch`并滚动到底部，就会找到每个命令对应的java类。\n\n##7 在Eclipse里单步调试\n以上费了这么大劲，为的是什么？就是为了利用Eclipse这个强大的IDE，能够进行单步调试。写代码其实不花时间，调试才是最花时间的，因此一定要有好的调试工具，磨刀不误砍柴功。\n\n如果想调试某一个类的代码，在Eclipse里下断点，然后\"Debug as ...\"就可以了。\n\n由于有Hadoop job的关系，比较难以难以在哪些地方下断点好。下面给出了Nutch 1.x 的代码中，一些比较好的断点位置：\n\n* Fetcher [line: 1115] - run\n* Fetcher [line: 530] - fetch\n* Fetcher$FetcherThread [line: 560] - run()\n* Generator [line: 443] - generate\n* Generator$Selector [line: 108] - map\n* OutlinkExtractor [line: 71 & 74] - getOutlinks\n\n\n##相关文章\n[Nutch 快速入门(Nutch 1.7)](http://www.yanjiuyanjiu.com/blog/20140121/)\n\n[Nutch 快速入门(Nutch 2.2.1)](http://www.yanjiuyanjiu.com/blog/20140201/)\n\n","slug":"2014-01-20-Running-Nutch-in-Eclipse","published":1,"updated":"2016-08-18T09:21:04.000Z","photos":[],"link":"","_id":"cis07pf3n001w01pqgckpy06e","content":"<p>环境：Ubuntu Desktop 12.04，JDK 1.7, Nutch 1.7</p>\n<p>本文主要参考<a href=\"http://wiki.apache.org/nutch/RunNutchInEclipse\" target=\"_blank\" rel=\"external\">Running Nutch in Eclipse</a></p>\n<p>##前提</p>\n<ul>\n<li>机器上安装了Ant, Eclipse</li>\n<li>Eclipse安装了subclipse, update site 是 <a href=\"http://subclipse.tigris.org/update_1.10.x\" target=\"_blank\" rel=\"external\">http://subclipse.tigris.org/update_1.10.x</a></li>\n<li>Eclipse安装了IvyDE, update site 是 <a href=\"http://www.apache.org/dist/ant/ivyde/updatesite\" target=\"_blank\" rel=\"external\">http://www.apache.org/dist/ant/ivyde/updatesite</a></li>\n<li>Eclipse安装了m2e插件，update site 是 <a href=\"http://download.eclipse.org/technology/m2e/releases\" target=\"_blank\" rel=\"external\">http://download.eclipse.org/technology/m2e/releases</a></li>\n</ul>\n<p>##1 下载源码<br>有两种方法，</p>\n<ol>\n<li>去官网首页下载apache-nutch-1.7-src.tar.gz</li>\n<li><p>用svn checkout</p>\n<pre><code>$ svn co https://svn.apache.org/repos/asf/nutch/tags/release-1.7\n</code></pre></li>\n</ol>\n<p>推荐用第2种方法，因为用SVN checkout出来的有<code>pom.xml</code>文件，即maven文件，但是压缩包里没有，只有ant的<code>build.xml</code>文件。</p>\n<p>##2 配置<br>把 conf/ 下的 <code>nutch-site.xml.template</code>复制一份，命名为<code>nutch-site.xml</code>，在里面添加如下配置：</p>\n<pre><code>&lt;property&gt;\n  &lt;name&gt;http.agent.name&lt;/name&gt;\n  &lt;value&gt;My Nutch Spider&lt;/value&gt;\n&lt;/property&gt;\n&lt;property&gt;\n  &lt;name&gt;plugin.folders&lt;/name&gt;\n  &lt;value&gt;$NUTCH_HOME/build/plugins&lt;/value&gt;\n&lt;/property&gt;\n</code></pre><p><code>$NUTCH_HOME</code>是指nutch源码的根目录，例如我的是<code>/home/soulmachine/local/opt/apache-nutch-1.7</code>.</p>\n<p>##3 生成Eclipse项目文件，即.project文件</p>\n<pre><code>$ ant eclipse\n</code></pre><a id=\"more\"></a>\n<p>如果发现一直卡在 <code>ivy:resolve .....</code>这里，原因很有可能是 <a href=\"http://repo1.maven.org\" target=\"_blank\" rel=\"external\">http://repo1.maven.org</a>被墙，参考<a href=\"http://blog.csdn.net/majian_1987/article/details/17004531\" target=\"_blank\" rel=\"external\">这里</a>，这时候要设置HTTP代理，</p>\n<pre><code>$ Ctrl+C\n$ export HTTP_PROXY=localhost:8087    #我用的goagent\n$ ant runtime\n</code></pre><p>##4 加载到Eclipse<br>启动Eclipse，点击”File-&gt;Import-&gt;General-&gt;Existing projects into workspace”，浏览到<code>$NUTCH_DIR</code>，点击”Finish”。</p>\n<p><img src=\"http://wiki.apache.org/nutch/RunNutchInEclipse?action=AttachFile&amp;do=get&amp;target=importproject.png\" alt=\"\"></p>\n<p>请等待一会儿，让Eclipse解析该项目，可以在右下角看到状态。</p>\n<p>##5 把conf/目录加入到class folder<br>在Package Explorer里右击项目，选择”Build Path-&gt;Configure Build Path-&gt;Order and Export”，下拉滚动条，找到conf/目录，打上勾，点击”Top”按钮。</p>\n<p><img src=\"http://wiki.apache.org/nutch/RunNutchInEclipse?action=AttachFile&amp;do=get&amp;target=order_and_export.png\" alt=\"\"></p>\n<p>##6 在Eclipse里运行org.apache.nutch.crawl.Crawl来抓取网页<br>在Package Explorer里找到<code>org.apache.nutch.crawl.Crawl</code>，右击，选择”Run as -&gt; Java Application”，发现输出如下：</p>\n<pre><code>Usage: Crawl &lt;urlDir&gt; -solr &lt;solrURL&gt; [-dir d] [-threads n] [-depth i] [-topN N]\n</code></pre><p>因为我们没有给main()函数提供必要的参数。</p>\n<p>###6.1 添加种子URL</p>\n<pre><code>$ cd PROJECT_DIR\n$ mkdir urls\n$ vim ./urls/seed.txt\nhttp://movie.douban.com/subject/5323968/\n</code></pre><p>###6.2 设置URL过滤规则<br>如果只想抓取某种类型的URL，可以在 <code>conf/regex-urlfilter.txt</code>设置正则表达式，于是，只有匹配这些正则表达式的URL才会被抓取。</p>\n<p>例如，我只想抓取豆瓣电影的数据，可以这样设置：</p>\n<pre><code>#注释掉这一行\n# skip URLs containing certain characters as probable queries, etc.\n#-[?*!@=]\n# accept anything else\n#注释掉这行\n#+.\n+^http:\\/\\/movie\\.douban\\.com\\/subject\\/[0-9]+\\/(\\?.+)?$\n</code></pre><p><strong>注意</strong>，每次修改了conf目录中的配置文件，必须重新编译，修改才能生效，原因是ant里有拷贝文件的任务，将conf/下的xml文件拷贝到<code>runtie/local/conf</code>和<code>runtime/deploy/conf</code>下。</p>\n<p>这里，我们不再使用命令行编译，而是在eclipse里右击build.xml，选择<code>Run as -&gt; Ant Build</code>.</p>\n<p>###6.3 安装Solr<br>见我的这篇文章，<a href=\"http://www.yanjiuyanjiu.com/blog/20140121/\" target=\"_blank\" rel=\"external\">Nutch 快速入门(Nutch 1.7)</a> 第6节。</p>\n<p>###6.4 给main()函数提供参数<br>右击<code>org.apache.nutch.crawl.Crawl</code>，选择”Run as -&gt; Run Configurations”，在<code>Program arguments</code>里填写：</p>\n<pre><code>urls -solr http://localhost:8983/solr/ -dir TestCrawl -depth 2 -topN 5\n</code></pre><p>在”VM Arguments”里填写<code>-Dhadoop.log.dir=logs -Dhadoop.log.file=hadoop.log</code></p>\n<p>###6.5 运行<br>最后点击”Apply”, “Run”，就开始抓取了。</p>\n<p>###6.6 查看结果</p>\n<p>####6.6.1 查看segments目录<br>右击<code>org.apache.nutch.segment.SegmentReader</code>，选择”Run as -&gt; Run Configurations”，在<code>Program arguments</code>里填写：</p>\n<pre><code>-dump TestCrawl/segments/* TestCrawl/segments/dump\n</code></pre><p>然后点击”Run”。</p>\n<p>用文本编辑器打开文件 <code>TestCrawl/segments/dump/dump</code>查看segments中存储的信息。</p>\n<p>####6.6.2 查看crawldb目录<br>右击<code>org.apache.nutch.crawl.CrawlDbReader</code>，选择”Run as -&gt; Run Configurations”，在<code>Program arguments</code>里填写：</p>\n<pre><code>TestCrawl/crawldb -stats\n</code></pre><p>然后点击”Run”，控制台会输出 crawldb统计信息。</p>\n<p>####6.6.3 查看linkdb目录<br>右击<code>org.apache.nutch.crawl.LinkDbReader</code>，选择”Run as -&gt; Run Configurations”，在<code>Program arguments</code>里填写：</p>\n<pre><code>TestCrawl/linkdb -dump TestCrawl/linkdb_dump\n</code></pre><p>然后点击”Run”。</p>\n<p>用文本编辑器打开文件 <code>TestCrawl/linkdb_dump/part-00000</code>查看linkdb中存储的信息</p>\n<p>###6.7 每个nutch命令对应的java类<br>怎么知道每个nutch命令对应的java类呢？打开<code>src/bin/nutch</code>并滚动到底部，就会找到每个命令对应的java类。</p>\n<p>##7 在Eclipse里单步调试<br>以上费了这么大劲，为的是什么？就是为了利用Eclipse这个强大的IDE，能够进行单步调试。写代码其实不花时间，调试才是最花时间的，因此一定要有好的调试工具，磨刀不误砍柴功。</p>\n<p>如果想调试某一个类的代码，在Eclipse里下断点，然后”Debug as …”就可以了。</p>\n<p>由于有Hadoop job的关系，比较难以难以在哪些地方下断点好。下面给出了Nutch 1.x 的代码中，一些比较好的断点位置：</p>\n<ul>\n<li>Fetcher [line: 1115] - run</li>\n<li>Fetcher [line: 530] - fetch</li>\n<li>Fetcher$FetcherThread [line: 560] - run()</li>\n<li>Generator [line: 443] - generate</li>\n<li>Generator$Selector [line: 108] - map</li>\n<li>OutlinkExtractor [line: 71 &amp; 74] - getOutlinks</li>\n</ul>\n<p>##相关文章<br><a href=\"http://www.yanjiuyanjiu.com/blog/20140121/\" target=\"_blank\" rel=\"external\">Nutch 快速入门(Nutch 1.7)</a></p>\n<p><a href=\"http://www.yanjiuyanjiu.com/blog/20140201/\" target=\"_blank\" rel=\"external\">Nutch 快速入门(Nutch 2.2.1)</a></p>\n","excerpt":"<p>环境：Ubuntu Desktop 12.04，JDK 1.7, Nutch 1.7</p>\n<p>本文主要参考<a href=\"http://wiki.apache.org/nutch/RunNutchInEclipse\">Running Nutch in Eclipse</a></p>\n<p>##前提</p>\n<ul>\n<li>机器上安装了Ant, Eclipse</li>\n<li>Eclipse安装了subclipse, update site 是 <a href=\"http://subclipse.tigris.org/update_1.10.x\">http://subclipse.tigris.org/update_1.10.x</a></li>\n<li>Eclipse安装了IvyDE, update site 是 <a href=\"http://www.apache.org/dist/ant/ivyde/updatesite\">http://www.apache.org/dist/ant/ivyde/updatesite</a></li>\n<li>Eclipse安装了m2e插件，update site 是 <a href=\"http://download.eclipse.org/technology/m2e/releases\">http://download.eclipse.org/technology/m2e/releases</a></li>\n</ul>\n<p>##1 下载源码<br>有两种方法，</p>\n<ol>\n<li>去官网首页下载apache-nutch-1.7-src.tar.gz</li>\n<li><p>用svn checkout</p>\n<pre><code>$ svn co https://svn.apache.org/repos/asf/nutch/tags/release-1.7\n</code></pre></li>\n</ol>\n<p>推荐用第2种方法，因为用SVN checkout出来的有<code>pom.xml</code>文件，即maven文件，但是压缩包里没有，只有ant的<code>build.xml</code>文件。</p>\n<p>##2 配置<br>把 conf/ 下的 <code>nutch-site.xml.template</code>复制一份，命名为<code>nutch-site.xml</code>，在里面添加如下配置：</p>\n<pre><code>&lt;property&gt;\n  &lt;name&gt;http.agent.name&lt;/name&gt;\n  &lt;value&gt;My Nutch Spider&lt;/value&gt;\n&lt;/property&gt;\n&lt;property&gt;\n  &lt;name&gt;plugin.folders&lt;/name&gt;\n  &lt;value&gt;$NUTCH_HOME/build/plugins&lt;/value&gt;\n&lt;/property&gt;\n</code></pre><p><code>$NUTCH_HOME</code>是指nutch源码的根目录，例如我的是<code>/home/soulmachine/local/opt/apache-nutch-1.7</code>.</p>\n<p>##3 生成Eclipse项目文件，即.project文件</p>\n<pre><code>$ ant eclipse\n</code></pre>","more":"<p>如果发现一直卡在 <code>ivy:resolve .....</code>这里，原因很有可能是 <a href=\"http://repo1.maven.org\">http://repo1.maven.org</a>被墙，参考<a href=\"http://blog.csdn.net/majian_1987/article/details/17004531\">这里</a>，这时候要设置HTTP代理，</p>\n<pre><code>$ Ctrl+C\n$ export HTTP_PROXY=localhost:8087    #我用的goagent\n$ ant runtime\n</code></pre><p>##4 加载到Eclipse<br>启动Eclipse，点击”File-&gt;Import-&gt;General-&gt;Existing projects into workspace”，浏览到<code>$NUTCH_DIR</code>，点击”Finish”。</p>\n<p><img src=\"http://wiki.apache.org/nutch/RunNutchInEclipse?action=AttachFile&amp;do=get&amp;target=importproject.png\" alt=\"\"></p>\n<p>请等待一会儿，让Eclipse解析该项目，可以在右下角看到状态。</p>\n<p>##5 把conf/目录加入到class folder<br>在Package Explorer里右击项目，选择”Build Path-&gt;Configure Build Path-&gt;Order and Export”，下拉滚动条，找到conf/目录，打上勾，点击”Top”按钮。</p>\n<p><img src=\"http://wiki.apache.org/nutch/RunNutchInEclipse?action=AttachFile&amp;do=get&amp;target=order_and_export.png\" alt=\"\"></p>\n<p>##6 在Eclipse里运行org.apache.nutch.crawl.Crawl来抓取网页<br>在Package Explorer里找到<code>org.apache.nutch.crawl.Crawl</code>，右击，选择”Run as -&gt; Java Application”，发现输出如下：</p>\n<pre><code>Usage: Crawl &lt;urlDir&gt; -solr &lt;solrURL&gt; [-dir d] [-threads n] [-depth i] [-topN N]\n</code></pre><p>因为我们没有给main()函数提供必要的参数。</p>\n<p>###6.1 添加种子URL</p>\n<pre><code>$ cd PROJECT_DIR\n$ mkdir urls\n$ vim ./urls/seed.txt\nhttp://movie.douban.com/subject/5323968/\n</code></pre><p>###6.2 设置URL过滤规则<br>如果只想抓取某种类型的URL，可以在 <code>conf/regex-urlfilter.txt</code>设置正则表达式，于是，只有匹配这些正则表达式的URL才会被抓取。</p>\n<p>例如，我只想抓取豆瓣电影的数据，可以这样设置：</p>\n<pre><code>#注释掉这一行\n# skip URLs containing certain characters as probable queries, etc.\n#-[?*!@=]\n# accept anything else\n#注释掉这行\n#+.\n+^http:\\/\\/movie\\.douban\\.com\\/subject\\/[0-9]+\\/(\\?.+)?$\n</code></pre><p><strong>注意</strong>，每次修改了conf目录中的配置文件，必须重新编译，修改才能生效，原因是ant里有拷贝文件的任务，将conf/下的xml文件拷贝到<code>runtie/local/conf</code>和<code>runtime/deploy/conf</code>下。</p>\n<p>这里，我们不再使用命令行编译，而是在eclipse里右击build.xml，选择<code>Run as -&gt; Ant Build</code>.</p>\n<p>###6.3 安装Solr<br>见我的这篇文章，<a href=\"http://www.yanjiuyanjiu.com/blog/20140121/\">Nutch 快速入门(Nutch 1.7)</a> 第6节。</p>\n<p>###6.4 给main()函数提供参数<br>右击<code>org.apache.nutch.crawl.Crawl</code>，选择”Run as -&gt; Run Configurations”，在<code>Program arguments</code>里填写：</p>\n<pre><code>urls -solr http://localhost:8983/solr/ -dir TestCrawl -depth 2 -topN 5\n</code></pre><p>在”VM Arguments”里填写<code>-Dhadoop.log.dir=logs -Dhadoop.log.file=hadoop.log</code></p>\n<p>###6.5 运行<br>最后点击”Apply”, “Run”，就开始抓取了。</p>\n<p>###6.6 查看结果</p>\n<p>####6.6.1 查看segments目录<br>右击<code>org.apache.nutch.segment.SegmentReader</code>，选择”Run as -&gt; Run Configurations”，在<code>Program arguments</code>里填写：</p>\n<pre><code>-dump TestCrawl/segments/* TestCrawl/segments/dump\n</code></pre><p>然后点击”Run”。</p>\n<p>用文本编辑器打开文件 <code>TestCrawl/segments/dump/dump</code>查看segments中存储的信息。</p>\n<p>####6.6.2 查看crawldb目录<br>右击<code>org.apache.nutch.crawl.CrawlDbReader</code>，选择”Run as -&gt; Run Configurations”，在<code>Program arguments</code>里填写：</p>\n<pre><code>TestCrawl/crawldb -stats\n</code></pre><p>然后点击”Run”，控制台会输出 crawldb统计信息。</p>\n<p>####6.6.3 查看linkdb目录<br>右击<code>org.apache.nutch.crawl.LinkDbReader</code>，选择”Run as -&gt; Run Configurations”，在<code>Program arguments</code>里填写：</p>\n<pre><code>TestCrawl/linkdb -dump TestCrawl/linkdb_dump\n</code></pre><p>然后点击”Run”。</p>\n<p>用文本编辑器打开文件 <code>TestCrawl/linkdb_dump/part-00000</code>查看linkdb中存储的信息</p>\n<p>###6.7 每个nutch命令对应的java类<br>怎么知道每个nutch命令对应的java类呢？打开<code>src/bin/nutch</code>并滚动到底部，就会找到每个命令对应的java类。</p>\n<p>##7 在Eclipse里单步调试<br>以上费了这么大劲，为的是什么？就是为了利用Eclipse这个强大的IDE，能够进行单步调试。写代码其实不花时间，调试才是最花时间的，因此一定要有好的调试工具，磨刀不误砍柴功。</p>\n<p>如果想调试某一个类的代码，在Eclipse里下断点，然后”Debug as …”就可以了。</p>\n<p>由于有Hadoop job的关系，比较难以难以在哪些地方下断点好。下面给出了Nutch 1.x 的代码中，一些比较好的断点位置：</p>\n<ul>\n<li>Fetcher [line: 1115] - run</li>\n<li>Fetcher [line: 530] - fetch</li>\n<li>Fetcher$FetcherThread [line: 560] - run()</li>\n<li>Generator [line: 443] - generate</li>\n<li>Generator$Selector [line: 108] - map</li>\n<li>OutlinkExtractor [line: 71 &amp; 74] - getOutlinks</li>\n</ul>\n<p>##相关文章<br><a href=\"http://www.yanjiuyanjiu.com/blog/20140121/\">Nutch 快速入门(Nutch 1.7)</a></p>\n<p><a href=\"http://www.yanjiuyanjiu.com/blog/20140201/\">Nutch 快速入门(Nutch 2.2.1)</a></p>"},{"layout":"post","title":"docker 快速入门","date":"2013-10-26T23:41:00.000Z","comments":1,"_content":"\n**前提条件：**要安装好 docker，见我的另一篇博客，[docker 安装](http://www.yanjiuyanjiu.com/blog/20131025)\n\n\n## 交互式命令行入门教程\n首先强烈建议玩一遍官方的一个交互式命令行入门教程，[Interactive commandline tutorial](http://www.docker.io/gettingstarted/)。甚至要多玩几遍，加深印象。\n\n初次过完这个教程，感觉docker用起来跟git很类似。\n\n玩完了后，在自己的真实机器上，把上面的命令重新敲一遍，感受一下。\n\n\n## Hello World\n参考官方文档[Hello World](http://docs.docker.io/en/latest/examples/hello_world/#running-examples)\n\n首先下载官方的ubuntu image:\n\n\tsudo docker pull ubuntu\n\n然后运行 hello world：\n\n\tsudo docker run ubuntu /bin/echo hello world\n\n## 三种运行命令的模式\ndocker 有三种运行命令的方式，短暂方式，交互方式，daemon方式。\n\n**短暂方式**，就是刚刚的那个\"hello world\"，命令执行完后，container就终止了，不过并没有消失，可以用 `sudo docker ps -a` 看一下所有的container，第一个就是刚刚执行过的container，可以再次执行一遍：\n\n\tsudo docker start container_id\n\n不过这次看不到\"hello world\"了，只能看到ID，用`logs`命令才能看得到，\n\n\tsudo docker logs container_id\n\n可以看到两个\"hello world\"，因为这个container运行了两次。\n\n\n**交互方式**，\n\n\tsudo docker run -i -t image_name /bin/bash\n\n**daemon方式**，即让软件作为长时间服务运行，这就是SAAS啊！\n\n例如，一个无限循环打印的脚本（替换为memcached, apache等，操作方法仍然不变！）：\n\n\tCONTAINER_ID=$(sudo docker run -d ubuntu /bin/sh -c \"while true; do echo hello world; sleep 1; done\")\n\n在container外面查看它的输出\n\n\tsudo docker logs $CONTAINER_ID\n\n或者连接上容器实时查看\n\n\tsudo docker attach $CONTAINER_ID\n\n终止容器\n\n\tsudo docker stop $CONTAINER_ID\n\n`sudo docker ps`看一下，已经没了\n\n\n## docker ps 命令详解\n`sudo docker ps`，列出当前所有正在运行的container\n\n`sudo docker ps -l`，列出最近一次启动的，且正在运行的container\n\n`sudo docker ps -a`，列出所有的container\n\n其他用法请参考 `sudo docker ps -h`\n\n还有一种方式可以让程序在daemon模式下运行，就是在Dockerfile里设置USER为daemon，见[Dockerfile tutorial Level2](http://www.docker.io/learn/dockerfile/level2/)。\n\n\n## 添加http代理\n在国内，pull或push的时候经常连不上docker.com（原因你懂的，或者在公司内部统一用一个代理上网的时候），可以在docker daemon进程启动的时候加个代理，例如\n\n\tsudo HTTP_PROXY=proxy_server:port docker -d &\n\ndocker貌似是不识别`http_proxy`, `https_proxy`和`no_proxy`环境变量的，因此要在命令行里指定，参考 [Github Issue #402 Using Docker behind a firewall](https://github.com/dotcloud/docker/issues/402)。\n\n如果在命令行里指定了`HTTP_PROXY`，则要unset掉`http_proxy`和`https_proxy`环境变量。原因是：\n\n* 首先， docker daemon进程是通过http协议与docker.com通信的\n* 其次，docker的各种命令（例如 `run`, `login`等）也是通过http协议与docker daemon进程通信的（发送jasn字符串，daemon进程返回的也是json字符串），有时候docker客户端命令貌似能识别http_proxy变量，这时，客户端发送一个命令，路径是`localhost->http_proxy->daemon进程`，daemon进程返回的数据，路径是 `daemon进程->proxy->proxy->localhost`，其中，从`proxy->localhost`的路径是不通的，因为proxy连接不了内网IP。\n\n之所以把这一步放在本文开始，是因为这一步不做的话，后面很多命令会出错，让人摸不着头脑，我在这里就掉进坑了，花了很长时间才搞明白，原来是网络连接不稳定。\n\n\n## 熟悉一下 Dockerfile\n完了几遍交互式入门教程后，你会好奇，怎么自己定制一个 image，例如把常用的软件装好后打包 ? 这时候该 Dockfile 登场了。Dockerfile 实质上是一个脚本文件，用于自动化创建image。\n\n<!--more-->\n\n请跟着官方教程走一遍，[Dockerfile Tutorial](http://www.docker.io/gettingstarted/)\n\n到这里， 官网的 Getting started 的内容基本上消化完了，接下来就是翻官网的[Documentation](http://docs.docker.io/en/latest/)了。\n\n## 我的第一个Dockerfile\n文件名为update.dockerfile，内容如下：\n\n\t# use the ubuntu base image provided by dotCloud\n\tFROM ubuntu\n\t\n\tMAINTAINER Frank Dai soulmachine@gmail.com\n\t\n\t\n\t# if you're behind a government firewall or company proxy\n\t# ENV http_proxy http://proxy-prc.intel.com:911\n\t# ENV https_proxy https://proxy-prc.intel.com:911\n\t# RUN echo \"Acquire::http::proxy \\\"proxy_server:port\\\";\" >> /etc/apt/apt.conf\n\t# RUN echo \"Acquire::https::proxy \\\"proxy_server:port\\\";\" >> /etc/apt/apt.conf\n\t\n\t\n\t# choose a faster mirror, see http://t.cn/zWYrzCE\n\tRUN echo \"deb mirror://mirrors.ubuntu.com/mirrors.txt precise main restricted universe multiverse\" > /etc/apt/sources.list\n\tRUN echo \"deb mirror://mirrors.ubuntu.com/mirrors.txt precise-updates main restricted universe multiverse\" >> /etc/apt/sources.list\n\tRUN echo \"deb mirror://mirrors.ubuntu.com/mirrors.txt precise-backports main restricted universe multiverse\" >> /etc/apt/sources.list\n\tRUN echo \"deb mirror://mirrors.ubuntu.com/mirrors.txt precise-security main restricted universe multiverse\" >> /etc/apt/sources.list\n\t\n\tRUN apt-get update -y\n\t# currently docker official ubuntu image has a problem with apt-get upgrade\n\t# RUN apt-get upgrade -y && apt-get dist-upgrade -y\n\tRUN apt-get clean all\n\t\n\t\n\t# install wget\n\tRUN apt-get install -y  wget\n\tRUN wget www.baidu.com\n\tRUN rm index.html\n\t\n\t#install vim editor\n\tRUN apt-get install -y vim\n\n**注意一个坑：** `apt-get upgrade` 在当前官方的ubuntu image里是无法运行成功的，见 [Issue #1724 apt-get upgrade in plain Ubuntu precise image fails](https://github.com/dotcloud/docker/issues/1724)。所以，干脆放弃更新吧，能`apt-get install`软件就行了，不要有更新强迫症 :)\n\n\n## 删除容器\n**每一行命令都会产生一个新的容器**（无论是在`sudo docker run -i -t ubuntu /bin/bash` 模式下，还是Dockerfile里的RUN命令），玩了一会儿后，`sudo docker ps -a` 会看到很多容器，很是干扰视线，可以用一行命令删除所有容器：\n\n\tsudo docker rm `sudo docker ps -a -q`\n\n## 创建image\n有两种用方式，\n\n* 写一个Dockerfile，然后用`docker build`创建一个image\n* 在容器里交互式地（例如`sudo docker run -i -t ubuntu /bin/bash`）进行一些列操作，然后`docker commit`固化成一个image。\n\nimage相当于编程语言里的类，container相当于实例，不过可以动态给实例安装新软件，然后把这个container用commit命令固化成一个image。\n\n\n使用前面写好的update.dockerfile，创建一个image：\n\n\tsudo docker build -t soulmachine/ubuntu:latest - < update.dockerfile\n\n\n## 下载image\n<https://index.docker.io/> 是官方的image仓库，也可以用 [Docker-Registry](https://github.com/dotcloud/docker-registry)创建自己的仓库，这就好比git，<https://index.docker.io/>相当于Github，也可以自己DIY搭建一个git服务器，把自己的代码托管到私有的服务器上。\n\n`sudo docker pull ubuntu` 是从 <https://index.docker.io/_/ubuntu/> 下载名为 ubuntu 的repo，里面包含了几个tag，默认使用latest这个tag。这个repo是docker官方的。\n\n\n## 上传并共享image\n自己build了一个image，想要共享，怎么办？参考这篇文章，[How to build and publish base boxes for Docker?](http://crohr.me/journal/2013/docker-repository-create-base-boxes.html)\n\n### 注册一个账号\n首先，要去 <https://index.docker.io/> 注册一个账号，例如我的是 soulmachine。\n\n### build一个image\nbuild命令格式如下：\n\n\tsudo docker build -t username/repo:tag - < Dockerfile\n\n如果没有tag，则默认为 latest。\n\n### 登陆\n\n\tsudo docker login\n\n输入自己的用户名和密码。\n\n### push 到 Docker index\n\n\tsudo docker push username/repo\n\n这条命令会把一个repo下面的所有tag都push到<https://index.docker.io/>\n\n\n## 安装JDK7失败\n我在container 里面安装jre7是可以的, `apt-get install openjdk-7-jre-headless` 成功。但是安装jdk7，`apt-get install openjdk-7-jdk`失败，错误消息如下：\n\n\tCreating fuse device...\n\tmknod: `fuse-': Operation not permitted\n\tmakedev fuse c 10 229 root root 0660: failed\n\tchown: cannot access `/dev/fuse': No such file or directory\n\tdpkg: error processing fuse (--configure):\n\t subprocess installed post-installation script returned error exit status 1\n\tProcessing triggers for libc-bin ...\n\tldconfig deferred processing now taking place\n\tErrors were encountered while processing:\n\t fuse\n\tE: Sub-process /usr/bin/dpkg returned an error code (1)\n\n原因是权限不够，见[Issue #963](https://github.com/dotcloud/docker/issues/963) 和 [Issue #514](https://github.com/dotcloud/docker/issues/514)\n\n所以，需要在启动container时，添加一个`-priviledged`参数，\n\n\tsudo docker run -i -t -priviledged soulmachine/ubuntu /bin/bash\n\n在里面执行`apt-get install openjdk-7-jdk`，这次成功了。\n\n那如何在dockerfile里用RUN命令安装JDK7呢？dockerfile里没法指定`-priviledged`，目前没有办法，不过可以折中一下，安装openjdk6。\n\n\n## ENTRYPOINT 和 CMD 的区别\n见[How to Use Entrypoint in Docker Builder](http://www.kstaken.com/blog/2013/07/06/how-to-use-entrypoint-in-a-dockerfile/)\n\n\n## docker 最佳实践\n见[Dockerfile Best Practices](http://crosbymichael.com/dockerfile-best-practices.html)\n\n\n## 关于docker 的书籍\n* [The Docker Book](http://dockerbook.com/)\n\n\n## 底层原理\n\nimage, container, fs layer，是什么关系？见这篇博客，[Solomon Hykes Explains Docker](http://www.activestate.com/blog/2013/06/solomon-hykes-explains-docker)\n\n\n## 参考资料\n1. [Official docs](http://docs.docker.io/)\n2. [Docker 初探](https://log.qingcloud.com/?p=129)\n","source":"_posts/2013-10-26-docker-tutorial.md","raw":"---\nlayout: post\ntitle: \"docker 快速入门\"\ndate: 2013-10-26 23:41\ncomments: true\ncategories: Docker\n---\n\n**前提条件：**要安装好 docker，见我的另一篇博客，[docker 安装](http://www.yanjiuyanjiu.com/blog/20131025)\n\n\n## 交互式命令行入门教程\n首先强烈建议玩一遍官方的一个交互式命令行入门教程，[Interactive commandline tutorial](http://www.docker.io/gettingstarted/)。甚至要多玩几遍，加深印象。\n\n初次过完这个教程，感觉docker用起来跟git很类似。\n\n玩完了后，在自己的真实机器上，把上面的命令重新敲一遍，感受一下。\n\n\n## Hello World\n参考官方文档[Hello World](http://docs.docker.io/en/latest/examples/hello_world/#running-examples)\n\n首先下载官方的ubuntu image:\n\n\tsudo docker pull ubuntu\n\n然后运行 hello world：\n\n\tsudo docker run ubuntu /bin/echo hello world\n\n## 三种运行命令的模式\ndocker 有三种运行命令的方式，短暂方式，交互方式，daemon方式。\n\n**短暂方式**，就是刚刚的那个\"hello world\"，命令执行完后，container就终止了，不过并没有消失，可以用 `sudo docker ps -a` 看一下所有的container，第一个就是刚刚执行过的container，可以再次执行一遍：\n\n\tsudo docker start container_id\n\n不过这次看不到\"hello world\"了，只能看到ID，用`logs`命令才能看得到，\n\n\tsudo docker logs container_id\n\n可以看到两个\"hello world\"，因为这个container运行了两次。\n\n\n**交互方式**，\n\n\tsudo docker run -i -t image_name /bin/bash\n\n**daemon方式**，即让软件作为长时间服务运行，这就是SAAS啊！\n\n例如，一个无限循环打印的脚本（替换为memcached, apache等，操作方法仍然不变！）：\n\n\tCONTAINER_ID=$(sudo docker run -d ubuntu /bin/sh -c \"while true; do echo hello world; sleep 1; done\")\n\n在container外面查看它的输出\n\n\tsudo docker logs $CONTAINER_ID\n\n或者连接上容器实时查看\n\n\tsudo docker attach $CONTAINER_ID\n\n终止容器\n\n\tsudo docker stop $CONTAINER_ID\n\n`sudo docker ps`看一下，已经没了\n\n\n## docker ps 命令详解\n`sudo docker ps`，列出当前所有正在运行的container\n\n`sudo docker ps -l`，列出最近一次启动的，且正在运行的container\n\n`sudo docker ps -a`，列出所有的container\n\n其他用法请参考 `sudo docker ps -h`\n\n还有一种方式可以让程序在daemon模式下运行，就是在Dockerfile里设置USER为daemon，见[Dockerfile tutorial Level2](http://www.docker.io/learn/dockerfile/level2/)。\n\n\n## 添加http代理\n在国内，pull或push的时候经常连不上docker.com（原因你懂的，或者在公司内部统一用一个代理上网的时候），可以在docker daemon进程启动的时候加个代理，例如\n\n\tsudo HTTP_PROXY=proxy_server:port docker -d &\n\ndocker貌似是不识别`http_proxy`, `https_proxy`和`no_proxy`环境变量的，因此要在命令行里指定，参考 [Github Issue #402 Using Docker behind a firewall](https://github.com/dotcloud/docker/issues/402)。\n\n如果在命令行里指定了`HTTP_PROXY`，则要unset掉`http_proxy`和`https_proxy`环境变量。原因是：\n\n* 首先， docker daemon进程是通过http协议与docker.com通信的\n* 其次，docker的各种命令（例如 `run`, `login`等）也是通过http协议与docker daemon进程通信的（发送jasn字符串，daemon进程返回的也是json字符串），有时候docker客户端命令貌似能识别http_proxy变量，这时，客户端发送一个命令，路径是`localhost->http_proxy->daemon进程`，daemon进程返回的数据，路径是 `daemon进程->proxy->proxy->localhost`，其中，从`proxy->localhost`的路径是不通的，因为proxy连接不了内网IP。\n\n之所以把这一步放在本文开始，是因为这一步不做的话，后面很多命令会出错，让人摸不着头脑，我在这里就掉进坑了，花了很长时间才搞明白，原来是网络连接不稳定。\n\n\n## 熟悉一下 Dockerfile\n完了几遍交互式入门教程后，你会好奇，怎么自己定制一个 image，例如把常用的软件装好后打包 ? 这时候该 Dockfile 登场了。Dockerfile 实质上是一个脚本文件，用于自动化创建image。\n\n<!--more-->\n\n请跟着官方教程走一遍，[Dockerfile Tutorial](http://www.docker.io/gettingstarted/)\n\n到这里， 官网的 Getting started 的内容基本上消化完了，接下来就是翻官网的[Documentation](http://docs.docker.io/en/latest/)了。\n\n## 我的第一个Dockerfile\n文件名为update.dockerfile，内容如下：\n\n\t# use the ubuntu base image provided by dotCloud\n\tFROM ubuntu\n\t\n\tMAINTAINER Frank Dai soulmachine@gmail.com\n\t\n\t\n\t# if you're behind a government firewall or company proxy\n\t# ENV http_proxy http://proxy-prc.intel.com:911\n\t# ENV https_proxy https://proxy-prc.intel.com:911\n\t# RUN echo \"Acquire::http::proxy \\\"proxy_server:port\\\";\" >> /etc/apt/apt.conf\n\t# RUN echo \"Acquire::https::proxy \\\"proxy_server:port\\\";\" >> /etc/apt/apt.conf\n\t\n\t\n\t# choose a faster mirror, see http://t.cn/zWYrzCE\n\tRUN echo \"deb mirror://mirrors.ubuntu.com/mirrors.txt precise main restricted universe multiverse\" > /etc/apt/sources.list\n\tRUN echo \"deb mirror://mirrors.ubuntu.com/mirrors.txt precise-updates main restricted universe multiverse\" >> /etc/apt/sources.list\n\tRUN echo \"deb mirror://mirrors.ubuntu.com/mirrors.txt precise-backports main restricted universe multiverse\" >> /etc/apt/sources.list\n\tRUN echo \"deb mirror://mirrors.ubuntu.com/mirrors.txt precise-security main restricted universe multiverse\" >> /etc/apt/sources.list\n\t\n\tRUN apt-get update -y\n\t# currently docker official ubuntu image has a problem with apt-get upgrade\n\t# RUN apt-get upgrade -y && apt-get dist-upgrade -y\n\tRUN apt-get clean all\n\t\n\t\n\t# install wget\n\tRUN apt-get install -y  wget\n\tRUN wget www.baidu.com\n\tRUN rm index.html\n\t\n\t#install vim editor\n\tRUN apt-get install -y vim\n\n**注意一个坑：** `apt-get upgrade` 在当前官方的ubuntu image里是无法运行成功的，见 [Issue #1724 apt-get upgrade in plain Ubuntu precise image fails](https://github.com/dotcloud/docker/issues/1724)。所以，干脆放弃更新吧，能`apt-get install`软件就行了，不要有更新强迫症 :)\n\n\n## 删除容器\n**每一行命令都会产生一个新的容器**（无论是在`sudo docker run -i -t ubuntu /bin/bash` 模式下，还是Dockerfile里的RUN命令），玩了一会儿后，`sudo docker ps -a` 会看到很多容器，很是干扰视线，可以用一行命令删除所有容器：\n\n\tsudo docker rm `sudo docker ps -a -q`\n\n## 创建image\n有两种用方式，\n\n* 写一个Dockerfile，然后用`docker build`创建一个image\n* 在容器里交互式地（例如`sudo docker run -i -t ubuntu /bin/bash`）进行一些列操作，然后`docker commit`固化成一个image。\n\nimage相当于编程语言里的类，container相当于实例，不过可以动态给实例安装新软件，然后把这个container用commit命令固化成一个image。\n\n\n使用前面写好的update.dockerfile，创建一个image：\n\n\tsudo docker build -t soulmachine/ubuntu:latest - < update.dockerfile\n\n\n## 下载image\n<https://index.docker.io/> 是官方的image仓库，也可以用 [Docker-Registry](https://github.com/dotcloud/docker-registry)创建自己的仓库，这就好比git，<https://index.docker.io/>相当于Github，也可以自己DIY搭建一个git服务器，把自己的代码托管到私有的服务器上。\n\n`sudo docker pull ubuntu` 是从 <https://index.docker.io/_/ubuntu/> 下载名为 ubuntu 的repo，里面包含了几个tag，默认使用latest这个tag。这个repo是docker官方的。\n\n\n## 上传并共享image\n自己build了一个image，想要共享，怎么办？参考这篇文章，[How to build and publish base boxes for Docker?](http://crohr.me/journal/2013/docker-repository-create-base-boxes.html)\n\n### 注册一个账号\n首先，要去 <https://index.docker.io/> 注册一个账号，例如我的是 soulmachine。\n\n### build一个image\nbuild命令格式如下：\n\n\tsudo docker build -t username/repo:tag - < Dockerfile\n\n如果没有tag，则默认为 latest。\n\n### 登陆\n\n\tsudo docker login\n\n输入自己的用户名和密码。\n\n### push 到 Docker index\n\n\tsudo docker push username/repo\n\n这条命令会把一个repo下面的所有tag都push到<https://index.docker.io/>\n\n\n## 安装JDK7失败\n我在container 里面安装jre7是可以的, `apt-get install openjdk-7-jre-headless` 成功。但是安装jdk7，`apt-get install openjdk-7-jdk`失败，错误消息如下：\n\n\tCreating fuse device...\n\tmknod: `fuse-': Operation not permitted\n\tmakedev fuse c 10 229 root root 0660: failed\n\tchown: cannot access `/dev/fuse': No such file or directory\n\tdpkg: error processing fuse (--configure):\n\t subprocess installed post-installation script returned error exit status 1\n\tProcessing triggers for libc-bin ...\n\tldconfig deferred processing now taking place\n\tErrors were encountered while processing:\n\t fuse\n\tE: Sub-process /usr/bin/dpkg returned an error code (1)\n\n原因是权限不够，见[Issue #963](https://github.com/dotcloud/docker/issues/963) 和 [Issue #514](https://github.com/dotcloud/docker/issues/514)\n\n所以，需要在启动container时，添加一个`-priviledged`参数，\n\n\tsudo docker run -i -t -priviledged soulmachine/ubuntu /bin/bash\n\n在里面执行`apt-get install openjdk-7-jdk`，这次成功了。\n\n那如何在dockerfile里用RUN命令安装JDK7呢？dockerfile里没法指定`-priviledged`，目前没有办法，不过可以折中一下，安装openjdk6。\n\n\n## ENTRYPOINT 和 CMD 的区别\n见[How to Use Entrypoint in Docker Builder](http://www.kstaken.com/blog/2013/07/06/how-to-use-entrypoint-in-a-dockerfile/)\n\n\n## docker 最佳实践\n见[Dockerfile Best Practices](http://crosbymichael.com/dockerfile-best-practices.html)\n\n\n## 关于docker 的书籍\n* [The Docker Book](http://dockerbook.com/)\n\n\n## 底层原理\n\nimage, container, fs layer，是什么关系？见这篇博客，[Solomon Hykes Explains Docker](http://www.activestate.com/blog/2013/06/solomon-hykes-explains-docker)\n\n\n## 参考资料\n1. [Official docs](http://docs.docker.io/)\n2. [Docker 初探](https://log.qingcloud.com/?p=129)\n","slug":"2013-10-26-docker-tutorial","published":1,"updated":"2016-08-18T09:21:04.000Z","photos":[],"link":"","_id":"cis07pf3q001z01pqfs8ehycj","content":"<p><strong>前提条件：</strong>要安装好 docker，见我的另一篇博客，<a href=\"http://www.yanjiuyanjiu.com/blog/20131025\" target=\"_blank\" rel=\"external\">docker 安装</a></p>\n<h2 id=\"交互式命令行入门教程\"><a href=\"#交互式命令行入门教程\" class=\"headerlink\" title=\"交互式命令行入门教程\"></a>交互式命令行入门教程</h2><p>首先强烈建议玩一遍官方的一个交互式命令行入门教程，<a href=\"http://www.docker.io/gettingstarted/\" target=\"_blank\" rel=\"external\">Interactive commandline tutorial</a>。甚至要多玩几遍，加深印象。</p>\n<p>初次过完这个教程，感觉docker用起来跟git很类似。</p>\n<p>玩完了后，在自己的真实机器上，把上面的命令重新敲一遍，感受一下。</p>\n<h2 id=\"Hello-World\"><a href=\"#Hello-World\" class=\"headerlink\" title=\"Hello World\"></a>Hello World</h2><p>参考官方文档<a href=\"http://docs.docker.io/en/latest/examples/hello_world/#running-examples\" target=\"_blank\" rel=\"external\">Hello World</a></p>\n<p>首先下载官方的ubuntu image:</p>\n<pre><code>sudo docker pull ubuntu\n</code></pre><p>然后运行 hello world：</p>\n<pre><code>sudo docker run ubuntu /bin/echo hello world\n</code></pre><h2 id=\"三种运行命令的模式\"><a href=\"#三种运行命令的模式\" class=\"headerlink\" title=\"三种运行命令的模式\"></a>三种运行命令的模式</h2><p>docker 有三种运行命令的方式，短暂方式，交互方式，daemon方式。</p>\n<p><strong>短暂方式</strong>，就是刚刚的那个”hello world”，命令执行完后，container就终止了，不过并没有消失，可以用 <code>sudo docker ps -a</code> 看一下所有的container，第一个就是刚刚执行过的container，可以再次执行一遍：</p>\n<pre><code>sudo docker start container_id\n</code></pre><p>不过这次看不到”hello world”了，只能看到ID，用<code>logs</code>命令才能看得到，</p>\n<pre><code>sudo docker logs container_id\n</code></pre><p>可以看到两个”hello world”，因为这个container运行了两次。</p>\n<p><strong>交互方式</strong>，</p>\n<pre><code>sudo docker run -i -t image_name /bin/bash\n</code></pre><p><strong>daemon方式</strong>，即让软件作为长时间服务运行，这就是SAAS啊！</p>\n<p>例如，一个无限循环打印的脚本（替换为memcached, apache等，操作方法仍然不变！）：</p>\n<pre><code>CONTAINER_ID=$(sudo docker run -d ubuntu /bin/sh -c &quot;while true; do echo hello world; sleep 1; done&quot;)\n</code></pre><p>在container外面查看它的输出</p>\n<pre><code>sudo docker logs $CONTAINER_ID\n</code></pre><p>或者连接上容器实时查看</p>\n<pre><code>sudo docker attach $CONTAINER_ID\n</code></pre><p>终止容器</p>\n<pre><code>sudo docker stop $CONTAINER_ID\n</code></pre><p><code>sudo docker ps</code>看一下，已经没了</p>\n<h2 id=\"docker-ps-命令详解\"><a href=\"#docker-ps-命令详解\" class=\"headerlink\" title=\"docker ps 命令详解\"></a>docker ps 命令详解</h2><p><code>sudo docker ps</code>，列出当前所有正在运行的container</p>\n<p><code>sudo docker ps -l</code>，列出最近一次启动的，且正在运行的container</p>\n<p><code>sudo docker ps -a</code>，列出所有的container</p>\n<p>其他用法请参考 <code>sudo docker ps -h</code></p>\n<p>还有一种方式可以让程序在daemon模式下运行，就是在Dockerfile里设置USER为daemon，见<a href=\"http://www.docker.io/learn/dockerfile/level2/\" target=\"_blank\" rel=\"external\">Dockerfile tutorial Level2</a>。</p>\n<h2 id=\"添加http代理\"><a href=\"#添加http代理\" class=\"headerlink\" title=\"添加http代理\"></a>添加http代理</h2><p>在国内，pull或push的时候经常连不上docker.com（原因你懂的，或者在公司内部统一用一个代理上网的时候），可以在docker daemon进程启动的时候加个代理，例如</p>\n<pre><code>sudo HTTP_PROXY=proxy_server:port docker -d &amp;\n</code></pre><p>docker貌似是不识别<code>http_proxy</code>, <code>https_proxy</code>和<code>no_proxy</code>环境变量的，因此要在命令行里指定，参考 <a href=\"https://github.com/dotcloud/docker/issues/402\" target=\"_blank\" rel=\"external\">Github Issue #402 Using Docker behind a firewall</a>。</p>\n<p>如果在命令行里指定了<code>HTTP_PROXY</code>，则要unset掉<code>http_proxy</code>和<code>https_proxy</code>环境变量。原因是：</p>\n<ul>\n<li>首先， docker daemon进程是通过http协议与docker.com通信的</li>\n<li>其次，docker的各种命令（例如 <code>run</code>, <code>login</code>等）也是通过http协议与docker daemon进程通信的（发送jasn字符串，daemon进程返回的也是json字符串），有时候docker客户端命令貌似能识别http_proxy变量，这时，客户端发送一个命令，路径是<code>localhost-&gt;http_proxy-&gt;daemon进程</code>，daemon进程返回的数据，路径是 <code>daemon进程-&gt;proxy-&gt;proxy-&gt;localhost</code>，其中，从<code>proxy-&gt;localhost</code>的路径是不通的，因为proxy连接不了内网IP。</li>\n</ul>\n<p>之所以把这一步放在本文开始，是因为这一步不做的话，后面很多命令会出错，让人摸不着头脑，我在这里就掉进坑了，花了很长时间才搞明白，原来是网络连接不稳定。</p>\n<h2 id=\"熟悉一下-Dockerfile\"><a href=\"#熟悉一下-Dockerfile\" class=\"headerlink\" title=\"熟悉一下 Dockerfile\"></a>熟悉一下 Dockerfile</h2><p>完了几遍交互式入门教程后，你会好奇，怎么自己定制一个 image，例如把常用的软件装好后打包 ? 这时候该 Dockfile 登场了。Dockerfile 实质上是一个脚本文件，用于自动化创建image。</p>\n<a id=\"more\"></a>\n<p>请跟着官方教程走一遍，<a href=\"http://www.docker.io/gettingstarted/\" target=\"_blank\" rel=\"external\">Dockerfile Tutorial</a></p>\n<p>到这里， 官网的 Getting started 的内容基本上消化完了，接下来就是翻官网的<a href=\"http://docs.docker.io/en/latest/\" target=\"_blank\" rel=\"external\">Documentation</a>了。</p>\n<h2 id=\"我的第一个Dockerfile\"><a href=\"#我的第一个Dockerfile\" class=\"headerlink\" title=\"我的第一个Dockerfile\"></a>我的第一个Dockerfile</h2><p>文件名为update.dockerfile，内容如下：</p>\n<pre><code># use the ubuntu base image provided by dotCloud\nFROM ubuntu\n\nMAINTAINER Frank Dai soulmachine@gmail.com\n\n\n# if you&apos;re behind a government firewall or company proxy\n# ENV http_proxy http://proxy-prc.intel.com:911\n# ENV https_proxy https://proxy-prc.intel.com:911\n# RUN echo &quot;Acquire::http::proxy \\&quot;proxy_server:port\\&quot;;&quot; &gt;&gt; /etc/apt/apt.conf\n# RUN echo &quot;Acquire::https::proxy \\&quot;proxy_server:port\\&quot;;&quot; &gt;&gt; /etc/apt/apt.conf\n\n\n# choose a faster mirror, see http://t.cn/zWYrzCE\nRUN echo &quot;deb mirror://mirrors.ubuntu.com/mirrors.txt precise main restricted universe multiverse&quot; &gt; /etc/apt/sources.list\nRUN echo &quot;deb mirror://mirrors.ubuntu.com/mirrors.txt precise-updates main restricted universe multiverse&quot; &gt;&gt; /etc/apt/sources.list\nRUN echo &quot;deb mirror://mirrors.ubuntu.com/mirrors.txt precise-backports main restricted universe multiverse&quot; &gt;&gt; /etc/apt/sources.list\nRUN echo &quot;deb mirror://mirrors.ubuntu.com/mirrors.txt precise-security main restricted universe multiverse&quot; &gt;&gt; /etc/apt/sources.list\n\nRUN apt-get update -y\n# currently docker official ubuntu image has a problem with apt-get upgrade\n# RUN apt-get upgrade -y &amp;&amp; apt-get dist-upgrade -y\nRUN apt-get clean all\n\n\n# install wget\nRUN apt-get install -y  wget\nRUN wget www.baidu.com\nRUN rm index.html\n\n#install vim editor\nRUN apt-get install -y vim\n</code></pre><p><strong>注意一个坑：</strong> <code>apt-get upgrade</code> 在当前官方的ubuntu image里是无法运行成功的，见 <a href=\"https://github.com/dotcloud/docker/issues/1724\" target=\"_blank\" rel=\"external\">Issue #1724 apt-get upgrade in plain Ubuntu precise image fails</a>。所以，干脆放弃更新吧，能<code>apt-get install</code>软件就行了，不要有更新强迫症 :)</p>\n<h2 id=\"删除容器\"><a href=\"#删除容器\" class=\"headerlink\" title=\"删除容器\"></a>删除容器</h2><p><strong>每一行命令都会产生一个新的容器</strong>（无论是在<code>sudo docker run -i -t ubuntu /bin/bash</code> 模式下，还是Dockerfile里的RUN命令），玩了一会儿后，<code>sudo docker ps -a</code> 会看到很多容器，很是干扰视线，可以用一行命令删除所有容器：</p>\n<pre><code>sudo docker rm `sudo docker ps -a -q`\n</code></pre><h2 id=\"创建image\"><a href=\"#创建image\" class=\"headerlink\" title=\"创建image\"></a>创建image</h2><p>有两种用方式，</p>\n<ul>\n<li>写一个Dockerfile，然后用<code>docker build</code>创建一个image</li>\n<li>在容器里交互式地（例如<code>sudo docker run -i -t ubuntu /bin/bash</code>）进行一些列操作，然后<code>docker commit</code>固化成一个image。</li>\n</ul>\n<p>image相当于编程语言里的类，container相当于实例，不过可以动态给实例安装新软件，然后把这个container用commit命令固化成一个image。</p>\n<p>使用前面写好的update.dockerfile，创建一个image：</p>\n<pre><code>sudo docker build -t soulmachine/ubuntu:latest - &lt; update.dockerfile\n</code></pre><h2 id=\"下载image\"><a href=\"#下载image\" class=\"headerlink\" title=\"下载image\"></a>下载image</h2><p><a href=\"https://index.docker.io/\" target=\"_blank\" rel=\"external\">https://index.docker.io/</a> 是官方的image仓库，也可以用 <a href=\"https://github.com/dotcloud/docker-registry\" target=\"_blank\" rel=\"external\">Docker-Registry</a>创建自己的仓库，这就好比git，<a href=\"https://index.docker.io/\" target=\"_blank\" rel=\"external\">https://index.docker.io/</a>相当于Github，也可以自己DIY搭建一个git服务器，把自己的代码托管到私有的服务器上。</p>\n<p><code>sudo docker pull ubuntu</code> 是从 <a href=\"https://index.docker.io/_/ubuntu/\" target=\"_blank\" rel=\"external\">https://index.docker.io/_/ubuntu/</a> 下载名为 ubuntu 的repo，里面包含了几个tag，默认使用latest这个tag。这个repo是docker官方的。</p>\n<h2 id=\"上传并共享image\"><a href=\"#上传并共享image\" class=\"headerlink\" title=\"上传并共享image\"></a>上传并共享image</h2><p>自己build了一个image，想要共享，怎么办？参考这篇文章，<a href=\"http://crohr.me/journal/2013/docker-repository-create-base-boxes.html\" target=\"_blank\" rel=\"external\">How to build and publish base boxes for Docker?</a></p>\n<h3 id=\"注册一个账号\"><a href=\"#注册一个账号\" class=\"headerlink\" title=\"注册一个账号\"></a>注册一个账号</h3><p>首先，要去 <a href=\"https://index.docker.io/\" target=\"_blank\" rel=\"external\">https://index.docker.io/</a> 注册一个账号，例如我的是 soulmachine。</p>\n<h3 id=\"build一个image\"><a href=\"#build一个image\" class=\"headerlink\" title=\"build一个image\"></a>build一个image</h3><p>build命令格式如下：</p>\n<pre><code>sudo docker build -t username/repo:tag - &lt; Dockerfile\n</code></pre><p>如果没有tag，则默认为 latest。</p>\n<h3 id=\"登陆\"><a href=\"#登陆\" class=\"headerlink\" title=\"登陆\"></a>登陆</h3><pre><code>sudo docker login\n</code></pre><p>输入自己的用户名和密码。</p>\n<h3 id=\"push-到-Docker-index\"><a href=\"#push-到-Docker-index\" class=\"headerlink\" title=\"push 到 Docker index\"></a>push 到 Docker index</h3><pre><code>sudo docker push username/repo\n</code></pre><p>这条命令会把一个repo下面的所有tag都push到<a href=\"https://index.docker.io/\" target=\"_blank\" rel=\"external\">https://index.docker.io/</a></p>\n<h2 id=\"安装JDK7失败\"><a href=\"#安装JDK7失败\" class=\"headerlink\" title=\"安装JDK7失败\"></a>安装JDK7失败</h2><p>我在container 里面安装jre7是可以的, <code>apt-get install openjdk-7-jre-headless</code> 成功。但是安装jdk7，<code>apt-get install openjdk-7-jdk</code>失败，错误消息如下：</p>\n<pre><code>Creating fuse device...\nmknod: `fuse-&apos;: Operation not permitted\nmakedev fuse c 10 229 root root 0660: failed\nchown: cannot access `/dev/fuse&apos;: No such file or directory\ndpkg: error processing fuse (--configure):\n subprocess installed post-installation script returned error exit status 1\nProcessing triggers for libc-bin ...\nldconfig deferred processing now taking place\nErrors were encountered while processing:\n fuse\nE: Sub-process /usr/bin/dpkg returned an error code (1)\n</code></pre><p>原因是权限不够，见<a href=\"https://github.com/dotcloud/docker/issues/963\" target=\"_blank\" rel=\"external\">Issue #963</a> 和 <a href=\"https://github.com/dotcloud/docker/issues/514\" target=\"_blank\" rel=\"external\">Issue #514</a></p>\n<p>所以，需要在启动container时，添加一个<code>-priviledged</code>参数，</p>\n<pre><code>sudo docker run -i -t -priviledged soulmachine/ubuntu /bin/bash\n</code></pre><p>在里面执行<code>apt-get install openjdk-7-jdk</code>，这次成功了。</p>\n<p>那如何在dockerfile里用RUN命令安装JDK7呢？dockerfile里没法指定<code>-priviledged</code>，目前没有办法，不过可以折中一下，安装openjdk6。</p>\n<h2 id=\"ENTRYPOINT-和-CMD-的区别\"><a href=\"#ENTRYPOINT-和-CMD-的区别\" class=\"headerlink\" title=\"ENTRYPOINT 和 CMD 的区别\"></a>ENTRYPOINT 和 CMD 的区别</h2><p>见<a href=\"http://www.kstaken.com/blog/2013/07/06/how-to-use-entrypoint-in-a-dockerfile/\" target=\"_blank\" rel=\"external\">How to Use Entrypoint in Docker Builder</a></p>\n<h2 id=\"docker-最佳实践\"><a href=\"#docker-最佳实践\" class=\"headerlink\" title=\"docker 最佳实践\"></a>docker 最佳实践</h2><p>见<a href=\"http://crosbymichael.com/dockerfile-best-practices.html\" target=\"_blank\" rel=\"external\">Dockerfile Best Practices</a></p>\n<h2 id=\"关于docker-的书籍\"><a href=\"#关于docker-的书籍\" class=\"headerlink\" title=\"关于docker 的书籍\"></a>关于docker 的书籍</h2><ul>\n<li><a href=\"http://dockerbook.com/\" target=\"_blank\" rel=\"external\">The Docker Book</a></li>\n</ul>\n<h2 id=\"底层原理\"><a href=\"#底层原理\" class=\"headerlink\" title=\"底层原理\"></a>底层原理</h2><p>image, container, fs layer，是什么关系？见这篇博客，<a href=\"http://www.activestate.com/blog/2013/06/solomon-hykes-explains-docker\" target=\"_blank\" rel=\"external\">Solomon Hykes Explains Docker</a></p>\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><ol>\n<li><a href=\"http://docs.docker.io/\" target=\"_blank\" rel=\"external\">Official docs</a></li>\n<li><a href=\"https://log.qingcloud.com/?p=129\" target=\"_blank\" rel=\"external\">Docker 初探</a></li>\n</ol>\n","excerpt":"<p><strong>前提条件：</strong>要安装好 docker，见我的另一篇博客，<a href=\"http://www.yanjiuyanjiu.com/blog/20131025\">docker 安装</a></p>\n<h2 id=\"交互式命令行入门教程\"><a href=\"#交互式命令行入门教程\" class=\"headerlink\" title=\"交互式命令行入门教程\"></a>交互式命令行入门教程</h2><p>首先强烈建议玩一遍官方的一个交互式命令行入门教程，<a href=\"http://www.docker.io/gettingstarted/\">Interactive commandline tutorial</a>。甚至要多玩几遍，加深印象。</p>\n<p>初次过完这个教程，感觉docker用起来跟git很类似。</p>\n<p>玩完了后，在自己的真实机器上，把上面的命令重新敲一遍，感受一下。</p>\n<h2 id=\"Hello-World\"><a href=\"#Hello-World\" class=\"headerlink\" title=\"Hello World\"></a>Hello World</h2><p>参考官方文档<a href=\"http://docs.docker.io/en/latest/examples/hello_world/#running-examples\">Hello World</a></p>\n<p>首先下载官方的ubuntu image:</p>\n<pre><code>sudo docker pull ubuntu\n</code></pre><p>然后运行 hello world：</p>\n<pre><code>sudo docker run ubuntu /bin/echo hello world\n</code></pre><h2 id=\"三种运行命令的模式\"><a href=\"#三种运行命令的模式\" class=\"headerlink\" title=\"三种运行命令的模式\"></a>三种运行命令的模式</h2><p>docker 有三种运行命令的方式，短暂方式，交互方式，daemon方式。</p>\n<p><strong>短暂方式</strong>，就是刚刚的那个”hello world”，命令执行完后，container就终止了，不过并没有消失，可以用 <code>sudo docker ps -a</code> 看一下所有的container，第一个就是刚刚执行过的container，可以再次执行一遍：</p>\n<pre><code>sudo docker start container_id\n</code></pre><p>不过这次看不到”hello world”了，只能看到ID，用<code>logs</code>命令才能看得到，</p>\n<pre><code>sudo docker logs container_id\n</code></pre><p>可以看到两个”hello world”，因为这个container运行了两次。</p>\n<p><strong>交互方式</strong>，</p>\n<pre><code>sudo docker run -i -t image_name /bin/bash\n</code></pre><p><strong>daemon方式</strong>，即让软件作为长时间服务运行，这就是SAAS啊！</p>\n<p>例如，一个无限循环打印的脚本（替换为memcached, apache等，操作方法仍然不变！）：</p>\n<pre><code>CONTAINER_ID=$(sudo docker run -d ubuntu /bin/sh -c &quot;while true; do echo hello world; sleep 1; done&quot;)\n</code></pre><p>在container外面查看它的输出</p>\n<pre><code>sudo docker logs $CONTAINER_ID\n</code></pre><p>或者连接上容器实时查看</p>\n<pre><code>sudo docker attach $CONTAINER_ID\n</code></pre><p>终止容器</p>\n<pre><code>sudo docker stop $CONTAINER_ID\n</code></pre><p><code>sudo docker ps</code>看一下，已经没了</p>\n<h2 id=\"docker-ps-命令详解\"><a href=\"#docker-ps-命令详解\" class=\"headerlink\" title=\"docker ps 命令详解\"></a>docker ps 命令详解</h2><p><code>sudo docker ps</code>，列出当前所有正在运行的container</p>\n<p><code>sudo docker ps -l</code>，列出最近一次启动的，且正在运行的container</p>\n<p><code>sudo docker ps -a</code>，列出所有的container</p>\n<p>其他用法请参考 <code>sudo docker ps -h</code></p>\n<p>还有一种方式可以让程序在daemon模式下运行，就是在Dockerfile里设置USER为daemon，见<a href=\"http://www.docker.io/learn/dockerfile/level2/\">Dockerfile tutorial Level2</a>。</p>\n<h2 id=\"添加http代理\"><a href=\"#添加http代理\" class=\"headerlink\" title=\"添加http代理\"></a>添加http代理</h2><p>在国内，pull或push的时候经常连不上docker.com（原因你懂的，或者在公司内部统一用一个代理上网的时候），可以在docker daemon进程启动的时候加个代理，例如</p>\n<pre><code>sudo HTTP_PROXY=proxy_server:port docker -d &amp;\n</code></pre><p>docker貌似是不识别<code>http_proxy</code>, <code>https_proxy</code>和<code>no_proxy</code>环境变量的，因此要在命令行里指定，参考 <a href=\"https://github.com/dotcloud/docker/issues/402\">Github Issue #402 Using Docker behind a firewall</a>。</p>\n<p>如果在命令行里指定了<code>HTTP_PROXY</code>，则要unset掉<code>http_proxy</code>和<code>https_proxy</code>环境变量。原因是：</p>\n<ul>\n<li>首先， docker daemon进程是通过http协议与docker.com通信的</li>\n<li>其次，docker的各种命令（例如 <code>run</code>, <code>login</code>等）也是通过http协议与docker daemon进程通信的（发送jasn字符串，daemon进程返回的也是json字符串），有时候docker客户端命令貌似能识别http_proxy变量，这时，客户端发送一个命令，路径是<code>localhost-&gt;http_proxy-&gt;daemon进程</code>，daemon进程返回的数据，路径是 <code>daemon进程-&gt;proxy-&gt;proxy-&gt;localhost</code>，其中，从<code>proxy-&gt;localhost</code>的路径是不通的，因为proxy连接不了内网IP。</li>\n</ul>\n<p>之所以把这一步放在本文开始，是因为这一步不做的话，后面很多命令会出错，让人摸不着头脑，我在这里就掉进坑了，花了很长时间才搞明白，原来是网络连接不稳定。</p>\n<h2 id=\"熟悉一下-Dockerfile\"><a href=\"#熟悉一下-Dockerfile\" class=\"headerlink\" title=\"熟悉一下 Dockerfile\"></a>熟悉一下 Dockerfile</h2><p>完了几遍交互式入门教程后，你会好奇，怎么自己定制一个 image，例如把常用的软件装好后打包 ? 这时候该 Dockfile 登场了。Dockerfile 实质上是一个脚本文件，用于自动化创建image。</p>","more":"<p>请跟着官方教程走一遍，<a href=\"http://www.docker.io/gettingstarted/\">Dockerfile Tutorial</a></p>\n<p>到这里， 官网的 Getting started 的内容基本上消化完了，接下来就是翻官网的<a href=\"http://docs.docker.io/en/latest/\">Documentation</a>了。</p>\n<h2 id=\"我的第一个Dockerfile\"><a href=\"#我的第一个Dockerfile\" class=\"headerlink\" title=\"我的第一个Dockerfile\"></a>我的第一个Dockerfile</h2><p>文件名为update.dockerfile，内容如下：</p>\n<pre><code># use the ubuntu base image provided by dotCloud\nFROM ubuntu\n\nMAINTAINER Frank Dai soulmachine@gmail.com\n\n\n# if you&apos;re behind a government firewall or company proxy\n# ENV http_proxy http://proxy-prc.intel.com:911\n# ENV https_proxy https://proxy-prc.intel.com:911\n# RUN echo &quot;Acquire::http::proxy \\&quot;proxy_server:port\\&quot;;&quot; &gt;&gt; /etc/apt/apt.conf\n# RUN echo &quot;Acquire::https::proxy \\&quot;proxy_server:port\\&quot;;&quot; &gt;&gt; /etc/apt/apt.conf\n\n\n# choose a faster mirror, see http://t.cn/zWYrzCE\nRUN echo &quot;deb mirror://mirrors.ubuntu.com/mirrors.txt precise main restricted universe multiverse&quot; &gt; /etc/apt/sources.list\nRUN echo &quot;deb mirror://mirrors.ubuntu.com/mirrors.txt precise-updates main restricted universe multiverse&quot; &gt;&gt; /etc/apt/sources.list\nRUN echo &quot;deb mirror://mirrors.ubuntu.com/mirrors.txt precise-backports main restricted universe multiverse&quot; &gt;&gt; /etc/apt/sources.list\nRUN echo &quot;deb mirror://mirrors.ubuntu.com/mirrors.txt precise-security main restricted universe multiverse&quot; &gt;&gt; /etc/apt/sources.list\n\nRUN apt-get update -y\n# currently docker official ubuntu image has a problem with apt-get upgrade\n# RUN apt-get upgrade -y &amp;&amp; apt-get dist-upgrade -y\nRUN apt-get clean all\n\n\n# install wget\nRUN apt-get install -y  wget\nRUN wget www.baidu.com\nRUN rm index.html\n\n#install vim editor\nRUN apt-get install -y vim\n</code></pre><p><strong>注意一个坑：</strong> <code>apt-get upgrade</code> 在当前官方的ubuntu image里是无法运行成功的，见 <a href=\"https://github.com/dotcloud/docker/issues/1724\">Issue #1724 apt-get upgrade in plain Ubuntu precise image fails</a>。所以，干脆放弃更新吧，能<code>apt-get install</code>软件就行了，不要有更新强迫症 :)</p>\n<h2 id=\"删除容器\"><a href=\"#删除容器\" class=\"headerlink\" title=\"删除容器\"></a>删除容器</h2><p><strong>每一行命令都会产生一个新的容器</strong>（无论是在<code>sudo docker run -i -t ubuntu /bin/bash</code> 模式下，还是Dockerfile里的RUN命令），玩了一会儿后，<code>sudo docker ps -a</code> 会看到很多容器，很是干扰视线，可以用一行命令删除所有容器：</p>\n<pre><code>sudo docker rm `sudo docker ps -a -q`\n</code></pre><h2 id=\"创建image\"><a href=\"#创建image\" class=\"headerlink\" title=\"创建image\"></a>创建image</h2><p>有两种用方式，</p>\n<ul>\n<li>写一个Dockerfile，然后用<code>docker build</code>创建一个image</li>\n<li>在容器里交互式地（例如<code>sudo docker run -i -t ubuntu /bin/bash</code>）进行一些列操作，然后<code>docker commit</code>固化成一个image。</li>\n</ul>\n<p>image相当于编程语言里的类，container相当于实例，不过可以动态给实例安装新软件，然后把这个container用commit命令固化成一个image。</p>\n<p>使用前面写好的update.dockerfile，创建一个image：</p>\n<pre><code>sudo docker build -t soulmachine/ubuntu:latest - &lt; update.dockerfile\n</code></pre><h2 id=\"下载image\"><a href=\"#下载image\" class=\"headerlink\" title=\"下载image\"></a>下载image</h2><p><a href=\"https://index.docker.io/\">https://index.docker.io/</a> 是官方的image仓库，也可以用 <a href=\"https://github.com/dotcloud/docker-registry\">Docker-Registry</a>创建自己的仓库，这就好比git，<a href=\"https://index.docker.io/\">https://index.docker.io/</a>相当于Github，也可以自己DIY搭建一个git服务器，把自己的代码托管到私有的服务器上。</p>\n<p><code>sudo docker pull ubuntu</code> 是从 <a href=\"https://index.docker.io/_/ubuntu/\">https://index.docker.io/_/ubuntu/</a> 下载名为 ubuntu 的repo，里面包含了几个tag，默认使用latest这个tag。这个repo是docker官方的。</p>\n<h2 id=\"上传并共享image\"><a href=\"#上传并共享image\" class=\"headerlink\" title=\"上传并共享image\"></a>上传并共享image</h2><p>自己build了一个image，想要共享，怎么办？参考这篇文章，<a href=\"http://crohr.me/journal/2013/docker-repository-create-base-boxes.html\">How to build and publish base boxes for Docker?</a></p>\n<h3 id=\"注册一个账号\"><a href=\"#注册一个账号\" class=\"headerlink\" title=\"注册一个账号\"></a>注册一个账号</h3><p>首先，要去 <a href=\"https://index.docker.io/\">https://index.docker.io/</a> 注册一个账号，例如我的是 soulmachine。</p>\n<h3 id=\"build一个image\"><a href=\"#build一个image\" class=\"headerlink\" title=\"build一个image\"></a>build一个image</h3><p>build命令格式如下：</p>\n<pre><code>sudo docker build -t username/repo:tag - &lt; Dockerfile\n</code></pre><p>如果没有tag，则默认为 latest。</p>\n<h3 id=\"登陆\"><a href=\"#登陆\" class=\"headerlink\" title=\"登陆\"></a>登陆</h3><pre><code>sudo docker login\n</code></pre><p>输入自己的用户名和密码。</p>\n<h3 id=\"push-到-Docker-index\"><a href=\"#push-到-Docker-index\" class=\"headerlink\" title=\"push 到 Docker index\"></a>push 到 Docker index</h3><pre><code>sudo docker push username/repo\n</code></pre><p>这条命令会把一个repo下面的所有tag都push到<a href=\"https://index.docker.io/\">https://index.docker.io/</a></p>\n<h2 id=\"安装JDK7失败\"><a href=\"#安装JDK7失败\" class=\"headerlink\" title=\"安装JDK7失败\"></a>安装JDK7失败</h2><p>我在container 里面安装jre7是可以的, <code>apt-get install openjdk-7-jre-headless</code> 成功。但是安装jdk7，<code>apt-get install openjdk-7-jdk</code>失败，错误消息如下：</p>\n<pre><code>Creating fuse device...\nmknod: `fuse-&apos;: Operation not permitted\nmakedev fuse c 10 229 root root 0660: failed\nchown: cannot access `/dev/fuse&apos;: No such file or directory\ndpkg: error processing fuse (--configure):\n subprocess installed post-installation script returned error exit status 1\nProcessing triggers for libc-bin ...\nldconfig deferred processing now taking place\nErrors were encountered while processing:\n fuse\nE: Sub-process /usr/bin/dpkg returned an error code (1)\n</code></pre><p>原因是权限不够，见<a href=\"https://github.com/dotcloud/docker/issues/963\">Issue #963</a> 和 <a href=\"https://github.com/dotcloud/docker/issues/514\">Issue #514</a></p>\n<p>所以，需要在启动container时，添加一个<code>-priviledged</code>参数，</p>\n<pre><code>sudo docker run -i -t -priviledged soulmachine/ubuntu /bin/bash\n</code></pre><p>在里面执行<code>apt-get install openjdk-7-jdk</code>，这次成功了。</p>\n<p>那如何在dockerfile里用RUN命令安装JDK7呢？dockerfile里没法指定<code>-priviledged</code>，目前没有办法，不过可以折中一下，安装openjdk6。</p>\n<h2 id=\"ENTRYPOINT-和-CMD-的区别\"><a href=\"#ENTRYPOINT-和-CMD-的区别\" class=\"headerlink\" title=\"ENTRYPOINT 和 CMD 的区别\"></a>ENTRYPOINT 和 CMD 的区别</h2><p>见<a href=\"http://www.kstaken.com/blog/2013/07/06/how-to-use-entrypoint-in-a-dockerfile/\">How to Use Entrypoint in Docker Builder</a></p>\n<h2 id=\"docker-最佳实践\"><a href=\"#docker-最佳实践\" class=\"headerlink\" title=\"docker 最佳实践\"></a>docker 最佳实践</h2><p>见<a href=\"http://crosbymichael.com/dockerfile-best-practices.html\">Dockerfile Best Practices</a></p>\n<h2 id=\"关于docker-的书籍\"><a href=\"#关于docker-的书籍\" class=\"headerlink\" title=\"关于docker 的书籍\"></a>关于docker 的书籍</h2><ul>\n<li><a href=\"http://dockerbook.com/\">The Docker Book</a></li>\n</ul>\n<h2 id=\"底层原理\"><a href=\"#底层原理\" class=\"headerlink\" title=\"底层原理\"></a>底层原理</h2><p>image, container, fs layer，是什么关系？见这篇博客，<a href=\"http://www.activestate.com/blog/2013/06/solomon-hykes-explains-docker\">Solomon Hykes Explains Docker</a></p>\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><ol>\n<li><a href=\"http://docs.docker.io/\">Official docs</a></li>\n<li><a href=\"https://log.qingcloud.com/?p=129\">Docker 初探</a></li>\n</ol>"},{"layout":"post","title":"使用docker打造spark集群","date":"2013-10-27T20:30:00.000Z","comments":1,"_content":"**前提条件：**安装好了docker，见我的另一篇博客，[Docker安装](http://www.yanjiuyanjiu.com/blog/20131025)\n\n有两种方式，\n\n* [Spark官方repo](https://github.com/apache/incubator-spark)里，docker文件夹下的脚本。官方的这个脚本封装很薄，尽可能把必要的信息展示出来。\n* [AMPLab开源的这个独立小项目](https://github.com/amplab/docker-scripts)，来打造一个spark集群。这个脚本封装很深，自带了一个DNS服务器，还有hadoop，非常自动化，缺点是很多信息看不到了。\n\n# 1. 第1种方式\n\n## git clone 源码\n首先要把官方repo的代码下载下来\n\n\tgit clone git@github.com:apache/incubator-spark.git\n\n## （可选）修改apt源\n在国内，将apt源修改国内源，例如163的源，速度会快很多。将`base/Dockerfile`里的\n\t\n\tRUN echo \"deb http://archive.ubuntu.com/ubuntu precise main universe\" > /etc/apt/sources.list\n\n替换为\n\n\tRUN echo \"deb http://mirrors.163.com/ubuntu/ precise main restricted universe multiverse\" > /etc/apt/sources.list\n\tRUN echo \"deb http://mirrors.163.com/ubuntu/ precise-security main restricted universe multiverse\" >> /etc/apt/sources.list\n\tRUN echo \"deb http://mirrors.163.com/ubuntu/ precise-updates main restricted universe multiverse\" >> /etc/apt/sources.list\n\tRUN echo \"deb http://mirrors.163.com/ubuntu/ precise-proposed main restricted universe multiverse\" >> /etc/apt/sources.list\n\tRUN echo \"deb http://mirrors.163.com/ubuntu/ precise-backports main restricted universe multiverse\" >> /etc/apt/sources.list\n\tRUN echo \"deb-src http://mirrors.163.com/ubuntu/ precise main restricted universe multiverse\" >> /etc/apt/sources.list\n\tRUN echo \"deb-src http://mirrors.163.com/ubuntu/ precise-security main restricted universe multiverse\" >> /etc/apt/sources.list\n\tRUN echo \"deb-src http://mirrors.163.com/ubuntu/ precise-updates main restricted universe multiverse\" >> /etc/apt/sources.list\n\tRUN echo \"deb-src http://mirrors.163.com/ubuntu/ precise-proposed main restricted universe multiverse\" >> /etc/apt/sources.list\n\tRUN echo \"deb-src http://mirrors.163.com/ubuntu/ precise-backports main restricted universe multiverse\" >> /etc/apt/sources.list\n\t\n## build镜像\n将`build`和`spark-test/build`里的`docker`命令前，添加`sudo`，然后执行`docker`下的`build`\n\n\tcd docker\n\t./build\n\n## 启动master\n\n\tsudo docker run -v $SPARK_HOME:/opt/spark spark-test-master\n\n## 启动worker\n新开一个终端窗口（强烈推荐tmux），启动一个worker\n\n\tsudo docker run -v $SPARK_HOME:/opt/spark spark-test-worker <master_ip>\n\n可以在master终端窗口看到worker注册上来了。\n\n可以再开多个终端窗口，启动多个worker。\n\t\n\n# 2. 第2种方式\n\n## 升级wget\n如果发现wget不识别`--no-proxy`选项，需要升级wget。\n\n## 下载镜像\n为了让脚本第一次执行的时候更快，还是手动下载所有的镜像吧，amplab在index.docker.io上有一个官方账号，把这个账号有关spark的repo都pull下来。\n\n\tsudo docker pull amplab/apache-hadoop-hdfs-precise\n\tsudo docker pull amplab/dnsmasq-precise\n\tsudo docker pull amplab/spark-worker\n\tsudo docker pull amplab/spark-master\n\tsudo docker pull amplab/spark-shell\n\t\n\n## git clone 脚本\n\n\tgit@github.com:amplab/docker-scripts.git\n\n这个脚本可以一键启动集群，爽啊哈哈哈！\n\n## 一键启动spark集群\n\n\tsudo ./deploy/deploy.sh -i amplab/spark:0.8.0 -w 3 \n\n## 启动 Spark shell\n启动一个交互式shell吧，IP为上一步输出的Master的IP\n\n\tsudo docker run -i -t -dns 172.17.0.90 amplab/spark-shell:0.8.0\n\n## 运行一个简单的的例子\n\n\tscala> val textFile = sc.textFile(\"hdfs://master:9000/user/hdfs/test.txt\")\n\tscala> textFile.count()\n\tscala> textFile.map({line => line}).collect()\n\t\n## 关闭集群\n\n\t$ sudo ./deploy/kill_all.sh spark\n\t$ sudo ./deploy/kill_all.sh nameserver\n\n## 更多详情请参考项目主页的文档\n\n<https://github.com/amplab/docker-scripts>\n","source":"_posts/2013-10-27-build-spark-cluster-with-docker.md","raw":"---\nlayout: post\ntitle: \"使用docker打造spark集群\"\ndate: 2013-10-27 20:30\ncomments: true\ncategories: Spark\n---\n**前提条件：**安装好了docker，见我的另一篇博客，[Docker安装](http://www.yanjiuyanjiu.com/blog/20131025)\n\n有两种方式，\n\n* [Spark官方repo](https://github.com/apache/incubator-spark)里，docker文件夹下的脚本。官方的这个脚本封装很薄，尽可能把必要的信息展示出来。\n* [AMPLab开源的这个独立小项目](https://github.com/amplab/docker-scripts)，来打造一个spark集群。这个脚本封装很深，自带了一个DNS服务器，还有hadoop，非常自动化，缺点是很多信息看不到了。\n\n# 1. 第1种方式\n\n## git clone 源码\n首先要把官方repo的代码下载下来\n\n\tgit clone git@github.com:apache/incubator-spark.git\n\n## （可选）修改apt源\n在国内，将apt源修改国内源，例如163的源，速度会快很多。将`base/Dockerfile`里的\n\t\n\tRUN echo \"deb http://archive.ubuntu.com/ubuntu precise main universe\" > /etc/apt/sources.list\n\n替换为\n\n\tRUN echo \"deb http://mirrors.163.com/ubuntu/ precise main restricted universe multiverse\" > /etc/apt/sources.list\n\tRUN echo \"deb http://mirrors.163.com/ubuntu/ precise-security main restricted universe multiverse\" >> /etc/apt/sources.list\n\tRUN echo \"deb http://mirrors.163.com/ubuntu/ precise-updates main restricted universe multiverse\" >> /etc/apt/sources.list\n\tRUN echo \"deb http://mirrors.163.com/ubuntu/ precise-proposed main restricted universe multiverse\" >> /etc/apt/sources.list\n\tRUN echo \"deb http://mirrors.163.com/ubuntu/ precise-backports main restricted universe multiverse\" >> /etc/apt/sources.list\n\tRUN echo \"deb-src http://mirrors.163.com/ubuntu/ precise main restricted universe multiverse\" >> /etc/apt/sources.list\n\tRUN echo \"deb-src http://mirrors.163.com/ubuntu/ precise-security main restricted universe multiverse\" >> /etc/apt/sources.list\n\tRUN echo \"deb-src http://mirrors.163.com/ubuntu/ precise-updates main restricted universe multiverse\" >> /etc/apt/sources.list\n\tRUN echo \"deb-src http://mirrors.163.com/ubuntu/ precise-proposed main restricted universe multiverse\" >> /etc/apt/sources.list\n\tRUN echo \"deb-src http://mirrors.163.com/ubuntu/ precise-backports main restricted universe multiverse\" >> /etc/apt/sources.list\n\t\n## build镜像\n将`build`和`spark-test/build`里的`docker`命令前，添加`sudo`，然后执行`docker`下的`build`\n\n\tcd docker\n\t./build\n\n## 启动master\n\n\tsudo docker run -v $SPARK_HOME:/opt/spark spark-test-master\n\n## 启动worker\n新开一个终端窗口（强烈推荐tmux），启动一个worker\n\n\tsudo docker run -v $SPARK_HOME:/opt/spark spark-test-worker <master_ip>\n\n可以在master终端窗口看到worker注册上来了。\n\n可以再开多个终端窗口，启动多个worker。\n\t\n\n# 2. 第2种方式\n\n## 升级wget\n如果发现wget不识别`--no-proxy`选项，需要升级wget。\n\n## 下载镜像\n为了让脚本第一次执行的时候更快，还是手动下载所有的镜像吧，amplab在index.docker.io上有一个官方账号，把这个账号有关spark的repo都pull下来。\n\n\tsudo docker pull amplab/apache-hadoop-hdfs-precise\n\tsudo docker pull amplab/dnsmasq-precise\n\tsudo docker pull amplab/spark-worker\n\tsudo docker pull amplab/spark-master\n\tsudo docker pull amplab/spark-shell\n\t\n\n## git clone 脚本\n\n\tgit@github.com:amplab/docker-scripts.git\n\n这个脚本可以一键启动集群，爽啊哈哈哈！\n\n## 一键启动spark集群\n\n\tsudo ./deploy/deploy.sh -i amplab/spark:0.8.0 -w 3 \n\n## 启动 Spark shell\n启动一个交互式shell吧，IP为上一步输出的Master的IP\n\n\tsudo docker run -i -t -dns 172.17.0.90 amplab/spark-shell:0.8.0\n\n## 运行一个简单的的例子\n\n\tscala> val textFile = sc.textFile(\"hdfs://master:9000/user/hdfs/test.txt\")\n\tscala> textFile.count()\n\tscala> textFile.map({line => line}).collect()\n\t\n## 关闭集群\n\n\t$ sudo ./deploy/kill_all.sh spark\n\t$ sudo ./deploy/kill_all.sh nameserver\n\n## 更多详情请参考项目主页的文档\n\n<https://github.com/amplab/docker-scripts>\n","slug":"2013-10-27-build-spark-cluster-with-docker","published":1,"updated":"2016-08-18T09:21:04.000Z","photos":[],"link":"","_id":"cis07pf3r002101pqcu3r8bms","content":"<p><strong>前提条件：</strong>安装好了docker，见我的另一篇博客，<a href=\"http://www.yanjiuyanjiu.com/blog/20131025\" target=\"_blank\" rel=\"external\">Docker安装</a></p>\n<p>有两种方式，</p>\n<ul>\n<li><a href=\"https://github.com/apache/incubator-spark\" target=\"_blank\" rel=\"external\">Spark官方repo</a>里，docker文件夹下的脚本。官方的这个脚本封装很薄，尽可能把必要的信息展示出来。</li>\n<li><a href=\"https://github.com/amplab/docker-scripts\" target=\"_blank\" rel=\"external\">AMPLab开源的这个独立小项目</a>，来打造一个spark集群。这个脚本封装很深，自带了一个DNS服务器，还有hadoop，非常自动化，缺点是很多信息看不到了。</li>\n</ul>\n<h1 id=\"1-第1种方式\"><a href=\"#1-第1种方式\" class=\"headerlink\" title=\"1. 第1种方式\"></a>1. 第1种方式</h1><h2 id=\"git-clone-源码\"><a href=\"#git-clone-源码\" class=\"headerlink\" title=\"git clone 源码\"></a>git clone 源码</h2><p>首先要把官方repo的代码下载下来</p>\n<pre><code>git clone git@github.com:apache/incubator-spark.git\n</code></pre><h2 id=\"（可选）修改apt源\"><a href=\"#（可选）修改apt源\" class=\"headerlink\" title=\"（可选）修改apt源\"></a>（可选）修改apt源</h2><p>在国内，将apt源修改国内源，例如163的源，速度会快很多。将<code>base/Dockerfile</code>里的</p>\n<pre><code>RUN echo &quot;deb http://archive.ubuntu.com/ubuntu precise main universe&quot; &gt; /etc/apt/sources.list\n</code></pre><p>替换为</p>\n<pre><code>RUN echo &quot;deb http://mirrors.163.com/ubuntu/ precise main restricted universe multiverse&quot; &gt; /etc/apt/sources.list\nRUN echo &quot;deb http://mirrors.163.com/ubuntu/ precise-security main restricted universe multiverse&quot; &gt;&gt; /etc/apt/sources.list\nRUN echo &quot;deb http://mirrors.163.com/ubuntu/ precise-updates main restricted universe multiverse&quot; &gt;&gt; /etc/apt/sources.list\nRUN echo &quot;deb http://mirrors.163.com/ubuntu/ precise-proposed main restricted universe multiverse&quot; &gt;&gt; /etc/apt/sources.list\nRUN echo &quot;deb http://mirrors.163.com/ubuntu/ precise-backports main restricted universe multiverse&quot; &gt;&gt; /etc/apt/sources.list\nRUN echo &quot;deb-src http://mirrors.163.com/ubuntu/ precise main restricted universe multiverse&quot; &gt;&gt; /etc/apt/sources.list\nRUN echo &quot;deb-src http://mirrors.163.com/ubuntu/ precise-security main restricted universe multiverse&quot; &gt;&gt; /etc/apt/sources.list\nRUN echo &quot;deb-src http://mirrors.163.com/ubuntu/ precise-updates main restricted universe multiverse&quot; &gt;&gt; /etc/apt/sources.list\nRUN echo &quot;deb-src http://mirrors.163.com/ubuntu/ precise-proposed main restricted universe multiverse&quot; &gt;&gt; /etc/apt/sources.list\nRUN echo &quot;deb-src http://mirrors.163.com/ubuntu/ precise-backports main restricted universe multiverse&quot; &gt;&gt; /etc/apt/sources.list\n</code></pre><h2 id=\"build镜像\"><a href=\"#build镜像\" class=\"headerlink\" title=\"build镜像\"></a>build镜像</h2><p>将<code>build</code>和<code>spark-test/build</code>里的<code>docker</code>命令前，添加<code>sudo</code>，然后执行<code>docker</code>下的<code>build</code></p>\n<pre><code>cd docker\n./build\n</code></pre><h2 id=\"启动master\"><a href=\"#启动master\" class=\"headerlink\" title=\"启动master\"></a>启动master</h2><pre><code>sudo docker run -v $SPARK_HOME:/opt/spark spark-test-master\n</code></pre><h2 id=\"启动worker\"><a href=\"#启动worker\" class=\"headerlink\" title=\"启动worker\"></a>启动worker</h2><p>新开一个终端窗口（强烈推荐tmux），启动一个worker</p>\n<pre><code>sudo docker run -v $SPARK_HOME:/opt/spark spark-test-worker &lt;master_ip&gt;\n</code></pre><p>可以在master终端窗口看到worker注册上来了。</p>\n<p>可以再开多个终端窗口，启动多个worker。</p>\n<h1 id=\"2-第2种方式\"><a href=\"#2-第2种方式\" class=\"headerlink\" title=\"2. 第2种方式\"></a>2. 第2种方式</h1><h2 id=\"升级wget\"><a href=\"#升级wget\" class=\"headerlink\" title=\"升级wget\"></a>升级wget</h2><p>如果发现wget不识别<code>--no-proxy</code>选项，需要升级wget。</p>\n<h2 id=\"下载镜像\"><a href=\"#下载镜像\" class=\"headerlink\" title=\"下载镜像\"></a>下载镜像</h2><p>为了让脚本第一次执行的时候更快，还是手动下载所有的镜像吧，amplab在index.docker.io上有一个官方账号，把这个账号有关spark的repo都pull下来。</p>\n<pre><code>sudo docker pull amplab/apache-hadoop-hdfs-precise\nsudo docker pull amplab/dnsmasq-precise\nsudo docker pull amplab/spark-worker\nsudo docker pull amplab/spark-master\nsudo docker pull amplab/spark-shell\n</code></pre><h2 id=\"git-clone-脚本\"><a href=\"#git-clone-脚本\" class=\"headerlink\" title=\"git clone 脚本\"></a>git clone 脚本</h2><pre><code>git@github.com:amplab/docker-scripts.git\n</code></pre><p>这个脚本可以一键启动集群，爽啊哈哈哈！</p>\n<h2 id=\"一键启动spark集群\"><a href=\"#一键启动spark集群\" class=\"headerlink\" title=\"一键启动spark集群\"></a>一键启动spark集群</h2><pre><code>sudo ./deploy/deploy.sh -i amplab/spark:0.8.0 -w 3 \n</code></pre><h2 id=\"启动-Spark-shell\"><a href=\"#启动-Spark-shell\" class=\"headerlink\" title=\"启动 Spark shell\"></a>启动 Spark shell</h2><p>启动一个交互式shell吧，IP为上一步输出的Master的IP</p>\n<pre><code>sudo docker run -i -t -dns 172.17.0.90 amplab/spark-shell:0.8.0\n</code></pre><h2 id=\"运行一个简单的的例子\"><a href=\"#运行一个简单的的例子\" class=\"headerlink\" title=\"运行一个简单的的例子\"></a>运行一个简单的的例子</h2><pre><code>scala&gt; val textFile = sc.textFile(&quot;hdfs://master:9000/user/hdfs/test.txt&quot;)\nscala&gt; textFile.count()\nscala&gt; textFile.map({line =&gt; line}).collect()\n</code></pre><h2 id=\"关闭集群\"><a href=\"#关闭集群\" class=\"headerlink\" title=\"关闭集群\"></a>关闭集群</h2><pre><code>$ sudo ./deploy/kill_all.sh spark\n$ sudo ./deploy/kill_all.sh nameserver\n</code></pre><h2 id=\"更多详情请参考项目主页的文档\"><a href=\"#更多详情请参考项目主页的文档\" class=\"headerlink\" title=\"更多详情请参考项目主页的文档\"></a>更多详情请参考项目主页的文档</h2><p><a href=\"https://github.com/amplab/docker-scripts\" target=\"_blank\" rel=\"external\">https://github.com/amplab/docker-scripts</a></p>\n","excerpt":"","more":"<p><strong>前提条件：</strong>安装好了docker，见我的另一篇博客，<a href=\"http://www.yanjiuyanjiu.com/blog/20131025\">Docker安装</a></p>\n<p>有两种方式，</p>\n<ul>\n<li><a href=\"https://github.com/apache/incubator-spark\">Spark官方repo</a>里，docker文件夹下的脚本。官方的这个脚本封装很薄，尽可能把必要的信息展示出来。</li>\n<li><a href=\"https://github.com/amplab/docker-scripts\">AMPLab开源的这个独立小项目</a>，来打造一个spark集群。这个脚本封装很深，自带了一个DNS服务器，还有hadoop，非常自动化，缺点是很多信息看不到了。</li>\n</ul>\n<h1 id=\"1-第1种方式\"><a href=\"#1-第1种方式\" class=\"headerlink\" title=\"1. 第1种方式\"></a>1. 第1种方式</h1><h2 id=\"git-clone-源码\"><a href=\"#git-clone-源码\" class=\"headerlink\" title=\"git clone 源码\"></a>git clone 源码</h2><p>首先要把官方repo的代码下载下来</p>\n<pre><code>git clone git@github.com:apache/incubator-spark.git\n</code></pre><h2 id=\"（可选）修改apt源\"><a href=\"#（可选）修改apt源\" class=\"headerlink\" title=\"（可选）修改apt源\"></a>（可选）修改apt源</h2><p>在国内，将apt源修改国内源，例如163的源，速度会快很多。将<code>base/Dockerfile</code>里的</p>\n<pre><code>RUN echo &quot;deb http://archive.ubuntu.com/ubuntu precise main universe&quot; &gt; /etc/apt/sources.list\n</code></pre><p>替换为</p>\n<pre><code>RUN echo &quot;deb http://mirrors.163.com/ubuntu/ precise main restricted universe multiverse&quot; &gt; /etc/apt/sources.list\nRUN echo &quot;deb http://mirrors.163.com/ubuntu/ precise-security main restricted universe multiverse&quot; &gt;&gt; /etc/apt/sources.list\nRUN echo &quot;deb http://mirrors.163.com/ubuntu/ precise-updates main restricted universe multiverse&quot; &gt;&gt; /etc/apt/sources.list\nRUN echo &quot;deb http://mirrors.163.com/ubuntu/ precise-proposed main restricted universe multiverse&quot; &gt;&gt; /etc/apt/sources.list\nRUN echo &quot;deb http://mirrors.163.com/ubuntu/ precise-backports main restricted universe multiverse&quot; &gt;&gt; /etc/apt/sources.list\nRUN echo &quot;deb-src http://mirrors.163.com/ubuntu/ precise main restricted universe multiverse&quot; &gt;&gt; /etc/apt/sources.list\nRUN echo &quot;deb-src http://mirrors.163.com/ubuntu/ precise-security main restricted universe multiverse&quot; &gt;&gt; /etc/apt/sources.list\nRUN echo &quot;deb-src http://mirrors.163.com/ubuntu/ precise-updates main restricted universe multiverse&quot; &gt;&gt; /etc/apt/sources.list\nRUN echo &quot;deb-src http://mirrors.163.com/ubuntu/ precise-proposed main restricted universe multiverse&quot; &gt;&gt; /etc/apt/sources.list\nRUN echo &quot;deb-src http://mirrors.163.com/ubuntu/ precise-backports main restricted universe multiverse&quot; &gt;&gt; /etc/apt/sources.list\n</code></pre><h2 id=\"build镜像\"><a href=\"#build镜像\" class=\"headerlink\" title=\"build镜像\"></a>build镜像</h2><p>将<code>build</code>和<code>spark-test/build</code>里的<code>docker</code>命令前，添加<code>sudo</code>，然后执行<code>docker</code>下的<code>build</code></p>\n<pre><code>cd docker\n./build\n</code></pre><h2 id=\"启动master\"><a href=\"#启动master\" class=\"headerlink\" title=\"启动master\"></a>启动master</h2><pre><code>sudo docker run -v $SPARK_HOME:/opt/spark spark-test-master\n</code></pre><h2 id=\"启动worker\"><a href=\"#启动worker\" class=\"headerlink\" title=\"启动worker\"></a>启动worker</h2><p>新开一个终端窗口（强烈推荐tmux），启动一个worker</p>\n<pre><code>sudo docker run -v $SPARK_HOME:/opt/spark spark-test-worker &lt;master_ip&gt;\n</code></pre><p>可以在master终端窗口看到worker注册上来了。</p>\n<p>可以再开多个终端窗口，启动多个worker。</p>\n<h1 id=\"2-第2种方式\"><a href=\"#2-第2种方式\" class=\"headerlink\" title=\"2. 第2种方式\"></a>2. 第2种方式</h1><h2 id=\"升级wget\"><a href=\"#升级wget\" class=\"headerlink\" title=\"升级wget\"></a>升级wget</h2><p>如果发现wget不识别<code>--no-proxy</code>选项，需要升级wget。</p>\n<h2 id=\"下载镜像\"><a href=\"#下载镜像\" class=\"headerlink\" title=\"下载镜像\"></a>下载镜像</h2><p>为了让脚本第一次执行的时候更快，还是手动下载所有的镜像吧，amplab在index.docker.io上有一个官方账号，把这个账号有关spark的repo都pull下来。</p>\n<pre><code>sudo docker pull amplab/apache-hadoop-hdfs-precise\nsudo docker pull amplab/dnsmasq-precise\nsudo docker pull amplab/spark-worker\nsudo docker pull amplab/spark-master\nsudo docker pull amplab/spark-shell\n</code></pre><h2 id=\"git-clone-脚本\"><a href=\"#git-clone-脚本\" class=\"headerlink\" title=\"git clone 脚本\"></a>git clone 脚本</h2><pre><code>git@github.com:amplab/docker-scripts.git\n</code></pre><p>这个脚本可以一键启动集群，爽啊哈哈哈！</p>\n<h2 id=\"一键启动spark集群\"><a href=\"#一键启动spark集群\" class=\"headerlink\" title=\"一键启动spark集群\"></a>一键启动spark集群</h2><pre><code>sudo ./deploy/deploy.sh -i amplab/spark:0.8.0 -w 3 \n</code></pre><h2 id=\"启动-Spark-shell\"><a href=\"#启动-Spark-shell\" class=\"headerlink\" title=\"启动 Spark shell\"></a>启动 Spark shell</h2><p>启动一个交互式shell吧，IP为上一步输出的Master的IP</p>\n<pre><code>sudo docker run -i -t -dns 172.17.0.90 amplab/spark-shell:0.8.0\n</code></pre><h2 id=\"运行一个简单的的例子\"><a href=\"#运行一个简单的的例子\" class=\"headerlink\" title=\"运行一个简单的的例子\"></a>运行一个简单的的例子</h2><pre><code>scala&gt; val textFile = sc.textFile(&quot;hdfs://master:9000/user/hdfs/test.txt&quot;)\nscala&gt; textFile.count()\nscala&gt; textFile.map({line =&gt; line}).collect()\n</code></pre><h2 id=\"关闭集群\"><a href=\"#关闭集群\" class=\"headerlink\" title=\"关闭集群\"></a>关闭集群</h2><pre><code>$ sudo ./deploy/kill_all.sh spark\n$ sudo ./deploy/kill_all.sh nameserver\n</code></pre><h2 id=\"更多详情请参考项目主页的文档\"><a href=\"#更多详情请参考项目主页的文档\" class=\"headerlink\" title=\"更多详情请参考项目主页的文档\"></a>更多详情请参考项目主页的文档</h2><p><a href=\"https://github.com/amplab/docker-scripts\">https://github.com/amplab/docker-scripts</a></p>\n"},{"layout":"post","title":"Nutch 快速入门(Nutch 1.7)","date":"2014-01-21T04:11:00.000Z","comments":1,"_content":"本文主要参考[Nutch Tutorial](http://wiki.apache.org/nutch/NutchTutorial)\n\nNutch 2.2.1目前性能没有Nutch 1.7好，参考这里，[NUTCH FIGHT! 1.7 vs 2.2.1](http://digitalpebble.blogspot.com/2013/09/nutch-fight-17-vs-221.html). 所以我目前还是使用的Nutch 1.7。\n\n##1 下载已编译好的二进制包，解压\n    $ wget http://psg.mtu.edu/pub/apache/nutch/1.7/apache-nutch-1.7-bin.tar.gz\n    $ tar zxf apache-nutch-1.7-bin.tar.gz\n\n##2 验证一下\n\n    $ cd apache-nutch-1.7\n    $ bin/nutch\n\n如果出现\"Permission denied\"请运行下面的命令：\n\n    $ chmod +x bin/nutch\n\n如果有Warning说 `JAVA_HOME`没有设置，请设置一下`JAVA_HOME`.\n\n##3 添加种子URL\n\n    mkdir ~/urls\n    vim ～/urls/seed.txt\n    http://movie.douban.com/subject/5323968/\n\n##4 设置URL过滤规则\n如果只想抓取某种类型的URL，可以在 `conf/regex-urlfilter.txt`设置正则表达式，于是，只有匹配这些正则表达式的URL才会被抓取。\n\n<!--more-->\n\n例如，我只想抓取豆瓣电影的数据，可以这样设置：\n    \n    #注释掉这一行\n    # skip URLs containing certain characters as probable queries, etc.\n    #-[?*!@=]\n    # accept anything else\n    #注释掉这行\n    #+.\n    +^http:\\/\\/movie\\.douban\\.com\\/subject\\/[0-9]+\\/(\\?.+)?$\n\n##5 设置agent名字\n\nconf/nutch-site.xml:\n\n    <property>\n      <name>http.agent.name</name>\n      <value>My Nutch Spider</value>\n    </property>\n\n这一步是从这本书上看到的，[Web Crawling and Data Mining with Apache Nutch](http://www.packtpub.com/web-crawling-and-data-mining-with-apache-nutch/book)，第14页。\n\n##6 安装Solr\n由于建索引的时候需要使用Solr，因此我们需要安装并启动一个Solr服务器。\n\n参考[Nutch Tutorial](http://wiki.apache.org/nutch/NutchTutorial) 第4、5、6步，以及[Solr Tutorial](http://lucene.apache.org/solr/4_6_1/tutorial.html)。\n\n###6.1 下载，解压\n\nwget http://mirrors.cnnic.cn/apache/lucene/solr/4.6.1/solr-4.6.1.tgz\ntar -zxf solr-4.6.1.tgz\n\n###6.2 运行Solr\n\n    cd example\n    java -jar start.jar\n\n验证是否启动成功\n\n用浏览器打开 <http://localhost:8983/solr/admin/>，如果能看到页面，说明启动成功。\n\n###6.3 将Nutch与Solr集成在一起\n\n将`NUTCH_DIR/conf/schema-solr4.xml`拷贝到`SOLR_DIR/solr/collection1/conf/`，重命名为schema.xml，并在`<fields>...</fields>`最后添加一行(具体解释见[Solr 4.2 - what is _version_field?](http://stackoverflow.com/questions/15527380/solr-4-2-what-is-version-field))，\n\n    <field name=\"_version_\" type=\"long\" indexed=\"true\" stored=\"true\" multiValued=\"false\"/>\n\n重启Solr，\n\n    # Ctrl+C to stop Solr\n    java -jar start.jar\n\n##7 使用crawl脚本一键抓取\nNutch自带了一个脚本，`./bin/crawl`，把抓取的各个步骤合并成一个命令，看一下它的用法\n\n    $ bin/crawl \n    Missing seedDir : crawl <seedDir> <crawlDir> <solrURL> <numberOfRounds>\n\n注意，是使用`bin/crawl`，不是`bin/nutch crawl`，后者已经是deprecated的了。\n\n###7.1 抓取网页\n\n    $ ./bin/crawl ~/urls/ ./TestCrawl http://localhost:8983/solr/ 2\n\n* `～/urls` 是存放了种子url的目录\n* TestCrawl 是存放数据的根目录（在Nutch 2.x中，则表示crawlId，这会在HBase中创建一张以crawlId为前缀的表，例如TestCrawl_Webpage）\n* http://localhost:8983/solr/ , 这是Solr服务器\n* 2，numberOfRounds，迭代的次数\n\n过了一会儿，屏幕上出现了一大堆url，可以看到爬虫正在抓取！\n\n    fetching http://music.douban.com/subject/25811077/ (queue crawl delay=5000ms)\n    fetching http://read.douban.com/ebook/1919781 (queue crawl delay=5000ms)\n    fetching http://www.douban.com/online/11670861/ (queue crawl delay=5000ms)\n    fetching http://book.douban.com/tag/绘本 (queue crawl delay=5000ms)\n    fetching http://movie.douban.com/tag/科幻 (queue crawl delay=5000ms)\n    49/50 spinwaiting/active, 56 pages, 0 errors, 0.9 1 pages/s, 332 245 kb/s, 131 URLs in 5 queues\n    fetching http://music.douban.com/subject/25762454/ (queue crawl delay=5000ms)\n    fetching http://read.douban.com/reader/ebook/1951242/ (queue crawl delay=5000ms)\n    fetching http://www.douban.com/mobile/read-notes (queue crawl delay=5000ms)\n    fetching http://book.douban.com/tag/诗歌 (queue crawl delay=5000ms)\n    50/50 spinwaiting/active, 61 pages, 0 errors, 0.9 1 pages/s, 334 366 kb/s, 127 URLs in 5 queues\n\n###7.2 查看结果\n\n    $ bin/nutch readdb TestCrawl/crawldb/ -stats\n    14/02/14 16:35:47 INFO crawl.CrawlDbReader: Statistics for CrawlDb: TestCrawl/crawldb/\n    14/02/14 16:35:47 INFO crawl.CrawlDbReader: TOTAL urls:\t70\n    14/02/14 16:35:47 INFO crawl.CrawlDbReader: retry 0:\t70\n    14/02/14 16:35:47 INFO crawl.CrawlDbReader: min score:\t0.005\n    14/02/14 16:35:47 INFO crawl.CrawlDbReader: avg score:\t0.03877143\n    14/02/14 16:35:47 INFO crawl.CrawlDbReader: max score:\t1.23\n    14/02/14 16:35:47 INFO crawl.CrawlDbReader: status 1 (db_unfetched):\t59\n    14/02/14 16:35:47 INFO crawl.CrawlDbReader: status 2 (db_fetched):\t11\n    14/02/14 16:35:47 INFO crawl.CrawlDbReader: CrawlDb statistics: done\n\n##8 一步一步使用单个命令抓取网页\n上一节为了简单性，一个命令搞定。本节我将严格按照抓取的步骤，一步一步来，揭开爬虫的神秘面纱。感兴趣的读者也可以看看 `bin/crawl` 脚本里的内容，可以很清楚的看到各个步骤。\n\n先删除第7节产生的数据，\n\n    $ rm -rf TestCrawl/\n\n###8.1 基本概念\nNutch data is composed of:\n\n- The crawl database, or `crawldb`. This contains information about every URL known to Nutch, including whether it was fetched, and, if so, when.\n- The link database, or `linkdb`. This contains the list of known links to each URL, including both the source URL and anchor text of the link.\n- A set of `segments`. Each segment is a set of URLs that are fetched as a unit. Segments are directories with the following subdirectories:\n  + a `crawl_generate` names a set of URLs to be fetched\n  + a `crawl_fetch` contains the status of fetching each URL\n  + a `content` contains the raw content retrieved from each URL\n  + a `parse_text` contains the parsed text of each URL\n  + a `parse_data` contains outlinks and metadata parsed from each URL\n  + a `crawl_parse` contains the outlink URLs, used to update the crawldb\n\n###8.2 inject:使用种子URL列表，生成crawldb\n\n    $ bin/nutch inject TestCrawl/crawldb ~/urls\n\n将根据`～/urls`下的种子URL，生成一个URL数据库，放在`crawdb`目录下。\n\n###8.3 generate\n\n    $ bin/nutch generate TestCrawl/crawldb TestCrawl/segments\n\n这会生成一个 fetch list，存放在一个`segments/日期`目录下。我们将这个目录的名字保存在shell变量`s1`里：\n\n    $ s1=`ls -d TestCrawl/segments/2* | tail -1`\n    $ echo $s1\n\n###8.4 fetch\n\n    $ bin/nutch fetch $s1\n\n将会在 `$1` 目录下，生成两个子目录, `crawl_fetch` 和 `content`。\n\n###8.5 parse\n\n    $ bin/nutch parse $s1\n\n将会在 `$1` 目录下，生成3个子目录, `crawl_parse`, `parse_data` 和 `parse_text` 。\n\n###8.6 updatedb\n\n    $ bin/nutch updatedb TestCrawl/crawldb $s1\n\n这将把`crawldb/current`重命名为`crawldb/old`，并生成新的 `crawldb/current` 。\n\n###8.7 查看结果\n\n    $ bin/nutch readdb TestCrawl/crawldb/ -stats\n\n###8.8 invertlinks\n\n在建立索引之前，我们首先要反转所有的链接，这样我们就可以获得一个页面所有的锚文本，并给这些锚文本建立索引。\n\n    $ bin/nutch invertlinks TestCrawl/linkdb -dir TestCrawl/segments\n\n###8.9 solrindex, 提交数据给solr，建立索引\n\n    $ bin/nutch solrindex http://localhost:8983/solr TestCrawl/crawldb/ -linkdb TestCrawl/linkdb/ TestCrawl/segments/20140203004348/ -filter -normalize\n\n###8.10 solrdedup, 给索引去重\n有时重复添加了数据，导致索引里有重复数据，我们需要去重，\n\n    $bin/nutch solrdedup http://localhost:8983/solr\n\n###8.11 solrclean, 删除索引\n如果数据过时了，需要在索引里删除，也是可以的。\n\n    $ bin/nutch solrclean TestCrawl/crawldb/ http://localhost:8983/solr\n\n##相关文章\n[Nutch 快速入门(Nutch 2.2.1)](http://www.yanjiuyanjiu.com/blog/20140201/)\n\n","source":"_posts/2014-01-21-nutch-tutorial-17.md","raw":"---\nlayout: post\ntitle: \"Nutch 快速入门(Nutch 1.7)\"\ndate: 2014-01-21 04:11\ncomments: true\ncategories: Search-Engine\n---\n本文主要参考[Nutch Tutorial](http://wiki.apache.org/nutch/NutchTutorial)\n\nNutch 2.2.1目前性能没有Nutch 1.7好，参考这里，[NUTCH FIGHT! 1.7 vs 2.2.1](http://digitalpebble.blogspot.com/2013/09/nutch-fight-17-vs-221.html). 所以我目前还是使用的Nutch 1.7。\n\n##1 下载已编译好的二进制包，解压\n    $ wget http://psg.mtu.edu/pub/apache/nutch/1.7/apache-nutch-1.7-bin.tar.gz\n    $ tar zxf apache-nutch-1.7-bin.tar.gz\n\n##2 验证一下\n\n    $ cd apache-nutch-1.7\n    $ bin/nutch\n\n如果出现\"Permission denied\"请运行下面的命令：\n\n    $ chmod +x bin/nutch\n\n如果有Warning说 `JAVA_HOME`没有设置，请设置一下`JAVA_HOME`.\n\n##3 添加种子URL\n\n    mkdir ~/urls\n    vim ～/urls/seed.txt\n    http://movie.douban.com/subject/5323968/\n\n##4 设置URL过滤规则\n如果只想抓取某种类型的URL，可以在 `conf/regex-urlfilter.txt`设置正则表达式，于是，只有匹配这些正则表达式的URL才会被抓取。\n\n<!--more-->\n\n例如，我只想抓取豆瓣电影的数据，可以这样设置：\n    \n    #注释掉这一行\n    # skip URLs containing certain characters as probable queries, etc.\n    #-[?*!@=]\n    # accept anything else\n    #注释掉这行\n    #+.\n    +^http:\\/\\/movie\\.douban\\.com\\/subject\\/[0-9]+\\/(\\?.+)?$\n\n##5 设置agent名字\n\nconf/nutch-site.xml:\n\n    <property>\n      <name>http.agent.name</name>\n      <value>My Nutch Spider</value>\n    </property>\n\n这一步是从这本书上看到的，[Web Crawling and Data Mining with Apache Nutch](http://www.packtpub.com/web-crawling-and-data-mining-with-apache-nutch/book)，第14页。\n\n##6 安装Solr\n由于建索引的时候需要使用Solr，因此我们需要安装并启动一个Solr服务器。\n\n参考[Nutch Tutorial](http://wiki.apache.org/nutch/NutchTutorial) 第4、5、6步，以及[Solr Tutorial](http://lucene.apache.org/solr/4_6_1/tutorial.html)。\n\n###6.1 下载，解压\n\nwget http://mirrors.cnnic.cn/apache/lucene/solr/4.6.1/solr-4.6.1.tgz\ntar -zxf solr-4.6.1.tgz\n\n###6.2 运行Solr\n\n    cd example\n    java -jar start.jar\n\n验证是否启动成功\n\n用浏览器打开 <http://localhost:8983/solr/admin/>，如果能看到页面，说明启动成功。\n\n###6.3 将Nutch与Solr集成在一起\n\n将`NUTCH_DIR/conf/schema-solr4.xml`拷贝到`SOLR_DIR/solr/collection1/conf/`，重命名为schema.xml，并在`<fields>...</fields>`最后添加一行(具体解释见[Solr 4.2 - what is _version_field?](http://stackoverflow.com/questions/15527380/solr-4-2-what-is-version-field))，\n\n    <field name=\"_version_\" type=\"long\" indexed=\"true\" stored=\"true\" multiValued=\"false\"/>\n\n重启Solr，\n\n    # Ctrl+C to stop Solr\n    java -jar start.jar\n\n##7 使用crawl脚本一键抓取\nNutch自带了一个脚本，`./bin/crawl`，把抓取的各个步骤合并成一个命令，看一下它的用法\n\n    $ bin/crawl \n    Missing seedDir : crawl <seedDir> <crawlDir> <solrURL> <numberOfRounds>\n\n注意，是使用`bin/crawl`，不是`bin/nutch crawl`，后者已经是deprecated的了。\n\n###7.1 抓取网页\n\n    $ ./bin/crawl ~/urls/ ./TestCrawl http://localhost:8983/solr/ 2\n\n* `～/urls` 是存放了种子url的目录\n* TestCrawl 是存放数据的根目录（在Nutch 2.x中，则表示crawlId，这会在HBase中创建一张以crawlId为前缀的表，例如TestCrawl_Webpage）\n* http://localhost:8983/solr/ , 这是Solr服务器\n* 2，numberOfRounds，迭代的次数\n\n过了一会儿，屏幕上出现了一大堆url，可以看到爬虫正在抓取！\n\n    fetching http://music.douban.com/subject/25811077/ (queue crawl delay=5000ms)\n    fetching http://read.douban.com/ebook/1919781 (queue crawl delay=5000ms)\n    fetching http://www.douban.com/online/11670861/ (queue crawl delay=5000ms)\n    fetching http://book.douban.com/tag/绘本 (queue crawl delay=5000ms)\n    fetching http://movie.douban.com/tag/科幻 (queue crawl delay=5000ms)\n    49/50 spinwaiting/active, 56 pages, 0 errors, 0.9 1 pages/s, 332 245 kb/s, 131 URLs in 5 queues\n    fetching http://music.douban.com/subject/25762454/ (queue crawl delay=5000ms)\n    fetching http://read.douban.com/reader/ebook/1951242/ (queue crawl delay=5000ms)\n    fetching http://www.douban.com/mobile/read-notes (queue crawl delay=5000ms)\n    fetching http://book.douban.com/tag/诗歌 (queue crawl delay=5000ms)\n    50/50 spinwaiting/active, 61 pages, 0 errors, 0.9 1 pages/s, 334 366 kb/s, 127 URLs in 5 queues\n\n###7.2 查看结果\n\n    $ bin/nutch readdb TestCrawl/crawldb/ -stats\n    14/02/14 16:35:47 INFO crawl.CrawlDbReader: Statistics for CrawlDb: TestCrawl/crawldb/\n    14/02/14 16:35:47 INFO crawl.CrawlDbReader: TOTAL urls:\t70\n    14/02/14 16:35:47 INFO crawl.CrawlDbReader: retry 0:\t70\n    14/02/14 16:35:47 INFO crawl.CrawlDbReader: min score:\t0.005\n    14/02/14 16:35:47 INFO crawl.CrawlDbReader: avg score:\t0.03877143\n    14/02/14 16:35:47 INFO crawl.CrawlDbReader: max score:\t1.23\n    14/02/14 16:35:47 INFO crawl.CrawlDbReader: status 1 (db_unfetched):\t59\n    14/02/14 16:35:47 INFO crawl.CrawlDbReader: status 2 (db_fetched):\t11\n    14/02/14 16:35:47 INFO crawl.CrawlDbReader: CrawlDb statistics: done\n\n##8 一步一步使用单个命令抓取网页\n上一节为了简单性，一个命令搞定。本节我将严格按照抓取的步骤，一步一步来，揭开爬虫的神秘面纱。感兴趣的读者也可以看看 `bin/crawl` 脚本里的内容，可以很清楚的看到各个步骤。\n\n先删除第7节产生的数据，\n\n    $ rm -rf TestCrawl/\n\n###8.1 基本概念\nNutch data is composed of:\n\n- The crawl database, or `crawldb`. This contains information about every URL known to Nutch, including whether it was fetched, and, if so, when.\n- The link database, or `linkdb`. This contains the list of known links to each URL, including both the source URL and anchor text of the link.\n- A set of `segments`. Each segment is a set of URLs that are fetched as a unit. Segments are directories with the following subdirectories:\n  + a `crawl_generate` names a set of URLs to be fetched\n  + a `crawl_fetch` contains the status of fetching each URL\n  + a `content` contains the raw content retrieved from each URL\n  + a `parse_text` contains the parsed text of each URL\n  + a `parse_data` contains outlinks and metadata parsed from each URL\n  + a `crawl_parse` contains the outlink URLs, used to update the crawldb\n\n###8.2 inject:使用种子URL列表，生成crawldb\n\n    $ bin/nutch inject TestCrawl/crawldb ~/urls\n\n将根据`～/urls`下的种子URL，生成一个URL数据库，放在`crawdb`目录下。\n\n###8.3 generate\n\n    $ bin/nutch generate TestCrawl/crawldb TestCrawl/segments\n\n这会生成一个 fetch list，存放在一个`segments/日期`目录下。我们将这个目录的名字保存在shell变量`s1`里：\n\n    $ s1=`ls -d TestCrawl/segments/2* | tail -1`\n    $ echo $s1\n\n###8.4 fetch\n\n    $ bin/nutch fetch $s1\n\n将会在 `$1` 目录下，生成两个子目录, `crawl_fetch` 和 `content`。\n\n###8.5 parse\n\n    $ bin/nutch parse $s1\n\n将会在 `$1` 目录下，生成3个子目录, `crawl_parse`, `parse_data` 和 `parse_text` 。\n\n###8.6 updatedb\n\n    $ bin/nutch updatedb TestCrawl/crawldb $s1\n\n这将把`crawldb/current`重命名为`crawldb/old`，并生成新的 `crawldb/current` 。\n\n###8.7 查看结果\n\n    $ bin/nutch readdb TestCrawl/crawldb/ -stats\n\n###8.8 invertlinks\n\n在建立索引之前，我们首先要反转所有的链接，这样我们就可以获得一个页面所有的锚文本，并给这些锚文本建立索引。\n\n    $ bin/nutch invertlinks TestCrawl/linkdb -dir TestCrawl/segments\n\n###8.9 solrindex, 提交数据给solr，建立索引\n\n    $ bin/nutch solrindex http://localhost:8983/solr TestCrawl/crawldb/ -linkdb TestCrawl/linkdb/ TestCrawl/segments/20140203004348/ -filter -normalize\n\n###8.10 solrdedup, 给索引去重\n有时重复添加了数据，导致索引里有重复数据，我们需要去重，\n\n    $bin/nutch solrdedup http://localhost:8983/solr\n\n###8.11 solrclean, 删除索引\n如果数据过时了，需要在索引里删除，也是可以的。\n\n    $ bin/nutch solrclean TestCrawl/crawldb/ http://localhost:8983/solr\n\n##相关文章\n[Nutch 快速入门(Nutch 2.2.1)](http://www.yanjiuyanjiu.com/blog/20140201/)\n\n","slug":"2014-01-21-nutch-tutorial-17","published":1,"updated":"2016-08-18T09:21:04.000Z","photos":[],"link":"","_id":"cis07pf3u002401pqbj4bvk5i","content":"<p>本文主要参考<a href=\"http://wiki.apache.org/nutch/NutchTutorial\" target=\"_blank\" rel=\"external\">Nutch Tutorial</a></p>\n<p>Nutch 2.2.1目前性能没有Nutch 1.7好，参考这里，<a href=\"http://digitalpebble.blogspot.com/2013/09/nutch-fight-17-vs-221.html\" target=\"_blank\" rel=\"external\">NUTCH FIGHT! 1.7 vs 2.2.1</a>. 所以我目前还是使用的Nutch 1.7。</p>\n<p>##1 下载已编译好的二进制包，解压<br>    $ wget <a href=\"http://psg.mtu.edu/pub/apache/nutch/1.7/apache-nutch-1.7-bin.tar.gz\" target=\"_blank\" rel=\"external\">http://psg.mtu.edu/pub/apache/nutch/1.7/apache-nutch-1.7-bin.tar.gz</a><br>    $ tar zxf apache-nutch-1.7-bin.tar.gz</p>\n<p>##2 验证一下</p>\n<pre><code>$ cd apache-nutch-1.7\n$ bin/nutch\n</code></pre><p>如果出现”Permission denied”请运行下面的命令：</p>\n<pre><code>$ chmod +x bin/nutch\n</code></pre><p>如果有Warning说 <code>JAVA_HOME</code>没有设置，请设置一下<code>JAVA_HOME</code>.</p>\n<p>##3 添加种子URL</p>\n<pre><code>mkdir ~/urls\nvim ～/urls/seed.txt\nhttp://movie.douban.com/subject/5323968/\n</code></pre><p>##4 设置URL过滤规则<br>如果只想抓取某种类型的URL，可以在 <code>conf/regex-urlfilter.txt</code>设置正则表达式，于是，只有匹配这些正则表达式的URL才会被抓取。</p>\n<a id=\"more\"></a>\n<p>例如，我只想抓取豆瓣电影的数据，可以这样设置：</p>\n<pre><code>#注释掉这一行\n# skip URLs containing certain characters as probable queries, etc.\n#-[?*!@=]\n# accept anything else\n#注释掉这行\n#+.\n+^http:\\/\\/movie\\.douban\\.com\\/subject\\/[0-9]+\\/(\\?.+)?$\n</code></pre><p>##5 设置agent名字</p>\n<p>conf/nutch-site.xml:</p>\n<pre><code>&lt;property&gt;\n  &lt;name&gt;http.agent.name&lt;/name&gt;\n  &lt;value&gt;My Nutch Spider&lt;/value&gt;\n&lt;/property&gt;\n</code></pre><p>这一步是从这本书上看到的，<a href=\"http://www.packtpub.com/web-crawling-and-data-mining-with-apache-nutch/book\" target=\"_blank\" rel=\"external\">Web Crawling and Data Mining with Apache Nutch</a>，第14页。</p>\n<p>##6 安装Solr<br>由于建索引的时候需要使用Solr，因此我们需要安装并启动一个Solr服务器。</p>\n<p>参考<a href=\"http://wiki.apache.org/nutch/NutchTutorial\" target=\"_blank\" rel=\"external\">Nutch Tutorial</a> 第4、5、6步，以及<a href=\"http://lucene.apache.org/solr/4_6_1/tutorial.html\" target=\"_blank\" rel=\"external\">Solr Tutorial</a>。</p>\n<p>###6.1 下载，解压</p>\n<p>wget <a href=\"http://mirrors.cnnic.cn/apache/lucene/solr/4.6.1/solr-4.6.1.tgz\" target=\"_blank\" rel=\"external\">http://mirrors.cnnic.cn/apache/lucene/solr/4.6.1/solr-4.6.1.tgz</a><br>tar -zxf solr-4.6.1.tgz</p>\n<p>###6.2 运行Solr</p>\n<pre><code>cd example\njava -jar start.jar\n</code></pre><p>验证是否启动成功</p>\n<p>用浏览器打开 <a href=\"http://localhost:8983/solr/admin/\" target=\"_blank\" rel=\"external\">http://localhost:8983/solr/admin/</a>，如果能看到页面，说明启动成功。</p>\n<p>###6.3 将Nutch与Solr集成在一起</p>\n<p>将<code>NUTCH_DIR/conf/schema-solr4.xml</code>拷贝到<code>SOLR_DIR/solr/collection1/conf/</code>，重命名为schema.xml，并在<code>&lt;fields&gt;...&lt;/fields&gt;</code>最后添加一行(具体解释见<a href=\"http://stackoverflow.com/questions/15527380/solr-4-2-what-is-version-field\" target=\"_blank\" rel=\"external\">Solr 4.2 - what is _version_field?</a>)，</p>\n<pre><code>&lt;field name=&quot;_version_&quot; type=&quot;long&quot; indexed=&quot;true&quot; stored=&quot;true&quot; multiValued=&quot;false&quot;/&gt;\n</code></pre><p>重启Solr，</p>\n<pre><code># Ctrl+C to stop Solr\njava -jar start.jar\n</code></pre><p>##7 使用crawl脚本一键抓取<br>Nutch自带了一个脚本，<code>./bin/crawl</code>，把抓取的各个步骤合并成一个命令，看一下它的用法</p>\n<pre><code>$ bin/crawl \nMissing seedDir : crawl &lt;seedDir&gt; &lt;crawlDir&gt; &lt;solrURL&gt; &lt;numberOfRounds&gt;\n</code></pre><p>注意，是使用<code>bin/crawl</code>，不是<code>bin/nutch crawl</code>，后者已经是deprecated的了。</p>\n<p>###7.1 抓取网页</p>\n<pre><code>$ ./bin/crawl ~/urls/ ./TestCrawl http://localhost:8983/solr/ 2\n</code></pre><ul>\n<li><code>～/urls</code> 是存放了种子url的目录</li>\n<li>TestCrawl 是存放数据的根目录（在Nutch 2.x中，则表示crawlId，这会在HBase中创建一张以crawlId为前缀的表，例如TestCrawl_Webpage）</li>\n<li><a href=\"http://localhost:8983/solr/\" target=\"_blank\" rel=\"external\">http://localhost:8983/solr/</a> , 这是Solr服务器</li>\n<li>2，numberOfRounds，迭代的次数</li>\n</ul>\n<p>过了一会儿，屏幕上出现了一大堆url，可以看到爬虫正在抓取！</p>\n<pre><code>fetching http://music.douban.com/subject/25811077/ (queue crawl delay=5000ms)\nfetching http://read.douban.com/ebook/1919781 (queue crawl delay=5000ms)\nfetching http://www.douban.com/online/11670861/ (queue crawl delay=5000ms)\nfetching http://book.douban.com/tag/绘本 (queue crawl delay=5000ms)\nfetching http://movie.douban.com/tag/科幻 (queue crawl delay=5000ms)\n49/50 spinwaiting/active, 56 pages, 0 errors, 0.9 1 pages/s, 332 245 kb/s, 131 URLs in 5 queues\nfetching http://music.douban.com/subject/25762454/ (queue crawl delay=5000ms)\nfetching http://read.douban.com/reader/ebook/1951242/ (queue crawl delay=5000ms)\nfetching http://www.douban.com/mobile/read-notes (queue crawl delay=5000ms)\nfetching http://book.douban.com/tag/诗歌 (queue crawl delay=5000ms)\n50/50 spinwaiting/active, 61 pages, 0 errors, 0.9 1 pages/s, 334 366 kb/s, 127 URLs in 5 queues\n</code></pre><p>###7.2 查看结果</p>\n<pre><code>$ bin/nutch readdb TestCrawl/crawldb/ -stats\n14/02/14 16:35:47 INFO crawl.CrawlDbReader: Statistics for CrawlDb: TestCrawl/crawldb/\n14/02/14 16:35:47 INFO crawl.CrawlDbReader: TOTAL urls:    70\n14/02/14 16:35:47 INFO crawl.CrawlDbReader: retry 0:    70\n14/02/14 16:35:47 INFO crawl.CrawlDbReader: min score:    0.005\n14/02/14 16:35:47 INFO crawl.CrawlDbReader: avg score:    0.03877143\n14/02/14 16:35:47 INFO crawl.CrawlDbReader: max score:    1.23\n14/02/14 16:35:47 INFO crawl.CrawlDbReader: status 1 (db_unfetched):    59\n14/02/14 16:35:47 INFO crawl.CrawlDbReader: status 2 (db_fetched):    11\n14/02/14 16:35:47 INFO crawl.CrawlDbReader: CrawlDb statistics: done\n</code></pre><p>##8 一步一步使用单个命令抓取网页<br>上一节为了简单性，一个命令搞定。本节我将严格按照抓取的步骤，一步一步来，揭开爬虫的神秘面纱。感兴趣的读者也可以看看 <code>bin/crawl</code> 脚本里的内容，可以很清楚的看到各个步骤。</p>\n<p>先删除第7节产生的数据，</p>\n<pre><code>$ rm -rf TestCrawl/\n</code></pre><p>###8.1 基本概念<br>Nutch data is composed of:</p>\n<ul>\n<li>The crawl database, or <code>crawldb</code>. This contains information about every URL known to Nutch, including whether it was fetched, and, if so, when.</li>\n<li>The link database, or <code>linkdb</code>. This contains the list of known links to each URL, including both the source URL and anchor text of the link.</li>\n<li>A set of <code>segments</code>. Each segment is a set of URLs that are fetched as a unit. Segments are directories with the following subdirectories:<ul>\n<li>a <code>crawl_generate</code> names a set of URLs to be fetched</li>\n<li>a <code>crawl_fetch</code> contains the status of fetching each URL</li>\n<li>a <code>content</code> contains the raw content retrieved from each URL</li>\n<li>a <code>parse_text</code> contains the parsed text of each URL</li>\n<li>a <code>parse_data</code> contains outlinks and metadata parsed from each URL</li>\n<li>a <code>crawl_parse</code> contains the outlink URLs, used to update the crawldb</li>\n</ul>\n</li>\n</ul>\n<p>###8.2 inject:使用种子URL列表，生成crawldb</p>\n<pre><code>$ bin/nutch inject TestCrawl/crawldb ~/urls\n</code></pre><p>将根据<code>～/urls</code>下的种子URL，生成一个URL数据库，放在<code>crawdb</code>目录下。</p>\n<p>###8.3 generate</p>\n<pre><code>$ bin/nutch generate TestCrawl/crawldb TestCrawl/segments\n</code></pre><p>这会生成一个 fetch list，存放在一个<code>segments/日期</code>目录下。我们将这个目录的名字保存在shell变量<code>s1</code>里：</p>\n<pre><code>$ s1=`ls -d TestCrawl/segments/2* | tail -1`\n$ echo $s1\n</code></pre><p>###8.4 fetch</p>\n<pre><code>$ bin/nutch fetch $s1\n</code></pre><p>将会在 <code>$1</code> 目录下，生成两个子目录, <code>crawl_fetch</code> 和 <code>content</code>。</p>\n<p>###8.5 parse</p>\n<pre><code>$ bin/nutch parse $s1\n</code></pre><p>将会在 <code>$1</code> 目录下，生成3个子目录, <code>crawl_parse</code>, <code>parse_data</code> 和 <code>parse_text</code> 。</p>\n<p>###8.6 updatedb</p>\n<pre><code>$ bin/nutch updatedb TestCrawl/crawldb $s1\n</code></pre><p>这将把<code>crawldb/current</code>重命名为<code>crawldb/old</code>，并生成新的 <code>crawldb/current</code> 。</p>\n<p>###8.7 查看结果</p>\n<pre><code>$ bin/nutch readdb TestCrawl/crawldb/ -stats\n</code></pre><p>###8.8 invertlinks</p>\n<p>在建立索引之前，我们首先要反转所有的链接，这样我们就可以获得一个页面所有的锚文本，并给这些锚文本建立索引。</p>\n<pre><code>$ bin/nutch invertlinks TestCrawl/linkdb -dir TestCrawl/segments\n</code></pre><p>###8.9 solrindex, 提交数据给solr，建立索引</p>\n<pre><code>$ bin/nutch solrindex http://localhost:8983/solr TestCrawl/crawldb/ -linkdb TestCrawl/linkdb/ TestCrawl/segments/20140203004348/ -filter -normalize\n</code></pre><p>###8.10 solrdedup, 给索引去重<br>有时重复添加了数据，导致索引里有重复数据，我们需要去重，</p>\n<pre><code>$bin/nutch solrdedup http://localhost:8983/solr\n</code></pre><p>###8.11 solrclean, 删除索引<br>如果数据过时了，需要在索引里删除，也是可以的。</p>\n<pre><code>$ bin/nutch solrclean TestCrawl/crawldb/ http://localhost:8983/solr\n</code></pre><p>##相关文章<br><a href=\"http://www.yanjiuyanjiu.com/blog/20140201/\" target=\"_blank\" rel=\"external\">Nutch 快速入门(Nutch 2.2.1)</a></p>\n","excerpt":"<p>本文主要参考<a href=\"http://wiki.apache.org/nutch/NutchTutorial\">Nutch Tutorial</a></p>\n<p>Nutch 2.2.1目前性能没有Nutch 1.7好，参考这里，<a href=\"http://digitalpebble.blogspot.com/2013/09/nutch-fight-17-vs-221.html\">NUTCH FIGHT! 1.7 vs 2.2.1</a>. 所以我目前还是使用的Nutch 1.7。</p>\n<p>##1 下载已编译好的二进制包，解压<br>    $ wget <a href=\"http://psg.mtu.edu/pub/apache/nutch/1.7/apache-nutch-1.7-bin.tar.gz\">http://psg.mtu.edu/pub/apache/nutch/1.7/apache-nutch-1.7-bin.tar.gz</a><br>    $ tar zxf apache-nutch-1.7-bin.tar.gz</p>\n<p>##2 验证一下</p>\n<pre><code>$ cd apache-nutch-1.7\n$ bin/nutch\n</code></pre><p>如果出现”Permission denied”请运行下面的命令：</p>\n<pre><code>$ chmod +x bin/nutch\n</code></pre><p>如果有Warning说 <code>JAVA_HOME</code>没有设置，请设置一下<code>JAVA_HOME</code>.</p>\n<p>##3 添加种子URL</p>\n<pre><code>mkdir ~/urls\nvim ～/urls/seed.txt\nhttp://movie.douban.com/subject/5323968/\n</code></pre><p>##4 设置URL过滤规则<br>如果只想抓取某种类型的URL，可以在 <code>conf/regex-urlfilter.txt</code>设置正则表达式，于是，只有匹配这些正则表达式的URL才会被抓取。</p>","more":"<p>例如，我只想抓取豆瓣电影的数据，可以这样设置：</p>\n<pre><code>#注释掉这一行\n# skip URLs containing certain characters as probable queries, etc.\n#-[?*!@=]\n# accept anything else\n#注释掉这行\n#+.\n+^http:\\/\\/movie\\.douban\\.com\\/subject\\/[0-9]+\\/(\\?.+)?$\n</code></pre><p>##5 设置agent名字</p>\n<p>conf/nutch-site.xml:</p>\n<pre><code>&lt;property&gt;\n  &lt;name&gt;http.agent.name&lt;/name&gt;\n  &lt;value&gt;My Nutch Spider&lt;/value&gt;\n&lt;/property&gt;\n</code></pre><p>这一步是从这本书上看到的，<a href=\"http://www.packtpub.com/web-crawling-and-data-mining-with-apache-nutch/book\">Web Crawling and Data Mining with Apache Nutch</a>，第14页。</p>\n<p>##6 安装Solr<br>由于建索引的时候需要使用Solr，因此我们需要安装并启动一个Solr服务器。</p>\n<p>参考<a href=\"http://wiki.apache.org/nutch/NutchTutorial\">Nutch Tutorial</a> 第4、5、6步，以及<a href=\"http://lucene.apache.org/solr/4_6_1/tutorial.html\">Solr Tutorial</a>。</p>\n<p>###6.1 下载，解压</p>\n<p>wget <a href=\"http://mirrors.cnnic.cn/apache/lucene/solr/4.6.1/solr-4.6.1.tgz\">http://mirrors.cnnic.cn/apache/lucene/solr/4.6.1/solr-4.6.1.tgz</a><br>tar -zxf solr-4.6.1.tgz</p>\n<p>###6.2 运行Solr</p>\n<pre><code>cd example\njava -jar start.jar\n</code></pre><p>验证是否启动成功</p>\n<p>用浏览器打开 <a href=\"http://localhost:8983/solr/admin/\">http://localhost:8983/solr/admin/</a>，如果能看到页面，说明启动成功。</p>\n<p>###6.3 将Nutch与Solr集成在一起</p>\n<p>将<code>NUTCH_DIR/conf/schema-solr4.xml</code>拷贝到<code>SOLR_DIR/solr/collection1/conf/</code>，重命名为schema.xml，并在<code>&lt;fields&gt;...&lt;/fields&gt;</code>最后添加一行(具体解释见<a href=\"http://stackoverflow.com/questions/15527380/solr-4-2-what-is-version-field\">Solr 4.2 - what is _version_field?</a>)，</p>\n<pre><code>&lt;field name=&quot;_version_&quot; type=&quot;long&quot; indexed=&quot;true&quot; stored=&quot;true&quot; multiValued=&quot;false&quot;/&gt;\n</code></pre><p>重启Solr，</p>\n<pre><code># Ctrl+C to stop Solr\njava -jar start.jar\n</code></pre><p>##7 使用crawl脚本一键抓取<br>Nutch自带了一个脚本，<code>./bin/crawl</code>，把抓取的各个步骤合并成一个命令，看一下它的用法</p>\n<pre><code>$ bin/crawl \nMissing seedDir : crawl &lt;seedDir&gt; &lt;crawlDir&gt; &lt;solrURL&gt; &lt;numberOfRounds&gt;\n</code></pre><p>注意，是使用<code>bin/crawl</code>，不是<code>bin/nutch crawl</code>，后者已经是deprecated的了。</p>\n<p>###7.1 抓取网页</p>\n<pre><code>$ ./bin/crawl ~/urls/ ./TestCrawl http://localhost:8983/solr/ 2\n</code></pre><ul>\n<li><code>～/urls</code> 是存放了种子url的目录</li>\n<li>TestCrawl 是存放数据的根目录（在Nutch 2.x中，则表示crawlId，这会在HBase中创建一张以crawlId为前缀的表，例如TestCrawl_Webpage）</li>\n<li><a href=\"http://localhost:8983/solr/\">http://localhost:8983/solr/</a> , 这是Solr服务器</li>\n<li>2，numberOfRounds，迭代的次数</li>\n</ul>\n<p>过了一会儿，屏幕上出现了一大堆url，可以看到爬虫正在抓取！</p>\n<pre><code>fetching http://music.douban.com/subject/25811077/ (queue crawl delay=5000ms)\nfetching http://read.douban.com/ebook/1919781 (queue crawl delay=5000ms)\nfetching http://www.douban.com/online/11670861/ (queue crawl delay=5000ms)\nfetching http://book.douban.com/tag/绘本 (queue crawl delay=5000ms)\nfetching http://movie.douban.com/tag/科幻 (queue crawl delay=5000ms)\n49/50 spinwaiting/active, 56 pages, 0 errors, 0.9 1 pages/s, 332 245 kb/s, 131 URLs in 5 queues\nfetching http://music.douban.com/subject/25762454/ (queue crawl delay=5000ms)\nfetching http://read.douban.com/reader/ebook/1951242/ (queue crawl delay=5000ms)\nfetching http://www.douban.com/mobile/read-notes (queue crawl delay=5000ms)\nfetching http://book.douban.com/tag/诗歌 (queue crawl delay=5000ms)\n50/50 spinwaiting/active, 61 pages, 0 errors, 0.9 1 pages/s, 334 366 kb/s, 127 URLs in 5 queues\n</code></pre><p>###7.2 查看结果</p>\n<pre><code>$ bin/nutch readdb TestCrawl/crawldb/ -stats\n14/02/14 16:35:47 INFO crawl.CrawlDbReader: Statistics for CrawlDb: TestCrawl/crawldb/\n14/02/14 16:35:47 INFO crawl.CrawlDbReader: TOTAL urls:    70\n14/02/14 16:35:47 INFO crawl.CrawlDbReader: retry 0:    70\n14/02/14 16:35:47 INFO crawl.CrawlDbReader: min score:    0.005\n14/02/14 16:35:47 INFO crawl.CrawlDbReader: avg score:    0.03877143\n14/02/14 16:35:47 INFO crawl.CrawlDbReader: max score:    1.23\n14/02/14 16:35:47 INFO crawl.CrawlDbReader: status 1 (db_unfetched):    59\n14/02/14 16:35:47 INFO crawl.CrawlDbReader: status 2 (db_fetched):    11\n14/02/14 16:35:47 INFO crawl.CrawlDbReader: CrawlDb statistics: done\n</code></pre><p>##8 一步一步使用单个命令抓取网页<br>上一节为了简单性，一个命令搞定。本节我将严格按照抓取的步骤，一步一步来，揭开爬虫的神秘面纱。感兴趣的读者也可以看看 <code>bin/crawl</code> 脚本里的内容，可以很清楚的看到各个步骤。</p>\n<p>先删除第7节产生的数据，</p>\n<pre><code>$ rm -rf TestCrawl/\n</code></pre><p>###8.1 基本概念<br>Nutch data is composed of:</p>\n<ul>\n<li>The crawl database, or <code>crawldb</code>. This contains information about every URL known to Nutch, including whether it was fetched, and, if so, when.</li>\n<li>The link database, or <code>linkdb</code>. This contains the list of known links to each URL, including both the source URL and anchor text of the link.</li>\n<li>A set of <code>segments</code>. Each segment is a set of URLs that are fetched as a unit. Segments are directories with the following subdirectories:<ul>\n<li>a <code>crawl_generate</code> names a set of URLs to be fetched</li>\n<li>a <code>crawl_fetch</code> contains the status of fetching each URL</li>\n<li>a <code>content</code> contains the raw content retrieved from each URL</li>\n<li>a <code>parse_text</code> contains the parsed text of each URL</li>\n<li>a <code>parse_data</code> contains outlinks and metadata parsed from each URL</li>\n<li>a <code>crawl_parse</code> contains the outlink URLs, used to update the crawldb</li>\n</ul>\n</li>\n</ul>\n<p>###8.2 inject:使用种子URL列表，生成crawldb</p>\n<pre><code>$ bin/nutch inject TestCrawl/crawldb ~/urls\n</code></pre><p>将根据<code>～/urls</code>下的种子URL，生成一个URL数据库，放在<code>crawdb</code>目录下。</p>\n<p>###8.3 generate</p>\n<pre><code>$ bin/nutch generate TestCrawl/crawldb TestCrawl/segments\n</code></pre><p>这会生成一个 fetch list，存放在一个<code>segments/日期</code>目录下。我们将这个目录的名字保存在shell变量<code>s1</code>里：</p>\n<pre><code>$ s1=`ls -d TestCrawl/segments/2* | tail -1`\n$ echo $s1\n</code></pre><p>###8.4 fetch</p>\n<pre><code>$ bin/nutch fetch $s1\n</code></pre><p>将会在 <code>$1</code> 目录下，生成两个子目录, <code>crawl_fetch</code> 和 <code>content</code>。</p>\n<p>###8.5 parse</p>\n<pre><code>$ bin/nutch parse $s1\n</code></pre><p>将会在 <code>$1</code> 目录下，生成3个子目录, <code>crawl_parse</code>, <code>parse_data</code> 和 <code>parse_text</code> 。</p>\n<p>###8.6 updatedb</p>\n<pre><code>$ bin/nutch updatedb TestCrawl/crawldb $s1\n</code></pre><p>这将把<code>crawldb/current</code>重命名为<code>crawldb/old</code>，并生成新的 <code>crawldb/current</code> 。</p>\n<p>###8.7 查看结果</p>\n<pre><code>$ bin/nutch readdb TestCrawl/crawldb/ -stats\n</code></pre><p>###8.8 invertlinks</p>\n<p>在建立索引之前，我们首先要反转所有的链接，这样我们就可以获得一个页面所有的锚文本，并给这些锚文本建立索引。</p>\n<pre><code>$ bin/nutch invertlinks TestCrawl/linkdb -dir TestCrawl/segments\n</code></pre><p>###8.9 solrindex, 提交数据给solr，建立索引</p>\n<pre><code>$ bin/nutch solrindex http://localhost:8983/solr TestCrawl/crawldb/ -linkdb TestCrawl/linkdb/ TestCrawl/segments/20140203004348/ -filter -normalize\n</code></pre><p>###8.10 solrdedup, 给索引去重<br>有时重复添加了数据，导致索引里有重复数据，我们需要去重，</p>\n<pre><code>$bin/nutch solrdedup http://localhost:8983/solr\n</code></pre><p>###8.11 solrclean, 删除索引<br>如果数据过时了，需要在索引里删除，也是可以的。</p>\n<pre><code>$ bin/nutch solrclean TestCrawl/crawldb/ http://localhost:8983/solr\n</code></pre><p>##相关文章<br><a href=\"http://www.yanjiuyanjiu.com/blog/20140201/\">Nutch 快速入门(Nutch 2.2.1)</a></p>"},{"layout":"post","title":"运行mahout的朴素贝叶斯分类器","date":"2013-12-23T17:20:00.000Z","comments":1,"_content":"##1.准备数据\n\n###1.1 下载数据集，并解压\n\n\twget http://people.csail.mit.edu/jrennie/20Newsgroups/20news-bydate.tar.gz\n\ttar -xf 20news-bydate.tar.gz\n\t#上传到hdfs\n\thadoop fs -put 20news-bydate-test .\n\thadoop fs -put 20news-bydate-train .\n\n###1.2 转换格式\n\n\t#转换为序列文件(sequence files)\n\tmahout seqdirectory -i 20news-bydate-train -o 20news-bydate-train-seq\n\tmahout seqdirectory -i 20news-bydate-test -o 20news-bydate-test-seq\n\t#转换为tf-idf向量\n\tmahout seq2sparse -i 20news-bydate-train-seq -o 20news-bydate-train-vector -lnorm -nv -wt tfidf\n\tmahout seq2sparse -i 20news-bydate-test-seq -o 20news-bydate-test-vector -lnorm -nv -wt tfidf\n\n##2. 训练朴素贝叶斯模型\n\n\tmahout trainnb -i 20news-bydate-train-vectors/tfidf-vectors -el -o model -li labelindex -ow\n\n##3. 测试朴素贝叶斯模型\n\n\tmahout testnb -i 20news-bydate-train-vectors/tfidf-vectors -m model -l labelindex -ow -o test-result\n\n##4. 查看训练后的结构\n\n\tmahout seqdumper -i labelindex \n\n    Input Path: labelindex\n    Key class: class org.apache.hadoop.io.Text Value Class: class org.apache.hadoop.io.IntWritable\n    Key: alt.atheism: Value: 0\n    Key: comp.graphics: Value: 1\n    Key: comp.os.ms-windows.misc: Value: 2\n    Key: comp.sys.ibm.pc.hardware: Value: 3\n    Key: comp.sys.mac.hardware: Value: 4\n    Key: comp.windows.x: Value: 5\n    Key: misc.forsale: Value: 6\n    Key: rec.autos: Value: 7\n    Key: rec.motorcycles: Value: 8\n    Key: rec.sport.baseball: Value: 9\n    Key: rec.sport.hockey: Value: 10\n    Key: sci.crypt: Value: 11\n    Key: sci.electronics: Value: 12\n    Key: sci.med: Value: 13\n    Key: sci.space: Value: 14\n    Key: soc.religion.christian: Value: 15\n    Key: talk.politics.guns: Value: 16\n    Key: talk.politics.mideast: Value: 17\n    Key: talk.politics.misc: Value: 18\n    Key: talk.religion.misc: Value: 19\n    Count: 20\n\n\n\n\n\n","source":"_posts/2013-12-23-run-mahout-nbc.md","raw":"---\nlayout: post\ntitle: \"运行mahout的朴素贝叶斯分类器\"\ndate: 2013-12-23 17:20\ncomments: true\ncategories: Machine-Learning\ntags: [mahout, naive bayes]\n---\n##1.准备数据\n\n###1.1 下载数据集，并解压\n\n\twget http://people.csail.mit.edu/jrennie/20Newsgroups/20news-bydate.tar.gz\n\ttar -xf 20news-bydate.tar.gz\n\t#上传到hdfs\n\thadoop fs -put 20news-bydate-test .\n\thadoop fs -put 20news-bydate-train .\n\n###1.2 转换格式\n\n\t#转换为序列文件(sequence files)\n\tmahout seqdirectory -i 20news-bydate-train -o 20news-bydate-train-seq\n\tmahout seqdirectory -i 20news-bydate-test -o 20news-bydate-test-seq\n\t#转换为tf-idf向量\n\tmahout seq2sparse -i 20news-bydate-train-seq -o 20news-bydate-train-vector -lnorm -nv -wt tfidf\n\tmahout seq2sparse -i 20news-bydate-test-seq -o 20news-bydate-test-vector -lnorm -nv -wt tfidf\n\n##2. 训练朴素贝叶斯模型\n\n\tmahout trainnb -i 20news-bydate-train-vectors/tfidf-vectors -el -o model -li labelindex -ow\n\n##3. 测试朴素贝叶斯模型\n\n\tmahout testnb -i 20news-bydate-train-vectors/tfidf-vectors -m model -l labelindex -ow -o test-result\n\n##4. 查看训练后的结构\n\n\tmahout seqdumper -i labelindex \n\n    Input Path: labelindex\n    Key class: class org.apache.hadoop.io.Text Value Class: class org.apache.hadoop.io.IntWritable\n    Key: alt.atheism: Value: 0\n    Key: comp.graphics: Value: 1\n    Key: comp.os.ms-windows.misc: Value: 2\n    Key: comp.sys.ibm.pc.hardware: Value: 3\n    Key: comp.sys.mac.hardware: Value: 4\n    Key: comp.windows.x: Value: 5\n    Key: misc.forsale: Value: 6\n    Key: rec.autos: Value: 7\n    Key: rec.motorcycles: Value: 8\n    Key: rec.sport.baseball: Value: 9\n    Key: rec.sport.hockey: Value: 10\n    Key: sci.crypt: Value: 11\n    Key: sci.electronics: Value: 12\n    Key: sci.med: Value: 13\n    Key: sci.space: Value: 14\n    Key: soc.religion.christian: Value: 15\n    Key: talk.politics.guns: Value: 16\n    Key: talk.politics.mideast: Value: 17\n    Key: talk.politics.misc: Value: 18\n    Key: talk.religion.misc: Value: 19\n    Count: 20\n\n\n\n\n\n","slug":"2013-12-23-run-mahout-nbc","published":1,"updated":"2016-08-18T09:21:04.000Z","photos":[],"link":"","_id":"cis07pf3v002601pqlioibhgp","content":"<p>##1.准备数据</p>\n<p>###1.1 下载数据集，并解压</p>\n<pre><code>wget http://people.csail.mit.edu/jrennie/20Newsgroups/20news-bydate.tar.gz\ntar -xf 20news-bydate.tar.gz\n#上传到hdfs\nhadoop fs -put 20news-bydate-test .\nhadoop fs -put 20news-bydate-train .\n</code></pre><p>###1.2 转换格式</p>\n<pre><code>#转换为序列文件(sequence files)\nmahout seqdirectory -i 20news-bydate-train -o 20news-bydate-train-seq\nmahout seqdirectory -i 20news-bydate-test -o 20news-bydate-test-seq\n#转换为tf-idf向量\nmahout seq2sparse -i 20news-bydate-train-seq -o 20news-bydate-train-vector -lnorm -nv -wt tfidf\nmahout seq2sparse -i 20news-bydate-test-seq -o 20news-bydate-test-vector -lnorm -nv -wt tfidf\n</code></pre><p>##2. 训练朴素贝叶斯模型</p>\n<pre><code>mahout trainnb -i 20news-bydate-train-vectors/tfidf-vectors -el -o model -li labelindex -ow\n</code></pre><p>##3. 测试朴素贝叶斯模型</p>\n<pre><code>mahout testnb -i 20news-bydate-train-vectors/tfidf-vectors -m model -l labelindex -ow -o test-result\n</code></pre><p>##4. 查看训练后的结构</p>\n<pre><code>mahout seqdumper -i labelindex \n\nInput Path: labelindex\nKey class: class org.apache.hadoop.io.Text Value Class: class org.apache.hadoop.io.IntWritable\nKey: alt.atheism: Value: 0\nKey: comp.graphics: Value: 1\nKey: comp.os.ms-windows.misc: Value: 2\nKey: comp.sys.ibm.pc.hardware: Value: 3\nKey: comp.sys.mac.hardware: Value: 4\nKey: comp.windows.x: Value: 5\nKey: misc.forsale: Value: 6\nKey: rec.autos: Value: 7\nKey: rec.motorcycles: Value: 8\nKey: rec.sport.baseball: Value: 9\nKey: rec.sport.hockey: Value: 10\nKey: sci.crypt: Value: 11\nKey: sci.electronics: Value: 12\nKey: sci.med: Value: 13\nKey: sci.space: Value: 14\nKey: soc.religion.christian: Value: 15\nKey: talk.politics.guns: Value: 16\nKey: talk.politics.mideast: Value: 17\nKey: talk.politics.misc: Value: 18\nKey: talk.religion.misc: Value: 19\nCount: 20\n</code></pre>","excerpt":"","more":"<p>##1.准备数据</p>\n<p>###1.1 下载数据集，并解压</p>\n<pre><code>wget http://people.csail.mit.edu/jrennie/20Newsgroups/20news-bydate.tar.gz\ntar -xf 20news-bydate.tar.gz\n#上传到hdfs\nhadoop fs -put 20news-bydate-test .\nhadoop fs -put 20news-bydate-train .\n</code></pre><p>###1.2 转换格式</p>\n<pre><code>#转换为序列文件(sequence files)\nmahout seqdirectory -i 20news-bydate-train -o 20news-bydate-train-seq\nmahout seqdirectory -i 20news-bydate-test -o 20news-bydate-test-seq\n#转换为tf-idf向量\nmahout seq2sparse -i 20news-bydate-train-seq -o 20news-bydate-train-vector -lnorm -nv -wt tfidf\nmahout seq2sparse -i 20news-bydate-test-seq -o 20news-bydate-test-vector -lnorm -nv -wt tfidf\n</code></pre><p>##2. 训练朴素贝叶斯模型</p>\n<pre><code>mahout trainnb -i 20news-bydate-train-vectors/tfidf-vectors -el -o model -li labelindex -ow\n</code></pre><p>##3. 测试朴素贝叶斯模型</p>\n<pre><code>mahout testnb -i 20news-bydate-train-vectors/tfidf-vectors -m model -l labelindex -ow -o test-result\n</code></pre><p>##4. 查看训练后的结构</p>\n<pre><code>mahout seqdumper -i labelindex \n\nInput Path: labelindex\nKey class: class org.apache.hadoop.io.Text Value Class: class org.apache.hadoop.io.IntWritable\nKey: alt.atheism: Value: 0\nKey: comp.graphics: Value: 1\nKey: comp.os.ms-windows.misc: Value: 2\nKey: comp.sys.ibm.pc.hardware: Value: 3\nKey: comp.sys.mac.hardware: Value: 4\nKey: comp.windows.x: Value: 5\nKey: misc.forsale: Value: 6\nKey: rec.autos: Value: 7\nKey: rec.motorcycles: Value: 8\nKey: rec.sport.baseball: Value: 9\nKey: rec.sport.hockey: Value: 10\nKey: sci.crypt: Value: 11\nKey: sci.electronics: Value: 12\nKey: sci.med: Value: 13\nKey: sci.space: Value: 14\nKey: soc.religion.christian: Value: 15\nKey: talk.politics.guns: Value: 16\nKey: talk.politics.mideast: Value: 17\nKey: talk.politics.misc: Value: 18\nKey: talk.religion.misc: Value: 19\nCount: 20\n</code></pre>"},{"layout":"post","title":"安装和配置Ubuntu服务器的详细步骤","date":"2013-10-28T23:26:00.000Z","comments":1,"published":0,"_content":"\n这是我安装Ubuntu服务器的过程，分享给大家。CentOS服务器请参考我另一篇博客，[安装和配置CentOS服务器的详细步骤](http://www.yanjiuyanjiu.com/blog/20120423/)。\n\n\n##安装操作系统\n\n所使用的ISO文件是 ubuntu-13.04-server-amd64.iso\n\n首先在虚拟机或物理机上安装操作系统，用户名为manong，密码 manong123\n\n\n##设置上网\n安装完操作系统后，还不能上网，配置DHCP方式上网：\n\n``` bash\nvim /etc/sysconfig/network-scripts/ifcfg-eth0\nDEVICE=\"eth0\"\nHWADDR=\"00:0C:29:BD:E1:19\"\nNM_CONTROLLED=\"yes\"\nONBOOT=\"yes\"\nBOOTPROTO=dhcp\nUSECTL=no\nTYPE=Ethernet\nPEERDNS=yes\n#保存退出\nsudo service network restart\n```\n\n<!-- more -->\n\n或者，配置静态IP\n\n``` bash\nDEVICE=\"eth0\"\nHWADDR=\"00:0C:29:10:F4:4C\"\nONBOOT=\"yes\"\nBOOTPROTO=static\nTYPE=Ethernet\nIPADDR=192.168.0.162\nNETMASK=255.255.255.0\nBROADCAST=192.168.0.255\nNETWORK=192.168.0.0\n#保存退出  \n#修改/etc/sysconfig/network\nsudo vim /etc/sysconfig/network\nNETWORKING=yes\nHOSTNAME=localhost.localdomain\nGATEWAY=192.168.0.1\n#保存退出，重启网络\nsudo service network restart\n```\n如果失败，比如IP已被占用，换一个IP试试\n\n修改DNS，即时生效\n\n``` bash\nsudo vim /etc/resolv.conf\nnameserver 192.168.0.1\n# google提供的域名服务器\nnameserver 8.8.8.8\nsearch localhost\n```\n\n##安装常用软件\n有两种方式，方法一，去官网下载已经编译好的二进制文件，或源代码，编译安装\n方法二，用yum 命令安装，安装官方yum源里已经编译好的程序包。  \n第一种方式要敲很多命令，比yum麻烦，但是可以预先下载好文件，省略了下载的时间，整体速度比yum安装方式快很多，而且可以安装最新版。推荐第一种方式\n\n第二种方式操作简单，敲打的命令少，但是往往yum源的更新速度跟不上各个软件的官网速度，用Yum安装的版本经常比较旧。\n\nyum的命令形式一般是如下：`yum [options] [command] [package ...]`，其中的[options]是可选的，选项包括-h（帮助），-y（当安装过程提示选择全部为\"yes\"），-q（不显示安装的过程）等等。[command]为所要进行的操作，[package ...]是操作的对象。\n\n``` bash\n#yum search package-name # 在线搜索包 \n#yum list installed # 列出所有已经安装的包\n#\n#sudo yum install package-name # 安装程序包 \n#sudo yum groupinsall group-name 安装程序组\n#\n#sudo yum remove package-name 删除程序包\n#sudo yum groupremove group-name 删除程序组\n#\n#yum update #全部更新\n#yum update package-name #更新程序包\n#sudo yum groupupdate groupn-name 升级程序组\n#sudo yum upgrade # 更新源列表\n#yum upgrade package-name #升级程序包\n#sudo yum clean all # 清除缓存\n#更新\nsudo yum update\n#清理缓存\nsudo yum clean all && yum clean metadata && yum clean dbcache\n```\n\n##安装编译工具\n\n###方法一\n去 http://gcc.gnu.org/ 下载源码\n\n``` bash\n# TODO\n```\n\n###方法二\n\n``` bash\nsudo yum groupinstall \"Development Tools\"\n```\n该命令类似于 Ubuntu 下的`apt-get install build-essential`，会自动安装一下软件包：autoconf automake bison byacc cscope ctags diffstat doxygen flex gcc gcc-c++ gcc-gfortran git indent intltool libtool patchutils rcs redhat-rpm-config rpm-build subversion swig systemtap，同时安装了以下依赖包：apr, apr-util, 等等。\n\n\n##安装JDK\n\n``` bash\n#删除旧的JDK\nyum list installed | grep jdk\n#复制显示出来的JDK，卸载\nsudo yum remove java-1.6.0-openjdk.x86_64\n#安装新的jdk\n```\n\n###方法一\n\n``` bash\n#从官网下载最新版的，当前是jdk6u32\n#开始安装\nchmod u+x chmod u+x jdk-6u32-linux-x64-rpm.bin\nsudo ./jdk-6u32-linux-x64-rpm.bin\n#设置环境变量，.bash_profile是当前用户，/etc/profile是所有用户的\nsudo vim /etc/profile\n#在末尾添加\nexport JAVA_HOME=/usr/java/default\nexport JRE_HOME=$JAVA_HOME/jre\nexport PATH=$PATH:$JAVA_HOME/bin\nexport CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar\n# 保存退出，输入以下命令使之立即生效：\nsource /etc/profile\n# 测试\njava -version\n```\n\n###方法二\n\n``` bash\nyum search jdk\n# java-1.6.0-openjdk只包含了JRE，如果在这台机器上开发java程序，则需要安装JDK，\n# 要选择 java-1.6.0-openjdk-devel，在服务器上我们只需要运行java程序，因此选择前者\nsudo yum install java-1.6.0-openjdk-devel\n# 使用 alternatives 工具设置默认JDK，参考：Installing a Java Development Kit on Red Hat Enterprise Linux\n/usr/sbin/alternatives --config java\n/usr/sbin/alternatives --config javac\n# 设置环境变量\n# 查询JDK路径\nwhereis java\nll /usr/bin/java\nll /etc/alternatives/java #这是可以看到JDK路径了\nsudo vim /etc/profile\n# 在末尾添加\nexport JAVA_HOME=/usr/lib/jvm/jre-1.6.0-openjdk.x86_64\nexport JRE_HOME=$JAVA_HOME/jre\nexport PATH=$PATH:$JAVA_HOME/bin\nexport CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar\n#保存退出，输入以下命令使之立即生效：\n# source /etc/profile\n# 测试\njava -version\n```\n\n##安装 apache\n\n###方法一\n源码在官网 http://httpd.apache.org/ 下载。  \n先下载apt, apr-util, pcre三个库，httpd 在编译时需要用到这三个库  \napr, apr-util官网 http://apr.apache.org , pcre官网为 [http://pcre.org ](http://pcre.org )\n\n``` bash\n# 编译，安装 apr\ntar -jxf apr-1.4.6.tar.bz2\ncd apr-1.4.6\n./configure\nmake\nsudo make install    # 默认会安装到 /usr/local/apr/\ncd ~\n#编译，安装 apr-util\ntar -jxf apr-util-1.4.1.tar.bz2\ncd apr-util-1.4.1\n./configure --with-apr=/usr/local/apr/\nmake\nsudo make install    # 默认会安装到 /usr/local/apr/\ncd ~\n#编译，安装 pcre\ntar -jxf pcre-8.30.tar.bz2\ncd  pcre-8.30\n./configure --with-apr=/usr/local/apr/\nmake\n# By default, `make install' installs the package's commands under\n#`/usr/local/bin', include files under `/usr/local/include', etc. \nsudo make install\ncd ~\n#编译，安装 apache\ntar -jxf httpd-2.2.22.tar.bz2\ncd httpd-2.2.22\n./configure\nmake\nsudo make install    # 默认会安装到/usr/local/apache2/\ncd ~\n#添加防火墙规则，让防火墙允许 apache的端口 80通过\nsudo vim /etc/sysconfig/iptables\n#添加如下一行（实际上是拷贝了原来的一行，仅仅改变了端口号），位置必须#要放在 含有 \"REJECT --reject-with\" 的行的前面\n-A INPUT -m state --state NEW -m tcp -p tcp --dport 80 -j ACCEPT\nsudo service iptables restart\n#测试\nsudo /usr/local/apache2/bin/apachectl start\n#在浏览器输入 http://ip地址 ，如果看到“It works”，说明安装成功\n/usr/local/apache2/bin/apachectl stop\n\n\n#设置为开机启动\n#将httpd注册为服务，通过chkconfig实现开机启动\n#以apachectl 为模板\nsudo cp /usr/local/apache2/bin/apachectl /etc/init.d/httpd\nsudo vim /etc/init.d/httpd\n# 在第一行 #!/bin/sh，添加如下一行，使其支持chkconfig命令\n# chkconfig: 2345 85 15\n# 保存，退出VIM编辑器\nsudo chmod u+x /etc/init.d/httpd\nsudo chkconfig --add httpd\nsudo chkconfig httpd on\n#检查一下，是否添加成功\nchkconfig --list httpd \n```\n\n###方法二\n\n``` bash\nsudo yum install httpd\n#可选？sudo yum install httpd-devel\n#测试\n#启动 apache http server\nsudo service httpd start\n#添加规则，让防火墙允许 apache的端口 80\nsudo vim /etc/sysconfig/iptables\n#添加如下一行，位置必须要放在 含有 \"REJECT --reject-with\" 的行的前面\n-A INPUT -m state --state NEW -m tcp -p tcp --dport 80 -j ACCEPT\nsudo service iptables restart\n#可以在浏览器输入 http://ip地址 测试了\n#设置为开机启动\nsudo chkconfig httpd on\n```\n\n##安装 mysql\n\n###方法一\n\n``` bash\n#去官网下载 Oracle & Red Hat 6的安装包，64位为MySQL-5.5.23-1.el6.x86_64.tar，\n#32位为 MySQL-5.5.23-1.el6.i686.tar\ntar -xf MySQL-5.5.23-1.el6.x86_64.tar\n#加 --force 是因为可能会与mysqllib库冲突\nsudo rpm -ivh --force  MySQL-server-5.5.23-1.el6.x86_64.rpm\nsudo rpm -ivh MySQL-client-5.5.23-1.el6.x86_64.rpm\n# 启动 mysql 服务器\nsudo service mysql start\n#设置为开机启动\nsudo chkconfig mysql on\n```\n\n###方法二\n\n``` bash\nsudo yum install mysql-server\nsudo chgrp -R mysql /var/lib/mysql\nsudo chmod -R 770 /var/lib/mysql\n# 启动 mysql 服务器\nsudo service mysqld start\n#设置为开机启动\nsudo chkconfig mysqld on\n```\n\n###公共的操作\n\n``` bash\n# root 初始密码为空，修改root密码\nmysql -u root\nmysql> use mysql;\nmysql> update user set password=password('root123') where user='root' AND host='localhost';\nmysql> flush privileges;\n# 打开MySQL中root账户的远程登录，参考：如何打开MySQL中root账户的远程登录mysql> GRANT ALL PRIVILEGES ON *.* TO root@\"%\" IDENTIFIED BY \"root\";\nmysql> update user set password=password('root123') where user='root' AND host='%';\nmysql> flush privileges;\nmysql> quit;\n#添加防火墙规则，让防火墙允许 mysql 的端口 3306通过\nsudo vim /etc/sysconfig/iptables\n#添加如下一行（实际上是拷贝了原来的一行，仅仅改变了端口号），位置必须#要放在 含有 \"REJECT --reject-with\" 的行的前面\n-A INPUT -m state --state NEW -m tcp -p tcp --dport 3306 -j ACCEPT\nsudo service iptables restart\n```\n\n##安装 php5\n\n###方法一\nTODO\n\n###方法二\n\n``` bash\nsudo yum install php php-pear\n#重启 apache，以确保apache 加载PHP模块\nsudo service httpd restart\n# 在 /var/www/html/下新建一个index.php文件，用于测试\ncd /var/www/html\nsudo vim index.php\n# 添加如下一行\n<?php phpinfo(); ?>\n# 在浏览器输入 http://xxx.xxx.xxx.xxx/index.php ，测试PHP是否成功安装\n\n# 如果需要在PHP中支持mysql，则需要安装 php-mysql 模块\nsudo yum install php-mysql\n# 如果需要在PHP中支持memcached，则需要安装 php-pecl-memcache 模块\nsudo yum install php-pecl-memcache\n#安装一些常用的PHP扩展模块\nsudo yum install php-devel php-gd php-mbstring php-xml\n\n#可以安装一个wordpress进行测试，注意要修改文件夹权限\nsudo chown -R apache.apache /var/www/html\n```\n\n## 安装 memcached\n\n###方法一\n\n``` bash\n# memcached依赖libevent，首先要安装 libevent\n# 去 http://libevent.org/ 下载libevent源码，然后编译，安装\ntar -zxf libevent-2.0.18-stable.tar.gz\ncd libevent-2.0.18-stable\n./configure\nmake\nsudo make install\n# 对于64位操作系统(32位不需要)，还需要配置：\nsudo ln -s /usr/local/lib/libevent-2.0.so.5 /usr/lib64//libevent-2.0.so.5\n# 去 http://www.memcached.org/ 下载 memcached，然后编译，安装\ntar -zxf memcached-1.4.13.tar.gz\ncd memcached-1.4.13\n./configure\nmake\nsudo make install\n# 启动, -p，端口,-m，内存, -u\nmemcached -p 11211 -m 512m -u root -d\n# 开机启动\n# centos设置开机启动有两种方式，一是把启动程序的命令添加到/etc/rc.d/rc.local文件中，二是把写好的启动脚本添加到目录/etc/rc.d/init.d/，然后使用命令chkconfig设置开机启动。第二种方式可以用 service xxx start|stop来启动或停止，所以推荐第二种。\n#将 memcached启动命令注册为一个服务\ncd /etc/init.d/\nsudo vim memcached\n#代码如下，参考：Linux中将memcached注册成服务并可以随机器启动时启动服务\n#chkconfig: 345 60 60\n#!/bin/bash\n\nstart()\n{\n        echo -n $\"Starting memcached: \"\n        /usr/local/bin/memcached -p 11211 -m 512m -u root -d\n        echo \"[OK]\"\n}\nstop()\n{\n        echo -n $\"Shutting down memcached: \"\n        memcached_pid_list=`pidof memcached` \n        kill -9 $memcached_pid_list\n        echo \"[OK]\"\n}\ncase \"$1\" in\n  start)\n        start\n        ;;\n  stop)\n        stop\n        ;;\n  restart)\n        stop\n        sleep 3\n        start\n        ;;\n    *)\n             echo $\"Usage: $0 {start|stop|restart}\"\n        exit 1\nesac\nexit 0\n#保存退出\nsudo chmod u+x memcached\nsudo chkconfig --add memcached\nsudo chkconfig  memcached on\n```\n\n###方法二\nTODO\n\n##安装 tomcat6\n\n###方法一\n\n``` bash\n# 去 http://tomcat.apache.org 下载 apache-tomcat-6.0.35.tar.gz\ntar -zxf apache-tomcat-6.0.35.tar.gz\nsudo mv apache-tomcat-6.0.35 /usr/local/\ncd /usr/local/apache-tomcat-6.0.35/bin\n#【可选】添加环境变量\nsudo vim /etc/profile\nexport CATALINA_HOME=/usr/local/apache-tomcat-6.0.35\n#启动 tomcat \nsudo ./startup.sh\n# 在浏览器输入 http://xxx.xxx.xxx.xxx:8080/ ，如果能看见tomcat页面，则表示安装成功了\n#设置开机启动\n#将 tomcat启动命令注册为一个服务\ncd /etc/init.d/\nsudo vim tomcatd\n#代码如下\n#chkconfig: 345 60 60\n#!/bin/bash\nCATALINA_HOME=/usr/local/apache-tomcat-6.0.35\n\nstart()\n{\n        echo -n $\"Starting Tomcat: \"\n        $CATALINA_HOME/bin/startup.sh\n        echo \"[OK]\"\n}\nstop()\n{\n        echo -n $\"Shutting down Tomcat: \"\n        $CATALINA_HOME/bin/shutdown.sh\n        echo \"[OK]\"\n}\ncase \"$1\" in\n  start)\n        start\n        ;;\n  stop)\n        stop\n        ;;\n  restart)\n        stop\n        sleep 3\n        start\n        ;;\n    *)\n             echo $\"Usage: $0 {start|stop|restart}\"\n        exit 1\nesac\nexit 0\n#保存退出\nsudo chmod u+x tomcatd\nsudo chkconfig --add tomcatd\nsudo chkconfig tomcatd on\n\n#添加防火墙规则，让防火墙允许 tomcat 的端口 8080 通过\nsudo vim /etc/sysconfig/iptables\n#添加如下一行（实际上是拷贝了原来的一行，仅仅改变了端口号），位置必须#要放在 含有 \"REJECT --reject-with\" 的行的前面\n-A INPUT -m state --state NEW -m tcp -p tcp --dport 8080 -j ACCEPT\nsudo service iptables restart\n```\n\n###方法二\n\n``` bash\n#搜索一下 tomcat包的名字\nyum search tomcat\nsudo yum search tomcat6.noarch\n```\n\n##安装Python\n\n###方法一：去[官网](http://www.python.org)下载源码，编译，安装\n\n``` bash\n#开始解压，编译，安装\ntar -jxf Python-3.2.3.tar.bz2\ncd Python-3.2.3\n# 查看一下说明, vim README\nsudo yum install zlib-devel bzip2-devel openssl-devel ncurses-devel sqlite-devel readline-devel tk-devel\n./configure\nmake\n#为了加快安装速度，这步可以省略\nmake test\n#卸载旧的python，注意，不能用 yum remove python，这会卸载几百个包，最终损坏系统\nsudo rpm -evf --nodeps python\nsudo make install\n#默认安装在 /usr/local/bin/python3\n```\n\n###方法二\n\n``` bash\nsudo yum install python\n```\n\n##安装ruby\n\n###方法一\n\n``` bash\n# http://www.ruby-lang.org/en/downloads/ ，选择 \"Stable Snapshot\"\ntar -zxf ruby-1.9-stable.tar.gz\ncd  cd ruby-1.9.3-p194/\n./configure\nmake\nsudo make install\n```\n\n###方法二\n\n``` bash\nsudo yum install ruby\n```\n\n##安装go\n\n``` bash\n#去官网 http://code.google.com/p/go/downloads 下载，go1.0.1.linux-i386.tar.gz (32位)，go1.0.1.linux-amd64.tar.gz（64位）\ntar -zxf go1.0.1.linux-amd64.tar.gz\nsudo mv go/ /usr/local/\n#设置环境变量\nsudo vim /etc/profile\nexport GOROOT=/usr/local/go\nexport PATH=$PATH:$GOROOT/bin\nsource /etc/profile\n#测试一下\ngo version\n```\n\n##安装lua\n\n``` bash\n# 去官网下载源码，编译，安装。由于官网仅提供源码，故推荐源码编译安装方式。\n# 去官网 http://www.lua.org/ 下载源码，lua-5.2.0.tar.gz\ntar -zxf lua-5.2.0.tar.gz \ncd lua-5.2.0\n# lua 依赖 readline.h 头文件\nsudo yum install  readline-devel\nmake linux\nsudo make install\n#安装 google protobuf\n#去官网 http://code.google.com/p/protobuf/下载\ntar -jxf protobuf-2.4.1.tar.bz2\ncd protobuf-2.4.1\n./configure\nmake\nsudo make install\n#测试\nprotoc\n```\n\n##清理安装包\n\n``` bash\ncd ~\nrm * -rf\n```\n\n##压缩打包\n安装完后，可以Clone，压缩打包成一个zip文件，方便分享给别人。\n\n在关机之前，有一件事需要做，\n\n\tsudo vim /etc/sysconfig/network-scripts/ifcfg-eth0, 把HWADDR=.... 这行删掉\n\tsudo rm /etc/udev/rules.d/70-persistent-net.rules\n\tsudo shutdown -h now\n\n如果没有执行上述命令，克隆后的虚拟机，开机后无法上网，重启网络，`sudo service network restart`也没有效果，会出现错误“Device eth0 does not seem to be present, delaying initialization.” \n\n这是因为克隆后的虚拟机，它的MAC地址变了，即在它的.vmx文件里，MAC地址变了（`ethernet0.generatedAddress`这项），但是linux不知道这个变化，网络配置文件还是旧的，这样跟它的而真实mac不匹配，网络就无法启动。\n\n执行上述命令，删除了`70-persistent-net.rules`后，相当于删除了旧的配置文件，在开机时会生成新的配置文件。\n\n关机后，右击标签，选择\"Manage->Clone\"，选择\"Create a full clone\"，克隆完成后，关闭这台虚拟机的标签（否则文件夹里有一些临时垃圾文件），然后把文件夹压缩打包。以后就可以把这个zip包拷贝给周围的人，别人就不用经历一遍重装的过程了。","source":"_posts/2013-10-28-install-and-configure-a-ubuntu-server-from-scratch.md","raw":"---\nlayout: post\ntitle: \"安装和配置Ubuntu服务器的详细步骤\"\ndate: 2013-10-28 23:26\ncomments: true\ncategories: \npublished: false\n---\n\n这是我安装Ubuntu服务器的过程，分享给大家。CentOS服务器请参考我另一篇博客，[安装和配置CentOS服务器的详细步骤](http://www.yanjiuyanjiu.com/blog/20120423/)。\n\n\n##安装操作系统\n\n所使用的ISO文件是 ubuntu-13.04-server-amd64.iso\n\n首先在虚拟机或物理机上安装操作系统，用户名为manong，密码 manong123\n\n\n##设置上网\n安装完操作系统后，还不能上网，配置DHCP方式上网：\n\n``` bash\nvim /etc/sysconfig/network-scripts/ifcfg-eth0\nDEVICE=\"eth0\"\nHWADDR=\"00:0C:29:BD:E1:19\"\nNM_CONTROLLED=\"yes\"\nONBOOT=\"yes\"\nBOOTPROTO=dhcp\nUSECTL=no\nTYPE=Ethernet\nPEERDNS=yes\n#保存退出\nsudo service network restart\n```\n\n<!-- more -->\n\n或者，配置静态IP\n\n``` bash\nDEVICE=\"eth0\"\nHWADDR=\"00:0C:29:10:F4:4C\"\nONBOOT=\"yes\"\nBOOTPROTO=static\nTYPE=Ethernet\nIPADDR=192.168.0.162\nNETMASK=255.255.255.0\nBROADCAST=192.168.0.255\nNETWORK=192.168.0.0\n#保存退出  \n#修改/etc/sysconfig/network\nsudo vim /etc/sysconfig/network\nNETWORKING=yes\nHOSTNAME=localhost.localdomain\nGATEWAY=192.168.0.1\n#保存退出，重启网络\nsudo service network restart\n```\n如果失败，比如IP已被占用，换一个IP试试\n\n修改DNS，即时生效\n\n``` bash\nsudo vim /etc/resolv.conf\nnameserver 192.168.0.1\n# google提供的域名服务器\nnameserver 8.8.8.8\nsearch localhost\n```\n\n##安装常用软件\n有两种方式，方法一，去官网下载已经编译好的二进制文件，或源代码，编译安装\n方法二，用yum 命令安装，安装官方yum源里已经编译好的程序包。  \n第一种方式要敲很多命令，比yum麻烦，但是可以预先下载好文件，省略了下载的时间，整体速度比yum安装方式快很多，而且可以安装最新版。推荐第一种方式\n\n第二种方式操作简单，敲打的命令少，但是往往yum源的更新速度跟不上各个软件的官网速度，用Yum安装的版本经常比较旧。\n\nyum的命令形式一般是如下：`yum [options] [command] [package ...]`，其中的[options]是可选的，选项包括-h（帮助），-y（当安装过程提示选择全部为\"yes\"），-q（不显示安装的过程）等等。[command]为所要进行的操作，[package ...]是操作的对象。\n\n``` bash\n#yum search package-name # 在线搜索包 \n#yum list installed # 列出所有已经安装的包\n#\n#sudo yum install package-name # 安装程序包 \n#sudo yum groupinsall group-name 安装程序组\n#\n#sudo yum remove package-name 删除程序包\n#sudo yum groupremove group-name 删除程序组\n#\n#yum update #全部更新\n#yum update package-name #更新程序包\n#sudo yum groupupdate groupn-name 升级程序组\n#sudo yum upgrade # 更新源列表\n#yum upgrade package-name #升级程序包\n#sudo yum clean all # 清除缓存\n#更新\nsudo yum update\n#清理缓存\nsudo yum clean all && yum clean metadata && yum clean dbcache\n```\n\n##安装编译工具\n\n###方法一\n去 http://gcc.gnu.org/ 下载源码\n\n``` bash\n# TODO\n```\n\n###方法二\n\n``` bash\nsudo yum groupinstall \"Development Tools\"\n```\n该命令类似于 Ubuntu 下的`apt-get install build-essential`，会自动安装一下软件包：autoconf automake bison byacc cscope ctags diffstat doxygen flex gcc gcc-c++ gcc-gfortran git indent intltool libtool patchutils rcs redhat-rpm-config rpm-build subversion swig systemtap，同时安装了以下依赖包：apr, apr-util, 等等。\n\n\n##安装JDK\n\n``` bash\n#删除旧的JDK\nyum list installed | grep jdk\n#复制显示出来的JDK，卸载\nsudo yum remove java-1.6.0-openjdk.x86_64\n#安装新的jdk\n```\n\n###方法一\n\n``` bash\n#从官网下载最新版的，当前是jdk6u32\n#开始安装\nchmod u+x chmod u+x jdk-6u32-linux-x64-rpm.bin\nsudo ./jdk-6u32-linux-x64-rpm.bin\n#设置环境变量，.bash_profile是当前用户，/etc/profile是所有用户的\nsudo vim /etc/profile\n#在末尾添加\nexport JAVA_HOME=/usr/java/default\nexport JRE_HOME=$JAVA_HOME/jre\nexport PATH=$PATH:$JAVA_HOME/bin\nexport CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar\n# 保存退出，输入以下命令使之立即生效：\nsource /etc/profile\n# 测试\njava -version\n```\n\n###方法二\n\n``` bash\nyum search jdk\n# java-1.6.0-openjdk只包含了JRE，如果在这台机器上开发java程序，则需要安装JDK，\n# 要选择 java-1.6.0-openjdk-devel，在服务器上我们只需要运行java程序，因此选择前者\nsudo yum install java-1.6.0-openjdk-devel\n# 使用 alternatives 工具设置默认JDK，参考：Installing a Java Development Kit on Red Hat Enterprise Linux\n/usr/sbin/alternatives --config java\n/usr/sbin/alternatives --config javac\n# 设置环境变量\n# 查询JDK路径\nwhereis java\nll /usr/bin/java\nll /etc/alternatives/java #这是可以看到JDK路径了\nsudo vim /etc/profile\n# 在末尾添加\nexport JAVA_HOME=/usr/lib/jvm/jre-1.6.0-openjdk.x86_64\nexport JRE_HOME=$JAVA_HOME/jre\nexport PATH=$PATH:$JAVA_HOME/bin\nexport CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar\n#保存退出，输入以下命令使之立即生效：\n# source /etc/profile\n# 测试\njava -version\n```\n\n##安装 apache\n\n###方法一\n源码在官网 http://httpd.apache.org/ 下载。  \n先下载apt, apr-util, pcre三个库，httpd 在编译时需要用到这三个库  \napr, apr-util官网 http://apr.apache.org , pcre官网为 [http://pcre.org ](http://pcre.org )\n\n``` bash\n# 编译，安装 apr\ntar -jxf apr-1.4.6.tar.bz2\ncd apr-1.4.6\n./configure\nmake\nsudo make install    # 默认会安装到 /usr/local/apr/\ncd ~\n#编译，安装 apr-util\ntar -jxf apr-util-1.4.1.tar.bz2\ncd apr-util-1.4.1\n./configure --with-apr=/usr/local/apr/\nmake\nsudo make install    # 默认会安装到 /usr/local/apr/\ncd ~\n#编译，安装 pcre\ntar -jxf pcre-8.30.tar.bz2\ncd  pcre-8.30\n./configure --with-apr=/usr/local/apr/\nmake\n# By default, `make install' installs the package's commands under\n#`/usr/local/bin', include files under `/usr/local/include', etc. \nsudo make install\ncd ~\n#编译，安装 apache\ntar -jxf httpd-2.2.22.tar.bz2\ncd httpd-2.2.22\n./configure\nmake\nsudo make install    # 默认会安装到/usr/local/apache2/\ncd ~\n#添加防火墙规则，让防火墙允许 apache的端口 80通过\nsudo vim /etc/sysconfig/iptables\n#添加如下一行（实际上是拷贝了原来的一行，仅仅改变了端口号），位置必须#要放在 含有 \"REJECT --reject-with\" 的行的前面\n-A INPUT -m state --state NEW -m tcp -p tcp --dport 80 -j ACCEPT\nsudo service iptables restart\n#测试\nsudo /usr/local/apache2/bin/apachectl start\n#在浏览器输入 http://ip地址 ，如果看到“It works”，说明安装成功\n/usr/local/apache2/bin/apachectl stop\n\n\n#设置为开机启动\n#将httpd注册为服务，通过chkconfig实现开机启动\n#以apachectl 为模板\nsudo cp /usr/local/apache2/bin/apachectl /etc/init.d/httpd\nsudo vim /etc/init.d/httpd\n# 在第一行 #!/bin/sh，添加如下一行，使其支持chkconfig命令\n# chkconfig: 2345 85 15\n# 保存，退出VIM编辑器\nsudo chmod u+x /etc/init.d/httpd\nsudo chkconfig --add httpd\nsudo chkconfig httpd on\n#检查一下，是否添加成功\nchkconfig --list httpd \n```\n\n###方法二\n\n``` bash\nsudo yum install httpd\n#可选？sudo yum install httpd-devel\n#测试\n#启动 apache http server\nsudo service httpd start\n#添加规则，让防火墙允许 apache的端口 80\nsudo vim /etc/sysconfig/iptables\n#添加如下一行，位置必须要放在 含有 \"REJECT --reject-with\" 的行的前面\n-A INPUT -m state --state NEW -m tcp -p tcp --dport 80 -j ACCEPT\nsudo service iptables restart\n#可以在浏览器输入 http://ip地址 测试了\n#设置为开机启动\nsudo chkconfig httpd on\n```\n\n##安装 mysql\n\n###方法一\n\n``` bash\n#去官网下载 Oracle & Red Hat 6的安装包，64位为MySQL-5.5.23-1.el6.x86_64.tar，\n#32位为 MySQL-5.5.23-1.el6.i686.tar\ntar -xf MySQL-5.5.23-1.el6.x86_64.tar\n#加 --force 是因为可能会与mysqllib库冲突\nsudo rpm -ivh --force  MySQL-server-5.5.23-1.el6.x86_64.rpm\nsudo rpm -ivh MySQL-client-5.5.23-1.el6.x86_64.rpm\n# 启动 mysql 服务器\nsudo service mysql start\n#设置为开机启动\nsudo chkconfig mysql on\n```\n\n###方法二\n\n``` bash\nsudo yum install mysql-server\nsudo chgrp -R mysql /var/lib/mysql\nsudo chmod -R 770 /var/lib/mysql\n# 启动 mysql 服务器\nsudo service mysqld start\n#设置为开机启动\nsudo chkconfig mysqld on\n```\n\n###公共的操作\n\n``` bash\n# root 初始密码为空，修改root密码\nmysql -u root\nmysql> use mysql;\nmysql> update user set password=password('root123') where user='root' AND host='localhost';\nmysql> flush privileges;\n# 打开MySQL中root账户的远程登录，参考：如何打开MySQL中root账户的远程登录mysql> GRANT ALL PRIVILEGES ON *.* TO root@\"%\" IDENTIFIED BY \"root\";\nmysql> update user set password=password('root123') where user='root' AND host='%';\nmysql> flush privileges;\nmysql> quit;\n#添加防火墙规则，让防火墙允许 mysql 的端口 3306通过\nsudo vim /etc/sysconfig/iptables\n#添加如下一行（实际上是拷贝了原来的一行，仅仅改变了端口号），位置必须#要放在 含有 \"REJECT --reject-with\" 的行的前面\n-A INPUT -m state --state NEW -m tcp -p tcp --dport 3306 -j ACCEPT\nsudo service iptables restart\n```\n\n##安装 php5\n\n###方法一\nTODO\n\n###方法二\n\n``` bash\nsudo yum install php php-pear\n#重启 apache，以确保apache 加载PHP模块\nsudo service httpd restart\n# 在 /var/www/html/下新建一个index.php文件，用于测试\ncd /var/www/html\nsudo vim index.php\n# 添加如下一行\n<?php phpinfo(); ?>\n# 在浏览器输入 http://xxx.xxx.xxx.xxx/index.php ，测试PHP是否成功安装\n\n# 如果需要在PHP中支持mysql，则需要安装 php-mysql 模块\nsudo yum install php-mysql\n# 如果需要在PHP中支持memcached，则需要安装 php-pecl-memcache 模块\nsudo yum install php-pecl-memcache\n#安装一些常用的PHP扩展模块\nsudo yum install php-devel php-gd php-mbstring php-xml\n\n#可以安装一个wordpress进行测试，注意要修改文件夹权限\nsudo chown -R apache.apache /var/www/html\n```\n\n## 安装 memcached\n\n###方法一\n\n``` bash\n# memcached依赖libevent，首先要安装 libevent\n# 去 http://libevent.org/ 下载libevent源码，然后编译，安装\ntar -zxf libevent-2.0.18-stable.tar.gz\ncd libevent-2.0.18-stable\n./configure\nmake\nsudo make install\n# 对于64位操作系统(32位不需要)，还需要配置：\nsudo ln -s /usr/local/lib/libevent-2.0.so.5 /usr/lib64//libevent-2.0.so.5\n# 去 http://www.memcached.org/ 下载 memcached，然后编译，安装\ntar -zxf memcached-1.4.13.tar.gz\ncd memcached-1.4.13\n./configure\nmake\nsudo make install\n# 启动, -p，端口,-m，内存, -u\nmemcached -p 11211 -m 512m -u root -d\n# 开机启动\n# centos设置开机启动有两种方式，一是把启动程序的命令添加到/etc/rc.d/rc.local文件中，二是把写好的启动脚本添加到目录/etc/rc.d/init.d/，然后使用命令chkconfig设置开机启动。第二种方式可以用 service xxx start|stop来启动或停止，所以推荐第二种。\n#将 memcached启动命令注册为一个服务\ncd /etc/init.d/\nsudo vim memcached\n#代码如下，参考：Linux中将memcached注册成服务并可以随机器启动时启动服务\n#chkconfig: 345 60 60\n#!/bin/bash\n\nstart()\n{\n        echo -n $\"Starting memcached: \"\n        /usr/local/bin/memcached -p 11211 -m 512m -u root -d\n        echo \"[OK]\"\n}\nstop()\n{\n        echo -n $\"Shutting down memcached: \"\n        memcached_pid_list=`pidof memcached` \n        kill -9 $memcached_pid_list\n        echo \"[OK]\"\n}\ncase \"$1\" in\n  start)\n        start\n        ;;\n  stop)\n        stop\n        ;;\n  restart)\n        stop\n        sleep 3\n        start\n        ;;\n    *)\n             echo $\"Usage: $0 {start|stop|restart}\"\n        exit 1\nesac\nexit 0\n#保存退出\nsudo chmod u+x memcached\nsudo chkconfig --add memcached\nsudo chkconfig  memcached on\n```\n\n###方法二\nTODO\n\n##安装 tomcat6\n\n###方法一\n\n``` bash\n# 去 http://tomcat.apache.org 下载 apache-tomcat-6.0.35.tar.gz\ntar -zxf apache-tomcat-6.0.35.tar.gz\nsudo mv apache-tomcat-6.0.35 /usr/local/\ncd /usr/local/apache-tomcat-6.0.35/bin\n#【可选】添加环境变量\nsudo vim /etc/profile\nexport CATALINA_HOME=/usr/local/apache-tomcat-6.0.35\n#启动 tomcat \nsudo ./startup.sh\n# 在浏览器输入 http://xxx.xxx.xxx.xxx:8080/ ，如果能看见tomcat页面，则表示安装成功了\n#设置开机启动\n#将 tomcat启动命令注册为一个服务\ncd /etc/init.d/\nsudo vim tomcatd\n#代码如下\n#chkconfig: 345 60 60\n#!/bin/bash\nCATALINA_HOME=/usr/local/apache-tomcat-6.0.35\n\nstart()\n{\n        echo -n $\"Starting Tomcat: \"\n        $CATALINA_HOME/bin/startup.sh\n        echo \"[OK]\"\n}\nstop()\n{\n        echo -n $\"Shutting down Tomcat: \"\n        $CATALINA_HOME/bin/shutdown.sh\n        echo \"[OK]\"\n}\ncase \"$1\" in\n  start)\n        start\n        ;;\n  stop)\n        stop\n        ;;\n  restart)\n        stop\n        sleep 3\n        start\n        ;;\n    *)\n             echo $\"Usage: $0 {start|stop|restart}\"\n        exit 1\nesac\nexit 0\n#保存退出\nsudo chmod u+x tomcatd\nsudo chkconfig --add tomcatd\nsudo chkconfig tomcatd on\n\n#添加防火墙规则，让防火墙允许 tomcat 的端口 8080 通过\nsudo vim /etc/sysconfig/iptables\n#添加如下一行（实际上是拷贝了原来的一行，仅仅改变了端口号），位置必须#要放在 含有 \"REJECT --reject-with\" 的行的前面\n-A INPUT -m state --state NEW -m tcp -p tcp --dport 8080 -j ACCEPT\nsudo service iptables restart\n```\n\n###方法二\n\n``` bash\n#搜索一下 tomcat包的名字\nyum search tomcat\nsudo yum search tomcat6.noarch\n```\n\n##安装Python\n\n###方法一：去[官网](http://www.python.org)下载源码，编译，安装\n\n``` bash\n#开始解压，编译，安装\ntar -jxf Python-3.2.3.tar.bz2\ncd Python-3.2.3\n# 查看一下说明, vim README\nsudo yum install zlib-devel bzip2-devel openssl-devel ncurses-devel sqlite-devel readline-devel tk-devel\n./configure\nmake\n#为了加快安装速度，这步可以省略\nmake test\n#卸载旧的python，注意，不能用 yum remove python，这会卸载几百个包，最终损坏系统\nsudo rpm -evf --nodeps python\nsudo make install\n#默认安装在 /usr/local/bin/python3\n```\n\n###方法二\n\n``` bash\nsudo yum install python\n```\n\n##安装ruby\n\n###方法一\n\n``` bash\n# http://www.ruby-lang.org/en/downloads/ ，选择 \"Stable Snapshot\"\ntar -zxf ruby-1.9-stable.tar.gz\ncd  cd ruby-1.9.3-p194/\n./configure\nmake\nsudo make install\n```\n\n###方法二\n\n``` bash\nsudo yum install ruby\n```\n\n##安装go\n\n``` bash\n#去官网 http://code.google.com/p/go/downloads 下载，go1.0.1.linux-i386.tar.gz (32位)，go1.0.1.linux-amd64.tar.gz（64位）\ntar -zxf go1.0.1.linux-amd64.tar.gz\nsudo mv go/ /usr/local/\n#设置环境变量\nsudo vim /etc/profile\nexport GOROOT=/usr/local/go\nexport PATH=$PATH:$GOROOT/bin\nsource /etc/profile\n#测试一下\ngo version\n```\n\n##安装lua\n\n``` bash\n# 去官网下载源码，编译，安装。由于官网仅提供源码，故推荐源码编译安装方式。\n# 去官网 http://www.lua.org/ 下载源码，lua-5.2.0.tar.gz\ntar -zxf lua-5.2.0.tar.gz \ncd lua-5.2.0\n# lua 依赖 readline.h 头文件\nsudo yum install  readline-devel\nmake linux\nsudo make install\n#安装 google protobuf\n#去官网 http://code.google.com/p/protobuf/下载\ntar -jxf protobuf-2.4.1.tar.bz2\ncd protobuf-2.4.1\n./configure\nmake\nsudo make install\n#测试\nprotoc\n```\n\n##清理安装包\n\n``` bash\ncd ~\nrm * -rf\n```\n\n##压缩打包\n安装完后，可以Clone，压缩打包成一个zip文件，方便分享给别人。\n\n在关机之前，有一件事需要做，\n\n\tsudo vim /etc/sysconfig/network-scripts/ifcfg-eth0, 把HWADDR=.... 这行删掉\n\tsudo rm /etc/udev/rules.d/70-persistent-net.rules\n\tsudo shutdown -h now\n\n如果没有执行上述命令，克隆后的虚拟机，开机后无法上网，重启网络，`sudo service network restart`也没有效果，会出现错误“Device eth0 does not seem to be present, delaying initialization.” \n\n这是因为克隆后的虚拟机，它的MAC地址变了，即在它的.vmx文件里，MAC地址变了（`ethernet0.generatedAddress`这项），但是linux不知道这个变化，网络配置文件还是旧的，这样跟它的而真实mac不匹配，网络就无法启动。\n\n执行上述命令，删除了`70-persistent-net.rules`后，相当于删除了旧的配置文件，在开机时会生成新的配置文件。\n\n关机后，右击标签，选择\"Manage->Clone\"，选择\"Create a full clone\"，克隆完成后，关闭这台虚拟机的标签（否则文件夹里有一些临时垃圾文件），然后把文件夹压缩打包。以后就可以把这个zip包拷贝给周围的人，别人就不用经历一遍重装的过程了。","slug":"2013-10-28-install-and-configure-a-ubuntu-server-from-scratch","updated":"2016-08-18T09:21:04.000Z","photos":[],"link":"","_id":"cis07pf3x002901pqwmgrobo6","content":"<p>这是我安装Ubuntu服务器的过程，分享给大家。CentOS服务器请参考我另一篇博客，<a href=\"http://www.yanjiuyanjiu.com/blog/20120423/\" target=\"_blank\" rel=\"external\">安装和配置CentOS服务器的详细步骤</a>。</p>\n<p>##安装操作系统</p>\n<p>所使用的ISO文件是 ubuntu-13.04-server-amd64.iso</p>\n<p>首先在虚拟机或物理机上安装操作系统，用户名为manong，密码 manong123</p>\n<p>##设置上网<br>安装完操作系统后，还不能上网，配置DHCP方式上网：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div></pre></td><td class=\"code\"><pre><div class=\"line\">vim /etc/sysconfig/network-scripts/ifcfg-eth0</div><div class=\"line\">DEVICE=<span class=\"string\">\"eth0\"</span></div><div class=\"line\">HWADDR=<span class=\"string\">\"00:0C:29:BD:E1:19\"</span></div><div class=\"line\">NM_CONTROLLED=<span class=\"string\">\"yes\"</span></div><div class=\"line\">ONBOOT=<span class=\"string\">\"yes\"</span></div><div class=\"line\">BOOTPROTO=dhcp</div><div class=\"line\">USECTL=no</div><div class=\"line\">TYPE=Ethernet</div><div class=\"line\">PEERDNS=yes</div><div class=\"line\"><span class=\"comment\">#保存退出</span></div><div class=\"line\">sudo service network restart</div></pre></td></tr></table></figure>\n<a id=\"more\"></a>\n<p>或者，配置静态IP</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div></pre></td><td class=\"code\"><pre><div class=\"line\">DEVICE=<span class=\"string\">\"eth0\"</span></div><div class=\"line\">HWADDR=<span class=\"string\">\"00:0C:29:10:F4:4C\"</span></div><div class=\"line\">ONBOOT=<span class=\"string\">\"yes\"</span></div><div class=\"line\">BOOTPROTO=static</div><div class=\"line\">TYPE=Ethernet</div><div class=\"line\">IPADDR=192.168.0.162</div><div class=\"line\">NETMASK=255.255.255.0</div><div class=\"line\">BROADCAST=192.168.0.255</div><div class=\"line\">NETWORK=192.168.0.0</div><div class=\"line\"><span class=\"comment\">#保存退出  </span></div><div class=\"line\"><span class=\"comment\">#修改/etc/sysconfig/network</span></div><div class=\"line\">sudo vim /etc/sysconfig/network</div><div class=\"line\">NETWORKING=yes</div><div class=\"line\">HOSTNAME=localhost.localdomain</div><div class=\"line\">GATEWAY=192.168.0.1</div><div class=\"line\"><span class=\"comment\">#保存退出，重启网络</span></div><div class=\"line\">sudo service network restart</div></pre></td></tr></table></figure>\n<p>如果失败，比如IP已被占用，换一个IP试试</p>\n<p>修改DNS，即时生效</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\">sudo vim /etc/resolv.conf</div><div class=\"line\">nameserver 192.168.0.1</div><div class=\"line\"><span class=\"comment\"># google提供的域名服务器</span></div><div class=\"line\">nameserver 8.8.8.8</div><div class=\"line\">search localhost</div></pre></td></tr></table></figure>\n<p>##安装常用软件<br>有两种方式，方法一，去官网下载已经编译好的二进制文件，或源代码，编译安装<br>方法二，用yum 命令安装，安装官方yum源里已经编译好的程序包。<br>第一种方式要敲很多命令，比yum麻烦，但是可以预先下载好文件，省略了下载的时间，整体速度比yum安装方式快很多，而且可以安装最新版。推荐第一种方式</p>\n<p>第二种方式操作简单，敲打的命令少，但是往往yum源的更新速度跟不上各个软件的官网速度，用Yum安装的版本经常比较旧。</p>\n<p>yum的命令形式一般是如下：<code>yum [options] [command] [package ...]</code>，其中的[options]是可选的，选项包括-h（帮助），-y（当安装过程提示选择全部为”yes”），-q（不显示安装的过程）等等。[command]为所要进行的操作，[package …]是操作的对象。</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">#yum search package-name # 在线搜索包 </span></div><div class=\"line\"><span class=\"comment\">#yum list installed # 列出所有已经安装的包</span></div><div class=\"line\"><span class=\"comment\">#</span></div><div class=\"line\"><span class=\"comment\">#sudo yum install package-name # 安装程序包 </span></div><div class=\"line\"><span class=\"comment\">#sudo yum groupinsall group-name 安装程序组</span></div><div class=\"line\"><span class=\"comment\">#</span></div><div class=\"line\"><span class=\"comment\">#sudo yum remove package-name 删除程序包</span></div><div class=\"line\"><span class=\"comment\">#sudo yum groupremove group-name 删除程序组</span></div><div class=\"line\"><span class=\"comment\">#</span></div><div class=\"line\"><span class=\"comment\">#yum update #全部更新</span></div><div class=\"line\"><span class=\"comment\">#yum update package-name #更新程序包</span></div><div class=\"line\"><span class=\"comment\">#sudo yum groupupdate groupn-name 升级程序组</span></div><div class=\"line\"><span class=\"comment\">#sudo yum upgrade # 更新源列表</span></div><div class=\"line\"><span class=\"comment\">#yum upgrade package-name #升级程序包</span></div><div class=\"line\"><span class=\"comment\">#sudo yum clean all # 清除缓存</span></div><div class=\"line\"><span class=\"comment\">#更新</span></div><div class=\"line\">sudo yum update</div><div class=\"line\"><span class=\"comment\">#清理缓存</span></div><div class=\"line\">sudo yum clean all &amp;&amp; yum clean metadata &amp;&amp; yum clean dbcache</div></pre></td></tr></table></figure>\n<p>##安装编译工具</p>\n<p>###方法一<br>去 <a href=\"http://gcc.gnu.org/\" target=\"_blank\" rel=\"external\">http://gcc.gnu.org/</a> 下载源码</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># TODO</span></div></pre></td></tr></table></figure>\n<p>###方法二</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">sudo yum groupinstall <span class=\"string\">\"Development Tools\"</span></div></pre></td></tr></table></figure>\n<p>该命令类似于 Ubuntu 下的<code>apt-get install build-essential</code>，会自动安装一下软件包：autoconf automake bison byacc cscope ctags diffstat doxygen flex gcc gcc-c++ gcc-gfortran git indent intltool libtool patchutils rcs redhat-rpm-config rpm-build subversion swig systemtap，同时安装了以下依赖包：apr, apr-util, 等等。</p>\n<p>##安装JDK</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">#删除旧的JDK</span></div><div class=\"line\">yum list installed | grep jdk</div><div class=\"line\"><span class=\"comment\">#复制显示出来的JDK，卸载</span></div><div class=\"line\">sudo yum remove java-1.6.0-openjdk.x86_64</div><div class=\"line\"><span class=\"comment\">#安装新的jdk</span></div></pre></td></tr></table></figure>\n<p>###方法一</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">#从官网下载最新版的，当前是jdk6u32</span></div><div class=\"line\"><span class=\"comment\">#开始安装</span></div><div class=\"line\">chmod u+x chmod u+x jdk-6u32-linux-x64-rpm.bin</div><div class=\"line\">sudo ./jdk-6u32-linux-x64-rpm.bin</div><div class=\"line\"><span class=\"comment\">#设置环境变量，.bash_profile是当前用户，/etc/profile是所有用户的</span></div><div class=\"line\">sudo vim /etc/profile</div><div class=\"line\"><span class=\"comment\">#在末尾添加</span></div><div class=\"line\"><span class=\"built_in\">export</span> JAVA_HOME=/usr/java/default</div><div class=\"line\"><span class=\"built_in\">export</span> JRE_HOME=<span class=\"variable\">$JAVA_HOME</span>/jre</div><div class=\"line\"><span class=\"built_in\">export</span> PATH=<span class=\"variable\">$PATH</span>:<span class=\"variable\">$JAVA_HOME</span>/bin</div><div class=\"line\"><span class=\"built_in\">export</span> CLASSPATH=.:<span class=\"variable\">$JAVA_HOME</span>/lib/dt.jar:<span class=\"variable\">$JAVA_HOME</span>/lib/tools.jar</div><div class=\"line\"><span class=\"comment\"># 保存退出，输入以下命令使之立即生效：</span></div><div class=\"line\"><span class=\"built_in\">source</span> /etc/profile</div><div class=\"line\"><span class=\"comment\"># 测试</span></div><div class=\"line\">java -version</div></pre></td></tr></table></figure>\n<p>###方法二</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div></pre></td><td class=\"code\"><pre><div class=\"line\">yum search jdk</div><div class=\"line\"><span class=\"comment\"># java-1.6.0-openjdk只包含了JRE，如果在这台机器上开发java程序，则需要安装JDK，</span></div><div class=\"line\"><span class=\"comment\"># 要选择 java-1.6.0-openjdk-devel，在服务器上我们只需要运行java程序，因此选择前者</span></div><div class=\"line\">sudo yum install java-1.6.0-openjdk-devel</div><div class=\"line\"><span class=\"comment\"># 使用 alternatives 工具设置默认JDK，参考：Installing a Java Development Kit on Red Hat Enterprise Linux</span></div><div class=\"line\">/usr/sbin/alternatives --config java</div><div class=\"line\">/usr/sbin/alternatives --config javac</div><div class=\"line\"><span class=\"comment\"># 设置环境变量</span></div><div class=\"line\"><span class=\"comment\"># 查询JDK路径</span></div><div class=\"line\">whereis java</div><div class=\"line\">ll /usr/bin/java</div><div class=\"line\">ll /etc/alternatives/java <span class=\"comment\">#这是可以看到JDK路径了</span></div><div class=\"line\">sudo vim /etc/profile</div><div class=\"line\"><span class=\"comment\"># 在末尾添加</span></div><div class=\"line\"><span class=\"built_in\">export</span> JAVA_HOME=/usr/lib/jvm/jre-1.6.0-openjdk.x86_64</div><div class=\"line\"><span class=\"built_in\">export</span> JRE_HOME=<span class=\"variable\">$JAVA_HOME</span>/jre</div><div class=\"line\"><span class=\"built_in\">export</span> PATH=<span class=\"variable\">$PATH</span>:<span class=\"variable\">$JAVA_HOME</span>/bin</div><div class=\"line\"><span class=\"built_in\">export</span> CLASSPATH=.:<span class=\"variable\">$JAVA_HOME</span>/lib/dt.jar:<span class=\"variable\">$JAVA_HOME</span>/lib/tools.jar</div><div class=\"line\"><span class=\"comment\">#保存退出，输入以下命令使之立即生效：</span></div><div class=\"line\"><span class=\"comment\"># source /etc/profile</span></div><div class=\"line\"><span class=\"comment\"># 测试</span></div><div class=\"line\">java -version</div></pre></td></tr></table></figure>\n<p>##安装 apache</p>\n<p>###方法一<br>源码在官网 <a href=\"http://httpd.apache.org/\" target=\"_blank\" rel=\"external\">http://httpd.apache.org/</a> 下载。<br>先下载apt, apr-util, pcre三个库，httpd 在编译时需要用到这三个库<br>apr, apr-util官网 <a href=\"http://apr.apache.org\" target=\"_blank\" rel=\"external\">http://apr.apache.org</a> , pcre官网为 <a href=\"http://pcre.org\" target=\"_blank\" rel=\"external\">http://pcre.org </a></p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div><div class=\"line\">51</div><div class=\"line\">52</div><div class=\"line\">53</div><div class=\"line\">54</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># 编译，安装 apr</span></div><div class=\"line\">tar -jxf apr-1.4.6.tar.bz2</div><div class=\"line\"><span class=\"built_in\">cd</span> apr-1.4.6</div><div class=\"line\">./configure</div><div class=\"line\">make</div><div class=\"line\">sudo make install    <span class=\"comment\"># 默认会安装到 /usr/local/apr/</span></div><div class=\"line\"><span class=\"built_in\">cd</span> ~</div><div class=\"line\"><span class=\"comment\">#编译，安装 apr-util</span></div><div class=\"line\">tar -jxf apr-util-1.4.1.tar.bz2</div><div class=\"line\"><span class=\"built_in\">cd</span> apr-util-1.4.1</div><div class=\"line\">./configure --with-apr=/usr/<span class=\"built_in\">local</span>/apr/</div><div class=\"line\">make</div><div class=\"line\">sudo make install    <span class=\"comment\"># 默认会安装到 /usr/local/apr/</span></div><div class=\"line\"><span class=\"built_in\">cd</span> ~</div><div class=\"line\"><span class=\"comment\">#编译，安装 pcre</span></div><div class=\"line\">tar -jxf pcre-8.30.tar.bz2</div><div class=\"line\"><span class=\"built_in\">cd</span>  pcre-8.30</div><div class=\"line\">./configure --with-apr=/usr/<span class=\"built_in\">local</span>/apr/</div><div class=\"line\">make</div><div class=\"line\"><span class=\"comment\"># By default, `make install' installs the package's commands under</span></div><div class=\"line\"><span class=\"comment\">#`/usr/local/bin', include files under `/usr/local/include', etc. </span></div><div class=\"line\">sudo make install</div><div class=\"line\"><span class=\"built_in\">cd</span> ~</div><div class=\"line\"><span class=\"comment\">#编译，安装 apache</span></div><div class=\"line\">tar -jxf httpd-2.2.22.tar.bz2</div><div class=\"line\"><span class=\"built_in\">cd</span> httpd-2.2.22</div><div class=\"line\">./configure</div><div class=\"line\">make</div><div class=\"line\">sudo make install    <span class=\"comment\"># 默认会安装到/usr/local/apache2/</span></div><div class=\"line\"><span class=\"built_in\">cd</span> ~</div><div class=\"line\"><span class=\"comment\">#添加防火墙规则，让防火墙允许 apache的端口 80通过</span></div><div class=\"line\">sudo vim /etc/sysconfig/iptables</div><div class=\"line\"><span class=\"comment\">#添加如下一行（实际上是拷贝了原来的一行，仅仅改变了端口号），位置必须#要放在 含有 \"REJECT --reject-with\" 的行的前面</span></div><div class=\"line\">-A INPUT -m state --state NEW -m tcp -p tcp --dport 80 -j ACCEPT</div><div class=\"line\">sudo service iptables restart</div><div class=\"line\"><span class=\"comment\">#测试</span></div><div class=\"line\">sudo /usr/<span class=\"built_in\">local</span>/apache2/bin/apachectl start</div><div class=\"line\"><span class=\"comment\">#在浏览器输入 http://ip地址 ，如果看到“It works”，说明安装成功</span></div><div class=\"line\">/usr/<span class=\"built_in\">local</span>/apache2/bin/apachectl stop</div><div class=\"line\"></div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\">#设置为开机启动</span></div><div class=\"line\"><span class=\"comment\">#将httpd注册为服务，通过chkconfig实现开机启动</span></div><div class=\"line\"><span class=\"comment\">#以apachectl 为模板</span></div><div class=\"line\">sudo cp /usr/<span class=\"built_in\">local</span>/apache2/bin/apachectl /etc/init.d/httpd</div><div class=\"line\">sudo vim /etc/init.d/httpd</div><div class=\"line\"><span class=\"comment\"># 在第一行 #!/bin/sh，添加如下一行，使其支持chkconfig命令</span></div><div class=\"line\"><span class=\"comment\"># chkconfig: 2345 85 15</span></div><div class=\"line\"><span class=\"comment\"># 保存，退出VIM编辑器</span></div><div class=\"line\">sudo chmod u+x /etc/init.d/httpd</div><div class=\"line\">sudo chkconfig --add httpd</div><div class=\"line\">sudo chkconfig httpd on</div><div class=\"line\"><span class=\"comment\">#检查一下，是否添加成功</span></div><div class=\"line\">chkconfig --list httpd</div></pre></td></tr></table></figure>\n<p>###方法二</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div></pre></td><td class=\"code\"><pre><div class=\"line\">sudo yum install httpd</div><div class=\"line\"><span class=\"comment\">#可选？sudo yum install httpd-devel</span></div><div class=\"line\"><span class=\"comment\">#测试</span></div><div class=\"line\"><span class=\"comment\">#启动 apache http server</span></div><div class=\"line\">sudo service httpd start</div><div class=\"line\"><span class=\"comment\">#添加规则，让防火墙允许 apache的端口 80</span></div><div class=\"line\">sudo vim /etc/sysconfig/iptables</div><div class=\"line\"><span class=\"comment\">#添加如下一行，位置必须要放在 含有 \"REJECT --reject-with\" 的行的前面</span></div><div class=\"line\">-A INPUT -m state --state NEW -m tcp -p tcp --dport 80 -j ACCEPT</div><div class=\"line\">sudo service iptables restart</div><div class=\"line\"><span class=\"comment\">#可以在浏览器输入 http://ip地址 测试了</span></div><div class=\"line\"><span class=\"comment\">#设置为开机启动</span></div><div class=\"line\">sudo chkconfig httpd on</div></pre></td></tr></table></figure>\n<p>##安装 mysql</p>\n<p>###方法一</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">#去官网下载 Oracle &amp; Red Hat 6的安装包，64位为MySQL-5.5.23-1.el6.x86_64.tar，</span></div><div class=\"line\"><span class=\"comment\">#32位为 MySQL-5.5.23-1.el6.i686.tar</span></div><div class=\"line\">tar -xf MySQL-5.5.23-1.el6.x86_64.tar</div><div class=\"line\"><span class=\"comment\">#加 --force 是因为可能会与mysqllib库冲突</span></div><div class=\"line\">sudo rpm -ivh --force  MySQL-server-5.5.23-1.el6.x86_64.rpm</div><div class=\"line\">sudo rpm -ivh MySQL-client-5.5.23-1.el6.x86_64.rpm</div><div class=\"line\"><span class=\"comment\"># 启动 mysql 服务器</span></div><div class=\"line\">sudo service mysql start</div><div class=\"line\"><span class=\"comment\">#设置为开机启动</span></div><div class=\"line\">sudo chkconfig mysql on</div></pre></td></tr></table></figure>\n<p>###方法二</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div></pre></td><td class=\"code\"><pre><div class=\"line\">sudo yum install mysql-server</div><div class=\"line\">sudo chgrp -R mysql /var/lib/mysql</div><div class=\"line\">sudo chmod -R 770 /var/lib/mysql</div><div class=\"line\"><span class=\"comment\"># 启动 mysql 服务器</span></div><div class=\"line\">sudo service mysqld start</div><div class=\"line\"><span class=\"comment\">#设置为开机启动</span></div><div class=\"line\">sudo chkconfig mysqld on</div></pre></td></tr></table></figure>\n<p>###公共的操作</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># root 初始密码为空，修改root密码</span></div><div class=\"line\">mysql -u root</div><div class=\"line\">mysql&gt; use mysql;</div><div class=\"line\">mysql&gt; update user <span class=\"built_in\">set</span> password=password(<span class=\"string\">'root123'</span>) <span class=\"built_in\">where</span> user=<span class=\"string\">'root'</span> AND host=<span class=\"string\">'localhost'</span>;</div><div class=\"line\">mysql&gt; flush privileges;</div><div class=\"line\"><span class=\"comment\"># 打开MySQL中root账户的远程登录，参考：如何打开MySQL中root账户的远程登录mysql&gt; GRANT ALL PRIVILEGES ON *.* TO root@\"%\" IDENTIFIED BY \"root\";</span></div><div class=\"line\">mysql&gt; update user <span class=\"built_in\">set</span> password=password(<span class=\"string\">'root123'</span>) <span class=\"built_in\">where</span> user=<span class=\"string\">'root'</span> AND host=<span class=\"string\">'%'</span>;</div><div class=\"line\">mysql&gt; flush privileges;</div><div class=\"line\">mysql&gt; quit;</div><div class=\"line\"><span class=\"comment\">#添加防火墙规则，让防火墙允许 mysql 的端口 3306通过</span></div><div class=\"line\">sudo vim /etc/sysconfig/iptables</div><div class=\"line\"><span class=\"comment\">#添加如下一行（实际上是拷贝了原来的一行，仅仅改变了端口号），位置必须#要放在 含有 \"REJECT --reject-with\" 的行的前面</span></div><div class=\"line\">-A INPUT -m state --state NEW -m tcp -p tcp --dport 3306 -j ACCEPT</div><div class=\"line\">sudo service iptables restart</div></pre></td></tr></table></figure>\n<p>##安装 php5</p>\n<p>###方法一<br>TODO</p>\n<p>###方法二</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div></pre></td><td class=\"code\"><pre><div class=\"line\">sudo yum install php php-pear</div><div class=\"line\"><span class=\"comment\">#重启 apache，以确保apache 加载PHP模块</span></div><div class=\"line\">sudo service httpd restart</div><div class=\"line\"><span class=\"comment\"># 在 /var/www/html/下新建一个index.php文件，用于测试</span></div><div class=\"line\"><span class=\"built_in\">cd</span> /var/www/html</div><div class=\"line\">sudo vim index.php</div><div class=\"line\"><span class=\"comment\"># 添加如下一行</span></div><div class=\"line\">&lt;?php phpinfo(); ?&gt;</div><div class=\"line\"><span class=\"comment\"># 在浏览器输入 http://xxx.xxx.xxx.xxx/index.php ，测试PHP是否成功安装</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\"># 如果需要在PHP中支持mysql，则需要安装 php-mysql 模块</span></div><div class=\"line\">sudo yum install php-mysql</div><div class=\"line\"><span class=\"comment\"># 如果需要在PHP中支持memcached，则需要安装 php-pecl-memcache 模块</span></div><div class=\"line\">sudo yum install php-pecl-memcache</div><div class=\"line\"><span class=\"comment\">#安装一些常用的PHP扩展模块</span></div><div class=\"line\">sudo yum install php-devel php-gd php-mbstring php-xml</div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\">#可以安装一个wordpress进行测试，注意要修改文件夹权限</span></div><div class=\"line\">sudo chown -R apache.apache /var/www/html</div></pre></td></tr></table></figure>\n<h2 id=\"安装-memcached\"><a href=\"#安装-memcached\" class=\"headerlink\" title=\"安装 memcached\"></a>安装 memcached</h2><p>###方法一</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div><div class=\"line\">51</div><div class=\"line\">52</div><div class=\"line\">53</div><div class=\"line\">54</div><div class=\"line\">55</div><div class=\"line\">56</div><div class=\"line\">57</div><div class=\"line\">58</div><div class=\"line\">59</div><div class=\"line\">60</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># memcached依赖libevent，首先要安装 libevent</span></div><div class=\"line\"><span class=\"comment\"># 去 http://libevent.org/ 下载libevent源码，然后编译，安装</span></div><div class=\"line\">tar -zxf libevent-2.0.18-stable.tar.gz</div><div class=\"line\"><span class=\"built_in\">cd</span> libevent-2.0.18-stable</div><div class=\"line\">./configure</div><div class=\"line\">make</div><div class=\"line\">sudo make install</div><div class=\"line\"><span class=\"comment\"># 对于64位操作系统(32位不需要)，还需要配置：</span></div><div class=\"line\">sudo ln <span class=\"_\">-s</span> /usr/<span class=\"built_in\">local</span>/lib/libevent-2.0.so.5 /usr/lib64//libevent-2.0.so.5</div><div class=\"line\"><span class=\"comment\"># 去 http://www.memcached.org/ 下载 memcached，然后编译，安装</span></div><div class=\"line\">tar -zxf memcached-1.4.13.tar.gz</div><div class=\"line\"><span class=\"built_in\">cd</span> memcached-1.4.13</div><div class=\"line\">./configure</div><div class=\"line\">make</div><div class=\"line\">sudo make install</div><div class=\"line\"><span class=\"comment\"># 启动, -p，端口,-m，内存, -u</span></div><div class=\"line\">memcached -p 11211 -m 512m -u root <span class=\"_\">-d</span></div><div class=\"line\"><span class=\"comment\"># 开机启动</span></div><div class=\"line\"><span class=\"comment\"># centos设置开机启动有两种方式，一是把启动程序的命令添加到/etc/rc.d/rc.local文件中，二是把写好的启动脚本添加到目录/etc/rc.d/init.d/，然后使用命令chkconfig设置开机启动。第二种方式可以用 service xxx start|stop来启动或停止，所以推荐第二种。</span></div><div class=\"line\"><span class=\"comment\">#将 memcached启动命令注册为一个服务</span></div><div class=\"line\"><span class=\"built_in\">cd</span> /etc/init.d/</div><div class=\"line\">sudo vim memcached</div><div class=\"line\"><span class=\"comment\">#代码如下，参考：Linux中将memcached注册成服务并可以随机器启动时启动服务</span></div><div class=\"line\"><span class=\"comment\">#chkconfig: 345 60 60</span></div><div class=\"line\"><span class=\"meta\">#!/bin/bash</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"function\"><span class=\"title\">start</span></span>()</div><div class=\"line\">&#123;</div><div class=\"line\">        <span class=\"built_in\">echo</span> -n $<span class=\"string\">\"Starting memcached: \"</span></div><div class=\"line\">        /usr/<span class=\"built_in\">local</span>/bin/memcached -p 11211 -m 512m -u root <span class=\"_\">-d</span></div><div class=\"line\">        <span class=\"built_in\">echo</span> <span class=\"string\">\"[OK]\"</span></div><div class=\"line\">&#125;</div><div class=\"line\"><span class=\"function\"><span class=\"title\">stop</span></span>()</div><div class=\"line\">&#123;</div><div class=\"line\">        <span class=\"built_in\">echo</span> -n $<span class=\"string\">\"Shutting down memcached: \"</span></div><div class=\"line\">        memcached_pid_list=`pidof memcached` </div><div class=\"line\">        <span class=\"built_in\">kill</span> -9 <span class=\"variable\">$memcached_pid_list</span></div><div class=\"line\">        <span class=\"built_in\">echo</span> <span class=\"string\">\"[OK]\"</span></div><div class=\"line\">&#125;</div><div class=\"line\"><span class=\"keyword\">case</span> <span class=\"string\">\"<span class=\"variable\">$1</span>\"</span> <span class=\"keyword\">in</span></div><div class=\"line\">  start)</div><div class=\"line\">        start</div><div class=\"line\">        ;;</div><div class=\"line\">  stop)</div><div class=\"line\">        stop</div><div class=\"line\">        ;;</div><div class=\"line\">  restart)</div><div class=\"line\">        stop</div><div class=\"line\">        sleep 3</div><div class=\"line\">        start</div><div class=\"line\">        ;;</div><div class=\"line\">    *)</div><div class=\"line\">             <span class=\"built_in\">echo</span> $<span class=\"string\">\"Usage: <span class=\"variable\">$0</span> &#123;start|stop|restart&#125;\"</span></div><div class=\"line\">        <span class=\"built_in\">exit</span> 1</div><div class=\"line\"><span class=\"keyword\">esac</span></div><div class=\"line\"><span class=\"built_in\">exit</span> 0</div><div class=\"line\"><span class=\"comment\">#保存退出</span></div><div class=\"line\">sudo chmod u+x memcached</div><div class=\"line\">sudo chkconfig --add memcached</div><div class=\"line\">sudo chkconfig  memcached on</div></pre></td></tr></table></figure>\n<p>###方法二<br>TODO</p>\n<p>##安装 tomcat6</p>\n<p>###方法一</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div><div class=\"line\">51</div><div class=\"line\">52</div><div class=\"line\">53</div><div class=\"line\">54</div><div class=\"line\">55</div><div class=\"line\">56</div><div class=\"line\">57</div><div class=\"line\">58</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># 去 http://tomcat.apache.org 下载 apache-tomcat-6.0.35.tar.gz</span></div><div class=\"line\">tar -zxf apache-tomcat-6.0.35.tar.gz</div><div class=\"line\">sudo mv apache-tomcat-6.0.35 /usr/<span class=\"built_in\">local</span>/</div><div class=\"line\"><span class=\"built_in\">cd</span> /usr/<span class=\"built_in\">local</span>/apache-tomcat-6.0.35/bin</div><div class=\"line\"><span class=\"comment\">#【可选】添加环境变量</span></div><div class=\"line\">sudo vim /etc/profile</div><div class=\"line\"><span class=\"built_in\">export</span> CATALINA_HOME=/usr/<span class=\"built_in\">local</span>/apache-tomcat-6.0.35</div><div class=\"line\"><span class=\"comment\">#启动 tomcat </span></div><div class=\"line\">sudo ./startup.sh</div><div class=\"line\"><span class=\"comment\"># 在浏览器输入 http://xxx.xxx.xxx.xxx:8080/ ，如果能看见tomcat页面，则表示安装成功了</span></div><div class=\"line\"><span class=\"comment\">#设置开机启动</span></div><div class=\"line\"><span class=\"comment\">#将 tomcat启动命令注册为一个服务</span></div><div class=\"line\"><span class=\"built_in\">cd</span> /etc/init.d/</div><div class=\"line\">sudo vim tomcatd</div><div class=\"line\"><span class=\"comment\">#代码如下</span></div><div class=\"line\"><span class=\"comment\">#chkconfig: 345 60 60</span></div><div class=\"line\"><span class=\"meta\">#!/bin/bash</span></div><div class=\"line\">CATALINA_HOME=/usr/<span class=\"built_in\">local</span>/apache-tomcat-6.0.35</div><div class=\"line\"></div><div class=\"line\"><span class=\"function\"><span class=\"title\">start</span></span>()</div><div class=\"line\">&#123;</div><div class=\"line\">        <span class=\"built_in\">echo</span> -n $<span class=\"string\">\"Starting Tomcat: \"</span></div><div class=\"line\">        <span class=\"variable\">$CATALINA_HOME</span>/bin/startup.sh</div><div class=\"line\">        <span class=\"built_in\">echo</span> <span class=\"string\">\"[OK]\"</span></div><div class=\"line\">&#125;</div><div class=\"line\"><span class=\"function\"><span class=\"title\">stop</span></span>()</div><div class=\"line\">&#123;</div><div class=\"line\">        <span class=\"built_in\">echo</span> -n $<span class=\"string\">\"Shutting down Tomcat: \"</span></div><div class=\"line\">        <span class=\"variable\">$CATALINA_HOME</span>/bin/shutdown.sh</div><div class=\"line\">        <span class=\"built_in\">echo</span> <span class=\"string\">\"[OK]\"</span></div><div class=\"line\">&#125;</div><div class=\"line\"><span class=\"keyword\">case</span> <span class=\"string\">\"<span class=\"variable\">$1</span>\"</span> <span class=\"keyword\">in</span></div><div class=\"line\">  start)</div><div class=\"line\">        start</div><div class=\"line\">        ;;</div><div class=\"line\">  stop)</div><div class=\"line\">        stop</div><div class=\"line\">        ;;</div><div class=\"line\">  restart)</div><div class=\"line\">        stop</div><div class=\"line\">        sleep 3</div><div class=\"line\">        start</div><div class=\"line\">        ;;</div><div class=\"line\">    *)</div><div class=\"line\">             <span class=\"built_in\">echo</span> $<span class=\"string\">\"Usage: <span class=\"variable\">$0</span> &#123;start|stop|restart&#125;\"</span></div><div class=\"line\">        <span class=\"built_in\">exit</span> 1</div><div class=\"line\"><span class=\"keyword\">esac</span></div><div class=\"line\"><span class=\"built_in\">exit</span> 0</div><div class=\"line\"><span class=\"comment\">#保存退出</span></div><div class=\"line\">sudo chmod u+x tomcatd</div><div class=\"line\">sudo chkconfig --add tomcatd</div><div class=\"line\">sudo chkconfig tomcatd on</div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\">#添加防火墙规则，让防火墙允许 tomcat 的端口 8080 通过</span></div><div class=\"line\">sudo vim /etc/sysconfig/iptables</div><div class=\"line\"><span class=\"comment\">#添加如下一行（实际上是拷贝了原来的一行，仅仅改变了端口号），位置必须#要放在 含有 \"REJECT --reject-with\" 的行的前面</span></div><div class=\"line\">-A INPUT -m state --state NEW -m tcp -p tcp --dport 8080 -j ACCEPT</div><div class=\"line\">sudo service iptables restart</div></pre></td></tr></table></figure>\n<p>###方法二</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">#搜索一下 tomcat包的名字</span></div><div class=\"line\">yum search tomcat</div><div class=\"line\">sudo yum search tomcat6.noarch</div></pre></td></tr></table></figure>\n<p>##安装Python</p>\n<p>###方法一：去<a href=\"http://www.python.org\" target=\"_blank\" rel=\"external\">官网</a>下载源码，编译，安装</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">#开始解压，编译，安装</span></div><div class=\"line\">tar -jxf Python-3.2.3.tar.bz2</div><div class=\"line\"><span class=\"built_in\">cd</span> Python-3.2.3</div><div class=\"line\"><span class=\"comment\"># 查看一下说明, vim README</span></div><div class=\"line\">sudo yum install zlib-devel bzip2-devel openssl-devel ncurses-devel sqlite-devel readline-devel tk-devel</div><div class=\"line\">./configure</div><div class=\"line\">make</div><div class=\"line\"><span class=\"comment\">#为了加快安装速度，这步可以省略</span></div><div class=\"line\">make <span class=\"built_in\">test</span></div><div class=\"line\"><span class=\"comment\">#卸载旧的python，注意，不能用 yum remove python，这会卸载几百个包，最终损坏系统</span></div><div class=\"line\">sudo rpm -evf --nodeps python</div><div class=\"line\">sudo make install</div><div class=\"line\"><span class=\"comment\">#默认安装在 /usr/local/bin/python3</span></div></pre></td></tr></table></figure>\n<p>###方法二</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">sudo yum install python</div></pre></td></tr></table></figure>\n<p>##安装ruby</p>\n<p>###方法一</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># http://www.ruby-lang.org/en/downloads/ ，选择 \"Stable Snapshot\"</span></div><div class=\"line\">tar -zxf ruby-1.9-stable.tar.gz</div><div class=\"line\"><span class=\"built_in\">cd</span>  <span class=\"built_in\">cd</span> ruby-1.9.3-p194/</div><div class=\"line\">./configure</div><div class=\"line\">make</div><div class=\"line\">sudo make install</div></pre></td></tr></table></figure>\n<p>###方法二</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">sudo yum install ruby</div></pre></td></tr></table></figure>\n<p>##安装go</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">#去官网 http://code.google.com/p/go/downloads 下载，go1.0.1.linux-i386.tar.gz (32位)，go1.0.1.linux-amd64.tar.gz（64位）</span></div><div class=\"line\">tar -zxf go1.0.1.linux-amd64.tar.gz</div><div class=\"line\">sudo mv go/ /usr/<span class=\"built_in\">local</span>/</div><div class=\"line\"><span class=\"comment\">#设置环境变量</span></div><div class=\"line\">sudo vim /etc/profile</div><div class=\"line\"><span class=\"built_in\">export</span> GOROOT=/usr/<span class=\"built_in\">local</span>/go</div><div class=\"line\"><span class=\"built_in\">export</span> PATH=<span class=\"variable\">$PATH</span>:<span class=\"variable\">$GOROOT</span>/bin</div><div class=\"line\"><span class=\"built_in\">source</span> /etc/profile</div><div class=\"line\"><span class=\"comment\">#测试一下</span></div><div class=\"line\">go version</div></pre></td></tr></table></figure>\n<p>##安装lua</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># 去官网下载源码，编译，安装。由于官网仅提供源码，故推荐源码编译安装方式。</span></div><div class=\"line\"><span class=\"comment\"># 去官网 http://www.lua.org/ 下载源码，lua-5.2.0.tar.gz</span></div><div class=\"line\">tar -zxf lua-5.2.0.tar.gz </div><div class=\"line\"><span class=\"built_in\">cd</span> lua-5.2.0</div><div class=\"line\"><span class=\"comment\"># lua 依赖 readline.h 头文件</span></div><div class=\"line\">sudo yum install  readline-devel</div><div class=\"line\">make linux</div><div class=\"line\">sudo make install</div><div class=\"line\"><span class=\"comment\">#安装 google protobuf</span></div><div class=\"line\"><span class=\"comment\">#去官网 http://code.google.com/p/protobuf/下载</span></div><div class=\"line\">tar -jxf protobuf-2.4.1.tar.bz2</div><div class=\"line\"><span class=\"built_in\">cd</span> protobuf-2.4.1</div><div class=\"line\">./configure</div><div class=\"line\">make</div><div class=\"line\">sudo make install</div><div class=\"line\"><span class=\"comment\">#测试</span></div><div class=\"line\">protoc</div></pre></td></tr></table></figure>\n<p>##清理安装包</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"built_in\">cd</span> ~</div><div class=\"line\">rm * -rf</div></pre></td></tr></table></figure>\n<p>##压缩打包<br>安装完后，可以Clone，压缩打包成一个zip文件，方便分享给别人。</p>\n<p>在关机之前，有一件事需要做，</p>\n<pre><code>sudo vim /etc/sysconfig/network-scripts/ifcfg-eth0, 把HWADDR=.... 这行删掉\nsudo rm /etc/udev/rules.d/70-persistent-net.rules\nsudo shutdown -h now\n</code></pre><p>如果没有执行上述命令，克隆后的虚拟机，开机后无法上网，重启网络，<code>sudo service network restart</code>也没有效果，会出现错误“Device eth0 does not seem to be present, delaying initialization.” </p>\n<p>这是因为克隆后的虚拟机，它的MAC地址变了，即在它的.vmx文件里，MAC地址变了（<code>ethernet0.generatedAddress</code>这项），但是linux不知道这个变化，网络配置文件还是旧的，这样跟它的而真实mac不匹配，网络就无法启动。</p>\n<p>执行上述命令，删除了<code>70-persistent-net.rules</code>后，相当于删除了旧的配置文件，在开机时会生成新的配置文件。</p>\n<p>关机后，右击标签，选择”Manage-&gt;Clone”，选择”Create a full clone”，克隆完成后，关闭这台虚拟机的标签（否则文件夹里有一些临时垃圾文件），然后把文件夹压缩打包。以后就可以把这个zip包拷贝给周围的人，别人就不用经历一遍重装的过程了。</p>\n","excerpt":"<p>这是我安装Ubuntu服务器的过程，分享给大家。CentOS服务器请参考我另一篇博客，<a href=\"http://www.yanjiuyanjiu.com/blog/20120423/\">安装和配置CentOS服务器的详细步骤</a>。</p>\n<p>##安装操作系统</p>\n<p>所使用的ISO文件是 ubuntu-13.04-server-amd64.iso</p>\n<p>首先在虚拟机或物理机上安装操作系统，用户名为manong，密码 manong123</p>\n<p>##设置上网<br>安装完操作系统后，还不能上网，配置DHCP方式上网：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div></pre></td><td class=\"code\"><pre><div class=\"line\">vim /etc/sysconfig/network-scripts/ifcfg-eth0</div><div class=\"line\">DEVICE=<span class=\"string\">\"eth0\"</span></div><div class=\"line\">HWADDR=<span class=\"string\">\"00:0C:29:BD:E1:19\"</span></div><div class=\"line\">NM_CONTROLLED=<span class=\"string\">\"yes\"</span></div><div class=\"line\">ONBOOT=<span class=\"string\">\"yes\"</span></div><div class=\"line\">BOOTPROTO=dhcp</div><div class=\"line\">USECTL=no</div><div class=\"line\">TYPE=Ethernet</div><div class=\"line\">PEERDNS=yes</div><div class=\"line\"><span class=\"comment\">#保存退出</span></div><div class=\"line\">sudo service network restart</div></pre></td></tr></table></figure>","more":"<p>或者，配置静态IP</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div></pre></td><td class=\"code\"><pre><div class=\"line\">DEVICE=<span class=\"string\">\"eth0\"</span></div><div class=\"line\">HWADDR=<span class=\"string\">\"00:0C:29:10:F4:4C\"</span></div><div class=\"line\">ONBOOT=<span class=\"string\">\"yes\"</span></div><div class=\"line\">BOOTPROTO=static</div><div class=\"line\">TYPE=Ethernet</div><div class=\"line\">IPADDR=192.168.0.162</div><div class=\"line\">NETMASK=255.255.255.0</div><div class=\"line\">BROADCAST=192.168.0.255</div><div class=\"line\">NETWORK=192.168.0.0</div><div class=\"line\"><span class=\"comment\">#保存退出  </span></div><div class=\"line\"><span class=\"comment\">#修改/etc/sysconfig/network</span></div><div class=\"line\">sudo vim /etc/sysconfig/network</div><div class=\"line\">NETWORKING=yes</div><div class=\"line\">HOSTNAME=localhost.localdomain</div><div class=\"line\">GATEWAY=192.168.0.1</div><div class=\"line\"><span class=\"comment\">#保存退出，重启网络</span></div><div class=\"line\">sudo service network restart</div></pre></td></tr></table></figure>\n<p>如果失败，比如IP已被占用，换一个IP试试</p>\n<p>修改DNS，即时生效</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\">sudo vim /etc/resolv.conf</div><div class=\"line\">nameserver 192.168.0.1</div><div class=\"line\"><span class=\"comment\"># google提供的域名服务器</span></div><div class=\"line\">nameserver 8.8.8.8</div><div class=\"line\">search localhost</div></pre></td></tr></table></figure>\n<p>##安装常用软件<br>有两种方式，方法一，去官网下载已经编译好的二进制文件，或源代码，编译安装<br>方法二，用yum 命令安装，安装官方yum源里已经编译好的程序包。<br>第一种方式要敲很多命令，比yum麻烦，但是可以预先下载好文件，省略了下载的时间，整体速度比yum安装方式快很多，而且可以安装最新版。推荐第一种方式</p>\n<p>第二种方式操作简单，敲打的命令少，但是往往yum源的更新速度跟不上各个软件的官网速度，用Yum安装的版本经常比较旧。</p>\n<p>yum的命令形式一般是如下：<code>yum [options] [command] [package ...]</code>，其中的[options]是可选的，选项包括-h（帮助），-y（当安装过程提示选择全部为”yes”），-q（不显示安装的过程）等等。[command]为所要进行的操作，[package …]是操作的对象。</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">#yum search package-name # 在线搜索包 </span></div><div class=\"line\"><span class=\"comment\">#yum list installed # 列出所有已经安装的包</span></div><div class=\"line\"><span class=\"comment\">#</span></div><div class=\"line\"><span class=\"comment\">#sudo yum install package-name # 安装程序包 </span></div><div class=\"line\"><span class=\"comment\">#sudo yum groupinsall group-name 安装程序组</span></div><div class=\"line\"><span class=\"comment\">#</span></div><div class=\"line\"><span class=\"comment\">#sudo yum remove package-name 删除程序包</span></div><div class=\"line\"><span class=\"comment\">#sudo yum groupremove group-name 删除程序组</span></div><div class=\"line\"><span class=\"comment\">#</span></div><div class=\"line\"><span class=\"comment\">#yum update #全部更新</span></div><div class=\"line\"><span class=\"comment\">#yum update package-name #更新程序包</span></div><div class=\"line\"><span class=\"comment\">#sudo yum groupupdate groupn-name 升级程序组</span></div><div class=\"line\"><span class=\"comment\">#sudo yum upgrade # 更新源列表</span></div><div class=\"line\"><span class=\"comment\">#yum upgrade package-name #升级程序包</span></div><div class=\"line\"><span class=\"comment\">#sudo yum clean all # 清除缓存</span></div><div class=\"line\"><span class=\"comment\">#更新</span></div><div class=\"line\">sudo yum update</div><div class=\"line\"><span class=\"comment\">#清理缓存</span></div><div class=\"line\">sudo yum clean all &amp;&amp; yum clean metadata &amp;&amp; yum clean dbcache</div></pre></td></tr></table></figure>\n<p>##安装编译工具</p>\n<p>###方法一<br>去 <a href=\"http://gcc.gnu.org/\">http://gcc.gnu.org/</a> 下载源码</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># TODO</span></div></pre></td></tr></table></figure>\n<p>###方法二</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">sudo yum groupinstall <span class=\"string\">\"Development Tools\"</span></div></pre></td></tr></table></figure>\n<p>该命令类似于 Ubuntu 下的<code>apt-get install build-essential</code>，会自动安装一下软件包：autoconf automake bison byacc cscope ctags diffstat doxygen flex gcc gcc-c++ gcc-gfortran git indent intltool libtool patchutils rcs redhat-rpm-config rpm-build subversion swig systemtap，同时安装了以下依赖包：apr, apr-util, 等等。</p>\n<p>##安装JDK</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">#删除旧的JDK</span></div><div class=\"line\">yum list installed | grep jdk</div><div class=\"line\"><span class=\"comment\">#复制显示出来的JDK，卸载</span></div><div class=\"line\">sudo yum remove java-1.6.0-openjdk.x86_64</div><div class=\"line\"><span class=\"comment\">#安装新的jdk</span></div></pre></td></tr></table></figure>\n<p>###方法一</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">#从官网下载最新版的，当前是jdk6u32</span></div><div class=\"line\"><span class=\"comment\">#开始安装</span></div><div class=\"line\">chmod u+x chmod u+x jdk-6u32-linux-x64-rpm.bin</div><div class=\"line\">sudo ./jdk-6u32-linux-x64-rpm.bin</div><div class=\"line\"><span class=\"comment\">#设置环境变量，.bash_profile是当前用户，/etc/profile是所有用户的</span></div><div class=\"line\">sudo vim /etc/profile</div><div class=\"line\"><span class=\"comment\">#在末尾添加</span></div><div class=\"line\"><span class=\"built_in\">export</span> JAVA_HOME=/usr/java/default</div><div class=\"line\"><span class=\"built_in\">export</span> JRE_HOME=<span class=\"variable\">$JAVA_HOME</span>/jre</div><div class=\"line\"><span class=\"built_in\">export</span> PATH=<span class=\"variable\">$PATH</span>:<span class=\"variable\">$JAVA_HOME</span>/bin</div><div class=\"line\"><span class=\"built_in\">export</span> CLASSPATH=.:<span class=\"variable\">$JAVA_HOME</span>/lib/dt.jar:<span class=\"variable\">$JAVA_HOME</span>/lib/tools.jar</div><div class=\"line\"><span class=\"comment\"># 保存退出，输入以下命令使之立即生效：</span></div><div class=\"line\"><span class=\"built_in\">source</span> /etc/profile</div><div class=\"line\"><span class=\"comment\"># 测试</span></div><div class=\"line\">java -version</div></pre></td></tr></table></figure>\n<p>###方法二</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div></pre></td><td class=\"code\"><pre><div class=\"line\">yum search jdk</div><div class=\"line\"><span class=\"comment\"># java-1.6.0-openjdk只包含了JRE，如果在这台机器上开发java程序，则需要安装JDK，</span></div><div class=\"line\"><span class=\"comment\"># 要选择 java-1.6.0-openjdk-devel，在服务器上我们只需要运行java程序，因此选择前者</span></div><div class=\"line\">sudo yum install java-1.6.0-openjdk-devel</div><div class=\"line\"><span class=\"comment\"># 使用 alternatives 工具设置默认JDK，参考：Installing a Java Development Kit on Red Hat Enterprise Linux</span></div><div class=\"line\">/usr/sbin/alternatives --config java</div><div class=\"line\">/usr/sbin/alternatives --config javac</div><div class=\"line\"><span class=\"comment\"># 设置环境变量</span></div><div class=\"line\"><span class=\"comment\"># 查询JDK路径</span></div><div class=\"line\">whereis java</div><div class=\"line\">ll /usr/bin/java</div><div class=\"line\">ll /etc/alternatives/java <span class=\"comment\">#这是可以看到JDK路径了</span></div><div class=\"line\">sudo vim /etc/profile</div><div class=\"line\"><span class=\"comment\"># 在末尾添加</span></div><div class=\"line\"><span class=\"built_in\">export</span> JAVA_HOME=/usr/lib/jvm/jre-1.6.0-openjdk.x86_64</div><div class=\"line\"><span class=\"built_in\">export</span> JRE_HOME=<span class=\"variable\">$JAVA_HOME</span>/jre</div><div class=\"line\"><span class=\"built_in\">export</span> PATH=<span class=\"variable\">$PATH</span>:<span class=\"variable\">$JAVA_HOME</span>/bin</div><div class=\"line\"><span class=\"built_in\">export</span> CLASSPATH=.:<span class=\"variable\">$JAVA_HOME</span>/lib/dt.jar:<span class=\"variable\">$JAVA_HOME</span>/lib/tools.jar</div><div class=\"line\"><span class=\"comment\">#保存退出，输入以下命令使之立即生效：</span></div><div class=\"line\"><span class=\"comment\"># source /etc/profile</span></div><div class=\"line\"><span class=\"comment\"># 测试</span></div><div class=\"line\">java -version</div></pre></td></tr></table></figure>\n<p>##安装 apache</p>\n<p>###方法一<br>源码在官网 <a href=\"http://httpd.apache.org/\">http://httpd.apache.org/</a> 下载。<br>先下载apt, apr-util, pcre三个库，httpd 在编译时需要用到这三个库<br>apr, apr-util官网 <a href=\"http://apr.apache.org\">http://apr.apache.org</a> , pcre官网为 <a href=\"http://pcre.org\">http://pcre.org </a></p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div><div class=\"line\">51</div><div class=\"line\">52</div><div class=\"line\">53</div><div class=\"line\">54</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># 编译，安装 apr</span></div><div class=\"line\">tar -jxf apr-1.4.6.tar.bz2</div><div class=\"line\"><span class=\"built_in\">cd</span> apr-1.4.6</div><div class=\"line\">./configure</div><div class=\"line\">make</div><div class=\"line\">sudo make install    <span class=\"comment\"># 默认会安装到 /usr/local/apr/</span></div><div class=\"line\"><span class=\"built_in\">cd</span> ~</div><div class=\"line\"><span class=\"comment\">#编译，安装 apr-util</span></div><div class=\"line\">tar -jxf apr-util-1.4.1.tar.bz2</div><div class=\"line\"><span class=\"built_in\">cd</span> apr-util-1.4.1</div><div class=\"line\">./configure --with-apr=/usr/<span class=\"built_in\">local</span>/apr/</div><div class=\"line\">make</div><div class=\"line\">sudo make install    <span class=\"comment\"># 默认会安装到 /usr/local/apr/</span></div><div class=\"line\"><span class=\"built_in\">cd</span> ~</div><div class=\"line\"><span class=\"comment\">#编译，安装 pcre</span></div><div class=\"line\">tar -jxf pcre-8.30.tar.bz2</div><div class=\"line\"><span class=\"built_in\">cd</span>  pcre-8.30</div><div class=\"line\">./configure --with-apr=/usr/<span class=\"built_in\">local</span>/apr/</div><div class=\"line\">make</div><div class=\"line\"><span class=\"comment\"># By default, `make install' installs the package's commands under</span></div><div class=\"line\"><span class=\"comment\">#`/usr/local/bin', include files under `/usr/local/include', etc. </span></div><div class=\"line\">sudo make install</div><div class=\"line\"><span class=\"built_in\">cd</span> ~</div><div class=\"line\"><span class=\"comment\">#编译，安装 apache</span></div><div class=\"line\">tar -jxf httpd-2.2.22.tar.bz2</div><div class=\"line\"><span class=\"built_in\">cd</span> httpd-2.2.22</div><div class=\"line\">./configure</div><div class=\"line\">make</div><div class=\"line\">sudo make install    <span class=\"comment\"># 默认会安装到/usr/local/apache2/</span></div><div class=\"line\"><span class=\"built_in\">cd</span> ~</div><div class=\"line\"><span class=\"comment\">#添加防火墙规则，让防火墙允许 apache的端口 80通过</span></div><div class=\"line\">sudo vim /etc/sysconfig/iptables</div><div class=\"line\"><span class=\"comment\">#添加如下一行（实际上是拷贝了原来的一行，仅仅改变了端口号），位置必须#要放在 含有 \"REJECT --reject-with\" 的行的前面</span></div><div class=\"line\">-A INPUT -m state --state NEW -m tcp -p tcp --dport 80 -j ACCEPT</div><div class=\"line\">sudo service iptables restart</div><div class=\"line\"><span class=\"comment\">#测试</span></div><div class=\"line\">sudo /usr/<span class=\"built_in\">local</span>/apache2/bin/apachectl start</div><div class=\"line\"><span class=\"comment\">#在浏览器输入 http://ip地址 ，如果看到“It works”，说明安装成功</span></div><div class=\"line\">/usr/<span class=\"built_in\">local</span>/apache2/bin/apachectl stop</div><div class=\"line\"></div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\">#设置为开机启动</span></div><div class=\"line\"><span class=\"comment\">#将httpd注册为服务，通过chkconfig实现开机启动</span></div><div class=\"line\"><span class=\"comment\">#以apachectl 为模板</span></div><div class=\"line\">sudo cp /usr/<span class=\"built_in\">local</span>/apache2/bin/apachectl /etc/init.d/httpd</div><div class=\"line\">sudo vim /etc/init.d/httpd</div><div class=\"line\"><span class=\"comment\"># 在第一行 #!/bin/sh，添加如下一行，使其支持chkconfig命令</span></div><div class=\"line\"><span class=\"comment\"># chkconfig: 2345 85 15</span></div><div class=\"line\"><span class=\"comment\"># 保存，退出VIM编辑器</span></div><div class=\"line\">sudo chmod u+x /etc/init.d/httpd</div><div class=\"line\">sudo chkconfig --add httpd</div><div class=\"line\">sudo chkconfig httpd on</div><div class=\"line\"><span class=\"comment\">#检查一下，是否添加成功</span></div><div class=\"line\">chkconfig --list httpd</div></pre></td></tr></table></figure>\n<p>###方法二</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div></pre></td><td class=\"code\"><pre><div class=\"line\">sudo yum install httpd</div><div class=\"line\"><span class=\"comment\">#可选？sudo yum install httpd-devel</span></div><div class=\"line\"><span class=\"comment\">#测试</span></div><div class=\"line\"><span class=\"comment\">#启动 apache http server</span></div><div class=\"line\">sudo service httpd start</div><div class=\"line\"><span class=\"comment\">#添加规则，让防火墙允许 apache的端口 80</span></div><div class=\"line\">sudo vim /etc/sysconfig/iptables</div><div class=\"line\"><span class=\"comment\">#添加如下一行，位置必须要放在 含有 \"REJECT --reject-with\" 的行的前面</span></div><div class=\"line\">-A INPUT -m state --state NEW -m tcp -p tcp --dport 80 -j ACCEPT</div><div class=\"line\">sudo service iptables restart</div><div class=\"line\"><span class=\"comment\">#可以在浏览器输入 http://ip地址 测试了</span></div><div class=\"line\"><span class=\"comment\">#设置为开机启动</span></div><div class=\"line\">sudo chkconfig httpd on</div></pre></td></tr></table></figure>\n<p>##安装 mysql</p>\n<p>###方法一</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">#去官网下载 Oracle &amp; Red Hat 6的安装包，64位为MySQL-5.5.23-1.el6.x86_64.tar，</span></div><div class=\"line\"><span class=\"comment\">#32位为 MySQL-5.5.23-1.el6.i686.tar</span></div><div class=\"line\">tar -xf MySQL-5.5.23-1.el6.x86_64.tar</div><div class=\"line\"><span class=\"comment\">#加 --force 是因为可能会与mysqllib库冲突</span></div><div class=\"line\">sudo rpm -ivh --force  MySQL-server-5.5.23-1.el6.x86_64.rpm</div><div class=\"line\">sudo rpm -ivh MySQL-client-5.5.23-1.el6.x86_64.rpm</div><div class=\"line\"><span class=\"comment\"># 启动 mysql 服务器</span></div><div class=\"line\">sudo service mysql start</div><div class=\"line\"><span class=\"comment\">#设置为开机启动</span></div><div class=\"line\">sudo chkconfig mysql on</div></pre></td></tr></table></figure>\n<p>###方法二</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div></pre></td><td class=\"code\"><pre><div class=\"line\">sudo yum install mysql-server</div><div class=\"line\">sudo chgrp -R mysql /var/lib/mysql</div><div class=\"line\">sudo chmod -R 770 /var/lib/mysql</div><div class=\"line\"><span class=\"comment\"># 启动 mysql 服务器</span></div><div class=\"line\">sudo service mysqld start</div><div class=\"line\"><span class=\"comment\">#设置为开机启动</span></div><div class=\"line\">sudo chkconfig mysqld on</div></pre></td></tr></table></figure>\n<p>###公共的操作</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># root 初始密码为空，修改root密码</span></div><div class=\"line\">mysql -u root</div><div class=\"line\">mysql&gt; use mysql;</div><div class=\"line\">mysql&gt; update user <span class=\"built_in\">set</span> password=password(<span class=\"string\">'root123'</span>) <span class=\"built_in\">where</span> user=<span class=\"string\">'root'</span> AND host=<span class=\"string\">'localhost'</span>;</div><div class=\"line\">mysql&gt; flush privileges;</div><div class=\"line\"><span class=\"comment\"># 打开MySQL中root账户的远程登录，参考：如何打开MySQL中root账户的远程登录mysql&gt; GRANT ALL PRIVILEGES ON *.* TO root@\"%\" IDENTIFIED BY \"root\";</span></div><div class=\"line\">mysql&gt; update user <span class=\"built_in\">set</span> password=password(<span class=\"string\">'root123'</span>) <span class=\"built_in\">where</span> user=<span class=\"string\">'root'</span> AND host=<span class=\"string\">'%'</span>;</div><div class=\"line\">mysql&gt; flush privileges;</div><div class=\"line\">mysql&gt; quit;</div><div class=\"line\"><span class=\"comment\">#添加防火墙规则，让防火墙允许 mysql 的端口 3306通过</span></div><div class=\"line\">sudo vim /etc/sysconfig/iptables</div><div class=\"line\"><span class=\"comment\">#添加如下一行（实际上是拷贝了原来的一行，仅仅改变了端口号），位置必须#要放在 含有 \"REJECT --reject-with\" 的行的前面</span></div><div class=\"line\">-A INPUT -m state --state NEW -m tcp -p tcp --dport 3306 -j ACCEPT</div><div class=\"line\">sudo service iptables restart</div></pre></td></tr></table></figure>\n<p>##安装 php5</p>\n<p>###方法一<br>TODO</p>\n<p>###方法二</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div></pre></td><td class=\"code\"><pre><div class=\"line\">sudo yum install php php-pear</div><div class=\"line\"><span class=\"comment\">#重启 apache，以确保apache 加载PHP模块</span></div><div class=\"line\">sudo service httpd restart</div><div class=\"line\"><span class=\"comment\"># 在 /var/www/html/下新建一个index.php文件，用于测试</span></div><div class=\"line\"><span class=\"built_in\">cd</span> /var/www/html</div><div class=\"line\">sudo vim index.php</div><div class=\"line\"><span class=\"comment\"># 添加如下一行</span></div><div class=\"line\">&lt;?php phpinfo(); ?&gt;</div><div class=\"line\"><span class=\"comment\"># 在浏览器输入 http://xxx.xxx.xxx.xxx/index.php ，测试PHP是否成功安装</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\"># 如果需要在PHP中支持mysql，则需要安装 php-mysql 模块</span></div><div class=\"line\">sudo yum install php-mysql</div><div class=\"line\"><span class=\"comment\"># 如果需要在PHP中支持memcached，则需要安装 php-pecl-memcache 模块</span></div><div class=\"line\">sudo yum install php-pecl-memcache</div><div class=\"line\"><span class=\"comment\">#安装一些常用的PHP扩展模块</span></div><div class=\"line\">sudo yum install php-devel php-gd php-mbstring php-xml</div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\">#可以安装一个wordpress进行测试，注意要修改文件夹权限</span></div><div class=\"line\">sudo chown -R apache.apache /var/www/html</div></pre></td></tr></table></figure>\n<h2 id=\"安装-memcached\"><a href=\"#安装-memcached\" class=\"headerlink\" title=\"安装 memcached\"></a>安装 memcached</h2><p>###方法一</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div><div class=\"line\">51</div><div class=\"line\">52</div><div class=\"line\">53</div><div class=\"line\">54</div><div class=\"line\">55</div><div class=\"line\">56</div><div class=\"line\">57</div><div class=\"line\">58</div><div class=\"line\">59</div><div class=\"line\">60</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># memcached依赖libevent，首先要安装 libevent</span></div><div class=\"line\"><span class=\"comment\"># 去 http://libevent.org/ 下载libevent源码，然后编译，安装</span></div><div class=\"line\">tar -zxf libevent-2.0.18-stable.tar.gz</div><div class=\"line\"><span class=\"built_in\">cd</span> libevent-2.0.18-stable</div><div class=\"line\">./configure</div><div class=\"line\">make</div><div class=\"line\">sudo make install</div><div class=\"line\"><span class=\"comment\"># 对于64位操作系统(32位不需要)，还需要配置：</span></div><div class=\"line\">sudo ln <span class=\"_\">-s</span> /usr/<span class=\"built_in\">local</span>/lib/libevent-2.0.so.5 /usr/lib64//libevent-2.0.so.5</div><div class=\"line\"><span class=\"comment\"># 去 http://www.memcached.org/ 下载 memcached，然后编译，安装</span></div><div class=\"line\">tar -zxf memcached-1.4.13.tar.gz</div><div class=\"line\"><span class=\"built_in\">cd</span> memcached-1.4.13</div><div class=\"line\">./configure</div><div class=\"line\">make</div><div class=\"line\">sudo make install</div><div class=\"line\"><span class=\"comment\"># 启动, -p，端口,-m，内存, -u</span></div><div class=\"line\">memcached -p 11211 -m 512m -u root <span class=\"_\">-d</span></div><div class=\"line\"><span class=\"comment\"># 开机启动</span></div><div class=\"line\"><span class=\"comment\"># centos设置开机启动有两种方式，一是把启动程序的命令添加到/etc/rc.d/rc.local文件中，二是把写好的启动脚本添加到目录/etc/rc.d/init.d/，然后使用命令chkconfig设置开机启动。第二种方式可以用 service xxx start|stop来启动或停止，所以推荐第二种。</span></div><div class=\"line\"><span class=\"comment\">#将 memcached启动命令注册为一个服务</span></div><div class=\"line\"><span class=\"built_in\">cd</span> /etc/init.d/</div><div class=\"line\">sudo vim memcached</div><div class=\"line\"><span class=\"comment\">#代码如下，参考：Linux中将memcached注册成服务并可以随机器启动时启动服务</span></div><div class=\"line\"><span class=\"comment\">#chkconfig: 345 60 60</span></div><div class=\"line\"><span class=\"meta\">#!/bin/bash</div><div class=\"line\"></span></div><div class=\"line\"><span class=\"function\"><span class=\"title\">start</span></span>()</div><div class=\"line\">&#123;</div><div class=\"line\">        <span class=\"built_in\">echo</span> -n $<span class=\"string\">\"Starting memcached: \"</span></div><div class=\"line\">        /usr/<span class=\"built_in\">local</span>/bin/memcached -p 11211 -m 512m -u root <span class=\"_\">-d</span></div><div class=\"line\">        <span class=\"built_in\">echo</span> <span class=\"string\">\"[OK]\"</span></div><div class=\"line\">&#125;</div><div class=\"line\"><span class=\"function\"><span class=\"title\">stop</span></span>()</div><div class=\"line\">&#123;</div><div class=\"line\">        <span class=\"built_in\">echo</span> -n $<span class=\"string\">\"Shutting down memcached: \"</span></div><div class=\"line\">        memcached_pid_list=`pidof memcached` </div><div class=\"line\">        <span class=\"built_in\">kill</span> -9 <span class=\"variable\">$memcached_pid_list</span></div><div class=\"line\">        <span class=\"built_in\">echo</span> <span class=\"string\">\"[OK]\"</span></div><div class=\"line\">&#125;</div><div class=\"line\"><span class=\"keyword\">case</span> <span class=\"string\">\"<span class=\"variable\">$1</span>\"</span> <span class=\"keyword\">in</span></div><div class=\"line\">  start)</div><div class=\"line\">        start</div><div class=\"line\">        ;;</div><div class=\"line\">  stop)</div><div class=\"line\">        stop</div><div class=\"line\">        ;;</div><div class=\"line\">  restart)</div><div class=\"line\">        stop</div><div class=\"line\">        sleep 3</div><div class=\"line\">        start</div><div class=\"line\">        ;;</div><div class=\"line\">    *)</div><div class=\"line\">             <span class=\"built_in\">echo</span> $<span class=\"string\">\"Usage: <span class=\"variable\">$0</span> &#123;start|stop|restart&#125;\"</span></div><div class=\"line\">        <span class=\"built_in\">exit</span> 1</div><div class=\"line\"><span class=\"keyword\">esac</span></div><div class=\"line\"><span class=\"built_in\">exit</span> 0</div><div class=\"line\"><span class=\"comment\">#保存退出</span></div><div class=\"line\">sudo chmod u+x memcached</div><div class=\"line\">sudo chkconfig --add memcached</div><div class=\"line\">sudo chkconfig  memcached on</div></pre></td></tr></table></figure>\n<p>###方法二<br>TODO</p>\n<p>##安装 tomcat6</p>\n<p>###方法一</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div><div class=\"line\">51</div><div class=\"line\">52</div><div class=\"line\">53</div><div class=\"line\">54</div><div class=\"line\">55</div><div class=\"line\">56</div><div class=\"line\">57</div><div class=\"line\">58</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># 去 http://tomcat.apache.org 下载 apache-tomcat-6.0.35.tar.gz</span></div><div class=\"line\">tar -zxf apache-tomcat-6.0.35.tar.gz</div><div class=\"line\">sudo mv apache-tomcat-6.0.35 /usr/<span class=\"built_in\">local</span>/</div><div class=\"line\"><span class=\"built_in\">cd</span> /usr/<span class=\"built_in\">local</span>/apache-tomcat-6.0.35/bin</div><div class=\"line\"><span class=\"comment\">#【可选】添加环境变量</span></div><div class=\"line\">sudo vim /etc/profile</div><div class=\"line\"><span class=\"built_in\">export</span> CATALINA_HOME=/usr/<span class=\"built_in\">local</span>/apache-tomcat-6.0.35</div><div class=\"line\"><span class=\"comment\">#启动 tomcat </span></div><div class=\"line\">sudo ./startup.sh</div><div class=\"line\"><span class=\"comment\"># 在浏览器输入 http://xxx.xxx.xxx.xxx:8080/ ，如果能看见tomcat页面，则表示安装成功了</span></div><div class=\"line\"><span class=\"comment\">#设置开机启动</span></div><div class=\"line\"><span class=\"comment\">#将 tomcat启动命令注册为一个服务</span></div><div class=\"line\"><span class=\"built_in\">cd</span> /etc/init.d/</div><div class=\"line\">sudo vim tomcatd</div><div class=\"line\"><span class=\"comment\">#代码如下</span></div><div class=\"line\"><span class=\"comment\">#chkconfig: 345 60 60</span></div><div class=\"line\"><span class=\"meta\">#!/bin/bash</span></div><div class=\"line\">CATALINA_HOME=/usr/<span class=\"built_in\">local</span>/apache-tomcat-6.0.35</div><div class=\"line\"></div><div class=\"line\"><span class=\"function\"><span class=\"title\">start</span></span>()</div><div class=\"line\">&#123;</div><div class=\"line\">        <span class=\"built_in\">echo</span> -n $<span class=\"string\">\"Starting Tomcat: \"</span></div><div class=\"line\">        <span class=\"variable\">$CATALINA_HOME</span>/bin/startup.sh</div><div class=\"line\">        <span class=\"built_in\">echo</span> <span class=\"string\">\"[OK]\"</span></div><div class=\"line\">&#125;</div><div class=\"line\"><span class=\"function\"><span class=\"title\">stop</span></span>()</div><div class=\"line\">&#123;</div><div class=\"line\">        <span class=\"built_in\">echo</span> -n $<span class=\"string\">\"Shutting down Tomcat: \"</span></div><div class=\"line\">        <span class=\"variable\">$CATALINA_HOME</span>/bin/shutdown.sh</div><div class=\"line\">        <span class=\"built_in\">echo</span> <span class=\"string\">\"[OK]\"</span></div><div class=\"line\">&#125;</div><div class=\"line\"><span class=\"keyword\">case</span> <span class=\"string\">\"<span class=\"variable\">$1</span>\"</span> <span class=\"keyword\">in</span></div><div class=\"line\">  start)</div><div class=\"line\">        start</div><div class=\"line\">        ;;</div><div class=\"line\">  stop)</div><div class=\"line\">        stop</div><div class=\"line\">        ;;</div><div class=\"line\">  restart)</div><div class=\"line\">        stop</div><div class=\"line\">        sleep 3</div><div class=\"line\">        start</div><div class=\"line\">        ;;</div><div class=\"line\">    *)</div><div class=\"line\">             <span class=\"built_in\">echo</span> $<span class=\"string\">\"Usage: <span class=\"variable\">$0</span> &#123;start|stop|restart&#125;\"</span></div><div class=\"line\">        <span class=\"built_in\">exit</span> 1</div><div class=\"line\"><span class=\"keyword\">esac</span></div><div class=\"line\"><span class=\"built_in\">exit</span> 0</div><div class=\"line\"><span class=\"comment\">#保存退出</span></div><div class=\"line\">sudo chmod u+x tomcatd</div><div class=\"line\">sudo chkconfig --add tomcatd</div><div class=\"line\">sudo chkconfig tomcatd on</div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\">#添加防火墙规则，让防火墙允许 tomcat 的端口 8080 通过</span></div><div class=\"line\">sudo vim /etc/sysconfig/iptables</div><div class=\"line\"><span class=\"comment\">#添加如下一行（实际上是拷贝了原来的一行，仅仅改变了端口号），位置必须#要放在 含有 \"REJECT --reject-with\" 的行的前面</span></div><div class=\"line\">-A INPUT -m state --state NEW -m tcp -p tcp --dport 8080 -j ACCEPT</div><div class=\"line\">sudo service iptables restart</div></pre></td></tr></table></figure>\n<p>###方法二</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">#搜索一下 tomcat包的名字</span></div><div class=\"line\">yum search tomcat</div><div class=\"line\">sudo yum search tomcat6.noarch</div></pre></td></tr></table></figure>\n<p>##安装Python</p>\n<p>###方法一：去<a href=\"http://www.python.org\">官网</a>下载源码，编译，安装</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">#开始解压，编译，安装</span></div><div class=\"line\">tar -jxf Python-3.2.3.tar.bz2</div><div class=\"line\"><span class=\"built_in\">cd</span> Python-3.2.3</div><div class=\"line\"><span class=\"comment\"># 查看一下说明, vim README</span></div><div class=\"line\">sudo yum install zlib-devel bzip2-devel openssl-devel ncurses-devel sqlite-devel readline-devel tk-devel</div><div class=\"line\">./configure</div><div class=\"line\">make</div><div class=\"line\"><span class=\"comment\">#为了加快安装速度，这步可以省略</span></div><div class=\"line\">make <span class=\"built_in\">test</span></div><div class=\"line\"><span class=\"comment\">#卸载旧的python，注意，不能用 yum remove python，这会卸载几百个包，最终损坏系统</span></div><div class=\"line\">sudo rpm -evf --nodeps python</div><div class=\"line\">sudo make install</div><div class=\"line\"><span class=\"comment\">#默认安装在 /usr/local/bin/python3</span></div></pre></td></tr></table></figure>\n<p>###方法二</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">sudo yum install python</div></pre></td></tr></table></figure>\n<p>##安装ruby</p>\n<p>###方法一</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># http://www.ruby-lang.org/en/downloads/ ，选择 \"Stable Snapshot\"</span></div><div class=\"line\">tar -zxf ruby-1.9-stable.tar.gz</div><div class=\"line\"><span class=\"built_in\">cd</span>  <span class=\"built_in\">cd</span> ruby-1.9.3-p194/</div><div class=\"line\">./configure</div><div class=\"line\">make</div><div class=\"line\">sudo make install</div></pre></td></tr></table></figure>\n<p>###方法二</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">sudo yum install ruby</div></pre></td></tr></table></figure>\n<p>##安装go</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">#去官网 http://code.google.com/p/go/downloads 下载，go1.0.1.linux-i386.tar.gz (32位)，go1.0.1.linux-amd64.tar.gz（64位）</span></div><div class=\"line\">tar -zxf go1.0.1.linux-amd64.tar.gz</div><div class=\"line\">sudo mv go/ /usr/<span class=\"built_in\">local</span>/</div><div class=\"line\"><span class=\"comment\">#设置环境变量</span></div><div class=\"line\">sudo vim /etc/profile</div><div class=\"line\"><span class=\"built_in\">export</span> GOROOT=/usr/<span class=\"built_in\">local</span>/go</div><div class=\"line\"><span class=\"built_in\">export</span> PATH=<span class=\"variable\">$PATH</span>:<span class=\"variable\">$GOROOT</span>/bin</div><div class=\"line\"><span class=\"built_in\">source</span> /etc/profile</div><div class=\"line\"><span class=\"comment\">#测试一下</span></div><div class=\"line\">go version</div></pre></td></tr></table></figure>\n<p>##安装lua</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># 去官网下载源码，编译，安装。由于官网仅提供源码，故推荐源码编译安装方式。</span></div><div class=\"line\"><span class=\"comment\"># 去官网 http://www.lua.org/ 下载源码，lua-5.2.0.tar.gz</span></div><div class=\"line\">tar -zxf lua-5.2.0.tar.gz </div><div class=\"line\"><span class=\"built_in\">cd</span> lua-5.2.0</div><div class=\"line\"><span class=\"comment\"># lua 依赖 readline.h 头文件</span></div><div class=\"line\">sudo yum install  readline-devel</div><div class=\"line\">make linux</div><div class=\"line\">sudo make install</div><div class=\"line\"><span class=\"comment\">#安装 google protobuf</span></div><div class=\"line\"><span class=\"comment\">#去官网 http://code.google.com/p/protobuf/下载</span></div><div class=\"line\">tar -jxf protobuf-2.4.1.tar.bz2</div><div class=\"line\"><span class=\"built_in\">cd</span> protobuf-2.4.1</div><div class=\"line\">./configure</div><div class=\"line\">make</div><div class=\"line\">sudo make install</div><div class=\"line\"><span class=\"comment\">#测试</span></div><div class=\"line\">protoc</div></pre></td></tr></table></figure>\n<p>##清理安装包</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"built_in\">cd</span> ~</div><div class=\"line\">rm * -rf</div></pre></td></tr></table></figure>\n<p>##压缩打包<br>安装完后，可以Clone，压缩打包成一个zip文件，方便分享给别人。</p>\n<p>在关机之前，有一件事需要做，</p>\n<pre><code>sudo vim /etc/sysconfig/network-scripts/ifcfg-eth0, 把HWADDR=.... 这行删掉\nsudo rm /etc/udev/rules.d/70-persistent-net.rules\nsudo shutdown -h now\n</code></pre><p>如果没有执行上述命令，克隆后的虚拟机，开机后无法上网，重启网络，<code>sudo service network restart</code>也没有效果，会出现错误“Device eth0 does not seem to be present, delaying initialization.” </p>\n<p>这是因为克隆后的虚拟机，它的MAC地址变了，即在它的.vmx文件里，MAC地址变了（<code>ethernet0.generatedAddress</code>这项），但是linux不知道这个变化，网络配置文件还是旧的，这样跟它的而真实mac不匹配，网络就无法启动。</p>\n<p>执行上述命令，删除了<code>70-persistent-net.rules</code>后，相当于删除了旧的配置文件，在开机时会生成新的配置文件。</p>\n<p>关机后，右击标签，选择”Manage-&gt;Clone”，选择”Create a full clone”，克隆完成后，关闭这台虚拟机的标签（否则文件夹里有一些临时垃圾文件），然后把文件夹压缩打包。以后就可以把这个zip包拷贝给周围的人，别人就不用经历一遍重装的过程了。</p>"},{"layout":"post","title":"集群时间同步--架设内网NTP服务器","date":"2014-01-24T16:40:00.000Z","comments":1,"_content":"\n环境：CentOS 6.5\n\n对于一个Linux集群，集群内的机器保持时间同步是很重要的，不然会出现很多问题。\n\n本文主要描述如何在集群内架设一台NTP服务器，其他机器都与这台服务器保持时间同步。\n\n##1 安装NTP\n在所有机器上执行，\n\n    $ sudo yum install ntp\n\n###2 调整时区\n把所有机器的时区调整为上海时区，即\"+8000\"时区。\n\n先看一下机器的时区是否是对的，\n\n    $ date -R\n\n如果不是\"+8000\"，则要修改时区，\n\n    $ cp /usr/share/zoneinfo/Asia/Shanghai /etc/localtime\n\n###3 （可选）同步BIOS时间\nLinux系统上面BIOS时间与linux系统时间是分开的，所以调整了时间之后，还需要使用`hwclock`才能将修改过的时间写入BIOS中。\n\n在`/etc/sysconfig/ntpd`中添加一行:\n\n    SYNC_HWCLOCK=yes\n\n##4 配置NTP服务器\n选择一台能够上网的机器作为NTP服务器，以后这台服务器提供时间同步服务，集群内的其他机器不需要上网去跟公共的NTP服务器同步了。\n\n<!-- more -->\n\n###4.1 修改/etc/ntp.conf\nntp只有一个配置文件, `/etc/ntp.conf`.\n\n只需修改一行，找到下面这行，取消注释，\n\n    #restrict 192.168.1.0 mask 255.255.255.0 nomodify notrap\n\n变成了\n\n    restrict 192.168.1.0 mask 255.255.255.0 nomodify notrap\n\n这一行的含义是允许所有IP为`192.168.1.x`的机器与本服务器同步，这样就把这台机器变成了一台NTP服务器，对别的机器提供NTP同步服务。\n\n###4.2 开机启动ntpd\n\n    $ sudo chkconfig ntpd on\n\n###4.3 启动ntpd\n\n    $ sudo service ntpd start\n\n###4.4 验证与状态检查\n\n####4.4.1 查看ntp的端口\n\n    $ netstat -unlnp\n\n应该看到123端口\n\n####4.4.2 查看ntp服务器有无和上层连通\n\n    $ ntpstat\n\n    synchronised to NTP server (218.75.4.130) at stratum 3 \n       time correct to within 598 ms\n       polling server every 64 s\n\n####4.4.3 查看ntp服务器与上层间的联系\n\n    $ ntptrace -n 127.0.0.1\n\n    127.0.0.1: stratum 3, offset -0.001095, synch distance 0.532610\n    116.193.83.174: timed out, nothing received\n\n####4.4.4 查看ntp服务器与上层ntp服务器的状态\n\n    $ ntpq -p\n         remote           refid      st t when poll reach   delay   offset  jitter\n    ==============================================================================\n    +dns.sjtu.edu.cn 202.112.31.197   3 u   47   64    3   28.873   76.001 114.194\n    +Hshh.org        209.51.161.238   2 u   48   64    3   43.694   75.042 131.058\n    +202.118.1.130   202.118.1.46     2 u   46   64    3   14.640   75.636 116.999\n    *dns1.synet.edu. 202.118.1.46     2 u   44   64    3   13.968   74.514 128.913\n\n其中:\n\n* remote - 本机和上层ntp的ip或主机名，“+”表示优先，“*”表示次优先\n* refid - 参考上一层ntp主机地址\n* st - stratum阶层\n* t: 这个.....我也不知道啥意思^_^\n* when - 多少秒前曾经同步过时间\n* poll - 下次更新在多少秒后\n* reach - 已经向上层ntp服务器要求更新的次数\n* delay - 网络延迟\n* offset - 时间补偿\n* jitter - 系统时间与bios时间差\n\n如果所有远程服务器的jitter值是4000并且delay和reach的值是0，那么说明时间同步是有问题的，可能的原因是防火墙阻断了与server之间的通讯，检查一下123端口是否正常开放。\n\n##5 配置客户机\n服务器配置好了，接下来就要配置所有的客户端机器，从该服务器同步时间。\n\n* 方法1，使用`ntpdate`与上面配置的NTP服务器定时同步（参考资料2），不推荐此方法\n* 方法2，安装ntpd，指定NTP服务器为上面配置的服务器地址，推荐。\n\n下面详细讲述方法2。以下操作适用于所有客户端机器。\n\n###5.1 指定NTP服务器\n\n删除 `/etc/ntp.conf` 里的所有公网ntp服务器，换成上面配置的服务器，\n\n    #server 0.centos.pool.ntp.org iburst\n    #server 1.centos.pool.ntp.org iburst\n    #server 2.centos.pool.ntp.org iburst\n    #server 3.centos.pool.ntp.org iburst\n    server techwolf-01 iburst\n\n用hostname或ip都可以。\n\n###5.2 开机启动ntpd\n\n    $ sudo chkconfig ntpd on\n\n###5.3 启动ntpd\n\n    $ sudo service ntpd start\n\n\n##参考资料\n\n1. [CentOS配置时间同步NTP](http://www.crsay.com/wiki/wiki.php/server/centos/ntp-set)\n1. [CentOS系统时间同步（NTP）](http://www.cnblogs.com/thinksasa/p/3479980.html)\n\n\n","source":"_posts/2014-01-24-cluster-time-sync-using-ntp.md","raw":"---\nlayout: post\ntitle: \"集群时间同步--架设内网NTP服务器\"\ndate: 2014-01-24 16:40\ncomments: true\ncategories: DevOps\n---\n\n环境：CentOS 6.5\n\n对于一个Linux集群，集群内的机器保持时间同步是很重要的，不然会出现很多问题。\n\n本文主要描述如何在集群内架设一台NTP服务器，其他机器都与这台服务器保持时间同步。\n\n##1 安装NTP\n在所有机器上执行，\n\n    $ sudo yum install ntp\n\n###2 调整时区\n把所有机器的时区调整为上海时区，即\"+8000\"时区。\n\n先看一下机器的时区是否是对的，\n\n    $ date -R\n\n如果不是\"+8000\"，则要修改时区，\n\n    $ cp /usr/share/zoneinfo/Asia/Shanghai /etc/localtime\n\n###3 （可选）同步BIOS时间\nLinux系统上面BIOS时间与linux系统时间是分开的，所以调整了时间之后，还需要使用`hwclock`才能将修改过的时间写入BIOS中。\n\n在`/etc/sysconfig/ntpd`中添加一行:\n\n    SYNC_HWCLOCK=yes\n\n##4 配置NTP服务器\n选择一台能够上网的机器作为NTP服务器，以后这台服务器提供时间同步服务，集群内的其他机器不需要上网去跟公共的NTP服务器同步了。\n\n<!-- more -->\n\n###4.1 修改/etc/ntp.conf\nntp只有一个配置文件, `/etc/ntp.conf`.\n\n只需修改一行，找到下面这行，取消注释，\n\n    #restrict 192.168.1.0 mask 255.255.255.0 nomodify notrap\n\n变成了\n\n    restrict 192.168.1.0 mask 255.255.255.0 nomodify notrap\n\n这一行的含义是允许所有IP为`192.168.1.x`的机器与本服务器同步，这样就把这台机器变成了一台NTP服务器，对别的机器提供NTP同步服务。\n\n###4.2 开机启动ntpd\n\n    $ sudo chkconfig ntpd on\n\n###4.3 启动ntpd\n\n    $ sudo service ntpd start\n\n###4.4 验证与状态检查\n\n####4.4.1 查看ntp的端口\n\n    $ netstat -unlnp\n\n应该看到123端口\n\n####4.4.2 查看ntp服务器有无和上层连通\n\n    $ ntpstat\n\n    synchronised to NTP server (218.75.4.130) at stratum 3 \n       time correct to within 598 ms\n       polling server every 64 s\n\n####4.4.3 查看ntp服务器与上层间的联系\n\n    $ ntptrace -n 127.0.0.1\n\n    127.0.0.1: stratum 3, offset -0.001095, synch distance 0.532610\n    116.193.83.174: timed out, nothing received\n\n####4.4.4 查看ntp服务器与上层ntp服务器的状态\n\n    $ ntpq -p\n         remote           refid      st t when poll reach   delay   offset  jitter\n    ==============================================================================\n    +dns.sjtu.edu.cn 202.112.31.197   3 u   47   64    3   28.873   76.001 114.194\n    +Hshh.org        209.51.161.238   2 u   48   64    3   43.694   75.042 131.058\n    +202.118.1.130   202.118.1.46     2 u   46   64    3   14.640   75.636 116.999\n    *dns1.synet.edu. 202.118.1.46     2 u   44   64    3   13.968   74.514 128.913\n\n其中:\n\n* remote - 本机和上层ntp的ip或主机名，“+”表示优先，“*”表示次优先\n* refid - 参考上一层ntp主机地址\n* st - stratum阶层\n* t: 这个.....我也不知道啥意思^_^\n* when - 多少秒前曾经同步过时间\n* poll - 下次更新在多少秒后\n* reach - 已经向上层ntp服务器要求更新的次数\n* delay - 网络延迟\n* offset - 时间补偿\n* jitter - 系统时间与bios时间差\n\n如果所有远程服务器的jitter值是4000并且delay和reach的值是0，那么说明时间同步是有问题的，可能的原因是防火墙阻断了与server之间的通讯，检查一下123端口是否正常开放。\n\n##5 配置客户机\n服务器配置好了，接下来就要配置所有的客户端机器，从该服务器同步时间。\n\n* 方法1，使用`ntpdate`与上面配置的NTP服务器定时同步（参考资料2），不推荐此方法\n* 方法2，安装ntpd，指定NTP服务器为上面配置的服务器地址，推荐。\n\n下面详细讲述方法2。以下操作适用于所有客户端机器。\n\n###5.1 指定NTP服务器\n\n删除 `/etc/ntp.conf` 里的所有公网ntp服务器，换成上面配置的服务器，\n\n    #server 0.centos.pool.ntp.org iburst\n    #server 1.centos.pool.ntp.org iburst\n    #server 2.centos.pool.ntp.org iburst\n    #server 3.centos.pool.ntp.org iburst\n    server techwolf-01 iburst\n\n用hostname或ip都可以。\n\n###5.2 开机启动ntpd\n\n    $ sudo chkconfig ntpd on\n\n###5.3 启动ntpd\n\n    $ sudo service ntpd start\n\n\n##参考资料\n\n1. [CentOS配置时间同步NTP](http://www.crsay.com/wiki/wiki.php/server/centos/ntp-set)\n1. [CentOS系统时间同步（NTP）](http://www.cnblogs.com/thinksasa/p/3479980.html)\n\n\n","slug":"2014-01-24-cluster-time-sync-using-ntp","published":1,"updated":"2016-08-18T09:21:04.000Z","photos":[],"link":"","_id":"cis07pf3y002b01pqh3pzd03v","content":"<p>环境：CentOS 6.5</p>\n<p>对于一个Linux集群，集群内的机器保持时间同步是很重要的，不然会出现很多问题。</p>\n<p>本文主要描述如何在集群内架设一台NTP服务器，其他机器都与这台服务器保持时间同步。</p>\n<p>##1 安装NTP<br>在所有机器上执行，</p>\n<pre><code>$ sudo yum install ntp\n</code></pre><p>###2 调整时区<br>把所有机器的时区调整为上海时区，即”+8000”时区。</p>\n<p>先看一下机器的时区是否是对的，</p>\n<pre><code>$ date -R\n</code></pre><p>如果不是”+8000”，则要修改时区，</p>\n<pre><code>$ cp /usr/share/zoneinfo/Asia/Shanghai /etc/localtime\n</code></pre><p>###3 （可选）同步BIOS时间<br>Linux系统上面BIOS时间与linux系统时间是分开的，所以调整了时间之后，还需要使用<code>hwclock</code>才能将修改过的时间写入BIOS中。</p>\n<p>在<code>/etc/sysconfig/ntpd</code>中添加一行:</p>\n<pre><code>SYNC_HWCLOCK=yes\n</code></pre><p>##4 配置NTP服务器<br>选择一台能够上网的机器作为NTP服务器，以后这台服务器提供时间同步服务，集群内的其他机器不需要上网去跟公共的NTP服务器同步了。</p>\n<a id=\"more\"></a>\n<p>###4.1 修改/etc/ntp.conf<br>ntp只有一个配置文件, <code>/etc/ntp.conf</code>.</p>\n<p>只需修改一行，找到下面这行，取消注释，</p>\n<pre><code>#restrict 192.168.1.0 mask 255.255.255.0 nomodify notrap\n</code></pre><p>变成了</p>\n<pre><code>restrict 192.168.1.0 mask 255.255.255.0 nomodify notrap\n</code></pre><p>这一行的含义是允许所有IP为<code>192.168.1.x</code>的机器与本服务器同步，这样就把这台机器变成了一台NTP服务器，对别的机器提供NTP同步服务。</p>\n<p>###4.2 开机启动ntpd</p>\n<pre><code>$ sudo chkconfig ntpd on\n</code></pre><p>###4.3 启动ntpd</p>\n<pre><code>$ sudo service ntpd start\n</code></pre><p>###4.4 验证与状态检查</p>\n<p>####4.4.1 查看ntp的端口</p>\n<pre><code>$ netstat -unlnp\n</code></pre><p>应该看到123端口</p>\n<p>####4.4.2 查看ntp服务器有无和上层连通</p>\n<pre><code>$ ntpstat\n\nsynchronised to NTP server (218.75.4.130) at stratum 3 \n   time correct to within 598 ms\n   polling server every 64 s\n</code></pre><p>####4.4.3 查看ntp服务器与上层间的联系</p>\n<pre><code>$ ntptrace -n 127.0.0.1\n\n127.0.0.1: stratum 3, offset -0.001095, synch distance 0.532610\n116.193.83.174: timed out, nothing received\n</code></pre><p>####4.4.4 查看ntp服务器与上层ntp服务器的状态</p>\n<pre><code>$ ntpq -p\n     remote           refid      st t when poll reach   delay   offset  jitter\n==============================================================================\n+dns.sjtu.edu.cn 202.112.31.197   3 u   47   64    3   28.873   76.001 114.194\n+Hshh.org        209.51.161.238   2 u   48   64    3   43.694   75.042 131.058\n+202.118.1.130   202.118.1.46     2 u   46   64    3   14.640   75.636 116.999\n*dns1.synet.edu. 202.118.1.46     2 u   44   64    3   13.968   74.514 128.913\n</code></pre><p>其中:</p>\n<ul>\n<li>remote - 本机和上层ntp的ip或主机名，“+”表示优先，“*”表示次优先</li>\n<li>refid - 参考上一层ntp主机地址</li>\n<li>st - stratum阶层</li>\n<li>t: 这个…..我也不知道啥意思^_^</li>\n<li>when - 多少秒前曾经同步过时间</li>\n<li>poll - 下次更新在多少秒后</li>\n<li>reach - 已经向上层ntp服务器要求更新的次数</li>\n<li>delay - 网络延迟</li>\n<li>offset - 时间补偿</li>\n<li>jitter - 系统时间与bios时间差</li>\n</ul>\n<p>如果所有远程服务器的jitter值是4000并且delay和reach的值是0，那么说明时间同步是有问题的，可能的原因是防火墙阻断了与server之间的通讯，检查一下123端口是否正常开放。</p>\n<p>##5 配置客户机<br>服务器配置好了，接下来就要配置所有的客户端机器，从该服务器同步时间。</p>\n<ul>\n<li>方法1，使用<code>ntpdate</code>与上面配置的NTP服务器定时同步（参考资料2），不推荐此方法</li>\n<li>方法2，安装ntpd，指定NTP服务器为上面配置的服务器地址，推荐。</li>\n</ul>\n<p>下面详细讲述方法2。以下操作适用于所有客户端机器。</p>\n<p>###5.1 指定NTP服务器</p>\n<p>删除 <code>/etc/ntp.conf</code> 里的所有公网ntp服务器，换成上面配置的服务器，</p>\n<pre><code>#server 0.centos.pool.ntp.org iburst\n#server 1.centos.pool.ntp.org iburst\n#server 2.centos.pool.ntp.org iburst\n#server 3.centos.pool.ntp.org iburst\nserver techwolf-01 iburst\n</code></pre><p>用hostname或ip都可以。</p>\n<p>###5.2 开机启动ntpd</p>\n<pre><code>$ sudo chkconfig ntpd on\n</code></pre><p>###5.3 启动ntpd</p>\n<pre><code>$ sudo service ntpd start\n</code></pre><p>##参考资料</p>\n<ol>\n<li><a href=\"http://www.crsay.com/wiki/wiki.php/server/centos/ntp-set\" target=\"_blank\" rel=\"external\">CentOS配置时间同步NTP</a></li>\n<li><a href=\"http://www.cnblogs.com/thinksasa/p/3479980.html\" target=\"_blank\" rel=\"external\">CentOS系统时间同步（NTP）</a></li>\n</ol>\n","excerpt":"<p>环境：CentOS 6.5</p>\n<p>对于一个Linux集群，集群内的机器保持时间同步是很重要的，不然会出现很多问题。</p>\n<p>本文主要描述如何在集群内架设一台NTP服务器，其他机器都与这台服务器保持时间同步。</p>\n<p>##1 安装NTP<br>在所有机器上执行，</p>\n<pre><code>$ sudo yum install ntp\n</code></pre><p>###2 调整时区<br>把所有机器的时区调整为上海时区，即”+8000”时区。</p>\n<p>先看一下机器的时区是否是对的，</p>\n<pre><code>$ date -R\n</code></pre><p>如果不是”+8000”，则要修改时区，</p>\n<pre><code>$ cp /usr/share/zoneinfo/Asia/Shanghai /etc/localtime\n</code></pre><p>###3 （可选）同步BIOS时间<br>Linux系统上面BIOS时间与linux系统时间是分开的，所以调整了时间之后，还需要使用<code>hwclock</code>才能将修改过的时间写入BIOS中。</p>\n<p>在<code>/etc/sysconfig/ntpd</code>中添加一行:</p>\n<pre><code>SYNC_HWCLOCK=yes\n</code></pre><p>##4 配置NTP服务器<br>选择一台能够上网的机器作为NTP服务器，以后这台服务器提供时间同步服务，集群内的其他机器不需要上网去跟公共的NTP服务器同步了。</p>","more":"<p>###4.1 修改/etc/ntp.conf<br>ntp只有一个配置文件, <code>/etc/ntp.conf</code>.</p>\n<p>只需修改一行，找到下面这行，取消注释，</p>\n<pre><code>#restrict 192.168.1.0 mask 255.255.255.0 nomodify notrap\n</code></pre><p>变成了</p>\n<pre><code>restrict 192.168.1.0 mask 255.255.255.0 nomodify notrap\n</code></pre><p>这一行的含义是允许所有IP为<code>192.168.1.x</code>的机器与本服务器同步，这样就把这台机器变成了一台NTP服务器，对别的机器提供NTP同步服务。</p>\n<p>###4.2 开机启动ntpd</p>\n<pre><code>$ sudo chkconfig ntpd on\n</code></pre><p>###4.3 启动ntpd</p>\n<pre><code>$ sudo service ntpd start\n</code></pre><p>###4.4 验证与状态检查</p>\n<p>####4.4.1 查看ntp的端口</p>\n<pre><code>$ netstat -unlnp\n</code></pre><p>应该看到123端口</p>\n<p>####4.4.2 查看ntp服务器有无和上层连通</p>\n<pre><code>$ ntpstat\n\nsynchronised to NTP server (218.75.4.130) at stratum 3 \n   time correct to within 598 ms\n   polling server every 64 s\n</code></pre><p>####4.4.3 查看ntp服务器与上层间的联系</p>\n<pre><code>$ ntptrace -n 127.0.0.1\n\n127.0.0.1: stratum 3, offset -0.001095, synch distance 0.532610\n116.193.83.174: timed out, nothing received\n</code></pre><p>####4.4.4 查看ntp服务器与上层ntp服务器的状态</p>\n<pre><code>$ ntpq -p\n     remote           refid      st t when poll reach   delay   offset  jitter\n==============================================================================\n+dns.sjtu.edu.cn 202.112.31.197   3 u   47   64    3   28.873   76.001 114.194\n+Hshh.org        209.51.161.238   2 u   48   64    3   43.694   75.042 131.058\n+202.118.1.130   202.118.1.46     2 u   46   64    3   14.640   75.636 116.999\n*dns1.synet.edu. 202.118.1.46     2 u   44   64    3   13.968   74.514 128.913\n</code></pre><p>其中:</p>\n<ul>\n<li>remote - 本机和上层ntp的ip或主机名，“+”表示优先，“*”表示次优先</li>\n<li>refid - 参考上一层ntp主机地址</li>\n<li>st - stratum阶层</li>\n<li>t: 这个…..我也不知道啥意思^_^</li>\n<li>when - 多少秒前曾经同步过时间</li>\n<li>poll - 下次更新在多少秒后</li>\n<li>reach - 已经向上层ntp服务器要求更新的次数</li>\n<li>delay - 网络延迟</li>\n<li>offset - 时间补偿</li>\n<li>jitter - 系统时间与bios时间差</li>\n</ul>\n<p>如果所有远程服务器的jitter值是4000并且delay和reach的值是0，那么说明时间同步是有问题的，可能的原因是防火墙阻断了与server之间的通讯，检查一下123端口是否正常开放。</p>\n<p>##5 配置客户机<br>服务器配置好了，接下来就要配置所有的客户端机器，从该服务器同步时间。</p>\n<ul>\n<li>方法1，使用<code>ntpdate</code>与上面配置的NTP服务器定时同步（参考资料2），不推荐此方法</li>\n<li>方法2，安装ntpd，指定NTP服务器为上面配置的服务器地址，推荐。</li>\n</ul>\n<p>下面详细讲述方法2。以下操作适用于所有客户端机器。</p>\n<p>###5.1 指定NTP服务器</p>\n<p>删除 <code>/etc/ntp.conf</code> 里的所有公网ntp服务器，换成上面配置的服务器，</p>\n<pre><code>#server 0.centos.pool.ntp.org iburst\n#server 1.centos.pool.ntp.org iburst\n#server 2.centos.pool.ntp.org iburst\n#server 3.centos.pool.ntp.org iburst\nserver techwolf-01 iburst\n</code></pre><p>用hostname或ip都可以。</p>\n<p>###5.2 开机启动ntpd</p>\n<pre><code>$ sudo chkconfig ntpd on\n</code></pre><p>###5.3 启动ntpd</p>\n<pre><code>$ sudo service ntpd start\n</code></pre><p>##参考资料</p>\n<ol>\n<li><a href=\"http://www.crsay.com/wiki/wiki.php/server/centos/ntp-set\">CentOS配置时间同步NTP</a></li>\n<li><a href=\"http://www.cnblogs.com/thinksasa/p/3479980.html\">CentOS系统时间同步（NTP）</a></li>\n</ol>"},{"layout":"post","title":"CentOS 6.5 升级内核到 3.10.28","date":"2014-01-23T00:02:00.000Z","comments":1,"_content":"\n本文适用于CentOS 6.4, CentOS 6.5，亲测可行，估计也适用于其他Linux发行版。\n\n## 1. 准备工作\n\n### 1.1 下载源码包\nLinux内核版本有两种：稳定版和开发版 ，Linux内核版本号由3个数字组成：r.x.y\n\n* r: 主版本号\n* x: 次版本号，偶数表示稳定版本；奇数表示开发中版本。\n* y: 修订版本号 ， 表示修改的次数\n\n\n去 <http://www.kernel.org> 首页，可以看到有stable, longterm等版本，longterm是比stable更稳定的版本，会长时间更新，因此我选择 3.10.28，\n\n\twget  https://www.kernel.org/pub/linux/kernel/v3.x/linux-3.10.28.tar.xz\n\n###1.2 解压\n\n\ttar -xf linux-3.10.28.tar.xz\n\n###1.3 更新当前系统\n\n\tsudo yum update\n\tsudo yum upgrade\n\n###1.4 安装编译内核所需要的软件包\n\n\tsudo yum groupinstall \"Development Tools\" # 一口气安装编译时所需的一切工具\n\tsudo yum install ncurses-devel #必须这样才能让 make *config 这个指令正确地执行。\n\tsudo yum install qt-devel #如果你没有 X 环境，这一条可以不用\n\tsudo yum install hmaccalc zlib-devel binutils-devel elfutils-libelf-devel #创建 CentOS-6 内核时需要它们\n\n\n##2 配置文件\n\n###2.1 查看当前系统内核\n\t\n\tuname -r\n\t2.6.32-358.11.1.el6.x86_64\n\n###2.2 将当前系统的配置文件拷贝到当前目录\n\n\tcp /boot/config-2.6.32-358.11.1.el6.x86_64 .config\n\n\n###2.3 使用旧内核配置，并自动接受每个新增选项的默认设置\n\n\tsh -c 'yes \"\" | make oldconfig'\n\n`make oldconfig`会读取当前目录下的`.config`文件，在`.config`文件里没有找到的选项则提示用户填写，然后备份`.config`文件为`.config.old`，并生成新的`.config`文件，参考 <http://stackoverflow.com/questions/4178526/what-does-make-oldconfig-do-exactly-linux-kernel-makefile>\n\n\n##3 编译\n\n\tsudo make -j8 bzImage #生成内核文件\n\tsudo make -j8 modules #编译模块\n\tsudo make -j8 modules_install #编译安装模块\n\n要严格按照这个顺序进行编译，**不能合并成一句**，`sudo make -j8 bzImage modules modules_install`。\n\n`-j`后面的数字是线程数，用于加快编译速度，一般的经验是，有多少G内存，就填写那个数字，例如有8G内存，则为`-j8`。\n\n\n##4 安装\n\n\tsudo make install\n\n如果出现了 `ERROR: modinfo: could not find module xxx`，数量少的话，可以忽略。\n\n\n##5 修改Grub引导顺序\n\n安装完成后，需要修改Grub引导顺序，让新安装的内核作为默认内核。\n\n编辑 `grub.conf`文件，\n\n\tsudo vim /etc/grub.conf\n\n数一下刚刚新安装的内核在哪个位置，从0开始，然后设置default为那个数字，一般新安装的内核在第一个位置，所以设置`default=0`。\n\n\n##6 重启\n\n\tsudo reboot\n\n重启后，看一下当前内核版本号，\n\n\tuname -r\n\t3.10.28\n\n成功啦！！\n\n\n##7 如果失败，则重新循环\n\n如果失败，重新开始的话，要清理上次编译的现场 \n\n\tmake mrproper #清理上次编译的现场 \n\n然后转到第2步，重新开始。\n\n\n## 参考资料 \n* [How to upgrade the kernel on CentOS](http://xmodulo.com/2013/07/how-to-upgrade-the-kernel-on-centos.html)\n* [CentOS 6.4 升级到 3.x Kernel](http://winotes.net/centos-64-upgrade-to-kernel-3x.html)\n* [CentOS Linux 升级内核步骤和方法](http://my.oschina.net/qichang/blog/101542)\n","source":"_posts/2014-01-23-centos-6-dot-4-upgrade-kernel.md","raw":"---\nlayout: post\ntitle: \"CentOS 6.5 升级内核到 3.10.28\"\ndate: 2014-01-23 00:02\ncomments: true\ncategories: DevOps\n---\n\n本文适用于CentOS 6.4, CentOS 6.5，亲测可行，估计也适用于其他Linux发行版。\n\n## 1. 准备工作\n\n### 1.1 下载源码包\nLinux内核版本有两种：稳定版和开发版 ，Linux内核版本号由3个数字组成：r.x.y\n\n* r: 主版本号\n* x: 次版本号，偶数表示稳定版本；奇数表示开发中版本。\n* y: 修订版本号 ， 表示修改的次数\n\n\n去 <http://www.kernel.org> 首页，可以看到有stable, longterm等版本，longterm是比stable更稳定的版本，会长时间更新，因此我选择 3.10.28，\n\n\twget  https://www.kernel.org/pub/linux/kernel/v3.x/linux-3.10.28.tar.xz\n\n###1.2 解压\n\n\ttar -xf linux-3.10.28.tar.xz\n\n###1.3 更新当前系统\n\n\tsudo yum update\n\tsudo yum upgrade\n\n###1.4 安装编译内核所需要的软件包\n\n\tsudo yum groupinstall \"Development Tools\" # 一口气安装编译时所需的一切工具\n\tsudo yum install ncurses-devel #必须这样才能让 make *config 这个指令正确地执行。\n\tsudo yum install qt-devel #如果你没有 X 环境，这一条可以不用\n\tsudo yum install hmaccalc zlib-devel binutils-devel elfutils-libelf-devel #创建 CentOS-6 内核时需要它们\n\n\n##2 配置文件\n\n###2.1 查看当前系统内核\n\t\n\tuname -r\n\t2.6.32-358.11.1.el6.x86_64\n\n###2.2 将当前系统的配置文件拷贝到当前目录\n\n\tcp /boot/config-2.6.32-358.11.1.el6.x86_64 .config\n\n\n###2.3 使用旧内核配置，并自动接受每个新增选项的默认设置\n\n\tsh -c 'yes \"\" | make oldconfig'\n\n`make oldconfig`会读取当前目录下的`.config`文件，在`.config`文件里没有找到的选项则提示用户填写，然后备份`.config`文件为`.config.old`，并生成新的`.config`文件，参考 <http://stackoverflow.com/questions/4178526/what-does-make-oldconfig-do-exactly-linux-kernel-makefile>\n\n\n##3 编译\n\n\tsudo make -j8 bzImage #生成内核文件\n\tsudo make -j8 modules #编译模块\n\tsudo make -j8 modules_install #编译安装模块\n\n要严格按照这个顺序进行编译，**不能合并成一句**，`sudo make -j8 bzImage modules modules_install`。\n\n`-j`后面的数字是线程数，用于加快编译速度，一般的经验是，有多少G内存，就填写那个数字，例如有8G内存，则为`-j8`。\n\n\n##4 安装\n\n\tsudo make install\n\n如果出现了 `ERROR: modinfo: could not find module xxx`，数量少的话，可以忽略。\n\n\n##5 修改Grub引导顺序\n\n安装完成后，需要修改Grub引导顺序，让新安装的内核作为默认内核。\n\n编辑 `grub.conf`文件，\n\n\tsudo vim /etc/grub.conf\n\n数一下刚刚新安装的内核在哪个位置，从0开始，然后设置default为那个数字，一般新安装的内核在第一个位置，所以设置`default=0`。\n\n\n##6 重启\n\n\tsudo reboot\n\n重启后，看一下当前内核版本号，\n\n\tuname -r\n\t3.10.28\n\n成功啦！！\n\n\n##7 如果失败，则重新循环\n\n如果失败，重新开始的话，要清理上次编译的现场 \n\n\tmake mrproper #清理上次编译的现场 \n\n然后转到第2步，重新开始。\n\n\n## 参考资料 \n* [How to upgrade the kernel on CentOS](http://xmodulo.com/2013/07/how-to-upgrade-the-kernel-on-centos.html)\n* [CentOS 6.4 升级到 3.x Kernel](http://winotes.net/centos-64-upgrade-to-kernel-3x.html)\n* [CentOS Linux 升级内核步骤和方法](http://my.oschina.net/qichang/blog/101542)\n","slug":"2014-01-23-centos-6-dot-4-upgrade-kernel","published":1,"updated":"2016-08-18T09:21:04.000Z","photos":[],"link":"","_id":"cis07pf3z002e01pq41pw8rnm","content":"<p>本文适用于CentOS 6.4, CentOS 6.5，亲测可行，估计也适用于其他Linux发行版。</p>\n<h2 id=\"1-准备工作\"><a href=\"#1-准备工作\" class=\"headerlink\" title=\"1. 准备工作\"></a>1. 准备工作</h2><h3 id=\"1-1-下载源码包\"><a href=\"#1-1-下载源码包\" class=\"headerlink\" title=\"1.1 下载源码包\"></a>1.1 下载源码包</h3><p>Linux内核版本有两种：稳定版和开发版 ，Linux内核版本号由3个数字组成：r.x.y</p>\n<ul>\n<li>r: 主版本号</li>\n<li>x: 次版本号，偶数表示稳定版本；奇数表示开发中版本。</li>\n<li>y: 修订版本号 ， 表示修改的次数</li>\n</ul>\n<p>去 <a href=\"http://www.kernel.org\" target=\"_blank\" rel=\"external\">http://www.kernel.org</a> 首页，可以看到有stable, longterm等版本，longterm是比stable更稳定的版本，会长时间更新，因此我选择 3.10.28，</p>\n<pre><code>wget  https://www.kernel.org/pub/linux/kernel/v3.x/linux-3.10.28.tar.xz\n</code></pre><p>###1.2 解压</p>\n<pre><code>tar -xf linux-3.10.28.tar.xz\n</code></pre><p>###1.3 更新当前系统</p>\n<pre><code>sudo yum update\nsudo yum upgrade\n</code></pre><p>###1.4 安装编译内核所需要的软件包</p>\n<pre><code>sudo yum groupinstall &quot;Development Tools&quot; # 一口气安装编译时所需的一切工具\nsudo yum install ncurses-devel #必须这样才能让 make *config 这个指令正确地执行。\nsudo yum install qt-devel #如果你没有 X 环境，这一条可以不用\nsudo yum install hmaccalc zlib-devel binutils-devel elfutils-libelf-devel #创建 CentOS-6 内核时需要它们\n</code></pre><p>##2 配置文件</p>\n<p>###2.1 查看当前系统内核</p>\n<pre><code>uname -r\n2.6.32-358.11.1.el6.x86_64\n</code></pre><p>###2.2 将当前系统的配置文件拷贝到当前目录</p>\n<pre><code>cp /boot/config-2.6.32-358.11.1.el6.x86_64 .config\n</code></pre><p>###2.3 使用旧内核配置，并自动接受每个新增选项的默认设置</p>\n<pre><code>sh -c &apos;yes &quot;&quot; | make oldconfig&apos;\n</code></pre><p><code>make oldconfig</code>会读取当前目录下的<code>.config</code>文件，在<code>.config</code>文件里没有找到的选项则提示用户填写，然后备份<code>.config</code>文件为<code>.config.old</code>，并生成新的<code>.config</code>文件，参考 <a href=\"http://stackoverflow.com/questions/4178526/what-does-make-oldconfig-do-exactly-linux-kernel-makefile\" target=\"_blank\" rel=\"external\">http://stackoverflow.com/questions/4178526/what-does-make-oldconfig-do-exactly-linux-kernel-makefile</a></p>\n<p>##3 编译</p>\n<pre><code>sudo make -j8 bzImage #生成内核文件\nsudo make -j8 modules #编译模块\nsudo make -j8 modules_install #编译安装模块\n</code></pre><p>要严格按照这个顺序进行编译，<strong>不能合并成一句</strong>，<code>sudo make -j8 bzImage modules modules_install</code>。</p>\n<p><code>-j</code>后面的数字是线程数，用于加快编译速度，一般的经验是，有多少G内存，就填写那个数字，例如有8G内存，则为<code>-j8</code>。</p>\n<p>##4 安装</p>\n<pre><code>sudo make install\n</code></pre><p>如果出现了 <code>ERROR: modinfo: could not find module xxx</code>，数量少的话，可以忽略。</p>\n<p>##5 修改Grub引导顺序</p>\n<p>安装完成后，需要修改Grub引导顺序，让新安装的内核作为默认内核。</p>\n<p>编辑 <code>grub.conf</code>文件，</p>\n<pre><code>sudo vim /etc/grub.conf\n</code></pre><p>数一下刚刚新安装的内核在哪个位置，从0开始，然后设置default为那个数字，一般新安装的内核在第一个位置，所以设置<code>default=0</code>。</p>\n<p>##6 重启</p>\n<pre><code>sudo reboot\n</code></pre><p>重启后，看一下当前内核版本号，</p>\n<pre><code>uname -r\n3.10.28\n</code></pre><p>成功啦！！</p>\n<p>##7 如果失败，则重新循环</p>\n<p>如果失败，重新开始的话，要清理上次编译的现场 </p>\n<pre><code>make mrproper #清理上次编译的现场 \n</code></pre><p>然后转到第2步，重新开始。</p>\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><ul>\n<li><a href=\"http://xmodulo.com/2013/07/how-to-upgrade-the-kernel-on-centos.html\" target=\"_blank\" rel=\"external\">How to upgrade the kernel on CentOS</a></li>\n<li><a href=\"http://winotes.net/centos-64-upgrade-to-kernel-3x.html\" target=\"_blank\" rel=\"external\">CentOS 6.4 升级到 3.x Kernel</a></li>\n<li><a href=\"http://my.oschina.net/qichang/blog/101542\" target=\"_blank\" rel=\"external\">CentOS Linux 升级内核步骤和方法</a></li>\n</ul>\n","excerpt":"","more":"<p>本文适用于CentOS 6.4, CentOS 6.5，亲测可行，估计也适用于其他Linux发行版。</p>\n<h2 id=\"1-准备工作\"><a href=\"#1-准备工作\" class=\"headerlink\" title=\"1. 准备工作\"></a>1. 准备工作</h2><h3 id=\"1-1-下载源码包\"><a href=\"#1-1-下载源码包\" class=\"headerlink\" title=\"1.1 下载源码包\"></a>1.1 下载源码包</h3><p>Linux内核版本有两种：稳定版和开发版 ，Linux内核版本号由3个数字组成：r.x.y</p>\n<ul>\n<li>r: 主版本号</li>\n<li>x: 次版本号，偶数表示稳定版本；奇数表示开发中版本。</li>\n<li>y: 修订版本号 ， 表示修改的次数</li>\n</ul>\n<p>去 <a href=\"http://www.kernel.org\">http://www.kernel.org</a> 首页，可以看到有stable, longterm等版本，longterm是比stable更稳定的版本，会长时间更新，因此我选择 3.10.28，</p>\n<pre><code>wget  https://www.kernel.org/pub/linux/kernel/v3.x/linux-3.10.28.tar.xz\n</code></pre><p>###1.2 解压</p>\n<pre><code>tar -xf linux-3.10.28.tar.xz\n</code></pre><p>###1.3 更新当前系统</p>\n<pre><code>sudo yum update\nsudo yum upgrade\n</code></pre><p>###1.4 安装编译内核所需要的软件包</p>\n<pre><code>sudo yum groupinstall &quot;Development Tools&quot; # 一口气安装编译时所需的一切工具\nsudo yum install ncurses-devel #必须这样才能让 make *config 这个指令正确地执行。\nsudo yum install qt-devel #如果你没有 X 环境，这一条可以不用\nsudo yum install hmaccalc zlib-devel binutils-devel elfutils-libelf-devel #创建 CentOS-6 内核时需要它们\n</code></pre><p>##2 配置文件</p>\n<p>###2.1 查看当前系统内核</p>\n<pre><code>uname -r\n2.6.32-358.11.1.el6.x86_64\n</code></pre><p>###2.2 将当前系统的配置文件拷贝到当前目录</p>\n<pre><code>cp /boot/config-2.6.32-358.11.1.el6.x86_64 .config\n</code></pre><p>###2.3 使用旧内核配置，并自动接受每个新增选项的默认设置</p>\n<pre><code>sh -c &apos;yes &quot;&quot; | make oldconfig&apos;\n</code></pre><p><code>make oldconfig</code>会读取当前目录下的<code>.config</code>文件，在<code>.config</code>文件里没有找到的选项则提示用户填写，然后备份<code>.config</code>文件为<code>.config.old</code>，并生成新的<code>.config</code>文件，参考 <a href=\"http://stackoverflow.com/questions/4178526/what-does-make-oldconfig-do-exactly-linux-kernel-makefile\">http://stackoverflow.com/questions/4178526/what-does-make-oldconfig-do-exactly-linux-kernel-makefile</a></p>\n<p>##3 编译</p>\n<pre><code>sudo make -j8 bzImage #生成内核文件\nsudo make -j8 modules #编译模块\nsudo make -j8 modules_install #编译安装模块\n</code></pre><p>要严格按照这个顺序进行编译，<strong>不能合并成一句</strong>，<code>sudo make -j8 bzImage modules modules_install</code>。</p>\n<p><code>-j</code>后面的数字是线程数，用于加快编译速度，一般的经验是，有多少G内存，就填写那个数字，例如有8G内存，则为<code>-j8</code>。</p>\n<p>##4 安装</p>\n<pre><code>sudo make install\n</code></pre><p>如果出现了 <code>ERROR: modinfo: could not find module xxx</code>，数量少的话，可以忽略。</p>\n<p>##5 修改Grub引导顺序</p>\n<p>安装完成后，需要修改Grub引导顺序，让新安装的内核作为默认内核。</p>\n<p>编辑 <code>grub.conf</code>文件，</p>\n<pre><code>sudo vim /etc/grub.conf\n</code></pre><p>数一下刚刚新安装的内核在哪个位置，从0开始，然后设置default为那个数字，一般新安装的内核在第一个位置，所以设置<code>default=0</code>。</p>\n<p>##6 重启</p>\n<pre><code>sudo reboot\n</code></pre><p>重启后，看一下当前内核版本号，</p>\n<pre><code>uname -r\n3.10.28\n</code></pre><p>成功啦！！</p>\n<p>##7 如果失败，则重新循环</p>\n<p>如果失败，重新开始的话，要清理上次编译的现场 </p>\n<pre><code>make mrproper #清理上次编译的现场 \n</code></pre><p>然后转到第2步，重新开始。</p>\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><ul>\n<li><a href=\"http://xmodulo.com/2013/07/how-to-upgrade-the-kernel-on-centos.html\">How to upgrade the kernel on CentOS</a></li>\n<li><a href=\"http://winotes.net/centos-64-upgrade-to-kernel-3x.html\">CentOS 6.4 升级到 3.x Kernel</a></li>\n<li><a href=\"http://my.oschina.net/qichang/blog/101542\">CentOS Linux 升级内核步骤和方法</a></li>\n</ul>\n"},{"layout":"post","title":"在Centos 6.5上安装docker","date":"2014-01-22T15:25:00.000Z","comments":1,"_content":"\n## 1 Enable EPEL Repo on CentOS\n\n参考 [Enable EPEL Repo on CentOS 5 and CentOS 6](http://www.centosblog.com/enable-epel-repo-on-centos-5-and-centos-6/)\n\n\trpm -Uvh http://download.fedoraproject.org/pub/epel/6/x86_64/epel-release-6-8.noarch.rpm\n\n## 2 Install docker\n\n\tyum install docker-io --enablerepo=epel\n\n## 3 启动 docker daemon 进程\n\n\tsudo docker -d &\n\n这时，有警告，说内核版本过低，\n\n\n> WARNING: You are running linux kernel version 2.6.32-431.el6.x86_64, which might be unstable running docker. Please upgrade your kernel to 3.8.0.\n\n如果你在公司，且公司内部都是通过代理上网，则可以把代理服务器告诉docker，用如下命令(参考[这里](https://github.com/dotcloud/docker/issues/402))：\n\n\tsudo HTTP_PROXY=http://xxx:port docker -d &\n\n## 4 升级内核\n\n见我的另一篇博客，[CentOS 6.4 升级内核到 3.11.6](http://www.yanjiuyanjiu.com/blog/20131024)\n\n## 5 下载 ubuntu 镜像\n\n\tsudo docker pull ubuntu\n\n## 6 运行 hello world\n\n\tsudo docker run ubuntu /bin/echo hello world\n\thello world\n\n安装成功了！！\n","source":"_posts/2014-01-22-install-docker-on-centos65.md","raw":"---\nlayout: post\ntitle: \"在Centos 6.5上安装docker\"\ndate: 2014-01-22 15:25\ncomments: true\ncategories: Docker\n---\n\n## 1 Enable EPEL Repo on CentOS\n\n参考 [Enable EPEL Repo on CentOS 5 and CentOS 6](http://www.centosblog.com/enable-epel-repo-on-centos-5-and-centos-6/)\n\n\trpm -Uvh http://download.fedoraproject.org/pub/epel/6/x86_64/epel-release-6-8.noarch.rpm\n\n## 2 Install docker\n\n\tyum install docker-io --enablerepo=epel\n\n## 3 启动 docker daemon 进程\n\n\tsudo docker -d &\n\n这时，有警告，说内核版本过低，\n\n\n> WARNING: You are running linux kernel version 2.6.32-431.el6.x86_64, which might be unstable running docker. Please upgrade your kernel to 3.8.0.\n\n如果你在公司，且公司内部都是通过代理上网，则可以把代理服务器告诉docker，用如下命令(参考[这里](https://github.com/dotcloud/docker/issues/402))：\n\n\tsudo HTTP_PROXY=http://xxx:port docker -d &\n\n## 4 升级内核\n\n见我的另一篇博客，[CentOS 6.4 升级内核到 3.11.6](http://www.yanjiuyanjiu.com/blog/20131024)\n\n## 5 下载 ubuntu 镜像\n\n\tsudo docker pull ubuntu\n\n## 6 运行 hello world\n\n\tsudo docker run ubuntu /bin/echo hello world\n\thello world\n\n安装成功了！！\n","slug":"2014-01-22-install-docker-on-centos65","published":1,"updated":"2016-08-18T09:21:04.000Z","photos":[],"link":"","_id":"cis07pf40002h01pqf4bup683","content":"<h2 id=\"1-Enable-EPEL-Repo-on-CentOS\"><a href=\"#1-Enable-EPEL-Repo-on-CentOS\" class=\"headerlink\" title=\"1 Enable EPEL Repo on CentOS\"></a>1 Enable EPEL Repo on CentOS</h2><p>参考 <a href=\"http://www.centosblog.com/enable-epel-repo-on-centos-5-and-centos-6/\" target=\"_blank\" rel=\"external\">Enable EPEL Repo on CentOS 5 and CentOS 6</a></p>\n<pre><code>rpm -Uvh http://download.fedoraproject.org/pub/epel/6/x86_64/epel-release-6-8.noarch.rpm\n</code></pre><h2 id=\"2-Install-docker\"><a href=\"#2-Install-docker\" class=\"headerlink\" title=\"2 Install docker\"></a>2 Install docker</h2><pre><code>yum install docker-io --enablerepo=epel\n</code></pre><h2 id=\"3-启动-docker-daemon-进程\"><a href=\"#3-启动-docker-daemon-进程\" class=\"headerlink\" title=\"3 启动 docker daemon 进程\"></a>3 启动 docker daemon 进程</h2><pre><code>sudo docker -d &amp;\n</code></pre><p>这时，有警告，说内核版本过低，</p>\n<blockquote>\n<p>WARNING: You are running linux kernel version 2.6.32-431.el6.x86_64, which might be unstable running docker. Please upgrade your kernel to 3.8.0.</p>\n</blockquote>\n<p>如果你在公司，且公司内部都是通过代理上网，则可以把代理服务器告诉docker，用如下命令(参考<a href=\"https://github.com/dotcloud/docker/issues/402\" target=\"_blank\" rel=\"external\">这里</a>)：</p>\n<pre><code>sudo HTTP_PROXY=http://xxx:port docker -d &amp;\n</code></pre><h2 id=\"4-升级内核\"><a href=\"#4-升级内核\" class=\"headerlink\" title=\"4 升级内核\"></a>4 升级内核</h2><p>见我的另一篇博客，<a href=\"http://www.yanjiuyanjiu.com/blog/20131024\" target=\"_blank\" rel=\"external\">CentOS 6.4 升级内核到 3.11.6</a></p>\n<h2 id=\"5-下载-ubuntu-镜像\"><a href=\"#5-下载-ubuntu-镜像\" class=\"headerlink\" title=\"5 下载 ubuntu 镜像\"></a>5 下载 ubuntu 镜像</h2><pre><code>sudo docker pull ubuntu\n</code></pre><h2 id=\"6-运行-hello-world\"><a href=\"#6-运行-hello-world\" class=\"headerlink\" title=\"6 运行 hello world\"></a>6 运行 hello world</h2><pre><code>sudo docker run ubuntu /bin/echo hello world\nhello world\n</code></pre><p>安装成功了！！</p>\n","excerpt":"","more":"<h2 id=\"1-Enable-EPEL-Repo-on-CentOS\"><a href=\"#1-Enable-EPEL-Repo-on-CentOS\" class=\"headerlink\" title=\"1 Enable EPEL Repo on CentOS\"></a>1 Enable EPEL Repo on CentOS</h2><p>参考 <a href=\"http://www.centosblog.com/enable-epel-repo-on-centos-5-and-centos-6/\">Enable EPEL Repo on CentOS 5 and CentOS 6</a></p>\n<pre><code>rpm -Uvh http://download.fedoraproject.org/pub/epel/6/x86_64/epel-release-6-8.noarch.rpm\n</code></pre><h2 id=\"2-Install-docker\"><a href=\"#2-Install-docker\" class=\"headerlink\" title=\"2 Install docker\"></a>2 Install docker</h2><pre><code>yum install docker-io --enablerepo=epel\n</code></pre><h2 id=\"3-启动-docker-daemon-进程\"><a href=\"#3-启动-docker-daemon-进程\" class=\"headerlink\" title=\"3 启动 docker daemon 进程\"></a>3 启动 docker daemon 进程</h2><pre><code>sudo docker -d &amp;\n</code></pre><p>这时，有警告，说内核版本过低，</p>\n<blockquote>\n<p>WARNING: You are running linux kernel version 2.6.32-431.el6.x86_64, which might be unstable running docker. Please upgrade your kernel to 3.8.0.</p>\n</blockquote>\n<p>如果你在公司，且公司内部都是通过代理上网，则可以把代理服务器告诉docker，用如下命令(参考<a href=\"https://github.com/dotcloud/docker/issues/402\">这里</a>)：</p>\n<pre><code>sudo HTTP_PROXY=http://xxx:port docker -d &amp;\n</code></pre><h2 id=\"4-升级内核\"><a href=\"#4-升级内核\" class=\"headerlink\" title=\"4 升级内核\"></a>4 升级内核</h2><p>见我的另一篇博客，<a href=\"http://www.yanjiuyanjiu.com/blog/20131024\">CentOS 6.4 升级内核到 3.11.6</a></p>\n<h2 id=\"5-下载-ubuntu-镜像\"><a href=\"#5-下载-ubuntu-镜像\" class=\"headerlink\" title=\"5 下载 ubuntu 镜像\"></a>5 下载 ubuntu 镜像</h2><pre><code>sudo docker pull ubuntu\n</code></pre><h2 id=\"6-运行-hello-world\"><a href=\"#6-运行-hello-world\" class=\"headerlink\" title=\"6 运行 hello world\"></a>6 运行 hello world</h2><pre><code>sudo docker run ubuntu /bin/echo hello world\nhello world\n</code></pre><p>安装成功了！！</p>\n"},{"layout":"post","title":"Ansible 快速入门","date":"2014-01-27T12:10:00.000Z","comments":1,"_content":"\nAnsible 是一个比Puppet, Chef 更轻量的provisioning 工具，不需要启动daemon进程。这点跟跟pssh差不多，但是比pssh更加强大。\n\n##前提\n* 所使用的remote_user要能够SSH无密码登录到所有机器，配置方法见[SSH无密码登录的配置](http://www.yanjiuyanjiu.com/blog/20120102/)\n* remote_use sudo的时候不需要密码，配置方法如下，\n\n        sudo chmod +w /etc/sudoers\n        sudo vim /etc/sudoers\n\n    找到 `root    ALL=(ALL:ALL) ALL`，在下面添加一行\n\n       username    ALL=(ALL:ALL) NOPASSWD:ALL\n\n    保存退出，然后恢复为只读，\n\n        sudo chmod +w /etc/sudoers \n\n如果忘记了以上两点，运行任何ansible命令的时候，会卡住不动很久。\n\n如果发现在 \"GATHERING FACTS\"这里卡住，多半是sudo需要密码，试试加上-K选项，例如`ansible-playbook -K playbook.yml`，参考[Running ansible on local Linux desktop hangs on Gathering Facts](https://groups.google.com/forum/#!topic/ansible-project/FL0mxyxOo4M)。\n\n`-vvvv`表示调试模式，加上后会输出很多中间信息，帮助你调试。\n\n##1. 安装Ansible\n只需要在一台机器上安装，其他机器不需要安装任何东西，这就是ansible比puppet, chef方便的地方。\n\n    sudo yum install ansible\n\n或者\n\n    sudo apt-get install ansible\n\n在`/etc/ansible/hosts`添加想要操作的机器(这个`hosts`文件也叫做[Inventory](http://docs.ansible.com/intro_inventory.html))，且这些机器都是能[SSH无密码登录的](http://www.yanjiuyanjiu.com/blog/20120102)，然后测试一下：\n\n    ansible all -a \"/bin/echo hello\"\n\n如果都成功了，说明安装成功。\n\n使用ansible有两种方式：Ad-hoc command 和 playbook。前者用于临时类批量操作，后者用于配置管理，类似与Puppet。\n\n##2. Ad-Hoc Commands\nAd-hoc命令的形式一般如下：\n\n    ansible groupname -m module -a arguments\n\n<!-- more -->\n例如：\n\n    ansible all -m yum -a \"name=wget state=present\"\n\n参考[Introduction To Ad-Hoc Commands](http://docs.ansible.com/intro_adhoc.html)\n\n##3. Playbook\n\n对于稳定的配置，就要使用playbook了。\n\n一个playbook由多个play组成，一个play由多个task组成，参考[Intro to Playbooks](http://docs.ansible.com/playbooks_intro.html)。\n\n一个playbook的文件内容通常是如下形式：\n\n    ---\n    - hosts: groupname\n      remote_user: yourname\n      sudo: yes\n    \n      tasks:\n        - task1\n        - task2\n\n一个play的文件内容通常是如下形式：\n\n    - task1\n    - task2\n        \n例如，批量安装wget和gcc的playbook，可以这么写：\n\n    ---\n    - hosts: all\n      remote_user: username\n      sudo: yes\n        \n      tasks:\n        - yum: name=wget state=present\n          when: ansible_distribution == 'CentOS' or ansible_distribution == 'Red Hat Enterprise Linux'\n        - yum: name=gcc state=present\n          when: ansible_distribution == 'CentOS' or ansible_distribution == 'Red Hat Enterprise Linux'\n\n这个play包含了2个task。执行一下这个playbook，看看效果:\n\n    ansible-playbook wget_playbook.yml\n\n接下来再举一个例子，我们写两个play，`play_debian.yml`和`play_centos.yml`，以及一个playbook，`playbook.yml`。\n\nplay_cenos.yml:\n\n    - yum: name=wget state=present\n    - yum: name=gcc state=present\n\nplay_deban.yml:\n\n    - apt: pkg=wget state=present\n    - apt: pkg=gcc state=present\n\nplaybook.yml:\n\n    ---\n    - hosts: all\n      remote_user: username\n      sudo: yes\n    \n      tasks:\n        - include: play_centos.yml\n          when: ansible_distribution == 'CentOS' or ansible_distribution == 'Red Hat Enterprise Linux'\n        - include: play_debian.yml\n          when: ansible_distribution == 'Debian' or ansible_distribution == 'Ubuntu'\n\n\n执行这个playbook:\n\n    ansible-playbook playbook.yml\n\n##4. 进阶\n想要进一步了解ansible，可以学习官网的例子, [ansible examples](https://github.com/ansible/ansible-examples/)。\n\n一定要仔细阅读官网给出的最佳实践规范，[Best Practices](http://docs.ansible.com/playbooks_best_practices.html)。\n","source":"_posts/2014-01-27-ansible-tutorial.md","raw":"---\nlayout: post\ntitle: \"Ansible 快速入门\"\ndate: 2014-01-27 12:10\ncomments: true\ncategories: DevOps\n---\n\nAnsible 是一个比Puppet, Chef 更轻量的provisioning 工具，不需要启动daemon进程。这点跟跟pssh差不多，但是比pssh更加强大。\n\n##前提\n* 所使用的remote_user要能够SSH无密码登录到所有机器，配置方法见[SSH无密码登录的配置](http://www.yanjiuyanjiu.com/blog/20120102/)\n* remote_use sudo的时候不需要密码，配置方法如下，\n\n        sudo chmod +w /etc/sudoers\n        sudo vim /etc/sudoers\n\n    找到 `root    ALL=(ALL:ALL) ALL`，在下面添加一行\n\n       username    ALL=(ALL:ALL) NOPASSWD:ALL\n\n    保存退出，然后恢复为只读，\n\n        sudo chmod +w /etc/sudoers \n\n如果忘记了以上两点，运行任何ansible命令的时候，会卡住不动很久。\n\n如果发现在 \"GATHERING FACTS\"这里卡住，多半是sudo需要密码，试试加上-K选项，例如`ansible-playbook -K playbook.yml`，参考[Running ansible on local Linux desktop hangs on Gathering Facts](https://groups.google.com/forum/#!topic/ansible-project/FL0mxyxOo4M)。\n\n`-vvvv`表示调试模式，加上后会输出很多中间信息，帮助你调试。\n\n##1. 安装Ansible\n只需要在一台机器上安装，其他机器不需要安装任何东西，这就是ansible比puppet, chef方便的地方。\n\n    sudo yum install ansible\n\n或者\n\n    sudo apt-get install ansible\n\n在`/etc/ansible/hosts`添加想要操作的机器(这个`hosts`文件也叫做[Inventory](http://docs.ansible.com/intro_inventory.html))，且这些机器都是能[SSH无密码登录的](http://www.yanjiuyanjiu.com/blog/20120102)，然后测试一下：\n\n    ansible all -a \"/bin/echo hello\"\n\n如果都成功了，说明安装成功。\n\n使用ansible有两种方式：Ad-hoc command 和 playbook。前者用于临时类批量操作，后者用于配置管理，类似与Puppet。\n\n##2. Ad-Hoc Commands\nAd-hoc命令的形式一般如下：\n\n    ansible groupname -m module -a arguments\n\n<!-- more -->\n例如：\n\n    ansible all -m yum -a \"name=wget state=present\"\n\n参考[Introduction To Ad-Hoc Commands](http://docs.ansible.com/intro_adhoc.html)\n\n##3. Playbook\n\n对于稳定的配置，就要使用playbook了。\n\n一个playbook由多个play组成，一个play由多个task组成，参考[Intro to Playbooks](http://docs.ansible.com/playbooks_intro.html)。\n\n一个playbook的文件内容通常是如下形式：\n\n    ---\n    - hosts: groupname\n      remote_user: yourname\n      sudo: yes\n    \n      tasks:\n        - task1\n        - task2\n\n一个play的文件内容通常是如下形式：\n\n    - task1\n    - task2\n        \n例如，批量安装wget和gcc的playbook，可以这么写：\n\n    ---\n    - hosts: all\n      remote_user: username\n      sudo: yes\n        \n      tasks:\n        - yum: name=wget state=present\n          when: ansible_distribution == 'CentOS' or ansible_distribution == 'Red Hat Enterprise Linux'\n        - yum: name=gcc state=present\n          when: ansible_distribution == 'CentOS' or ansible_distribution == 'Red Hat Enterprise Linux'\n\n这个play包含了2个task。执行一下这个playbook，看看效果:\n\n    ansible-playbook wget_playbook.yml\n\n接下来再举一个例子，我们写两个play，`play_debian.yml`和`play_centos.yml`，以及一个playbook，`playbook.yml`。\n\nplay_cenos.yml:\n\n    - yum: name=wget state=present\n    - yum: name=gcc state=present\n\nplay_deban.yml:\n\n    - apt: pkg=wget state=present\n    - apt: pkg=gcc state=present\n\nplaybook.yml:\n\n    ---\n    - hosts: all\n      remote_user: username\n      sudo: yes\n    \n      tasks:\n        - include: play_centos.yml\n          when: ansible_distribution == 'CentOS' or ansible_distribution == 'Red Hat Enterprise Linux'\n        - include: play_debian.yml\n          when: ansible_distribution == 'Debian' or ansible_distribution == 'Ubuntu'\n\n\n执行这个playbook:\n\n    ansible-playbook playbook.yml\n\n##4. 进阶\n想要进一步了解ansible，可以学习官网的例子, [ansible examples](https://github.com/ansible/ansible-examples/)。\n\n一定要仔细阅读官网给出的最佳实践规范，[Best Practices](http://docs.ansible.com/playbooks_best_practices.html)。\n","slug":"2014-01-27-ansible-tutorial","published":1,"updated":"2016-08-18T09:21:04.000Z","photos":[],"link":"","_id":"cis07pf42002k01pqrgegud7a","content":"<p>Ansible 是一个比Puppet, Chef 更轻量的provisioning 工具，不需要启动daemon进程。这点跟跟pssh差不多，但是比pssh更加强大。</p>\n<p>##前提</p>\n<ul>\n<li>所使用的remote_user要能够SSH无密码登录到所有机器，配置方法见<a href=\"http://www.yanjiuyanjiu.com/blog/20120102/\" target=\"_blank\" rel=\"external\">SSH无密码登录的配置</a></li>\n<li><p>remote_use sudo的时候不需要密码，配置方法如下，</p>\n<pre><code>sudo chmod +w /etc/sudoers\nsudo vim /etc/sudoers\n</code></pre><p>  找到 <code>root    ALL=(ALL:ALL) ALL</code>，在下面添加一行</p>\n<pre><code>username    ALL=(ALL:ALL) NOPASSWD:ALL\n</code></pre><p>  保存退出，然后恢复为只读，</p>\n<pre><code>sudo chmod +w /etc/sudoers \n</code></pre></li>\n</ul>\n<p>如果忘记了以上两点，运行任何ansible命令的时候，会卡住不动很久。</p>\n<p>如果发现在 “GATHERING FACTS”这里卡住，多半是sudo需要密码，试试加上-K选项，例如<code>ansible-playbook -K playbook.yml</code>，参考<a href=\"https://groups.google.com/forum/#!topic/ansible-project/FL0mxyxOo4M\" target=\"_blank\" rel=\"external\">Running ansible on local Linux desktop hangs on Gathering Facts</a>。</p>\n<p><code>-vvvv</code>表示调试模式，加上后会输出很多中间信息，帮助你调试。</p>\n<p>##1. 安装Ansible<br>只需要在一台机器上安装，其他机器不需要安装任何东西，这就是ansible比puppet, chef方便的地方。</p>\n<pre><code>sudo yum install ansible\n</code></pre><p>或者</p>\n<pre><code>sudo apt-get install ansible\n</code></pre><p>在<code>/etc/ansible/hosts</code>添加想要操作的机器(这个<code>hosts</code>文件也叫做<a href=\"http://docs.ansible.com/intro_inventory.html\" target=\"_blank\" rel=\"external\">Inventory</a>)，且这些机器都是能<a href=\"http://www.yanjiuyanjiu.com/blog/20120102\" target=\"_blank\" rel=\"external\">SSH无密码登录的</a>，然后测试一下：</p>\n<pre><code>ansible all -a &quot;/bin/echo hello&quot;\n</code></pre><p>如果都成功了，说明安装成功。</p>\n<p>使用ansible有两种方式：Ad-hoc command 和 playbook。前者用于临时类批量操作，后者用于配置管理，类似与Puppet。</p>\n<p>##2. Ad-Hoc Commands<br>Ad-hoc命令的形式一般如下：</p>\n<pre><code>ansible groupname -m module -a arguments\n</code></pre><a id=\"more\"></a>\n<p>例如：</p>\n<pre><code>ansible all -m yum -a &quot;name=wget state=present&quot;\n</code></pre><p>参考<a href=\"http://docs.ansible.com/intro_adhoc.html\" target=\"_blank\" rel=\"external\">Introduction To Ad-Hoc Commands</a></p>\n<p>##3. Playbook</p>\n<p>对于稳定的配置，就要使用playbook了。</p>\n<p>一个playbook由多个play组成，一个play由多个task组成，参考<a href=\"http://docs.ansible.com/playbooks_intro.html\" target=\"_blank\" rel=\"external\">Intro to Playbooks</a>。</p>\n<p>一个playbook的文件内容通常是如下形式：</p>\n<pre><code>---\n- hosts: groupname\n  remote_user: yourname\n  sudo: yes\n\n  tasks:\n    - task1\n    - task2\n</code></pre><p>一个play的文件内容通常是如下形式：</p>\n<pre><code>- task1\n- task2\n</code></pre><p>例如，批量安装wget和gcc的playbook，可以这么写：</p>\n<pre><code>---\n- hosts: all\n  remote_user: username\n  sudo: yes\n\n  tasks:\n    - yum: name=wget state=present\n      when: ansible_distribution == &apos;CentOS&apos; or ansible_distribution == &apos;Red Hat Enterprise Linux&apos;\n    - yum: name=gcc state=present\n      when: ansible_distribution == &apos;CentOS&apos; or ansible_distribution == &apos;Red Hat Enterprise Linux&apos;\n</code></pre><p>这个play包含了2个task。执行一下这个playbook，看看效果:</p>\n<pre><code>ansible-playbook wget_playbook.yml\n</code></pre><p>接下来再举一个例子，我们写两个play，<code>play_debian.yml</code>和<code>play_centos.yml</code>，以及一个playbook，<code>playbook.yml</code>。</p>\n<p>play_cenos.yml:</p>\n<pre><code>- yum: name=wget state=present\n- yum: name=gcc state=present\n</code></pre><p>play_deban.yml:</p>\n<pre><code>- apt: pkg=wget state=present\n- apt: pkg=gcc state=present\n</code></pre><p>playbook.yml:</p>\n<pre><code>---\n- hosts: all\n  remote_user: username\n  sudo: yes\n\n  tasks:\n    - include: play_centos.yml\n      when: ansible_distribution == &apos;CentOS&apos; or ansible_distribution == &apos;Red Hat Enterprise Linux&apos;\n    - include: play_debian.yml\n      when: ansible_distribution == &apos;Debian&apos; or ansible_distribution == &apos;Ubuntu&apos;\n</code></pre><p>执行这个playbook:</p>\n<pre><code>ansible-playbook playbook.yml\n</code></pre><p>##4. 进阶<br>想要进一步了解ansible，可以学习官网的例子, <a href=\"https://github.com/ansible/ansible-examples/\" target=\"_blank\" rel=\"external\">ansible examples</a>。</p>\n<p>一定要仔细阅读官网给出的最佳实践规范，<a href=\"http://docs.ansible.com/playbooks_best_practices.html\" target=\"_blank\" rel=\"external\">Best Practices</a>。</p>\n","excerpt":"<p>Ansible 是一个比Puppet, Chef 更轻量的provisioning 工具，不需要启动daemon进程。这点跟跟pssh差不多，但是比pssh更加强大。</p>\n<p>##前提</p>\n<ul>\n<li>所使用的remote_user要能够SSH无密码登录到所有机器，配置方法见<a href=\"http://www.yanjiuyanjiu.com/blog/20120102/\">SSH无密码登录的配置</a></li>\n<li><p>remote_use sudo的时候不需要密码，配置方法如下，</p>\n<pre><code>sudo chmod +w /etc/sudoers\nsudo vim /etc/sudoers\n</code></pre><p>  找到 <code>root    ALL=(ALL:ALL) ALL</code>，在下面添加一行</p>\n<pre><code>username    ALL=(ALL:ALL) NOPASSWD:ALL\n</code></pre><p>  保存退出，然后恢复为只读，</p>\n<pre><code>sudo chmod +w /etc/sudoers \n</code></pre></li>\n</ul>\n<p>如果忘记了以上两点，运行任何ansible命令的时候，会卡住不动很久。</p>\n<p>如果发现在 “GATHERING FACTS”这里卡住，多半是sudo需要密码，试试加上-K选项，例如<code>ansible-playbook -K playbook.yml</code>，参考<a href=\"https://groups.google.com/forum/#!topic/ansible-project/FL0mxyxOo4M\">Running ansible on local Linux desktop hangs on Gathering Facts</a>。</p>\n<p><code>-vvvv</code>表示调试模式，加上后会输出很多中间信息，帮助你调试。</p>\n<p>##1. 安装Ansible<br>只需要在一台机器上安装，其他机器不需要安装任何东西，这就是ansible比puppet, chef方便的地方。</p>\n<pre><code>sudo yum install ansible\n</code></pre><p>或者</p>\n<pre><code>sudo apt-get install ansible\n</code></pre><p>在<code>/etc/ansible/hosts</code>添加想要操作的机器(这个<code>hosts</code>文件也叫做<a href=\"http://docs.ansible.com/intro_inventory.html\">Inventory</a>)，且这些机器都是能<a href=\"http://www.yanjiuyanjiu.com/blog/20120102\">SSH无密码登录的</a>，然后测试一下：</p>\n<pre><code>ansible all -a &quot;/bin/echo hello&quot;\n</code></pre><p>如果都成功了，说明安装成功。</p>\n<p>使用ansible有两种方式：Ad-hoc command 和 playbook。前者用于临时类批量操作，后者用于配置管理，类似与Puppet。</p>\n<p>##2. Ad-Hoc Commands<br>Ad-hoc命令的形式一般如下：</p>\n<pre><code>ansible groupname -m module -a arguments\n</code></pre>","more":"<p>例如：</p>\n<pre><code>ansible all -m yum -a &quot;name=wget state=present&quot;\n</code></pre><p>参考<a href=\"http://docs.ansible.com/intro_adhoc.html\">Introduction To Ad-Hoc Commands</a></p>\n<p>##3. Playbook</p>\n<p>对于稳定的配置，就要使用playbook了。</p>\n<p>一个playbook由多个play组成，一个play由多个task组成，参考<a href=\"http://docs.ansible.com/playbooks_intro.html\">Intro to Playbooks</a>。</p>\n<p>一个playbook的文件内容通常是如下形式：</p>\n<pre><code>---\n- hosts: groupname\n  remote_user: yourname\n  sudo: yes\n\n  tasks:\n    - task1\n    - task2\n</code></pre><p>一个play的文件内容通常是如下形式：</p>\n<pre><code>- task1\n- task2\n</code></pre><p>例如，批量安装wget和gcc的playbook，可以这么写：</p>\n<pre><code>---\n- hosts: all\n  remote_user: username\n  sudo: yes\n\n  tasks:\n    - yum: name=wget state=present\n      when: ansible_distribution == &apos;CentOS&apos; or ansible_distribution == &apos;Red Hat Enterprise Linux&apos;\n    - yum: name=gcc state=present\n      when: ansible_distribution == &apos;CentOS&apos; or ansible_distribution == &apos;Red Hat Enterprise Linux&apos;\n</code></pre><p>这个play包含了2个task。执行一下这个playbook，看看效果:</p>\n<pre><code>ansible-playbook wget_playbook.yml\n</code></pre><p>接下来再举一个例子，我们写两个play，<code>play_debian.yml</code>和<code>play_centos.yml</code>，以及一个playbook，<code>playbook.yml</code>。</p>\n<p>play_cenos.yml:</p>\n<pre><code>- yum: name=wget state=present\n- yum: name=gcc state=present\n</code></pre><p>play_deban.yml:</p>\n<pre><code>- apt: pkg=wget state=present\n- apt: pkg=gcc state=present\n</code></pre><p>playbook.yml:</p>\n<pre><code>---\n- hosts: all\n  remote_user: username\n  sudo: yes\n\n  tasks:\n    - include: play_centos.yml\n      when: ansible_distribution == &apos;CentOS&apos; or ansible_distribution == &apos;Red Hat Enterprise Linux&apos;\n    - include: play_debian.yml\n      when: ansible_distribution == &apos;Debian&apos; or ansible_distribution == &apos;Ubuntu&apos;\n</code></pre><p>执行这个playbook:</p>\n<pre><code>ansible-playbook playbook.yml\n</code></pre><p>##4. 进阶<br>想要进一步了解ansible，可以学习官网的例子, <a href=\"https://github.com/ansible/ansible-examples/\">ansible examples</a>。</p>\n<p>一定要仔细阅读官网给出的最佳实践规范，<a href=\"http://docs.ansible.com/playbooks_best_practices.html\">Best Practices</a>。</p>"},{"layout":"post","title":"/boot 目录空间不足","date":"2014-01-26T22:07:00.000Z","comments":1,"_content":"今天在服务器上执行 `sudo yum -y update`的时候报错：\n\n> ... needs 18MB on the /boot filesystem\n\n## 1. 列出所有的内核文件\n\n    rpm -q kernel\n    kernel-2.6.32-431.el6.x86_64\n    kernel-2.6.32-431.3.1.el6.x86_64\n\n发现有多个内核，因此可以删除所有不再使用的内核文件，来释放空间。\n\n##2. 查看当前正在使用的内核\n\n    uname -r\n    2.6.32-431.3.1.el6.x86_64\n\n注意，如果你是刚刚 `yum -y update`过，需要重启一下，内核才会更新，不重启的话`uname -r`还是显示的旧的。\n\n##3. 删除没有使用的内核\n\n    rpm -e 2.6.32-431.el6.x86_64\n    rpm -e xxx\n\n将`rpm -q kernel`显示的内核复制粘贴到`xxx`位置。\n\n## 4. 手动删除其他文件\n把所有未使用的版本全部删除。\n\n    sudo rm -rf /lib/modules/2.6.32-431.el6.x86_64\n    sudo rm -rf /usr/src/kernels/2.6.32-431.el6.x86_64\n    sudo rm -rf /usr/src/kernels/2.6.32-431.el6.x86_64.debug\n    sudo rm /boot/*2.6.32-431*\n\n##5. 删除grub里的条目\n上面的步骤做完了后，最后，把grub里未使用的内核删掉，条目序号是从0开始编号的，删除条目后，记得把`default`设置为正确的序号。\n\n##6. 再执行 yum update\n\n    sudo yum -y update\n\n\n##参考资料\n[boot目录空间不足]( http://rajaruan.blog.51cto.com/2771737/868293)\n\n[yum update -y，提示/boot 空间不足的解决方法]( http://www.xiaohuai.com/3301)\n\n[如何卸载自己编译的内核？【已解决，方法见6L】](http://forum.ubuntu.org.cn/viewtopic.php?f=97&t=334647)\n","source":"_posts/2014-01-26-boot-space-insufficient.md","raw":"---\nlayout: post\ntitle: \"/boot 目录空间不足\"\ndate: 2014-01-26 22:07\ncomments: true\ncategories: DevOps\n---\n今天在服务器上执行 `sudo yum -y update`的时候报错：\n\n> ... needs 18MB on the /boot filesystem\n\n## 1. 列出所有的内核文件\n\n    rpm -q kernel\n    kernel-2.6.32-431.el6.x86_64\n    kernel-2.6.32-431.3.1.el6.x86_64\n\n发现有多个内核，因此可以删除所有不再使用的内核文件，来释放空间。\n\n##2. 查看当前正在使用的内核\n\n    uname -r\n    2.6.32-431.3.1.el6.x86_64\n\n注意，如果你是刚刚 `yum -y update`过，需要重启一下，内核才会更新，不重启的话`uname -r`还是显示的旧的。\n\n##3. 删除没有使用的内核\n\n    rpm -e 2.6.32-431.el6.x86_64\n    rpm -e xxx\n\n将`rpm -q kernel`显示的内核复制粘贴到`xxx`位置。\n\n## 4. 手动删除其他文件\n把所有未使用的版本全部删除。\n\n    sudo rm -rf /lib/modules/2.6.32-431.el6.x86_64\n    sudo rm -rf /usr/src/kernels/2.6.32-431.el6.x86_64\n    sudo rm -rf /usr/src/kernels/2.6.32-431.el6.x86_64.debug\n    sudo rm /boot/*2.6.32-431*\n\n##5. 删除grub里的条目\n上面的步骤做完了后，最后，把grub里未使用的内核删掉，条目序号是从0开始编号的，删除条目后，记得把`default`设置为正确的序号。\n\n##6. 再执行 yum update\n\n    sudo yum -y update\n\n\n##参考资料\n[boot目录空间不足]( http://rajaruan.blog.51cto.com/2771737/868293)\n\n[yum update -y，提示/boot 空间不足的解决方法]( http://www.xiaohuai.com/3301)\n\n[如何卸载自己编译的内核？【已解决，方法见6L】](http://forum.ubuntu.org.cn/viewtopic.php?f=97&t=334647)\n","slug":"2014-01-26-boot-space-insufficient","published":1,"updated":"2016-08-18T09:21:04.000Z","photos":[],"link":"","_id":"cis07pf43002m01pqxb0z9mti","content":"<p>今天在服务器上执行 <code>sudo yum -y update</code>的时候报错：</p>\n<blockquote>\n<p>… needs 18MB on the /boot filesystem</p>\n</blockquote>\n<h2 id=\"1-列出所有的内核文件\"><a href=\"#1-列出所有的内核文件\" class=\"headerlink\" title=\"1. 列出所有的内核文件\"></a>1. 列出所有的内核文件</h2><pre><code>rpm -q kernel\nkernel-2.6.32-431.el6.x86_64\nkernel-2.6.32-431.3.1.el6.x86_64\n</code></pre><p>发现有多个内核，因此可以删除所有不再使用的内核文件，来释放空间。</p>\n<p>##2. 查看当前正在使用的内核</p>\n<pre><code>uname -r\n2.6.32-431.3.1.el6.x86_64\n</code></pre><p>注意，如果你是刚刚 <code>yum -y update</code>过，需要重启一下，内核才会更新，不重启的话<code>uname -r</code>还是显示的旧的。</p>\n<p>##3. 删除没有使用的内核</p>\n<pre><code>rpm -e 2.6.32-431.el6.x86_64\nrpm -e xxx\n</code></pre><p>将<code>rpm -q kernel</code>显示的内核复制粘贴到<code>xxx</code>位置。</p>\n<h2 id=\"4-手动删除其他文件\"><a href=\"#4-手动删除其他文件\" class=\"headerlink\" title=\"4. 手动删除其他文件\"></a>4. 手动删除其他文件</h2><p>把所有未使用的版本全部删除。</p>\n<pre><code>sudo rm -rf /lib/modules/2.6.32-431.el6.x86_64\nsudo rm -rf /usr/src/kernels/2.6.32-431.el6.x86_64\nsudo rm -rf /usr/src/kernels/2.6.32-431.el6.x86_64.debug\nsudo rm /boot/*2.6.32-431*\n</code></pre><p>##5. 删除grub里的条目<br>上面的步骤做完了后，最后，把grub里未使用的内核删掉，条目序号是从0开始编号的，删除条目后，记得把<code>default</code>设置为正确的序号。</p>\n<p>##6. 再执行 yum update</p>\n<pre><code>sudo yum -y update\n</code></pre><p>##参考资料<br><a href=\"http://rajaruan.blog.51cto.com/2771737/868293\" target=\"_blank\" rel=\"external\">boot目录空间不足</a></p>\n<p><a href=\"http://www.xiaohuai.com/3301\" target=\"_blank\" rel=\"external\">yum update -y，提示/boot 空间不足的解决方法</a></p>\n<p><a href=\"http://forum.ubuntu.org.cn/viewtopic.php?f=97&amp;t=334647\" target=\"_blank\" rel=\"external\">如何卸载自己编译的内核？【已解决，方法见6L】</a></p>\n","excerpt":"","more":"<p>今天在服务器上执行 <code>sudo yum -y update</code>的时候报错：</p>\n<blockquote>\n<p>… needs 18MB on the /boot filesystem</p>\n</blockquote>\n<h2 id=\"1-列出所有的内核文件\"><a href=\"#1-列出所有的内核文件\" class=\"headerlink\" title=\"1. 列出所有的内核文件\"></a>1. 列出所有的内核文件</h2><pre><code>rpm -q kernel\nkernel-2.6.32-431.el6.x86_64\nkernel-2.6.32-431.3.1.el6.x86_64\n</code></pre><p>发现有多个内核，因此可以删除所有不再使用的内核文件，来释放空间。</p>\n<p>##2. 查看当前正在使用的内核</p>\n<pre><code>uname -r\n2.6.32-431.3.1.el6.x86_64\n</code></pre><p>注意，如果你是刚刚 <code>yum -y update</code>过，需要重启一下，内核才会更新，不重启的话<code>uname -r</code>还是显示的旧的。</p>\n<p>##3. 删除没有使用的内核</p>\n<pre><code>rpm -e 2.6.32-431.el6.x86_64\nrpm -e xxx\n</code></pre><p>将<code>rpm -q kernel</code>显示的内核复制粘贴到<code>xxx</code>位置。</p>\n<h2 id=\"4-手动删除其他文件\"><a href=\"#4-手动删除其他文件\" class=\"headerlink\" title=\"4. 手动删除其他文件\"></a>4. 手动删除其他文件</h2><p>把所有未使用的版本全部删除。</p>\n<pre><code>sudo rm -rf /lib/modules/2.6.32-431.el6.x86_64\nsudo rm -rf /usr/src/kernels/2.6.32-431.el6.x86_64\nsudo rm -rf /usr/src/kernels/2.6.32-431.el6.x86_64.debug\nsudo rm /boot/*2.6.32-431*\n</code></pre><p>##5. 删除grub里的条目<br>上面的步骤做完了后，最后，把grub里未使用的内核删掉，条目序号是从0开始编号的，删除条目后，记得把<code>default</code>设置为正确的序号。</p>\n<p>##6. 再执行 yum update</p>\n<pre><code>sudo yum -y update\n</code></pre><p>##参考资料<br><a href=\"http://rajaruan.blog.51cto.com/2771737/868293\">boot目录空间不足</a></p>\n<p><a href=\"http://www.xiaohuai.com/3301\">yum update -y，提示/boot 空间不足的解决方法</a></p>\n<p><a href=\"http://forum.ubuntu.org.cn/viewtopic.php?f=97&amp;t=334647\">如何卸载自己编译的内核？【已解决，方法见6L】</a></p>\n"},{"layout":"post","title":"Restore Octopress at a new computer","date":"2014-01-28T00:04:00.000Z","comments":1,"_content":"OS: Ubuntu 12.04 64-bit\n\n##1. Install ruby\n\n###1.1 Install ruby via RVM\n\n    $ \\curl -sSL https://get.rvm.io | bash -s stable --ruby\n\n###1.2 [Integrating RVM with gnome-terminal](https://rvm.io/integration/gnome-terminal)\n`/etc/profile`, `~/.bash_profile` are for login shell, and `~/.bashrc` is for interactive shell, and RVM's path is added to `~/.bash_profile`, so you need to set the shell as a login shell.\n\n###1.3 Give it a try\nExit current shell, and open a new shell,\n\n    ruby -v\n\nYou have successfully installed ruby.\n\n##2. Install Python\n\n    $ sudo apt-get install -y python\n\nBecause [Pygments](http://pygments.org/) syntax highlighting needs Python.\n\n\n##3. Clone your blog to the new machine\nFirst you need to clone the `source` branch to the local octopress folder.\n\n    $ git clone -b source git@github.com:username/username.github.com.git octopress\n\n<!-- more -->\nThen clone the `master` branch to the `_deploy` subfolder.\n\n    $ cd octopress\n    $ git clone git@github.com:username/username.github.com.git _deploy \n\nThen run the rake installation to configure everything\n\n    $ gem install bundler\n    $ bundle install\n\nNOW you've setup with a new local copy of your Octopress blog.\n\nYou don't need to run `rake setup_github_pages` any more.\n\n\n##4. Blogging at more than one computer\n\n###4.1 Pushing changes\nIf you want to blog at more than one computer, you need to make sure that you push everything before switching computers. From the first machine do the following whenever you’ve made changes:\n\n    $ rake new_post[\"hello world\"] \n    $ rake generate\n    $ rake deploy\n\nThis will generate your blog, copy the generated files into `_deploy/`, add them to git, commit and push them up to the master branch, see [Deploying to Github Pages](http://octopress.org/docs/deploying/github/). \nDon't forget to commit the source for your blog.\n\n    $ git add .\n    $ git commit -am \"Some comment here.\" \n    $ git push origin source  # update the remote source branch \n\n###4.2 Pull changes at another computer\n\n    $ cd octopress\n    $ git pull origin source  # update the local source branch\n    $ cd ./_deploy\n    $ git pull origin master  # update the local master branch\n\n## Reference\n[Clone Your Octopress to Blog From Two Places](http://blog.zerosharp.com/clone-your-octopress-to-blog-from-two-places/)\n\n","source":"_posts/2014-01-28-restore-octopress-at-a-new-computer.md","raw":"---\nlayout: post\ntitle: \"Restore Octopress at a new computer\"\ndate: 2014-01-28 00:04\ncomments: true\ncategories: Tools\n---\nOS: Ubuntu 12.04 64-bit\n\n##1. Install ruby\n\n###1.1 Install ruby via RVM\n\n    $ \\curl -sSL https://get.rvm.io | bash -s stable --ruby\n\n###1.2 [Integrating RVM with gnome-terminal](https://rvm.io/integration/gnome-terminal)\n`/etc/profile`, `~/.bash_profile` are for login shell, and `~/.bashrc` is for interactive shell, and RVM's path is added to `~/.bash_profile`, so you need to set the shell as a login shell.\n\n###1.3 Give it a try\nExit current shell, and open a new shell,\n\n    ruby -v\n\nYou have successfully installed ruby.\n\n##2. Install Python\n\n    $ sudo apt-get install -y python\n\nBecause [Pygments](http://pygments.org/) syntax highlighting needs Python.\n\n\n##3. Clone your blog to the new machine\nFirst you need to clone the `source` branch to the local octopress folder.\n\n    $ git clone -b source git@github.com:username/username.github.com.git octopress\n\n<!-- more -->\nThen clone the `master` branch to the `_deploy` subfolder.\n\n    $ cd octopress\n    $ git clone git@github.com:username/username.github.com.git _deploy \n\nThen run the rake installation to configure everything\n\n    $ gem install bundler\n    $ bundle install\n\nNOW you've setup with a new local copy of your Octopress blog.\n\nYou don't need to run `rake setup_github_pages` any more.\n\n\n##4. Blogging at more than one computer\n\n###4.1 Pushing changes\nIf you want to blog at more than one computer, you need to make sure that you push everything before switching computers. From the first machine do the following whenever you’ve made changes:\n\n    $ rake new_post[\"hello world\"] \n    $ rake generate\n    $ rake deploy\n\nThis will generate your blog, copy the generated files into `_deploy/`, add them to git, commit and push them up to the master branch, see [Deploying to Github Pages](http://octopress.org/docs/deploying/github/). \nDon't forget to commit the source for your blog.\n\n    $ git add .\n    $ git commit -am \"Some comment here.\" \n    $ git push origin source  # update the remote source branch \n\n###4.2 Pull changes at another computer\n\n    $ cd octopress\n    $ git pull origin source  # update the local source branch\n    $ cd ./_deploy\n    $ git pull origin master  # update the local master branch\n\n## Reference\n[Clone Your Octopress to Blog From Two Places](http://blog.zerosharp.com/clone-your-octopress-to-blog-from-two-places/)\n\n","slug":"2014-01-28-restore-octopress-at-a-new-computer","published":1,"updated":"2016-08-18T09:21:04.000Z","photos":[],"link":"","_id":"cis07pf45002p01pqy57h1pru","content":"<p>OS: Ubuntu 12.04 64-bit</p>\n<p>##1. Install ruby</p>\n<p>###1.1 Install ruby via RVM</p>\n<pre><code>$ \\curl -sSL https://get.rvm.io | bash -s stable --ruby\n</code></pre><p>###1.2 <a href=\"https://rvm.io/integration/gnome-terminal\" target=\"_blank\" rel=\"external\">Integrating RVM with gnome-terminal</a><br><code>/etc/profile</code>, <code>~/.bash_profile</code> are for login shell, and <code>~/.bashrc</code> is for interactive shell, and RVM’s path is added to <code>~/.bash_profile</code>, so you need to set the shell as a login shell.</p>\n<p>###1.3 Give it a try<br>Exit current shell, and open a new shell,</p>\n<pre><code>ruby -v\n</code></pre><p>You have successfully installed ruby.</p>\n<p>##2. Install Python</p>\n<pre><code>$ sudo apt-get install -y python\n</code></pre><p>Because <a href=\"http://pygments.org/\" target=\"_blank\" rel=\"external\">Pygments</a> syntax highlighting needs Python.</p>\n<p>##3. Clone your blog to the new machine<br>First you need to clone the <code>source</code> branch to the local octopress folder.</p>\n<pre><code>$ git clone -b source git@github.com:username/username.github.com.git octopress\n</code></pre><a id=\"more\"></a>\n<p>Then clone the <code>master</code> branch to the <code>_deploy</code> subfolder.</p>\n<pre><code>$ cd octopress\n$ git clone git@github.com:username/username.github.com.git _deploy \n</code></pre><p>Then run the rake installation to configure everything</p>\n<pre><code>$ gem install bundler\n$ bundle install\n</code></pre><p>NOW you’ve setup with a new local copy of your Octopress blog.</p>\n<p>You don’t need to run <code>rake setup_github_pages</code> any more.</p>\n<p>##4. Blogging at more than one computer</p>\n<p>###4.1 Pushing changes<br>If you want to blog at more than one computer, you need to make sure that you push everything before switching computers. From the first machine do the following whenever you’ve made changes:</p>\n<pre><code>$ rake new_post[&quot;hello world&quot;] \n$ rake generate\n$ rake deploy\n</code></pre><p>This will generate your blog, copy the generated files into <code>_deploy/</code>, add them to git, commit and push them up to the master branch, see <a href=\"http://octopress.org/docs/deploying/github/\" target=\"_blank\" rel=\"external\">Deploying to Github Pages</a>.<br>Don’t forget to commit the source for your blog.</p>\n<pre><code>$ git add .\n$ git commit -am &quot;Some comment here.&quot; \n$ git push origin source  # update the remote source branch \n</code></pre><p>###4.2 Pull changes at another computer</p>\n<pre><code>$ cd octopress\n$ git pull origin source  # update the local source branch\n$ cd ./_deploy\n$ git pull origin master  # update the local master branch\n</code></pre><h2 id=\"Reference\"><a href=\"#Reference\" class=\"headerlink\" title=\"Reference\"></a>Reference</h2><p><a href=\"http://blog.zerosharp.com/clone-your-octopress-to-blog-from-two-places/\" target=\"_blank\" rel=\"external\">Clone Your Octopress to Blog From Two Places</a></p>\n","excerpt":"<p>OS: Ubuntu 12.04 64-bit</p>\n<p>##1. Install ruby</p>\n<p>###1.1 Install ruby via RVM</p>\n<pre><code>$ \\curl -sSL https://get.rvm.io | bash -s stable --ruby\n</code></pre><p>###1.2 <a href=\"https://rvm.io/integration/gnome-terminal\">Integrating RVM with gnome-terminal</a><br><code>/etc/profile</code>, <code>~/.bash_profile</code> are for login shell, and <code>~/.bashrc</code> is for interactive shell, and RVM’s path is added to <code>~/.bash_profile</code>, so you need to set the shell as a login shell.</p>\n<p>###1.3 Give it a try<br>Exit current shell, and open a new shell,</p>\n<pre><code>ruby -v\n</code></pre><p>You have successfully installed ruby.</p>\n<p>##2. Install Python</p>\n<pre><code>$ sudo apt-get install -y python\n</code></pre><p>Because <a href=\"http://pygments.org/\">Pygments</a> syntax highlighting needs Python.</p>\n<p>##3. Clone your blog to the new machine<br>First you need to clone the <code>source</code> branch to the local octopress folder.</p>\n<pre><code>$ git clone -b source git@github.com:username/username.github.com.git octopress\n</code></pre>","more":"<p>Then clone the <code>master</code> branch to the <code>_deploy</code> subfolder.</p>\n<pre><code>$ cd octopress\n$ git clone git@github.com:username/username.github.com.git _deploy \n</code></pre><p>Then run the rake installation to configure everything</p>\n<pre><code>$ gem install bundler\n$ bundle install\n</code></pre><p>NOW you’ve setup with a new local copy of your Octopress blog.</p>\n<p>You don’t need to run <code>rake setup_github_pages</code> any more.</p>\n<p>##4. Blogging at more than one computer</p>\n<p>###4.1 Pushing changes<br>If you want to blog at more than one computer, you need to make sure that you push everything before switching computers. From the first machine do the following whenever you’ve made changes:</p>\n<pre><code>$ rake new_post[&quot;hello world&quot;] \n$ rake generate\n$ rake deploy\n</code></pre><p>This will generate your blog, copy the generated files into <code>_deploy/</code>, add them to git, commit and push them up to the master branch, see <a href=\"http://octopress.org/docs/deploying/github/\">Deploying to Github Pages</a>.<br>Don’t forget to commit the source for your blog.</p>\n<pre><code>$ git add .\n$ git commit -am &quot;Some comment here.&quot; \n$ git push origin source  # update the remote source branch \n</code></pre><p>###4.2 Pull changes at another computer</p>\n<pre><code>$ cd octopress\n$ git pull origin source  # update the local source branch\n$ cd ./_deploy\n$ git pull origin master  # update the local master branch\n</code></pre><h2 id=\"Reference\"><a href=\"#Reference\" class=\"headerlink\" title=\"Reference\"></a>Reference</h2><p><a href=\"http://blog.zerosharp.com/clone-your-octopress-to-blog-from-two-places/\">Clone Your Octopress to Blog From Two Places</a></p>"},{"layout":"post","title":"Rdesktop 快速入门","date":"2014-01-25T22:05:00.000Z","comments":1,"_content":"\nrdesktop是一款Linux下兼容Windows Remote Desktop Protocal(RDP)协议的客户端，可以用它连接开启了3389的windows机器。输入`rdesktop`可以看到该命令的所有选项，其中最常用的选项如下：\n> -u: user name\n> -p: password (- to prompt)\n> -f: full-screen mode\n> -g: desktop geometry (WxH)\n> -x: RDP5 experience (m[odem 28.8], b[roadband], l[an] or hex nr.)\n\n举几个例子，\n\n    rdesktop -u feng -p 123456 -xl -f 192.168.1.250\n\n这条命令表示，-xl表示客户端和win机器在同一个局域网，因此可以画质调节到最好，-f表示全屏，这条命令最好在局域网下使用。\n\n    rdesktop -u feng -p 123456 -xm -f 192.168.1.250\n\n跟上一条命令相比，把-xl换成了-xm，画质调节到最差\n\n    rdesktop -u feng -p 123456 -xm -g 1024x768 192.168.1.250\n\n跟上一条命令相比，将全屏改成了分辨率1024x768\n","source":"_posts/2014-01-25-rdesktop-tutorial.md","raw":"---\nlayout: post\ntitle: \"Rdesktop 快速入门\"\ndate: 2014-01-25 22:05\ncomments: true\ncategories: DevOps\n---\n\nrdesktop是一款Linux下兼容Windows Remote Desktop Protocal(RDP)协议的客户端，可以用它连接开启了3389的windows机器。输入`rdesktop`可以看到该命令的所有选项，其中最常用的选项如下：\n> -u: user name\n> -p: password (- to prompt)\n> -f: full-screen mode\n> -g: desktop geometry (WxH)\n> -x: RDP5 experience (m[odem 28.8], b[roadband], l[an] or hex nr.)\n\n举几个例子，\n\n    rdesktop -u feng -p 123456 -xl -f 192.168.1.250\n\n这条命令表示，-xl表示客户端和win机器在同一个局域网，因此可以画质调节到最好，-f表示全屏，这条命令最好在局域网下使用。\n\n    rdesktop -u feng -p 123456 -xm -f 192.168.1.250\n\n跟上一条命令相比，把-xl换成了-xm，画质调节到最差\n\n    rdesktop -u feng -p 123456 -xm -g 1024x768 192.168.1.250\n\n跟上一条命令相比，将全屏改成了分辨率1024x768\n","slug":"2014-01-25-rdesktop-tutorial","published":1,"updated":"2016-08-18T09:21:04.000Z","photos":[],"link":"","_id":"cis07pf46002s01pqnv5lbqpd","content":"<p>rdesktop是一款Linux下兼容Windows Remote Desktop Protocal(RDP)协议的客户端，可以用它连接开启了3389的windows机器。输入<code>rdesktop</code>可以看到该命令的所有选项，其中最常用的选项如下：</p>\n<blockquote>\n<p>-u: user name<br>-p: password (- to prompt)<br>-f: full-screen mode<br>-g: desktop geometry (WxH)<br>-x: RDP5 experience (m[odem 28.8], b[roadband], l[an] or hex nr.)</p>\n</blockquote>\n<p>举几个例子，</p>\n<pre><code>rdesktop -u feng -p 123456 -xl -f 192.168.1.250\n</code></pre><p>这条命令表示，-xl表示客户端和win机器在同一个局域网，因此可以画质调节到最好，-f表示全屏，这条命令最好在局域网下使用。</p>\n<pre><code>rdesktop -u feng -p 123456 -xm -f 192.168.1.250\n</code></pre><p>跟上一条命令相比，把-xl换成了-xm，画质调节到最差</p>\n<pre><code>rdesktop -u feng -p 123456 -xm -g 1024x768 192.168.1.250\n</code></pre><p>跟上一条命令相比，将全屏改成了分辨率1024x768</p>\n","excerpt":"","more":"<p>rdesktop是一款Linux下兼容Windows Remote Desktop Protocal(RDP)协议的客户端，可以用它连接开启了3389的windows机器。输入<code>rdesktop</code>可以看到该命令的所有选项，其中最常用的选项如下：</p>\n<blockquote>\n<p>-u: user name<br>-p: password (- to prompt)<br>-f: full-screen mode<br>-g: desktop geometry (WxH)<br>-x: RDP5 experience (m[odem 28.8], b[roadband], l[an] or hex nr.)</p>\n</blockquote>\n<p>举几个例子，</p>\n<pre><code>rdesktop -u feng -p 123456 -xl -f 192.168.1.250\n</code></pre><p>这条命令表示，-xl表示客户端和win机器在同一个局域网，因此可以画质调节到最好，-f表示全屏，这条命令最好在局域网下使用。</p>\n<pre><code>rdesktop -u feng -p 123456 -xm -f 192.168.1.250\n</code></pre><p>跟上一条命令相比，把-xl换成了-xm，画质调节到最差</p>\n<pre><code>rdesktop -u feng -p 123456 -xm -g 1024x768 192.168.1.250\n</code></pre><p>跟上一条命令相比，将全屏改成了分辨率1024x768</p>\n"},{"layout":"post","title":"给CentOS安装UEK内核","date":"2014-01-31T22:05:00.000Z","comments":1,"_content":"\n最近给CentOS 6.5 安装了docker，不过每次运行都会报警：\n\n> WARNING: You are running linux kernel version 2.6.32-431.3.1.el6.x86_64, which might be unstable running docker. Please upgrade your kernel to 3.8.0.\n\n给CentOS 升级内核，有三种途径，一种是yum官方源里有更新的版本，一种途径是自己编译，另一种途径是使用别人编译好了的内核。\n\nCentOS yum源是出了名的更新慢，目前没有 3.8版内核，第二种途径很麻烦，工作量很大，因此本文用第三种。例如UEK，Oracle提供了一个公共的yum源，<http://public-yum.oracle.com/>\n\n##添加yum源\n\nUEK的稳定版还是 2.6 内核的，beta版的内核是3.8的，所以我们使用beta源\n\n    sudo wget http://public-yum.oracle.com/beta/public-yum-ol6-beta.repo -P /etc/yum.repos.d\n\n由于UEK3还没有加入到正式版本中，还目前属于测试阶段，，需要手工将 `enabled=0`改为 `enabled=1`\n\n    sudo vim /etc/yum.repos.d/public-yum-ol6-beta.repo\n\n##添加GPG key\n\n    sudo wget http://public-yum.oracle.com/RPM-GPG-KEY-oracle-ol6 -O /etc/pki/rpm-gpg/RPM-GPG-KEY-oracle\n    gpg --quiet --with-fingerprint /etc/pki/rpm-gpg/RPM-GPG-KEY-oracle\n\n##更新yum源\n\n    sudo yum update\n\n##列出所有的kernel\n\n    yum list kernel*\n    \n<!-- more -->\n\n##安装 kernel\n\n    sudo yum install kernel-uek\n\n##修改/etc/grub.conf\n修改 `/etc/grub.conf`，将`default`设置为UEK，一般新安装的内核会在一个，所以设置 `default=0`。\n\n##重启\n\n    sudo reboot\n    uname -r\n    3.8.13-16.el6uek.x86_64\n\n内核切换成功了。\n    \n##测试一下，docker不再报警了\n\n    sudo docker service docker stop\n    sudo docker -d\n\n`Ctrl+C` 终止 docker，然后用 `sudo service docker start` 再次启动docker。\n\n##参考资料\n[Public Yum Server from Oracle](http://public-yum.oracle.com/)\n\n[UEK R3升级手记](http://blog.liulantao.com/Technology/2013/09/23/kernel-uek-3813-upgrade-notes.html)\n\n","source":"_posts/2014-01-31-install-uek-for-centos.md","raw":"---\nlayout: post\ntitle: \"给CentOS安装UEK内核\"\ndate: 2014-01-31 22:05\ncomments: true\ncategories: DevOps\n---\n\n最近给CentOS 6.5 安装了docker，不过每次运行都会报警：\n\n> WARNING: You are running linux kernel version 2.6.32-431.3.1.el6.x86_64, which might be unstable running docker. Please upgrade your kernel to 3.8.0.\n\n给CentOS 升级内核，有三种途径，一种是yum官方源里有更新的版本，一种途径是自己编译，另一种途径是使用别人编译好了的内核。\n\nCentOS yum源是出了名的更新慢，目前没有 3.8版内核，第二种途径很麻烦，工作量很大，因此本文用第三种。例如UEK，Oracle提供了一个公共的yum源，<http://public-yum.oracle.com/>\n\n##添加yum源\n\nUEK的稳定版还是 2.6 内核的，beta版的内核是3.8的，所以我们使用beta源\n\n    sudo wget http://public-yum.oracle.com/beta/public-yum-ol6-beta.repo -P /etc/yum.repos.d\n\n由于UEK3还没有加入到正式版本中，还目前属于测试阶段，，需要手工将 `enabled=0`改为 `enabled=1`\n\n    sudo vim /etc/yum.repos.d/public-yum-ol6-beta.repo\n\n##添加GPG key\n\n    sudo wget http://public-yum.oracle.com/RPM-GPG-KEY-oracle-ol6 -O /etc/pki/rpm-gpg/RPM-GPG-KEY-oracle\n    gpg --quiet --with-fingerprint /etc/pki/rpm-gpg/RPM-GPG-KEY-oracle\n\n##更新yum源\n\n    sudo yum update\n\n##列出所有的kernel\n\n    yum list kernel*\n    \n<!-- more -->\n\n##安装 kernel\n\n    sudo yum install kernel-uek\n\n##修改/etc/grub.conf\n修改 `/etc/grub.conf`，将`default`设置为UEK，一般新安装的内核会在一个，所以设置 `default=0`。\n\n##重启\n\n    sudo reboot\n    uname -r\n    3.8.13-16.el6uek.x86_64\n\n内核切换成功了。\n    \n##测试一下，docker不再报警了\n\n    sudo docker service docker stop\n    sudo docker -d\n\n`Ctrl+C` 终止 docker，然后用 `sudo service docker start` 再次启动docker。\n\n##参考资料\n[Public Yum Server from Oracle](http://public-yum.oracle.com/)\n\n[UEK R3升级手记](http://blog.liulantao.com/Technology/2013/09/23/kernel-uek-3813-upgrade-notes.html)\n\n","slug":"2014-01-31-install-uek-for-centos","published":1,"updated":"2016-08-18T09:21:04.000Z","photos":[],"link":"","_id":"cis07pf48002u01pqeb8z2s8e","content":"<p>最近给CentOS 6.5 安装了docker，不过每次运行都会报警：</p>\n<blockquote>\n<p>WARNING: You are running linux kernel version 2.6.32-431.3.1.el6.x86_64, which might be unstable running docker. Please upgrade your kernel to 3.8.0.</p>\n</blockquote>\n<p>给CentOS 升级内核，有三种途径，一种是yum官方源里有更新的版本，一种途径是自己编译，另一种途径是使用别人编译好了的内核。</p>\n<p>CentOS yum源是出了名的更新慢，目前没有 3.8版内核，第二种途径很麻烦，工作量很大，因此本文用第三种。例如UEK，Oracle提供了一个公共的yum源，<a href=\"http://public-yum.oracle.com/\" target=\"_blank\" rel=\"external\">http://public-yum.oracle.com/</a></p>\n<p>##添加yum源</p>\n<p>UEK的稳定版还是 2.6 内核的，beta版的内核是3.8的，所以我们使用beta源</p>\n<pre><code>sudo wget http://public-yum.oracle.com/beta/public-yum-ol6-beta.repo -P /etc/yum.repos.d\n</code></pre><p>由于UEK3还没有加入到正式版本中，还目前属于测试阶段，，需要手工将 <code>enabled=0</code>改为 <code>enabled=1</code></p>\n<pre><code>sudo vim /etc/yum.repos.d/public-yum-ol6-beta.repo\n</code></pre><p>##添加GPG key</p>\n<pre><code>sudo wget http://public-yum.oracle.com/RPM-GPG-KEY-oracle-ol6 -O /etc/pki/rpm-gpg/RPM-GPG-KEY-oracle\ngpg --quiet --with-fingerprint /etc/pki/rpm-gpg/RPM-GPG-KEY-oracle\n</code></pre><p>##更新yum源</p>\n<pre><code>sudo yum update\n</code></pre><p>##列出所有的kernel</p>\n<pre><code>yum list kernel*\n</code></pre><a id=\"more\"></a>\n<p>##安装 kernel</p>\n<pre><code>sudo yum install kernel-uek\n</code></pre><p>##修改/etc/grub.conf<br>修改 <code>/etc/grub.conf</code>，将<code>default</code>设置为UEK，一般新安装的内核会在一个，所以设置 <code>default=0</code>。</p>\n<p>##重启</p>\n<pre><code>sudo reboot\nuname -r\n3.8.13-16.el6uek.x86_64\n</code></pre><p>内核切换成功了。</p>\n<p>##测试一下，docker不再报警了</p>\n<pre><code>sudo docker service docker stop\nsudo docker -d\n</code></pre><p><code>Ctrl+C</code> 终止 docker，然后用 <code>sudo service docker start</code> 再次启动docker。</p>\n<p>##参考资料<br><a href=\"http://public-yum.oracle.com/\" target=\"_blank\" rel=\"external\">Public Yum Server from Oracle</a></p>\n<p><a href=\"http://blog.liulantao.com/Technology/2013/09/23/kernel-uek-3813-upgrade-notes.html\" target=\"_blank\" rel=\"external\">UEK R3升级手记</a></p>\n","excerpt":"<p>最近给CentOS 6.5 安装了docker，不过每次运行都会报警：</p>\n<blockquote>\n<p>WARNING: You are running linux kernel version 2.6.32-431.3.1.el6.x86_64, which might be unstable running docker. Please upgrade your kernel to 3.8.0.</p>\n</blockquote>\n<p>给CentOS 升级内核，有三种途径，一种是yum官方源里有更新的版本，一种途径是自己编译，另一种途径是使用别人编译好了的内核。</p>\n<p>CentOS yum源是出了名的更新慢，目前没有 3.8版内核，第二种途径很麻烦，工作量很大，因此本文用第三种。例如UEK，Oracle提供了一个公共的yum源，<a href=\"http://public-yum.oracle.com/\">http://public-yum.oracle.com/</a></p>\n<p>##添加yum源</p>\n<p>UEK的稳定版还是 2.6 内核的，beta版的内核是3.8的，所以我们使用beta源</p>\n<pre><code>sudo wget http://public-yum.oracle.com/beta/public-yum-ol6-beta.repo -P /etc/yum.repos.d\n</code></pre><p>由于UEK3还没有加入到正式版本中，还目前属于测试阶段，，需要手工将 <code>enabled=0</code>改为 <code>enabled=1</code></p>\n<pre><code>sudo vim /etc/yum.repos.d/public-yum-ol6-beta.repo\n</code></pre><p>##添加GPG key</p>\n<pre><code>sudo wget http://public-yum.oracle.com/RPM-GPG-KEY-oracle-ol6 -O /etc/pki/rpm-gpg/RPM-GPG-KEY-oracle\ngpg --quiet --with-fingerprint /etc/pki/rpm-gpg/RPM-GPG-KEY-oracle\n</code></pre><p>##更新yum源</p>\n<pre><code>sudo yum update\n</code></pre><p>##列出所有的kernel</p>\n<pre><code>yum list kernel*\n</code></pre>","more":"<p>##安装 kernel</p>\n<pre><code>sudo yum install kernel-uek\n</code></pre><p>##修改/etc/grub.conf<br>修改 <code>/etc/grub.conf</code>，将<code>default</code>设置为UEK，一般新安装的内核会在一个，所以设置 <code>default=0</code>。</p>\n<p>##重启</p>\n<pre><code>sudo reboot\nuname -r\n3.8.13-16.el6uek.x86_64\n</code></pre><p>内核切换成功了。</p>\n<p>##测试一下，docker不再报警了</p>\n<pre><code>sudo docker service docker stop\nsudo docker -d\n</code></pre><p><code>Ctrl+C</code> 终止 docker，然后用 <code>sudo service docker start</code> 再次启动docker。</p>\n<p>##参考资料<br><a href=\"http://public-yum.oracle.com/\">Public Yum Server from Oracle</a></p>\n<p><a href=\"http://blog.liulantao.com/Technology/2013/09/23/kernel-uek-3813-upgrade-notes.html\">UEK R3升级手记</a></p>"},{"layout":"post","title":"在CentOS上安装Hadoop集群","date":"2014-02-02T12:39:00.000Z","comments":1,"_content":"Ubuntu上安装，请参考我的另一篇博客，[在Ubuntu上安装Hadoop](http://www.yanjiuyanjiu.com/blog/20120103/)。\n\n**环境**：CentOS 6.5, OPenJDK 1.7, Hadoop 1.2.1\n\n本文主要参考官网的文档，[Hadoop 1.2.1 Getting Started](http://hadoop.apache.org/docs/r1.2.1/#Getting+Started)\n\n##1 单机模式(Standalone Mode)\n为了能顺利安装成功，我们先练习在单台机器上安装Hadoop。在单台机器上，可以配置成单机模式(Standalone Mode)和伪分布式模式(Pseudo-Distributed Mode)，参考官方文档[Single Node Setup](http://hadoop.apache.org/docs/r1.2.1/single_node_setup.html)。\n\n###1.1 下载Hadoop 1.2.1，解压\n用浏览器下载或wget,\n\n    $ wget http://mirror.olnevhost.net/pub/apache/hadoop/common/stable1/hadoop-1.2.1-bin.tar.gz\n    $ tar -zxf hadoop-1.2.1-bin.tar.gz -C ~/local/opt\n    $ cd ~/local/opt/hadoop-1.2.1\n\n###1.2 编辑 conf/hadoop-env.sh，设置 `JAVA_HOME`\n\n    $ echo $JAVA_HOME\n    /usr/lib/jvm/java\n    $ vim conf/hadoop-env.sh\n\n取消`JAVA_HOME`那一行的注释，设置正确的JDK位置\n\n    export JAVA_HOME=/usr/lib/jvm/java\n\n###1.3 运行一个job\n默认情况下，Hadoop就被配置为Standalone模式了，此时Hadoop的所有模块都运行在一个java进程里。\n\n我们运行一个例子测试一下。下面的几行命令，把 `conf`下的所有xml文件作为输入，在文件中查找指定的正则表达式，把匹配的结果输出到`output`目录。\n\n    $ mkdir input \n    $ cp conf/*.xml input \n    $ bin/hadoop jar hadoop-examples-*.jar grep input output 'dfs[a-z.]+' \n    $ cat output/*\n\n可以看到正常的结果，说明单机模式运行成功了，下面开始配置伪分布式模式。\n\n<!-- more -->\n\n##2 伪分布式模式(Pseudo-Distributed Mode)\nHadoop能在单台机器上以伪分布式模式运行，即每个Hadoop模块运行在单独的java进程里。\n\n\n###2.1 编辑 conf/hadoop-env.sh，设置 `JAVA_HOME`\n\n    $ echo $JAVA_HOME\n    /usr/lib/jvm/java\n    $ vim conf/hadoop-env.sh\n\n###2.2 设置无密码SSH登录\n先检查一下是能够无密码登录本机，\n\n    ssh localhost\n\n如果提示输入密码，说明不能，按如下步骤设置。\n\n    $ ssh-keygen -t dsa -P '' -f ~/.ssh/id_dsa \n    $ cat ~/.ssh/id_dsa.pub >> ~/.ssh/authorized_keys\n\n###2.3 配置\n\nconf/core-site.xml:\n\n    <configuration>\n         <property>\n             <name>fs.default.name</name>\n             <value>hdfs://localhost:9000</value>\n         </property>\n    </configuration>\n\nconf/hdfs-site.xml:\n\n    <configuration>\n         <property>\n             <name>dfs.replication</name>\n             <value>1</value>\n         </property>\n    </configuration>\n\nconf/mapred-site.xml:\n\n    <configuration>\n         <property>\n             <name>mapred.job.tracker</name>\n             <value>localhost:9001</value>\n         </property>\n    </configuration>\n\n\n\n###2.4 启动Hadoop\n\n格式化namenode\n\n\t$ bin/hadoop namenode -format\n\n启动 Hadoop 后台进程\n\n\t$ bin/start-all.sh\n\nHadoop的log写入到了`${HADOOP_HOME}/logs`目录下。\n\n现在可以用浏览器打开NameNode和JobTracker的web界面了。\n\n* NameNode - <http://localhost:50070/>\n* JobTracker - <http://localhost:50030/>\n\n\n###2.5 运行一个例子\n运行的例子跟单机模式下的例子相同。\n\n将输入数据拷贝到分布式文件系统中:\n\n    $ bin/hadoop fs -put conf input\n\n运行 Hadoop 自带的例子:\n\n    $ bin/hadoop jar hadoop-examples-*.jar grep input output 'dfs[a-z.]+'\n\n查看输出文件:\n\n    $ bin/hadoop fs -cat output/*\n\n    1\tdfs.replication\n    1\tdfs.server.namenode.\n    1\tdfsadmin\n\n结束后，关闭 Hadoop:\n\n    $ bin/stop-all.sh\n\n    stopping jobtracker\n    localhost: stopping tasktracker\n    stopping namenode\n    localhost: stopping datanode\n    localhost: stopping secondarynamenode\n\n##3 分布式模式(Fully-Distributed Mode)\n主要参考官方文档[Cluster Setup](http://hadoop.apache.org/docs/r1.2.1/cluster_setup.html).\n\n###3.1 准备3台机器\n如果你已经有了三台机器，这一步可以省略。\n\n如果没有，则可以用VMware Workstation 或 VirtualBox创建3台虚拟机。首先用vmware workstation 新建一台CentOS 6.5，装好操作系统，选择 Basic Server，安装JDK，参考我的另一篇博客，[安装和配置CentOS服务器的详细步骤](http://www.yanjiuyanjiu.com/blog/20120423/)。安装好后然后用**浅拷贝**`Create a linked clone` 克隆出2台，这样有了3台虚拟机。启动3台机器，假设IP分别为`192.168.1.131, 192.168.1.132, 192.168.1.133`, 131做为NameNode,JobTracker和SecondaryNameNode，身兼3个角色，这3个角色应该放到3台不同的机器上，这里为了简化，用一台机器来做3个角色；132和133为 slave。三台机器上的用户名是`hadoop`，也可以用其他用户名，但必须三台机器都相同。\n\n####3.1.1 关闭防火墙\n临时关闭防火墙\n\n\t$ sudo service iptables stop\n\n下次开机后，防火墙还是会启动。\n\n永久关闭防火墙\n\n\t$ sudo chkconfig iptables off\n\n由于这几台虚拟机是开发机，不是生产环境，因此不必考虑安全性，可以永久关闭防火墙，还能给开发阶段带来很多便利。\n\n####3.1.2 修改hostname\n如果集群中的每一台机器事先已经有了hostname，则这一步可以跳过。\n\n这一步看起来貌似不必要，其实是必须的，否则最后运行wordcount等例子时，会出现“Too many fetch-failures”。因为HDFS用hostname而不是IP，来相互之间进行通信（见后面的注意1）。\n\n在CentOS上修改hostname，包含两个步骤(假设将hostname1改为hostname2，参考[这里](http://www.ichiayi.com/wiki/tech/linux_hostname)，但不需要第一步)：\n\n1. 将 `/etc/sysconfig/network` 內的 HOSTNAME 改成 yourhostname\n2. 用`hostname`命令，临时修改机器名， `sudo hostname yourhostname`\n\n用`exit`命令退出shell，再次登录，命令提示字符串就会变成`[username@yourhostname ~]$`。\n\n用上述方法，将131改名为master，132改名为slave01，133改名为slave02。\n\n**注意**，对于有的Ubuntu/Debia 系统，会把本机的hostname解析成 127.0.1.1，例如：\n\n    127.0.0.1       localhost\n    127.0.1.1       master\n\n将第二行改为(参考[利用Cloudera实现Hadoop](http://wiki.ubuntu.org.cn/%E5%88%A9%E7%94%A8Cloudera%E5%AE%9E%E7%8E%B0Hadoop))\n\n    127.0.0.1       master\n\n####3.1.3 修改所有机器的`/etc/hosts`文件\n在所有机器的`/etc/hosts`文件中，添加所有hostname对应的IP，一般在一台机器上设置好，然后scp到所有机器。例如\n\n\t192.168.1.131 master\n\t192.168.1.132 slave01\n\t192.168.1.133 slave02\n\n##3.2 配置 master 无密码登陆到所有机器（包括master自己登陆自己）\n参考我的另一篇博客，[SSH无密码登录的配置](http://www.yanjiuyanjiu.com/blog/20120102/)\n\n##3.3 把Hadoop压缩包上传到所有机器，并解压\n将 hadoop-1.2.1-bin.tar.gz 上传到所有机器，然后解压。**注意，所有机器的hadoop路径必须一致，因为master会登陆到slave上执行命令，master认为slave的hadoop路径与自己一样。**\n\n下面开始配置，配置好了后，把conf 目录scp到所有其他机器。\n\n\n###3.4 修改6个配置文件\nHadoop的配置文件比较多，其设计原则可以概括为如下两点：\n\n* 尽可能模块化。例如core-xxx.xml是针对基础公共库core的，hdfs-xxx.xml是针对分布式文件系统HDFS的，mapred-xxx.xml是针对分布式计算框架MapReduce的。\n* 动静分离。例如，在Hadoop 1.0.0之前，作业队列权限管理相关的配置被放在mapred-site.xml里，而该文件爱你是不可以动态加载的，每次修改后必须重启Hadoop，但从 1.0.0后，这些配置选项被剥离出来放到独立的配置文件mapred-queue-acls.xml中，该文件可以通过Hadoop命令动态加载。在conf下，core-default.xml, hdfs-default.xml和mapred-default.xml是只读的，core-site.xml, hdfs-site.xml和mapred-site.xml才是用户可以修改的。要想覆盖默认配置，就在xxx-site.xml里修改。\n\n以下操作在master上进行。\n\n###3.4.1 conf/hadoop-env.sh\n在 conf/hadoop-env.sh里，设置 `JAVA_HOME`。如果集群中，每台机器的JDK不一定统一安装在同一个路径，那就要在每个节点的hadoop-env.sh里分别设置`JAVA_HOME`。\n\n    export JAVA_HOME=/usr/lib/jvm/java\n\n还要设置`HADOOP_PID_DIR`，这里我们令其为`HADOOP_PID_DIR=/home/hadoop/local/var/hadoop/pids`，参考[Hadoop的pid配置](http://www.iteye.com/topic/299219)。\n\n    export HADOOP_PID_DIR=/home/hadoop/local/var/hadoop/pids\n\n注意，还要**禁用IPv6**，用命令`cat /proc/sys/net/ipv6/conf/all/disable_ipv6`检查一下系统是否启用了IPv6，如果是0,说明启用了。Hadoop在IPv6的情况下运行不正常，因此需禁用IPv6。\n\n不过我们不用真的禁用IPv6，还有另外一种方法，让java优先选择IPv4即可，在conf/hadoop-env.sh 里添加如下一行，\n\n    export HADOOP_OPTS=\"-server -Djava.net.preferIPv4Stack=true $HADOOP_OPTS\"\n\n参考[Disabling IPv6](http://www.michael-noll.com/tutorials/running-hadoop-on-ubuntu-linux-single-node-cluster/#disabling-ipv6)，以及Web Crawling and Data Mining with Apache Nutch这本书的第66页。\n\n###3.4.2 conf/masters\n\n\tmaster\n\n###3.4.3 conf/slaves\n\n\tslave01\n\tslave02\n\n这里解释一下，masters文件，存放的其实是SecondaryNameNode。关于masters和slaves两个配置文件，更精确的说明见这个StackOverflow答案，[hadoop conf/masters and conf/slaves on jobtracker?](http://stackoverflow.com/a/19779590/381712)\n\n###3.4.4 conf/core-site.xml\n\n\t<configuration>\n\t    <property>\n\t        <name>fs.default.name</name>\n\t        <value>hdfs://master:9000</value>\n\t    </property>\n\t    <property>\n\t        <name>fs.checkpoint.dir</name>\n\t        <value>/home/hadoop/local/var/hadoop/dfs/namesecondary</value>\n\t    </property>\n\t</configuration>\n\nHadoop会自动创建目录。\n\n###3.4.5 conf/hdfs-site.xml\n\n\t<configuration>\n\t     <property>\n\t         <name>dfs.name.dir</name>\n\t         <value>/home/hadoop/local/var/hadoop/dfs/name</value>\n\t     </property>\n\t     <property>\n\t         <name>dfs.data.dir</name>\n\t         <value>/home/hadoop/local/var/hadoop/dfs/data</value>\n\t     </property>\n\t     <property>\n\t       <name>dfs.replication</name>\n\t       <value>2</value>\n\t     </property>\n\t</configuration>\n\n我们只有2台slave，因此`dfs.replication`设置为2。\n\nHadoop会自动在master创建 /home/hadoop/local/var/hadoop/dfs/name 目录，在 slaves上创建 /home/hadoop/local/var/hadoop/dfs/data 目录。\n\n###3.4.6 conf/mapred-site.xml\n\n\t<configuration>\n\t    <property>\n\t        <name>mapred.job.tracker</name>\n\t        <value>master:9001</value>\n\t    </property>\n\t    <property>\n\t        <name>mapred.local.dir</name>\n\t        <value>/home/hadoop/local/var/hadoop/mapred/local</value>\n\t    </property>\n\t    <property>\n\t        <name>mapreduce.jobtracker.staging.root.dir</name>\n\t        <value>/user</value>\n\t    </property>\n\t</configuration>\n\n###3.5 将配置文件拷贝到所有slaves\n\n\t$ cd ~/local/opt/hadoop-1.2.1/conf/\n\t$ scp hadoop-env.sh core-site.xml hdfs-site.xml mapred-site.xml masters slaves hadoop@slave01:~/local/opt/hadoop-1.2.1/conf/\n\t$ scp hadoop-env.sh core-site.xml hdfs-site.xml mapred-site.xml masters slaves hadoop@slave02:~/local/opt/hadoop-1.2.1/conf/\n\n###3.6 运行 hadoop\n在master上执行以下命令，启动hadoop\n\n\t$ cd ~/local/opt/hadoop-1.2.1/\n\t#只需一次，下次启动不再需要格式化，只需 start-all.sh\n\t$ bin/hadoop namenode -format\n\t$ bin/start-all.sh\n\n###3.7 检查是否启动成功\n\n在master上执行：\n\n\t$ jps\n\t\n\t2615 NameNode\n\t2767 JobTracker\n\t2874 Jps\n\n在一台slave上执行：\n\n\t$ jps\n\t\n\t3415 DataNode\n\t3582 TaskTracker\n\t3499 SecondaryNameNode\n\t3619 Jps\n\n在另一台slave上执行：\n\n\t$ jps\n\t\n\t3741 Jps\n\t3618 DataNode\n\t3702 TaskTracker\n\n可见进程都启动起来了，说明hadoop运行成功。\n\n###3.8 运行wordcount例子，进一步测试是否安装成功\n将输入数据拷贝到分布式文件系统中:\n\n\t$ cd ~/local/opt/hadoop-1.2.1/\n\t$ bin/hadoop fs -put conf input\n\n运行 Hadoop 自带的例子:\n\n\t$ bin/hadoop jar hadoop-examples-*.jar wordcount input output\n\n查看输出文件:\n\n\t$ bin/hadoop fs -ls output\n\t$ bin/hadoop fs -cat output/part-r-00000\n\n如果能看到结果，说明这个例子运行成功。\n\n###3.9 停止 hadoop集群\n在master上执行：\n\n\t$ bin/stop-all.sh\n\n###3.10 （可选）在master上设置环境变量HADOOP\\_PREFIX，并将HADOOP\\_PREFIX/bin加入PATH\n这一步是为了将bin目录加入PATH，这样可以在任何位置执行hadoop的各种命令。这步是可选的。\n\nHadoop不推荐使用`HADOOP_HOME`，你可以试一下，当设置了`HADOOP_HOME`后，执行`bin/start-all.sh`，第一行会打印出一行警告信息，`Warning: $HADOOP_HOME is deprecated.` 应该用`HADOOP_PREFIX`代替，见邮件列表里的这封[邮件](http://mail-archives.apache.org/mod_mbox/hadoop-common-user/201202.mbox/%3CCB4ECC21.33727%25evans@yahoo-inc.com%3E)。\n\n给所有机器设置环境变量`HADOOP_PREFIX`，并将`$HADOOP_PREFIX/bin`加入PATH。\n\n在 `~/.bashrc`中添加如下4行：\n\n    export HADOOP_PREFIX=$HOME/local/opt/hadoop-1.2.1\n    export PATH=$PATH:$HADOOP_PREFIX/bin\n\nsource使之立刻生效，\n\n\t$ source ~/.bashrc\n\n\n##4. 排除错误\n本文已经尽可能的把步骤详细列出来了，但是我相信大部分人不会一次成功。这时候，查找错误就很重要了。查找错误最重要的手段是查看hadoop的日志，一般在logs目录下。把错误消息复制粘贴到google，搜索一下，慢慢找错误。\n\n##注意\n1. 所有配置文件只能用hostname，不能用IP。两年前我不懂，还为此[在stackoverflow上发了帖子](http://stackoverflow.com/questions/8702637/hadoop-conf-fs-default-name-cant-be-setted-ipport-format-directly)。hadoop会反向解析hostname，即使是用了IP，也会使用hostname 来启动TaskTracker。参考[hdfs LAN ip address hostname resolution](http://stackoverflow.com/questions/15230946/hdfs-lan-ip-address-hostname-resolution)，[hadoop入门经验总结- 杨贵堂的博客](http://www.makenotes.net/?p=337004)，[hadoop集群配置](http://51mst.iteye.com/blog/1152439)。\n1. 在第2.5步骤，如果出现 `SafeModeException` 异常，不用担心，等待几分钟即可。因为hadoop刚刚启动时，会进入安全模式进行自检，这需要花点时间。\n1. 如果在任何一步失败，可以`stop-all.sh`, 然后`hadoop  namenode -format`，重试几次，一般可以成功。如果还是不成功，多看看 logs目录下的日志文件，把错误消息复制粘贴到google，搜索答案。\n\n","source":"_posts/2014-02-02-hadoop-installatioin-on-centos.md","raw":"---\nlayout: post\ntitle: \"在CentOS上安装Hadoop集群\"\ndate: 2014-02-02 12:39\ncomments: true\ncategories: Hadoop\n---\nUbuntu上安装，请参考我的另一篇博客，[在Ubuntu上安装Hadoop](http://www.yanjiuyanjiu.com/blog/20120103/)。\n\n**环境**：CentOS 6.5, OPenJDK 1.7, Hadoop 1.2.1\n\n本文主要参考官网的文档，[Hadoop 1.2.1 Getting Started](http://hadoop.apache.org/docs/r1.2.1/#Getting+Started)\n\n##1 单机模式(Standalone Mode)\n为了能顺利安装成功，我们先练习在单台机器上安装Hadoop。在单台机器上，可以配置成单机模式(Standalone Mode)和伪分布式模式(Pseudo-Distributed Mode)，参考官方文档[Single Node Setup](http://hadoop.apache.org/docs/r1.2.1/single_node_setup.html)。\n\n###1.1 下载Hadoop 1.2.1，解压\n用浏览器下载或wget,\n\n    $ wget http://mirror.olnevhost.net/pub/apache/hadoop/common/stable1/hadoop-1.2.1-bin.tar.gz\n    $ tar -zxf hadoop-1.2.1-bin.tar.gz -C ~/local/opt\n    $ cd ~/local/opt/hadoop-1.2.1\n\n###1.2 编辑 conf/hadoop-env.sh，设置 `JAVA_HOME`\n\n    $ echo $JAVA_HOME\n    /usr/lib/jvm/java\n    $ vim conf/hadoop-env.sh\n\n取消`JAVA_HOME`那一行的注释，设置正确的JDK位置\n\n    export JAVA_HOME=/usr/lib/jvm/java\n\n###1.3 运行一个job\n默认情况下，Hadoop就被配置为Standalone模式了，此时Hadoop的所有模块都运行在一个java进程里。\n\n我们运行一个例子测试一下。下面的几行命令，把 `conf`下的所有xml文件作为输入，在文件中查找指定的正则表达式，把匹配的结果输出到`output`目录。\n\n    $ mkdir input \n    $ cp conf/*.xml input \n    $ bin/hadoop jar hadoop-examples-*.jar grep input output 'dfs[a-z.]+' \n    $ cat output/*\n\n可以看到正常的结果，说明单机模式运行成功了，下面开始配置伪分布式模式。\n\n<!-- more -->\n\n##2 伪分布式模式(Pseudo-Distributed Mode)\nHadoop能在单台机器上以伪分布式模式运行，即每个Hadoop模块运行在单独的java进程里。\n\n\n###2.1 编辑 conf/hadoop-env.sh，设置 `JAVA_HOME`\n\n    $ echo $JAVA_HOME\n    /usr/lib/jvm/java\n    $ vim conf/hadoop-env.sh\n\n###2.2 设置无密码SSH登录\n先检查一下是能够无密码登录本机，\n\n    ssh localhost\n\n如果提示输入密码，说明不能，按如下步骤设置。\n\n    $ ssh-keygen -t dsa -P '' -f ~/.ssh/id_dsa \n    $ cat ~/.ssh/id_dsa.pub >> ~/.ssh/authorized_keys\n\n###2.3 配置\n\nconf/core-site.xml:\n\n    <configuration>\n         <property>\n             <name>fs.default.name</name>\n             <value>hdfs://localhost:9000</value>\n         </property>\n    </configuration>\n\nconf/hdfs-site.xml:\n\n    <configuration>\n         <property>\n             <name>dfs.replication</name>\n             <value>1</value>\n         </property>\n    </configuration>\n\nconf/mapred-site.xml:\n\n    <configuration>\n         <property>\n             <name>mapred.job.tracker</name>\n             <value>localhost:9001</value>\n         </property>\n    </configuration>\n\n\n\n###2.4 启动Hadoop\n\n格式化namenode\n\n\t$ bin/hadoop namenode -format\n\n启动 Hadoop 后台进程\n\n\t$ bin/start-all.sh\n\nHadoop的log写入到了`${HADOOP_HOME}/logs`目录下。\n\n现在可以用浏览器打开NameNode和JobTracker的web界面了。\n\n* NameNode - <http://localhost:50070/>\n* JobTracker - <http://localhost:50030/>\n\n\n###2.5 运行一个例子\n运行的例子跟单机模式下的例子相同。\n\n将输入数据拷贝到分布式文件系统中:\n\n    $ bin/hadoop fs -put conf input\n\n运行 Hadoop 自带的例子:\n\n    $ bin/hadoop jar hadoop-examples-*.jar grep input output 'dfs[a-z.]+'\n\n查看输出文件:\n\n    $ bin/hadoop fs -cat output/*\n\n    1\tdfs.replication\n    1\tdfs.server.namenode.\n    1\tdfsadmin\n\n结束后，关闭 Hadoop:\n\n    $ bin/stop-all.sh\n\n    stopping jobtracker\n    localhost: stopping tasktracker\n    stopping namenode\n    localhost: stopping datanode\n    localhost: stopping secondarynamenode\n\n##3 分布式模式(Fully-Distributed Mode)\n主要参考官方文档[Cluster Setup](http://hadoop.apache.org/docs/r1.2.1/cluster_setup.html).\n\n###3.1 准备3台机器\n如果你已经有了三台机器，这一步可以省略。\n\n如果没有，则可以用VMware Workstation 或 VirtualBox创建3台虚拟机。首先用vmware workstation 新建一台CentOS 6.5，装好操作系统，选择 Basic Server，安装JDK，参考我的另一篇博客，[安装和配置CentOS服务器的详细步骤](http://www.yanjiuyanjiu.com/blog/20120423/)。安装好后然后用**浅拷贝**`Create a linked clone` 克隆出2台，这样有了3台虚拟机。启动3台机器，假设IP分别为`192.168.1.131, 192.168.1.132, 192.168.1.133`, 131做为NameNode,JobTracker和SecondaryNameNode，身兼3个角色，这3个角色应该放到3台不同的机器上，这里为了简化，用一台机器来做3个角色；132和133为 slave。三台机器上的用户名是`hadoop`，也可以用其他用户名，但必须三台机器都相同。\n\n####3.1.1 关闭防火墙\n临时关闭防火墙\n\n\t$ sudo service iptables stop\n\n下次开机后，防火墙还是会启动。\n\n永久关闭防火墙\n\n\t$ sudo chkconfig iptables off\n\n由于这几台虚拟机是开发机，不是生产环境，因此不必考虑安全性，可以永久关闭防火墙，还能给开发阶段带来很多便利。\n\n####3.1.2 修改hostname\n如果集群中的每一台机器事先已经有了hostname，则这一步可以跳过。\n\n这一步看起来貌似不必要，其实是必须的，否则最后运行wordcount等例子时，会出现“Too many fetch-failures”。因为HDFS用hostname而不是IP，来相互之间进行通信（见后面的注意1）。\n\n在CentOS上修改hostname，包含两个步骤(假设将hostname1改为hostname2，参考[这里](http://www.ichiayi.com/wiki/tech/linux_hostname)，但不需要第一步)：\n\n1. 将 `/etc/sysconfig/network` 內的 HOSTNAME 改成 yourhostname\n2. 用`hostname`命令，临时修改机器名， `sudo hostname yourhostname`\n\n用`exit`命令退出shell，再次登录，命令提示字符串就会变成`[username@yourhostname ~]$`。\n\n用上述方法，将131改名为master，132改名为slave01，133改名为slave02。\n\n**注意**，对于有的Ubuntu/Debia 系统，会把本机的hostname解析成 127.0.1.1，例如：\n\n    127.0.0.1       localhost\n    127.0.1.1       master\n\n将第二行改为(参考[利用Cloudera实现Hadoop](http://wiki.ubuntu.org.cn/%E5%88%A9%E7%94%A8Cloudera%E5%AE%9E%E7%8E%B0Hadoop))\n\n    127.0.0.1       master\n\n####3.1.3 修改所有机器的`/etc/hosts`文件\n在所有机器的`/etc/hosts`文件中，添加所有hostname对应的IP，一般在一台机器上设置好，然后scp到所有机器。例如\n\n\t192.168.1.131 master\n\t192.168.1.132 slave01\n\t192.168.1.133 slave02\n\n##3.2 配置 master 无密码登陆到所有机器（包括master自己登陆自己）\n参考我的另一篇博客，[SSH无密码登录的配置](http://www.yanjiuyanjiu.com/blog/20120102/)\n\n##3.3 把Hadoop压缩包上传到所有机器，并解压\n将 hadoop-1.2.1-bin.tar.gz 上传到所有机器，然后解压。**注意，所有机器的hadoop路径必须一致，因为master会登陆到slave上执行命令，master认为slave的hadoop路径与自己一样。**\n\n下面开始配置，配置好了后，把conf 目录scp到所有其他机器。\n\n\n###3.4 修改6个配置文件\nHadoop的配置文件比较多，其设计原则可以概括为如下两点：\n\n* 尽可能模块化。例如core-xxx.xml是针对基础公共库core的，hdfs-xxx.xml是针对分布式文件系统HDFS的，mapred-xxx.xml是针对分布式计算框架MapReduce的。\n* 动静分离。例如，在Hadoop 1.0.0之前，作业队列权限管理相关的配置被放在mapred-site.xml里，而该文件爱你是不可以动态加载的，每次修改后必须重启Hadoop，但从 1.0.0后，这些配置选项被剥离出来放到独立的配置文件mapred-queue-acls.xml中，该文件可以通过Hadoop命令动态加载。在conf下，core-default.xml, hdfs-default.xml和mapred-default.xml是只读的，core-site.xml, hdfs-site.xml和mapred-site.xml才是用户可以修改的。要想覆盖默认配置，就在xxx-site.xml里修改。\n\n以下操作在master上进行。\n\n###3.4.1 conf/hadoop-env.sh\n在 conf/hadoop-env.sh里，设置 `JAVA_HOME`。如果集群中，每台机器的JDK不一定统一安装在同一个路径，那就要在每个节点的hadoop-env.sh里分别设置`JAVA_HOME`。\n\n    export JAVA_HOME=/usr/lib/jvm/java\n\n还要设置`HADOOP_PID_DIR`，这里我们令其为`HADOOP_PID_DIR=/home/hadoop/local/var/hadoop/pids`，参考[Hadoop的pid配置](http://www.iteye.com/topic/299219)。\n\n    export HADOOP_PID_DIR=/home/hadoop/local/var/hadoop/pids\n\n注意，还要**禁用IPv6**，用命令`cat /proc/sys/net/ipv6/conf/all/disable_ipv6`检查一下系统是否启用了IPv6，如果是0,说明启用了。Hadoop在IPv6的情况下运行不正常，因此需禁用IPv6。\n\n不过我们不用真的禁用IPv6，还有另外一种方法，让java优先选择IPv4即可，在conf/hadoop-env.sh 里添加如下一行，\n\n    export HADOOP_OPTS=\"-server -Djava.net.preferIPv4Stack=true $HADOOP_OPTS\"\n\n参考[Disabling IPv6](http://www.michael-noll.com/tutorials/running-hadoop-on-ubuntu-linux-single-node-cluster/#disabling-ipv6)，以及Web Crawling and Data Mining with Apache Nutch这本书的第66页。\n\n###3.4.2 conf/masters\n\n\tmaster\n\n###3.4.3 conf/slaves\n\n\tslave01\n\tslave02\n\n这里解释一下，masters文件，存放的其实是SecondaryNameNode。关于masters和slaves两个配置文件，更精确的说明见这个StackOverflow答案，[hadoop conf/masters and conf/slaves on jobtracker?](http://stackoverflow.com/a/19779590/381712)\n\n###3.4.4 conf/core-site.xml\n\n\t<configuration>\n\t    <property>\n\t        <name>fs.default.name</name>\n\t        <value>hdfs://master:9000</value>\n\t    </property>\n\t    <property>\n\t        <name>fs.checkpoint.dir</name>\n\t        <value>/home/hadoop/local/var/hadoop/dfs/namesecondary</value>\n\t    </property>\n\t</configuration>\n\nHadoop会自动创建目录。\n\n###3.4.5 conf/hdfs-site.xml\n\n\t<configuration>\n\t     <property>\n\t         <name>dfs.name.dir</name>\n\t         <value>/home/hadoop/local/var/hadoop/dfs/name</value>\n\t     </property>\n\t     <property>\n\t         <name>dfs.data.dir</name>\n\t         <value>/home/hadoop/local/var/hadoop/dfs/data</value>\n\t     </property>\n\t     <property>\n\t       <name>dfs.replication</name>\n\t       <value>2</value>\n\t     </property>\n\t</configuration>\n\n我们只有2台slave，因此`dfs.replication`设置为2。\n\nHadoop会自动在master创建 /home/hadoop/local/var/hadoop/dfs/name 目录，在 slaves上创建 /home/hadoop/local/var/hadoop/dfs/data 目录。\n\n###3.4.6 conf/mapred-site.xml\n\n\t<configuration>\n\t    <property>\n\t        <name>mapred.job.tracker</name>\n\t        <value>master:9001</value>\n\t    </property>\n\t    <property>\n\t        <name>mapred.local.dir</name>\n\t        <value>/home/hadoop/local/var/hadoop/mapred/local</value>\n\t    </property>\n\t    <property>\n\t        <name>mapreduce.jobtracker.staging.root.dir</name>\n\t        <value>/user</value>\n\t    </property>\n\t</configuration>\n\n###3.5 将配置文件拷贝到所有slaves\n\n\t$ cd ~/local/opt/hadoop-1.2.1/conf/\n\t$ scp hadoop-env.sh core-site.xml hdfs-site.xml mapred-site.xml masters slaves hadoop@slave01:~/local/opt/hadoop-1.2.1/conf/\n\t$ scp hadoop-env.sh core-site.xml hdfs-site.xml mapred-site.xml masters slaves hadoop@slave02:~/local/opt/hadoop-1.2.1/conf/\n\n###3.6 运行 hadoop\n在master上执行以下命令，启动hadoop\n\n\t$ cd ~/local/opt/hadoop-1.2.1/\n\t#只需一次，下次启动不再需要格式化，只需 start-all.sh\n\t$ bin/hadoop namenode -format\n\t$ bin/start-all.sh\n\n###3.7 检查是否启动成功\n\n在master上执行：\n\n\t$ jps\n\t\n\t2615 NameNode\n\t2767 JobTracker\n\t2874 Jps\n\n在一台slave上执行：\n\n\t$ jps\n\t\n\t3415 DataNode\n\t3582 TaskTracker\n\t3499 SecondaryNameNode\n\t3619 Jps\n\n在另一台slave上执行：\n\n\t$ jps\n\t\n\t3741 Jps\n\t3618 DataNode\n\t3702 TaskTracker\n\n可见进程都启动起来了，说明hadoop运行成功。\n\n###3.8 运行wordcount例子，进一步测试是否安装成功\n将输入数据拷贝到分布式文件系统中:\n\n\t$ cd ~/local/opt/hadoop-1.2.1/\n\t$ bin/hadoop fs -put conf input\n\n运行 Hadoop 自带的例子:\n\n\t$ bin/hadoop jar hadoop-examples-*.jar wordcount input output\n\n查看输出文件:\n\n\t$ bin/hadoop fs -ls output\n\t$ bin/hadoop fs -cat output/part-r-00000\n\n如果能看到结果，说明这个例子运行成功。\n\n###3.9 停止 hadoop集群\n在master上执行：\n\n\t$ bin/stop-all.sh\n\n###3.10 （可选）在master上设置环境变量HADOOP\\_PREFIX，并将HADOOP\\_PREFIX/bin加入PATH\n这一步是为了将bin目录加入PATH，这样可以在任何位置执行hadoop的各种命令。这步是可选的。\n\nHadoop不推荐使用`HADOOP_HOME`，你可以试一下，当设置了`HADOOP_HOME`后，执行`bin/start-all.sh`，第一行会打印出一行警告信息，`Warning: $HADOOP_HOME is deprecated.` 应该用`HADOOP_PREFIX`代替，见邮件列表里的这封[邮件](http://mail-archives.apache.org/mod_mbox/hadoop-common-user/201202.mbox/%3CCB4ECC21.33727%25evans@yahoo-inc.com%3E)。\n\n给所有机器设置环境变量`HADOOP_PREFIX`，并将`$HADOOP_PREFIX/bin`加入PATH。\n\n在 `~/.bashrc`中添加如下4行：\n\n    export HADOOP_PREFIX=$HOME/local/opt/hadoop-1.2.1\n    export PATH=$PATH:$HADOOP_PREFIX/bin\n\nsource使之立刻生效，\n\n\t$ source ~/.bashrc\n\n\n##4. 排除错误\n本文已经尽可能的把步骤详细列出来了，但是我相信大部分人不会一次成功。这时候，查找错误就很重要了。查找错误最重要的手段是查看hadoop的日志，一般在logs目录下。把错误消息复制粘贴到google，搜索一下，慢慢找错误。\n\n##注意\n1. 所有配置文件只能用hostname，不能用IP。两年前我不懂，还为此[在stackoverflow上发了帖子](http://stackoverflow.com/questions/8702637/hadoop-conf-fs-default-name-cant-be-setted-ipport-format-directly)。hadoop会反向解析hostname，即使是用了IP，也会使用hostname 来启动TaskTracker。参考[hdfs LAN ip address hostname resolution](http://stackoverflow.com/questions/15230946/hdfs-lan-ip-address-hostname-resolution)，[hadoop入门经验总结- 杨贵堂的博客](http://www.makenotes.net/?p=337004)，[hadoop集群配置](http://51mst.iteye.com/blog/1152439)。\n1. 在第2.5步骤，如果出现 `SafeModeException` 异常，不用担心，等待几分钟即可。因为hadoop刚刚启动时，会进入安全模式进行自检，这需要花点时间。\n1. 如果在任何一步失败，可以`stop-all.sh`, 然后`hadoop  namenode -format`，重试几次，一般可以成功。如果还是不成功，多看看 logs目录下的日志文件，把错误消息复制粘贴到google，搜索答案。\n\n","slug":"2014-02-02-hadoop-installatioin-on-centos","published":1,"updated":"2016-08-18T09:21:04.000Z","photos":[],"link":"","_id":"cis07pf49002w01pqvrurrks1","content":"<p>Ubuntu上安装，请参考我的另一篇博客，<a href=\"http://www.yanjiuyanjiu.com/blog/20120103/\" target=\"_blank\" rel=\"external\">在Ubuntu上安装Hadoop</a>。</p>\n<p><strong>环境</strong>：CentOS 6.5, OPenJDK 1.7, Hadoop 1.2.1</p>\n<p>本文主要参考官网的文档，<a href=\"http://hadoop.apache.org/docs/r1.2.1/#Getting+Started\" target=\"_blank\" rel=\"external\">Hadoop 1.2.1 Getting Started</a></p>\n<p>##1 单机模式(Standalone Mode)<br>为了能顺利安装成功，我们先练习在单台机器上安装Hadoop。在单台机器上，可以配置成单机模式(Standalone Mode)和伪分布式模式(Pseudo-Distributed Mode)，参考官方文档<a href=\"http://hadoop.apache.org/docs/r1.2.1/single_node_setup.html\" target=\"_blank\" rel=\"external\">Single Node Setup</a>。</p>\n<p>###1.1 下载Hadoop 1.2.1，解压<br>用浏览器下载或wget,</p>\n<pre><code>$ wget http://mirror.olnevhost.net/pub/apache/hadoop/common/stable1/hadoop-1.2.1-bin.tar.gz\n$ tar -zxf hadoop-1.2.1-bin.tar.gz -C ~/local/opt\n$ cd ~/local/opt/hadoop-1.2.1\n</code></pre><p>###1.2 编辑 conf/hadoop-env.sh，设置 <code>JAVA_HOME</code></p>\n<pre><code>$ echo $JAVA_HOME\n/usr/lib/jvm/java\n$ vim conf/hadoop-env.sh\n</code></pre><p>取消<code>JAVA_HOME</code>那一行的注释，设置正确的JDK位置</p>\n<pre><code>export JAVA_HOME=/usr/lib/jvm/java\n</code></pre><p>###1.3 运行一个job<br>默认情况下，Hadoop就被配置为Standalone模式了，此时Hadoop的所有模块都运行在一个java进程里。</p>\n<p>我们运行一个例子测试一下。下面的几行命令，把 <code>conf</code>下的所有xml文件作为输入，在文件中查找指定的正则表达式，把匹配的结果输出到<code>output</code>目录。</p>\n<pre><code>$ mkdir input \n$ cp conf/*.xml input \n$ bin/hadoop jar hadoop-examples-*.jar grep input output &apos;dfs[a-z.]+&apos; \n$ cat output/*\n</code></pre><p>可以看到正常的结果，说明单机模式运行成功了，下面开始配置伪分布式模式。</p>\n<a id=\"more\"></a>\n<p>##2 伪分布式模式(Pseudo-Distributed Mode)<br>Hadoop能在单台机器上以伪分布式模式运行，即每个Hadoop模块运行在单独的java进程里。</p>\n<p>###2.1 编辑 conf/hadoop-env.sh，设置 <code>JAVA_HOME</code></p>\n<pre><code>$ echo $JAVA_HOME\n/usr/lib/jvm/java\n$ vim conf/hadoop-env.sh\n</code></pre><p>###2.2 设置无密码SSH登录<br>先检查一下是能够无密码登录本机，</p>\n<pre><code>ssh localhost\n</code></pre><p>如果提示输入密码，说明不能，按如下步骤设置。</p>\n<pre><code>$ ssh-keygen -t dsa -P &apos;&apos; -f ~/.ssh/id_dsa \n$ cat ~/.ssh/id_dsa.pub &gt;&gt; ~/.ssh/authorized_keys\n</code></pre><p>###2.3 配置</p>\n<p>conf/core-site.xml:</p>\n<pre><code>&lt;configuration&gt;\n     &lt;property&gt;\n         &lt;name&gt;fs.default.name&lt;/name&gt;\n         &lt;value&gt;hdfs://localhost:9000&lt;/value&gt;\n     &lt;/property&gt;\n&lt;/configuration&gt;\n</code></pre><p>conf/hdfs-site.xml:</p>\n<pre><code>&lt;configuration&gt;\n     &lt;property&gt;\n         &lt;name&gt;dfs.replication&lt;/name&gt;\n         &lt;value&gt;1&lt;/value&gt;\n     &lt;/property&gt;\n&lt;/configuration&gt;\n</code></pre><p>conf/mapred-site.xml:</p>\n<pre><code>&lt;configuration&gt;\n     &lt;property&gt;\n         &lt;name&gt;mapred.job.tracker&lt;/name&gt;\n         &lt;value&gt;localhost:9001&lt;/value&gt;\n     &lt;/property&gt;\n&lt;/configuration&gt;\n</code></pre><p>###2.4 启动Hadoop</p>\n<p>格式化namenode</p>\n<pre><code>$ bin/hadoop namenode -format\n</code></pre><p>启动 Hadoop 后台进程</p>\n<pre><code>$ bin/start-all.sh\n</code></pre><p>Hadoop的log写入到了<code>${HADOOP_HOME}/logs</code>目录下。</p>\n<p>现在可以用浏览器打开NameNode和JobTracker的web界面了。</p>\n<ul>\n<li>NameNode - <a href=\"http://localhost:50070/\" target=\"_blank\" rel=\"external\">http://localhost:50070/</a></li>\n<li>JobTracker - <a href=\"http://localhost:50030/\" target=\"_blank\" rel=\"external\">http://localhost:50030/</a></li>\n</ul>\n<p>###2.5 运行一个例子<br>运行的例子跟单机模式下的例子相同。</p>\n<p>将输入数据拷贝到分布式文件系统中:</p>\n<pre><code>$ bin/hadoop fs -put conf input\n</code></pre><p>运行 Hadoop 自带的例子:</p>\n<pre><code>$ bin/hadoop jar hadoop-examples-*.jar grep input output &apos;dfs[a-z.]+&apos;\n</code></pre><p>查看输出文件:</p>\n<pre><code>$ bin/hadoop fs -cat output/*\n\n1    dfs.replication\n1    dfs.server.namenode.\n1    dfsadmin\n</code></pre><p>结束后，关闭 Hadoop:</p>\n<pre><code>$ bin/stop-all.sh\n\nstopping jobtracker\nlocalhost: stopping tasktracker\nstopping namenode\nlocalhost: stopping datanode\nlocalhost: stopping secondarynamenode\n</code></pre><p>##3 分布式模式(Fully-Distributed Mode)<br>主要参考官方文档<a href=\"http://hadoop.apache.org/docs/r1.2.1/cluster_setup.html\" target=\"_blank\" rel=\"external\">Cluster Setup</a>.</p>\n<p>###3.1 准备3台机器<br>如果你已经有了三台机器，这一步可以省略。</p>\n<p>如果没有，则可以用VMware Workstation 或 VirtualBox创建3台虚拟机。首先用vmware workstation 新建一台CentOS 6.5，装好操作系统，选择 Basic Server，安装JDK，参考我的另一篇博客，<a href=\"http://www.yanjiuyanjiu.com/blog/20120423/\" target=\"_blank\" rel=\"external\">安装和配置CentOS服务器的详细步骤</a>。安装好后然后用<strong>浅拷贝</strong><code>Create a linked clone</code> 克隆出2台，这样有了3台虚拟机。启动3台机器，假设IP分别为<code>192.168.1.131, 192.168.1.132, 192.168.1.133</code>, 131做为NameNode,JobTracker和SecondaryNameNode，身兼3个角色，这3个角色应该放到3台不同的机器上，这里为了简化，用一台机器来做3个角色；132和133为 slave。三台机器上的用户名是<code>hadoop</code>，也可以用其他用户名，但必须三台机器都相同。</p>\n<p>####3.1.1 关闭防火墙<br>临时关闭防火墙</p>\n<pre><code>$ sudo service iptables stop\n</code></pre><p>下次开机后，防火墙还是会启动。</p>\n<p>永久关闭防火墙</p>\n<pre><code>$ sudo chkconfig iptables off\n</code></pre><p>由于这几台虚拟机是开发机，不是生产环境，因此不必考虑安全性，可以永久关闭防火墙，还能给开发阶段带来很多便利。</p>\n<p>####3.1.2 修改hostname<br>如果集群中的每一台机器事先已经有了hostname，则这一步可以跳过。</p>\n<p>这一步看起来貌似不必要，其实是必须的，否则最后运行wordcount等例子时，会出现“Too many fetch-failures”。因为HDFS用hostname而不是IP，来相互之间进行通信（见后面的注意1）。</p>\n<p>在CentOS上修改hostname，包含两个步骤(假设将hostname1改为hostname2，参考<a href=\"http://www.ichiayi.com/wiki/tech/linux_hostname\" target=\"_blank\" rel=\"external\">这里</a>，但不需要第一步)：</p>\n<ol>\n<li>将 <code>/etc/sysconfig/network</code> 內的 HOSTNAME 改成 yourhostname</li>\n<li>用<code>hostname</code>命令，临时修改机器名， <code>sudo hostname yourhostname</code></li>\n</ol>\n<p>用<code>exit</code>命令退出shell，再次登录，命令提示字符串就会变成<code>[username@yourhostname ~]$</code>。</p>\n<p>用上述方法，将131改名为master，132改名为slave01，133改名为slave02。</p>\n<p><strong>注意</strong>，对于有的Ubuntu/Debia 系统，会把本机的hostname解析成 127.0.1.1，例如：</p>\n<pre><code>127.0.0.1       localhost\n127.0.1.1       master\n</code></pre><p>将第二行改为(参考<a href=\"http://wiki.ubuntu.org.cn/%E5%88%A9%E7%94%A8Cloudera%E5%AE%9E%E7%8E%B0Hadoop\" target=\"_blank\" rel=\"external\">利用Cloudera实现Hadoop</a>)</p>\n<pre><code>127.0.0.1       master\n</code></pre><p>####3.1.3 修改所有机器的<code>/etc/hosts</code>文件<br>在所有机器的<code>/etc/hosts</code>文件中，添加所有hostname对应的IP，一般在一台机器上设置好，然后scp到所有机器。例如</p>\n<pre><code>192.168.1.131 master\n192.168.1.132 slave01\n192.168.1.133 slave02\n</code></pre><p>##3.2 配置 master 无密码登陆到所有机器（包括master自己登陆自己）<br>参考我的另一篇博客，<a href=\"http://www.yanjiuyanjiu.com/blog/20120102/\" target=\"_blank\" rel=\"external\">SSH无密码登录的配置</a></p>\n<p>##3.3 把Hadoop压缩包上传到所有机器，并解压<br>将 hadoop-1.2.1-bin.tar.gz 上传到所有机器，然后解压。<strong>注意，所有机器的hadoop路径必须一致，因为master会登陆到slave上执行命令，master认为slave的hadoop路径与自己一样。</strong></p>\n<p>下面开始配置，配置好了后，把conf 目录scp到所有其他机器。</p>\n<p>###3.4 修改6个配置文件<br>Hadoop的配置文件比较多，其设计原则可以概括为如下两点：</p>\n<ul>\n<li>尽可能模块化。例如core-xxx.xml是针对基础公共库core的，hdfs-xxx.xml是针对分布式文件系统HDFS的，mapred-xxx.xml是针对分布式计算框架MapReduce的。</li>\n<li>动静分离。例如，在Hadoop 1.0.0之前，作业队列权限管理相关的配置被放在mapred-site.xml里，而该文件爱你是不可以动态加载的，每次修改后必须重启Hadoop，但从 1.0.0后，这些配置选项被剥离出来放到独立的配置文件mapred-queue-acls.xml中，该文件可以通过Hadoop命令动态加载。在conf下，core-default.xml, hdfs-default.xml和mapred-default.xml是只读的，core-site.xml, hdfs-site.xml和mapred-site.xml才是用户可以修改的。要想覆盖默认配置，就在xxx-site.xml里修改。</li>\n</ul>\n<p>以下操作在master上进行。</p>\n<p>###3.4.1 conf/hadoop-env.sh<br>在 conf/hadoop-env.sh里，设置 <code>JAVA_HOME</code>。如果集群中，每台机器的JDK不一定统一安装在同一个路径，那就要在每个节点的hadoop-env.sh里分别设置<code>JAVA_HOME</code>。</p>\n<pre><code>export JAVA_HOME=/usr/lib/jvm/java\n</code></pre><p>还要设置<code>HADOOP_PID_DIR</code>，这里我们令其为<code>HADOOP_PID_DIR=/home/hadoop/local/var/hadoop/pids</code>，参考<a href=\"http://www.iteye.com/topic/299219\" target=\"_blank\" rel=\"external\">Hadoop的pid配置</a>。</p>\n<pre><code>export HADOOP_PID_DIR=/home/hadoop/local/var/hadoop/pids\n</code></pre><p>注意，还要<strong>禁用IPv6</strong>，用命令<code>cat /proc/sys/net/ipv6/conf/all/disable_ipv6</code>检查一下系统是否启用了IPv6，如果是0,说明启用了。Hadoop在IPv6的情况下运行不正常，因此需禁用IPv6。</p>\n<p>不过我们不用真的禁用IPv6，还有另外一种方法，让java优先选择IPv4即可，在conf/hadoop-env.sh 里添加如下一行，</p>\n<pre><code>export HADOOP_OPTS=&quot;-server -Djava.net.preferIPv4Stack=true $HADOOP_OPTS&quot;\n</code></pre><p>参考<a href=\"http://www.michael-noll.com/tutorials/running-hadoop-on-ubuntu-linux-single-node-cluster/#disabling-ipv6\" target=\"_blank\" rel=\"external\">Disabling IPv6</a>，以及Web Crawling and Data Mining with Apache Nutch这本书的第66页。</p>\n<p>###3.4.2 conf/masters</p>\n<pre><code>master\n</code></pre><p>###3.4.3 conf/slaves</p>\n<pre><code>slave01\nslave02\n</code></pre><p>这里解释一下，masters文件，存放的其实是SecondaryNameNode。关于masters和slaves两个配置文件，更精确的说明见这个StackOverflow答案，<a href=\"http://stackoverflow.com/a/19779590/381712\" target=\"_blank\" rel=\"external\">hadoop conf/masters and conf/slaves on jobtracker?</a></p>\n<p>###3.4.4 conf/core-site.xml</p>\n<pre><code>&lt;configuration&gt;\n    &lt;property&gt;\n        &lt;name&gt;fs.default.name&lt;/name&gt;\n        &lt;value&gt;hdfs://master:9000&lt;/value&gt;\n    &lt;/property&gt;\n    &lt;property&gt;\n        &lt;name&gt;fs.checkpoint.dir&lt;/name&gt;\n        &lt;value&gt;/home/hadoop/local/var/hadoop/dfs/namesecondary&lt;/value&gt;\n    &lt;/property&gt;\n&lt;/configuration&gt;\n</code></pre><p>Hadoop会自动创建目录。</p>\n<p>###3.4.5 conf/hdfs-site.xml</p>\n<pre><code>&lt;configuration&gt;\n     &lt;property&gt;\n         &lt;name&gt;dfs.name.dir&lt;/name&gt;\n         &lt;value&gt;/home/hadoop/local/var/hadoop/dfs/name&lt;/value&gt;\n     &lt;/property&gt;\n     &lt;property&gt;\n         &lt;name&gt;dfs.data.dir&lt;/name&gt;\n         &lt;value&gt;/home/hadoop/local/var/hadoop/dfs/data&lt;/value&gt;\n     &lt;/property&gt;\n     &lt;property&gt;\n       &lt;name&gt;dfs.replication&lt;/name&gt;\n       &lt;value&gt;2&lt;/value&gt;\n     &lt;/property&gt;\n&lt;/configuration&gt;\n</code></pre><p>我们只有2台slave，因此<code>dfs.replication</code>设置为2。</p>\n<p>Hadoop会自动在master创建 /home/hadoop/local/var/hadoop/dfs/name 目录，在 slaves上创建 /home/hadoop/local/var/hadoop/dfs/data 目录。</p>\n<p>###3.4.6 conf/mapred-site.xml</p>\n<pre><code>&lt;configuration&gt;\n    &lt;property&gt;\n        &lt;name&gt;mapred.job.tracker&lt;/name&gt;\n        &lt;value&gt;master:9001&lt;/value&gt;\n    &lt;/property&gt;\n    &lt;property&gt;\n        &lt;name&gt;mapred.local.dir&lt;/name&gt;\n        &lt;value&gt;/home/hadoop/local/var/hadoop/mapred/local&lt;/value&gt;\n    &lt;/property&gt;\n    &lt;property&gt;\n        &lt;name&gt;mapreduce.jobtracker.staging.root.dir&lt;/name&gt;\n        &lt;value&gt;/user&lt;/value&gt;\n    &lt;/property&gt;\n&lt;/configuration&gt;\n</code></pre><p>###3.5 将配置文件拷贝到所有slaves</p>\n<pre><code>$ cd ~/local/opt/hadoop-1.2.1/conf/\n$ scp hadoop-env.sh core-site.xml hdfs-site.xml mapred-site.xml masters slaves hadoop@slave01:~/local/opt/hadoop-1.2.1/conf/\n$ scp hadoop-env.sh core-site.xml hdfs-site.xml mapred-site.xml masters slaves hadoop@slave02:~/local/opt/hadoop-1.2.1/conf/\n</code></pre><p>###3.6 运行 hadoop<br>在master上执行以下命令，启动hadoop</p>\n<pre><code>$ cd ~/local/opt/hadoop-1.2.1/\n#只需一次，下次启动不再需要格式化，只需 start-all.sh\n$ bin/hadoop namenode -format\n$ bin/start-all.sh\n</code></pre><p>###3.7 检查是否启动成功</p>\n<p>在master上执行：</p>\n<pre><code>$ jps\n\n2615 NameNode\n2767 JobTracker\n2874 Jps\n</code></pre><p>在一台slave上执行：</p>\n<pre><code>$ jps\n\n3415 DataNode\n3582 TaskTracker\n3499 SecondaryNameNode\n3619 Jps\n</code></pre><p>在另一台slave上执行：</p>\n<pre><code>$ jps\n\n3741 Jps\n3618 DataNode\n3702 TaskTracker\n</code></pre><p>可见进程都启动起来了，说明hadoop运行成功。</p>\n<p>###3.8 运行wordcount例子，进一步测试是否安装成功<br>将输入数据拷贝到分布式文件系统中:</p>\n<pre><code>$ cd ~/local/opt/hadoop-1.2.1/\n$ bin/hadoop fs -put conf input\n</code></pre><p>运行 Hadoop 自带的例子:</p>\n<pre><code>$ bin/hadoop jar hadoop-examples-*.jar wordcount input output\n</code></pre><p>查看输出文件:</p>\n<pre><code>$ bin/hadoop fs -ls output\n$ bin/hadoop fs -cat output/part-r-00000\n</code></pre><p>如果能看到结果，说明这个例子运行成功。</p>\n<p>###3.9 停止 hadoop集群<br>在master上执行：</p>\n<pre><code>$ bin/stop-all.sh\n</code></pre><p>###3.10 （可选）在master上设置环境变量HADOOP_PREFIX，并将HADOOP_PREFIX/bin加入PATH<br>这一步是为了将bin目录加入PATH，这样可以在任何位置执行hadoop的各种命令。这步是可选的。</p>\n<p>Hadoop不推荐使用<code>HADOOP_HOME</code>，你可以试一下，当设置了<code>HADOOP_HOME</code>后，执行<code>bin/start-all.sh</code>，第一行会打印出一行警告信息，<code>Warning: $HADOOP_HOME is deprecated.</code> 应该用<code>HADOOP_PREFIX</code>代替，见邮件列表里的这封<a href=\"http://mail-archives.apache.org/mod_mbox/hadoop-common-user/201202.mbox/%3CCB4ECC21.33727%25evans@yahoo-inc.com%3E\" target=\"_blank\" rel=\"external\">邮件</a>。</p>\n<p>给所有机器设置环境变量<code>HADOOP_PREFIX</code>，并将<code>$HADOOP_PREFIX/bin</code>加入PATH。</p>\n<p>在 <code>~/.bashrc</code>中添加如下4行：</p>\n<pre><code>export HADOOP_PREFIX=$HOME/local/opt/hadoop-1.2.1\nexport PATH=$PATH:$HADOOP_PREFIX/bin\n</code></pre><p>source使之立刻生效，</p>\n<pre><code>$ source ~/.bashrc\n</code></pre><p>##4. 排除错误<br>本文已经尽可能的把步骤详细列出来了，但是我相信大部分人不会一次成功。这时候，查找错误就很重要了。查找错误最重要的手段是查看hadoop的日志，一般在logs目录下。把错误消息复制粘贴到google，搜索一下，慢慢找错误。</p>\n<p>##注意</p>\n<ol>\n<li>所有配置文件只能用hostname，不能用IP。两年前我不懂，还为此<a href=\"http://stackoverflow.com/questions/8702637/hadoop-conf-fs-default-name-cant-be-setted-ipport-format-directly\" target=\"_blank\" rel=\"external\">在stackoverflow上发了帖子</a>。hadoop会反向解析hostname，即使是用了IP，也会使用hostname 来启动TaskTracker。参考<a href=\"http://stackoverflow.com/questions/15230946/hdfs-lan-ip-address-hostname-resolution\" target=\"_blank\" rel=\"external\">hdfs LAN ip address hostname resolution</a>，<a href=\"http://www.makenotes.net/?p=337004\" target=\"_blank\" rel=\"external\">hadoop入门经验总结- 杨贵堂的博客</a>，<a href=\"http://51mst.iteye.com/blog/1152439\" target=\"_blank\" rel=\"external\">hadoop集群配置</a>。</li>\n<li>在第2.5步骤，如果出现 <code>SafeModeException</code> 异常，不用担心，等待几分钟即可。因为hadoop刚刚启动时，会进入安全模式进行自检，这需要花点时间。</li>\n<li>如果在任何一步失败，可以<code>stop-all.sh</code>, 然后<code>hadoop  namenode -format</code>，重试几次，一般可以成功。如果还是不成功，多看看 logs目录下的日志文件，把错误消息复制粘贴到google，搜索答案。</li>\n</ol>\n","excerpt":"<p>Ubuntu上安装，请参考我的另一篇博客，<a href=\"http://www.yanjiuyanjiu.com/blog/20120103/\">在Ubuntu上安装Hadoop</a>。</p>\n<p><strong>环境</strong>：CentOS 6.5, OPenJDK 1.7, Hadoop 1.2.1</p>\n<p>本文主要参考官网的文档，<a href=\"http://hadoop.apache.org/docs/r1.2.1/#Getting+Started\">Hadoop 1.2.1 Getting Started</a></p>\n<p>##1 单机模式(Standalone Mode)<br>为了能顺利安装成功，我们先练习在单台机器上安装Hadoop。在单台机器上，可以配置成单机模式(Standalone Mode)和伪分布式模式(Pseudo-Distributed Mode)，参考官方文档<a href=\"http://hadoop.apache.org/docs/r1.2.1/single_node_setup.html\">Single Node Setup</a>。</p>\n<p>###1.1 下载Hadoop 1.2.1，解压<br>用浏览器下载或wget,</p>\n<pre><code>$ wget http://mirror.olnevhost.net/pub/apache/hadoop/common/stable1/hadoop-1.2.1-bin.tar.gz\n$ tar -zxf hadoop-1.2.1-bin.tar.gz -C ~/local/opt\n$ cd ~/local/opt/hadoop-1.2.1\n</code></pre><p>###1.2 编辑 conf/hadoop-env.sh，设置 <code>JAVA_HOME</code></p>\n<pre><code>$ echo $JAVA_HOME\n/usr/lib/jvm/java\n$ vim conf/hadoop-env.sh\n</code></pre><p>取消<code>JAVA_HOME</code>那一行的注释，设置正确的JDK位置</p>\n<pre><code>export JAVA_HOME=/usr/lib/jvm/java\n</code></pre><p>###1.3 运行一个job<br>默认情况下，Hadoop就被配置为Standalone模式了，此时Hadoop的所有模块都运行在一个java进程里。</p>\n<p>我们运行一个例子测试一下。下面的几行命令，把 <code>conf</code>下的所有xml文件作为输入，在文件中查找指定的正则表达式，把匹配的结果输出到<code>output</code>目录。</p>\n<pre><code>$ mkdir input \n$ cp conf/*.xml input \n$ bin/hadoop jar hadoop-examples-*.jar grep input output &apos;dfs[a-z.]+&apos; \n$ cat output/*\n</code></pre><p>可以看到正常的结果，说明单机模式运行成功了，下面开始配置伪分布式模式。</p>","more":"<p>##2 伪分布式模式(Pseudo-Distributed Mode)<br>Hadoop能在单台机器上以伪分布式模式运行，即每个Hadoop模块运行在单独的java进程里。</p>\n<p>###2.1 编辑 conf/hadoop-env.sh，设置 <code>JAVA_HOME</code></p>\n<pre><code>$ echo $JAVA_HOME\n/usr/lib/jvm/java\n$ vim conf/hadoop-env.sh\n</code></pre><p>###2.2 设置无密码SSH登录<br>先检查一下是能够无密码登录本机，</p>\n<pre><code>ssh localhost\n</code></pre><p>如果提示输入密码，说明不能，按如下步骤设置。</p>\n<pre><code>$ ssh-keygen -t dsa -P &apos;&apos; -f ~/.ssh/id_dsa \n$ cat ~/.ssh/id_dsa.pub &gt;&gt; ~/.ssh/authorized_keys\n</code></pre><p>###2.3 配置</p>\n<p>conf/core-site.xml:</p>\n<pre><code>&lt;configuration&gt;\n     &lt;property&gt;\n         &lt;name&gt;fs.default.name&lt;/name&gt;\n         &lt;value&gt;hdfs://localhost:9000&lt;/value&gt;\n     &lt;/property&gt;\n&lt;/configuration&gt;\n</code></pre><p>conf/hdfs-site.xml:</p>\n<pre><code>&lt;configuration&gt;\n     &lt;property&gt;\n         &lt;name&gt;dfs.replication&lt;/name&gt;\n         &lt;value&gt;1&lt;/value&gt;\n     &lt;/property&gt;\n&lt;/configuration&gt;\n</code></pre><p>conf/mapred-site.xml:</p>\n<pre><code>&lt;configuration&gt;\n     &lt;property&gt;\n         &lt;name&gt;mapred.job.tracker&lt;/name&gt;\n         &lt;value&gt;localhost:9001&lt;/value&gt;\n     &lt;/property&gt;\n&lt;/configuration&gt;\n</code></pre><p>###2.4 启动Hadoop</p>\n<p>格式化namenode</p>\n<pre><code>$ bin/hadoop namenode -format\n</code></pre><p>启动 Hadoop 后台进程</p>\n<pre><code>$ bin/start-all.sh\n</code></pre><p>Hadoop的log写入到了<code>${HADOOP_HOME}/logs</code>目录下。</p>\n<p>现在可以用浏览器打开NameNode和JobTracker的web界面了。</p>\n<ul>\n<li>NameNode - <a href=\"http://localhost:50070/\">http://localhost:50070/</a></li>\n<li>JobTracker - <a href=\"http://localhost:50030/\">http://localhost:50030/</a></li>\n</ul>\n<p>###2.5 运行一个例子<br>运行的例子跟单机模式下的例子相同。</p>\n<p>将输入数据拷贝到分布式文件系统中:</p>\n<pre><code>$ bin/hadoop fs -put conf input\n</code></pre><p>运行 Hadoop 自带的例子:</p>\n<pre><code>$ bin/hadoop jar hadoop-examples-*.jar grep input output &apos;dfs[a-z.]+&apos;\n</code></pre><p>查看输出文件:</p>\n<pre><code>$ bin/hadoop fs -cat output/*\n\n1    dfs.replication\n1    dfs.server.namenode.\n1    dfsadmin\n</code></pre><p>结束后，关闭 Hadoop:</p>\n<pre><code>$ bin/stop-all.sh\n\nstopping jobtracker\nlocalhost: stopping tasktracker\nstopping namenode\nlocalhost: stopping datanode\nlocalhost: stopping secondarynamenode\n</code></pre><p>##3 分布式模式(Fully-Distributed Mode)<br>主要参考官方文档<a href=\"http://hadoop.apache.org/docs/r1.2.1/cluster_setup.html\">Cluster Setup</a>.</p>\n<p>###3.1 准备3台机器<br>如果你已经有了三台机器，这一步可以省略。</p>\n<p>如果没有，则可以用VMware Workstation 或 VirtualBox创建3台虚拟机。首先用vmware workstation 新建一台CentOS 6.5，装好操作系统，选择 Basic Server，安装JDK，参考我的另一篇博客，<a href=\"http://www.yanjiuyanjiu.com/blog/20120423/\">安装和配置CentOS服务器的详细步骤</a>。安装好后然后用<strong>浅拷贝</strong><code>Create a linked clone</code> 克隆出2台，这样有了3台虚拟机。启动3台机器，假设IP分别为<code>192.168.1.131, 192.168.1.132, 192.168.1.133</code>, 131做为NameNode,JobTracker和SecondaryNameNode，身兼3个角色，这3个角色应该放到3台不同的机器上，这里为了简化，用一台机器来做3个角色；132和133为 slave。三台机器上的用户名是<code>hadoop</code>，也可以用其他用户名，但必须三台机器都相同。</p>\n<p>####3.1.1 关闭防火墙<br>临时关闭防火墙</p>\n<pre><code>$ sudo service iptables stop\n</code></pre><p>下次开机后，防火墙还是会启动。</p>\n<p>永久关闭防火墙</p>\n<pre><code>$ sudo chkconfig iptables off\n</code></pre><p>由于这几台虚拟机是开发机，不是生产环境，因此不必考虑安全性，可以永久关闭防火墙，还能给开发阶段带来很多便利。</p>\n<p>####3.1.2 修改hostname<br>如果集群中的每一台机器事先已经有了hostname，则这一步可以跳过。</p>\n<p>这一步看起来貌似不必要，其实是必须的，否则最后运行wordcount等例子时，会出现“Too many fetch-failures”。因为HDFS用hostname而不是IP，来相互之间进行通信（见后面的注意1）。</p>\n<p>在CentOS上修改hostname，包含两个步骤(假设将hostname1改为hostname2，参考<a href=\"http://www.ichiayi.com/wiki/tech/linux_hostname\">这里</a>，但不需要第一步)：</p>\n<ol>\n<li>将 <code>/etc/sysconfig/network</code> 內的 HOSTNAME 改成 yourhostname</li>\n<li>用<code>hostname</code>命令，临时修改机器名， <code>sudo hostname yourhostname</code></li>\n</ol>\n<p>用<code>exit</code>命令退出shell，再次登录，命令提示字符串就会变成<code>[username@yourhostname ~]$</code>。</p>\n<p>用上述方法，将131改名为master，132改名为slave01，133改名为slave02。</p>\n<p><strong>注意</strong>，对于有的Ubuntu/Debia 系统，会把本机的hostname解析成 127.0.1.1，例如：</p>\n<pre><code>127.0.0.1       localhost\n127.0.1.1       master\n</code></pre><p>将第二行改为(参考<a href=\"http://wiki.ubuntu.org.cn/%E5%88%A9%E7%94%A8Cloudera%E5%AE%9E%E7%8E%B0Hadoop\">利用Cloudera实现Hadoop</a>)</p>\n<pre><code>127.0.0.1       master\n</code></pre><p>####3.1.3 修改所有机器的<code>/etc/hosts</code>文件<br>在所有机器的<code>/etc/hosts</code>文件中，添加所有hostname对应的IP，一般在一台机器上设置好，然后scp到所有机器。例如</p>\n<pre><code>192.168.1.131 master\n192.168.1.132 slave01\n192.168.1.133 slave02\n</code></pre><p>##3.2 配置 master 无密码登陆到所有机器（包括master自己登陆自己）<br>参考我的另一篇博客，<a href=\"http://www.yanjiuyanjiu.com/blog/20120102/\">SSH无密码登录的配置</a></p>\n<p>##3.3 把Hadoop压缩包上传到所有机器，并解压<br>将 hadoop-1.2.1-bin.tar.gz 上传到所有机器，然后解压。<strong>注意，所有机器的hadoop路径必须一致，因为master会登陆到slave上执行命令，master认为slave的hadoop路径与自己一样。</strong></p>\n<p>下面开始配置，配置好了后，把conf 目录scp到所有其他机器。</p>\n<p>###3.4 修改6个配置文件<br>Hadoop的配置文件比较多，其设计原则可以概括为如下两点：</p>\n<ul>\n<li>尽可能模块化。例如core-xxx.xml是针对基础公共库core的，hdfs-xxx.xml是针对分布式文件系统HDFS的，mapred-xxx.xml是针对分布式计算框架MapReduce的。</li>\n<li>动静分离。例如，在Hadoop 1.0.0之前，作业队列权限管理相关的配置被放在mapred-site.xml里，而该文件爱你是不可以动态加载的，每次修改后必须重启Hadoop，但从 1.0.0后，这些配置选项被剥离出来放到独立的配置文件mapred-queue-acls.xml中，该文件可以通过Hadoop命令动态加载。在conf下，core-default.xml, hdfs-default.xml和mapred-default.xml是只读的，core-site.xml, hdfs-site.xml和mapred-site.xml才是用户可以修改的。要想覆盖默认配置，就在xxx-site.xml里修改。</li>\n</ul>\n<p>以下操作在master上进行。</p>\n<p>###3.4.1 conf/hadoop-env.sh<br>在 conf/hadoop-env.sh里，设置 <code>JAVA_HOME</code>。如果集群中，每台机器的JDK不一定统一安装在同一个路径，那就要在每个节点的hadoop-env.sh里分别设置<code>JAVA_HOME</code>。</p>\n<pre><code>export JAVA_HOME=/usr/lib/jvm/java\n</code></pre><p>还要设置<code>HADOOP_PID_DIR</code>，这里我们令其为<code>HADOOP_PID_DIR=/home/hadoop/local/var/hadoop/pids</code>，参考<a href=\"http://www.iteye.com/topic/299219\">Hadoop的pid配置</a>。</p>\n<pre><code>export HADOOP_PID_DIR=/home/hadoop/local/var/hadoop/pids\n</code></pre><p>注意，还要<strong>禁用IPv6</strong>，用命令<code>cat /proc/sys/net/ipv6/conf/all/disable_ipv6</code>检查一下系统是否启用了IPv6，如果是0,说明启用了。Hadoop在IPv6的情况下运行不正常，因此需禁用IPv6。</p>\n<p>不过我们不用真的禁用IPv6，还有另外一种方法，让java优先选择IPv4即可，在conf/hadoop-env.sh 里添加如下一行，</p>\n<pre><code>export HADOOP_OPTS=&quot;-server -Djava.net.preferIPv4Stack=true $HADOOP_OPTS&quot;\n</code></pre><p>参考<a href=\"http://www.michael-noll.com/tutorials/running-hadoop-on-ubuntu-linux-single-node-cluster/#disabling-ipv6\">Disabling IPv6</a>，以及Web Crawling and Data Mining with Apache Nutch这本书的第66页。</p>\n<p>###3.4.2 conf/masters</p>\n<pre><code>master\n</code></pre><p>###3.4.3 conf/slaves</p>\n<pre><code>slave01\nslave02\n</code></pre><p>这里解释一下，masters文件，存放的其实是SecondaryNameNode。关于masters和slaves两个配置文件，更精确的说明见这个StackOverflow答案，<a href=\"http://stackoverflow.com/a/19779590/381712\">hadoop conf/masters and conf/slaves on jobtracker?</a></p>\n<p>###3.4.4 conf/core-site.xml</p>\n<pre><code>&lt;configuration&gt;\n    &lt;property&gt;\n        &lt;name&gt;fs.default.name&lt;/name&gt;\n        &lt;value&gt;hdfs://master:9000&lt;/value&gt;\n    &lt;/property&gt;\n    &lt;property&gt;\n        &lt;name&gt;fs.checkpoint.dir&lt;/name&gt;\n        &lt;value&gt;/home/hadoop/local/var/hadoop/dfs/namesecondary&lt;/value&gt;\n    &lt;/property&gt;\n&lt;/configuration&gt;\n</code></pre><p>Hadoop会自动创建目录。</p>\n<p>###3.4.5 conf/hdfs-site.xml</p>\n<pre><code>&lt;configuration&gt;\n     &lt;property&gt;\n         &lt;name&gt;dfs.name.dir&lt;/name&gt;\n         &lt;value&gt;/home/hadoop/local/var/hadoop/dfs/name&lt;/value&gt;\n     &lt;/property&gt;\n     &lt;property&gt;\n         &lt;name&gt;dfs.data.dir&lt;/name&gt;\n         &lt;value&gt;/home/hadoop/local/var/hadoop/dfs/data&lt;/value&gt;\n     &lt;/property&gt;\n     &lt;property&gt;\n       &lt;name&gt;dfs.replication&lt;/name&gt;\n       &lt;value&gt;2&lt;/value&gt;\n     &lt;/property&gt;\n&lt;/configuration&gt;\n</code></pre><p>我们只有2台slave，因此<code>dfs.replication</code>设置为2。</p>\n<p>Hadoop会自动在master创建 /home/hadoop/local/var/hadoop/dfs/name 目录，在 slaves上创建 /home/hadoop/local/var/hadoop/dfs/data 目录。</p>\n<p>###3.4.6 conf/mapred-site.xml</p>\n<pre><code>&lt;configuration&gt;\n    &lt;property&gt;\n        &lt;name&gt;mapred.job.tracker&lt;/name&gt;\n        &lt;value&gt;master:9001&lt;/value&gt;\n    &lt;/property&gt;\n    &lt;property&gt;\n        &lt;name&gt;mapred.local.dir&lt;/name&gt;\n        &lt;value&gt;/home/hadoop/local/var/hadoop/mapred/local&lt;/value&gt;\n    &lt;/property&gt;\n    &lt;property&gt;\n        &lt;name&gt;mapreduce.jobtracker.staging.root.dir&lt;/name&gt;\n        &lt;value&gt;/user&lt;/value&gt;\n    &lt;/property&gt;\n&lt;/configuration&gt;\n</code></pre><p>###3.5 将配置文件拷贝到所有slaves</p>\n<pre><code>$ cd ~/local/opt/hadoop-1.2.1/conf/\n$ scp hadoop-env.sh core-site.xml hdfs-site.xml mapred-site.xml masters slaves hadoop@slave01:~/local/opt/hadoop-1.2.1/conf/\n$ scp hadoop-env.sh core-site.xml hdfs-site.xml mapred-site.xml masters slaves hadoop@slave02:~/local/opt/hadoop-1.2.1/conf/\n</code></pre><p>###3.6 运行 hadoop<br>在master上执行以下命令，启动hadoop</p>\n<pre><code>$ cd ~/local/opt/hadoop-1.2.1/\n#只需一次，下次启动不再需要格式化，只需 start-all.sh\n$ bin/hadoop namenode -format\n$ bin/start-all.sh\n</code></pre><p>###3.7 检查是否启动成功</p>\n<p>在master上执行：</p>\n<pre><code>$ jps\n\n2615 NameNode\n2767 JobTracker\n2874 Jps\n</code></pre><p>在一台slave上执行：</p>\n<pre><code>$ jps\n\n3415 DataNode\n3582 TaskTracker\n3499 SecondaryNameNode\n3619 Jps\n</code></pre><p>在另一台slave上执行：</p>\n<pre><code>$ jps\n\n3741 Jps\n3618 DataNode\n3702 TaskTracker\n</code></pre><p>可见进程都启动起来了，说明hadoop运行成功。</p>\n<p>###3.8 运行wordcount例子，进一步测试是否安装成功<br>将输入数据拷贝到分布式文件系统中:</p>\n<pre><code>$ cd ~/local/opt/hadoop-1.2.1/\n$ bin/hadoop fs -put conf input\n</code></pre><p>运行 Hadoop 自带的例子:</p>\n<pre><code>$ bin/hadoop jar hadoop-examples-*.jar wordcount input output\n</code></pre><p>查看输出文件:</p>\n<pre><code>$ bin/hadoop fs -ls output\n$ bin/hadoop fs -cat output/part-r-00000\n</code></pre><p>如果能看到结果，说明这个例子运行成功。</p>\n<p>###3.9 停止 hadoop集群<br>在master上执行：</p>\n<pre><code>$ bin/stop-all.sh\n</code></pre><p>###3.10 （可选）在master上设置环境变量HADOOP_PREFIX，并将HADOOP_PREFIX/bin加入PATH<br>这一步是为了将bin目录加入PATH，这样可以在任何位置执行hadoop的各种命令。这步是可选的。</p>\n<p>Hadoop不推荐使用<code>HADOOP_HOME</code>，你可以试一下，当设置了<code>HADOOP_HOME</code>后，执行<code>bin/start-all.sh</code>，第一行会打印出一行警告信息，<code>Warning: $HADOOP_HOME is deprecated.</code> 应该用<code>HADOOP_PREFIX</code>代替，见邮件列表里的这封<a href=\"http://mail-archives.apache.org/mod_mbox/hadoop-common-user/201202.mbox/%3CCB4ECC21.33727%25evans@yahoo-inc.com%3E\">邮件</a>。</p>\n<p>给所有机器设置环境变量<code>HADOOP_PREFIX</code>，并将<code>$HADOOP_PREFIX/bin</code>加入PATH。</p>\n<p>在 <code>~/.bashrc</code>中添加如下4行：</p>\n<pre><code>export HADOOP_PREFIX=$HOME/local/opt/hadoop-1.2.1\nexport PATH=$PATH:$HADOOP_PREFIX/bin\n</code></pre><p>source使之立刻生效，</p>\n<pre><code>$ source ~/.bashrc\n</code></pre><p>##4. 排除错误<br>本文已经尽可能的把步骤详细列出来了，但是我相信大部分人不会一次成功。这时候，查找错误就很重要了。查找错误最重要的手段是查看hadoop的日志，一般在logs目录下。把错误消息复制粘贴到google，搜索一下，慢慢找错误。</p>\n<p>##注意</p>\n<ol>\n<li>所有配置文件只能用hostname，不能用IP。两年前我不懂，还为此<a href=\"http://stackoverflow.com/questions/8702637/hadoop-conf-fs-default-name-cant-be-setted-ipport-format-directly\">在stackoverflow上发了帖子</a>。hadoop会反向解析hostname，即使是用了IP，也会使用hostname 来启动TaskTracker。参考<a href=\"http://stackoverflow.com/questions/15230946/hdfs-lan-ip-address-hostname-resolution\">hdfs LAN ip address hostname resolution</a>，<a href=\"http://www.makenotes.net/?p=337004\">hadoop入门经验总结- 杨贵堂的博客</a>，<a href=\"http://51mst.iteye.com/blog/1152439\">hadoop集群配置</a>。</li>\n<li>在第2.5步骤，如果出现 <code>SafeModeException</code> 异常，不用担心，等待几分钟即可。因为hadoop刚刚启动时，会进入安全模式进行自检，这需要花点时间。</li>\n<li>如果在任何一步失败，可以<code>stop-all.sh</code>, 然后<code>hadoop  namenode -format</code>，重试几次，一般可以成功。如果还是不成功，多看看 logs目录下的日志文件，把错误消息复制粘贴到google，搜索答案。</li>\n</ol>"},{"layout":"post","title":"Spark开发环境的配置","date":"2014-01-30T16:36:00.000Z","comments":1,"_content":"\n**软件版本**：Spark 0.9\n\n配置Spark开发环境，其实分为三个层次，一种是针对运维人员，把Spark安装部署到集群；一种是针对普通开发者，引入Spark的jar包，调用Spark提供的接口，编写分布式程序，写好后编译成jar，就可以提交到Spark集群去运行了；第三种是针对Spark开发者，为了给Spark贡献代码，需要git clone Spark的代码，然后导入IDE，为Spark开发代码。\n\n##1 部署Spark集群\n这种是运维人员在生产环境下，搭建起一个Spark集群。\n\n###（可选）创建新用户 Spark\n一般我倾向于把需要启动daemon进程，对外提供服务的程序，即服务器类的程序，安装在单独的用户下面。这样可以做到隔离，运维方面，安全性也提高了。\n\n创建一个新的group,\n\n    $ sudo groupadd spark\n\n创建一个新的用户，并加入group,\n\n    $ sudo useradd -g spark spark\n\n给新用户设置密码，\n\n    $ sudo passwd spark\n\n在每台机器上创建 spark 新用户，并配置好SSH无密码，参考我的另一篇博客，[SSH无密码登录的配置](http://www.yanjiuyanjiu.com/blog/20120102/)\n\n\n假设有三台机器，hostname分别是 master, worker01, worker02。\n\n###1.1 下载 Spark 预编译好的二进制包\n如果你需要用到HDFS，则要针对Hadoop 1.x 和Hadoop 2.x 选择不同的版本。这里我选择 Hadoop 2.x 版。\n\n    spark@master $ wget http://d3kbcqa49mib13.cloudfront.net/spark-0.9.0-incubating-bin-hadoop1.tgz\n    spark@master $ tar zxf spark-0.9.0-incubating-bin-hadoop1.tgz -C ~/local/opt\n\n###1.2 将tgz压缩包scp到所有机器，解压到相同的路径\n\n    spark@master $ scp spark-0.9.0-incubating-bin-hadoop1.tgz spark@worker01:~\n    spark@master $ ssh worker01\n    spark@worker01 $ tar zxf spark-0.9.0-incubating-bin-hadoop1.tgz -C ~/local/opt\n    spark@worker01 $ exit\n    spark@master $ scp spark-0.9.0-incubating-bin-hadoop1.tgz spark@worker02:~\n    spark@master $ ssh worker02\n    spark@worker02 $ tar zxf spark-0.9.0-incubating-bin-hadoop1.tgz -C ~/local/opt\n    spark@worker02 $ exit\n\n###1.3 修改配置文件\nSpark 0.9 以后，配置文件简单多了，只有一个必须要配置，就是 `conf/slaves` 这个文件。在这个文件里添加slave的hostname。\n\n###1.4 拷贝配置文件到所有slave\n\n    spark@master $ spark@master $ scp ./conf/slaves spark@worker01:~/local/opt/spark-0.9.0-incubating-bin-hadoop1/conf\n    spark@master $ spark@master $ scp ./conf/slaves spark@worker02:~/local/opt/spark-0.9.0-incubating-bin-hadoop1/conf\n\n###1.5 启动Spark集群\n\n    spark@master $ ./sbin/start-all.sh\n\n<!-- more -->\n\n也可以一台一台启动，先启动 master\n\n    spark@master $ ./sbin/start-master.sh\n\n启动两台 slave，\n\n    spark@worker01 $ ./sbin/start-slave.sh 1 spark://master:7077\n    spark@worker02 $ ./sbin/start-slave.sh 2 spark://master:7077\n\n其中，`1`, `2` 是 worker的编号，可以是任意数字，只要不重复即可，`spark://master:7077` 是 master 的地址。以后向集群提交作业的时候，也需要这个地址。\n\n###1.6 测试一下，向集群提交一个作业\n\n    spark@master $ ./bin/run-example org.apache.spark.examples.SparkPi spark://master:7077\n\n\n##2 配置普通开发环境\nTODO\n\n##3 配置Spark开发环境\n当你需要修改Spark的代码，或给Spark添加代码，就需要阅读本节了。\n\n### 3.1 git clone 代码\n\n    git clone git@github.com:apache/incubator-spark.git\n\n###3.2 编译\nSpark脚本会自动下载对应版本的sbt和scala编译器，因此机器事先不需要安装sbt和scala\n\n按照 github 官方repo首页的文档，输入如下一行命令即可开始编译，\n\n    ./sbt/sbt assembly\n\n###3.3 运行一个例子\n\n    ./run-example org.apache.spark.examples.SparkPi local\n\n说明安装成功了。\n\n###3.4 试用 spark shell\n<!-- more -->\n\n./spark-shell\n\n会出现`scala>`提示符号，可见spark脚本自动下载了scala编译器，其实就是一个jar，例如`scala-compiler-2.10.3.jar`。\n\n\n###3.5 安装scala\n开发Spark的时候，由于Intellij Idea 需要调用外部的sbt和scala，因此机器上还是需要安装scala和sbt。\n\n打开 `projects/SparkBuild.scala`，搜索`scalaVersion`，获得spark所使用的scala编译器版本，然后去scala官网<http://www.scala-lang.org/>，下载该版本的scala编译器，并设置`SCALA_HOME`环境变量，将bin目录加入PATH。例如下载scala-2.10.3.tgz，解压到/opt，设置环境变量如下：\n\n    sudo vim /etc/profile\n    export SCALA_HOME=/opt/scala-2.10.3\n    export PATH=$PATH:$SCALA_HOME/bin\n\n###3.6 安装sbt\n\n打开`projects/build.properties`，可以看到spark所使用的sbt版本号，去\n官网<http://www.scala-sbt.org/>下载该版本的sbt，双击安装。并设置`SBT_HOME`环境变量，将bin目录加入PATH。\n\n###3.7 下载并安装idea\n\nSpark核心团队的hashjoin曾在我博客上留言，说他们都使用idea在开发spark，我用过[Scala IDE](www.scala-ide.org)和idea，两者各有优劣，总的来说，idea要好用一些，虽然我是老牌eclipse用户，但我还是转向了idea。\n\n去idea官网下载idea的tar.gz包，解压就行。运行idea，安装scala插件。\n\n###3.8 生成idea项目文件\n在源码根目录，使用如下命令\n\n    ./sbt/sbt gen-idea\n\n就生成了idea项目文件。\n\n###3.9 Open Project\n使用 idea，点击`File->Open project`，浏览到 `incubator-spark`文件夹，打开项目，就可以修改Spark代码了。\n\n","source":"_posts/2014-01-30-spark-development-environment.md","raw":"---\nlayout: post\ntitle: \"Spark开发环境的配置\"\ndate: 2014-01-30 16:36\ncomments: true\ncategories: Spark\n---\n\n**软件版本**：Spark 0.9\n\n配置Spark开发环境，其实分为三个层次，一种是针对运维人员，把Spark安装部署到集群；一种是针对普通开发者，引入Spark的jar包，调用Spark提供的接口，编写分布式程序，写好后编译成jar，就可以提交到Spark集群去运行了；第三种是针对Spark开发者，为了给Spark贡献代码，需要git clone Spark的代码，然后导入IDE，为Spark开发代码。\n\n##1 部署Spark集群\n这种是运维人员在生产环境下，搭建起一个Spark集群。\n\n###（可选）创建新用户 Spark\n一般我倾向于把需要启动daemon进程，对外提供服务的程序，即服务器类的程序，安装在单独的用户下面。这样可以做到隔离，运维方面，安全性也提高了。\n\n创建一个新的group,\n\n    $ sudo groupadd spark\n\n创建一个新的用户，并加入group,\n\n    $ sudo useradd -g spark spark\n\n给新用户设置密码，\n\n    $ sudo passwd spark\n\n在每台机器上创建 spark 新用户，并配置好SSH无密码，参考我的另一篇博客，[SSH无密码登录的配置](http://www.yanjiuyanjiu.com/blog/20120102/)\n\n\n假设有三台机器，hostname分别是 master, worker01, worker02。\n\n###1.1 下载 Spark 预编译好的二进制包\n如果你需要用到HDFS，则要针对Hadoop 1.x 和Hadoop 2.x 选择不同的版本。这里我选择 Hadoop 2.x 版。\n\n    spark@master $ wget http://d3kbcqa49mib13.cloudfront.net/spark-0.9.0-incubating-bin-hadoop1.tgz\n    spark@master $ tar zxf spark-0.9.0-incubating-bin-hadoop1.tgz -C ~/local/opt\n\n###1.2 将tgz压缩包scp到所有机器，解压到相同的路径\n\n    spark@master $ scp spark-0.9.0-incubating-bin-hadoop1.tgz spark@worker01:~\n    spark@master $ ssh worker01\n    spark@worker01 $ tar zxf spark-0.9.0-incubating-bin-hadoop1.tgz -C ~/local/opt\n    spark@worker01 $ exit\n    spark@master $ scp spark-0.9.0-incubating-bin-hadoop1.tgz spark@worker02:~\n    spark@master $ ssh worker02\n    spark@worker02 $ tar zxf spark-0.9.0-incubating-bin-hadoop1.tgz -C ~/local/opt\n    spark@worker02 $ exit\n\n###1.3 修改配置文件\nSpark 0.9 以后，配置文件简单多了，只有一个必须要配置，就是 `conf/slaves` 这个文件。在这个文件里添加slave的hostname。\n\n###1.4 拷贝配置文件到所有slave\n\n    spark@master $ spark@master $ scp ./conf/slaves spark@worker01:~/local/opt/spark-0.9.0-incubating-bin-hadoop1/conf\n    spark@master $ spark@master $ scp ./conf/slaves spark@worker02:~/local/opt/spark-0.9.0-incubating-bin-hadoop1/conf\n\n###1.5 启动Spark集群\n\n    spark@master $ ./sbin/start-all.sh\n\n<!-- more -->\n\n也可以一台一台启动，先启动 master\n\n    spark@master $ ./sbin/start-master.sh\n\n启动两台 slave，\n\n    spark@worker01 $ ./sbin/start-slave.sh 1 spark://master:7077\n    spark@worker02 $ ./sbin/start-slave.sh 2 spark://master:7077\n\n其中，`1`, `2` 是 worker的编号，可以是任意数字，只要不重复即可，`spark://master:7077` 是 master 的地址。以后向集群提交作业的时候，也需要这个地址。\n\n###1.6 测试一下，向集群提交一个作业\n\n    spark@master $ ./bin/run-example org.apache.spark.examples.SparkPi spark://master:7077\n\n\n##2 配置普通开发环境\nTODO\n\n##3 配置Spark开发环境\n当你需要修改Spark的代码，或给Spark添加代码，就需要阅读本节了。\n\n### 3.1 git clone 代码\n\n    git clone git@github.com:apache/incubator-spark.git\n\n###3.2 编译\nSpark脚本会自动下载对应版本的sbt和scala编译器，因此机器事先不需要安装sbt和scala\n\n按照 github 官方repo首页的文档，输入如下一行命令即可开始编译，\n\n    ./sbt/sbt assembly\n\n###3.3 运行一个例子\n\n    ./run-example org.apache.spark.examples.SparkPi local\n\n说明安装成功了。\n\n###3.4 试用 spark shell\n<!-- more -->\n\n./spark-shell\n\n会出现`scala>`提示符号，可见spark脚本自动下载了scala编译器，其实就是一个jar，例如`scala-compiler-2.10.3.jar`。\n\n\n###3.5 安装scala\n开发Spark的时候，由于Intellij Idea 需要调用外部的sbt和scala，因此机器上还是需要安装scala和sbt。\n\n打开 `projects/SparkBuild.scala`，搜索`scalaVersion`，获得spark所使用的scala编译器版本，然后去scala官网<http://www.scala-lang.org/>，下载该版本的scala编译器，并设置`SCALA_HOME`环境变量，将bin目录加入PATH。例如下载scala-2.10.3.tgz，解压到/opt，设置环境变量如下：\n\n    sudo vim /etc/profile\n    export SCALA_HOME=/opt/scala-2.10.3\n    export PATH=$PATH:$SCALA_HOME/bin\n\n###3.6 安装sbt\n\n打开`projects/build.properties`，可以看到spark所使用的sbt版本号，去\n官网<http://www.scala-sbt.org/>下载该版本的sbt，双击安装。并设置`SBT_HOME`环境变量，将bin目录加入PATH。\n\n###3.7 下载并安装idea\n\nSpark核心团队的hashjoin曾在我博客上留言，说他们都使用idea在开发spark，我用过[Scala IDE](www.scala-ide.org)和idea，两者各有优劣，总的来说，idea要好用一些，虽然我是老牌eclipse用户，但我还是转向了idea。\n\n去idea官网下载idea的tar.gz包，解压就行。运行idea，安装scala插件。\n\n###3.8 生成idea项目文件\n在源码根目录，使用如下命令\n\n    ./sbt/sbt gen-idea\n\n就生成了idea项目文件。\n\n###3.9 Open Project\n使用 idea，点击`File->Open project`，浏览到 `incubator-spark`文件夹，打开项目，就可以修改Spark代码了。\n\n","slug":"2014-01-30-spark-development-environment","published":1,"updated":"2016-08-18T09:21:04.000Z","photos":[],"link":"","_id":"cis07pf4a002y01pqfgtclqzm","content":"<p><strong>软件版本</strong>：Spark 0.9</p>\n<p>配置Spark开发环境，其实分为三个层次，一种是针对运维人员，把Spark安装部署到集群；一种是针对普通开发者，引入Spark的jar包，调用Spark提供的接口，编写分布式程序，写好后编译成jar，就可以提交到Spark集群去运行了；第三种是针对Spark开发者，为了给Spark贡献代码，需要git clone Spark的代码，然后导入IDE，为Spark开发代码。</p>\n<p>##1 部署Spark集群<br>这种是运维人员在生产环境下，搭建起一个Spark集群。</p>\n<p>###（可选）创建新用户 Spark<br>一般我倾向于把需要启动daemon进程，对外提供服务的程序，即服务器类的程序，安装在单独的用户下面。这样可以做到隔离，运维方面，安全性也提高了。</p>\n<p>创建一个新的group,</p>\n<pre><code>$ sudo groupadd spark\n</code></pre><p>创建一个新的用户，并加入group,</p>\n<pre><code>$ sudo useradd -g spark spark\n</code></pre><p>给新用户设置密码，</p>\n<pre><code>$ sudo passwd spark\n</code></pre><p>在每台机器上创建 spark 新用户，并配置好SSH无密码，参考我的另一篇博客，<a href=\"http://www.yanjiuyanjiu.com/blog/20120102/\" target=\"_blank\" rel=\"external\">SSH无密码登录的配置</a></p>\n<p>假设有三台机器，hostname分别是 master, worker01, worker02。</p>\n<p>###1.1 下载 Spark 预编译好的二进制包<br>如果你需要用到HDFS，则要针对Hadoop 1.x 和Hadoop 2.x 选择不同的版本。这里我选择 Hadoop 2.x 版。</p>\n<pre><code>spark@master $ wget http://d3kbcqa49mib13.cloudfront.net/spark-0.9.0-incubating-bin-hadoop1.tgz\nspark@master $ tar zxf spark-0.9.0-incubating-bin-hadoop1.tgz -C ~/local/opt\n</code></pre><p>###1.2 将tgz压缩包scp到所有机器，解压到相同的路径</p>\n<pre><code>spark@master $ scp spark-0.9.0-incubating-bin-hadoop1.tgz spark@worker01:~\nspark@master $ ssh worker01\nspark@worker01 $ tar zxf spark-0.9.0-incubating-bin-hadoop1.tgz -C ~/local/opt\nspark@worker01 $ exit\nspark@master $ scp spark-0.9.0-incubating-bin-hadoop1.tgz spark@worker02:~\nspark@master $ ssh worker02\nspark@worker02 $ tar zxf spark-0.9.0-incubating-bin-hadoop1.tgz -C ~/local/opt\nspark@worker02 $ exit\n</code></pre><p>###1.3 修改配置文件<br>Spark 0.9 以后，配置文件简单多了，只有一个必须要配置，就是 <code>conf/slaves</code> 这个文件。在这个文件里添加slave的hostname。</p>\n<p>###1.4 拷贝配置文件到所有slave</p>\n<pre><code>spark@master $ spark@master $ scp ./conf/slaves spark@worker01:~/local/opt/spark-0.9.0-incubating-bin-hadoop1/conf\nspark@master $ spark@master $ scp ./conf/slaves spark@worker02:~/local/opt/spark-0.9.0-incubating-bin-hadoop1/conf\n</code></pre><p>###1.5 启动Spark集群</p>\n<pre><code>spark@master $ ./sbin/start-all.sh\n</code></pre><a id=\"more\"></a>\n<p>也可以一台一台启动，先启动 master</p>\n<pre><code>spark@master $ ./sbin/start-master.sh\n</code></pre><p>启动两台 slave，</p>\n<pre><code>spark@worker01 $ ./sbin/start-slave.sh 1 spark://master:7077\nspark@worker02 $ ./sbin/start-slave.sh 2 spark://master:7077\n</code></pre><p>其中，<code>1</code>, <code>2</code> 是 worker的编号，可以是任意数字，只要不重复即可，<code>spark://master:7077</code> 是 master 的地址。以后向集群提交作业的时候，也需要这个地址。</p>\n<p>###1.6 测试一下，向集群提交一个作业</p>\n<pre><code>spark@master $ ./bin/run-example org.apache.spark.examples.SparkPi spark://master:7077\n</code></pre><p>##2 配置普通开发环境<br>TODO</p>\n<p>##3 配置Spark开发环境<br>当你需要修改Spark的代码，或给Spark添加代码，就需要阅读本节了。</p>\n<h3 id=\"3-1-git-clone-代码\"><a href=\"#3-1-git-clone-代码\" class=\"headerlink\" title=\"3.1 git clone 代码\"></a>3.1 git clone 代码</h3><pre><code>git clone git@github.com:apache/incubator-spark.git\n</code></pre><p>###3.2 编译<br>Spark脚本会自动下载对应版本的sbt和scala编译器，因此机器事先不需要安装sbt和scala</p>\n<p>按照 github 官方repo首页的文档，输入如下一行命令即可开始编译，</p>\n<pre><code>./sbt/sbt assembly\n</code></pre><p>###3.3 运行一个例子</p>\n<pre><code>./run-example org.apache.spark.examples.SparkPi local\n</code></pre><p>说明安装成功了。</p>\n<p>###3.4 试用 spark shell<br><!-- more --></p>\n<p>./spark-shell</p>\n<p>会出现<code>scala&gt;</code>提示符号，可见spark脚本自动下载了scala编译器，其实就是一个jar，例如<code>scala-compiler-2.10.3.jar</code>。</p>\n<p>###3.5 安装scala<br>开发Spark的时候，由于Intellij Idea 需要调用外部的sbt和scala，因此机器上还是需要安装scala和sbt。</p>\n<p>打开 <code>projects/SparkBuild.scala</code>，搜索<code>scalaVersion</code>，获得spark所使用的scala编译器版本，然后去scala官网<a href=\"http://www.scala-lang.org/\" target=\"_blank\" rel=\"external\">http://www.scala-lang.org/</a>，下载该版本的scala编译器，并设置<code>SCALA_HOME</code>环境变量，将bin目录加入PATH。例如下载scala-2.10.3.tgz，解压到/opt，设置环境变量如下：</p>\n<pre><code>sudo vim /etc/profile\nexport SCALA_HOME=/opt/scala-2.10.3\nexport PATH=$PATH:$SCALA_HOME/bin\n</code></pre><p>###3.6 安装sbt</p>\n<p>打开<code>projects/build.properties</code>，可以看到spark所使用的sbt版本号，去<br>官网<a href=\"http://www.scala-sbt.org/\" target=\"_blank\" rel=\"external\">http://www.scala-sbt.org/</a>下载该版本的sbt，双击安装。并设置<code>SBT_HOME</code>环境变量，将bin目录加入PATH。</p>\n<p>###3.7 下载并安装idea</p>\n<p>Spark核心团队的hashjoin曾在我博客上留言，说他们都使用idea在开发spark，我用过<a href=\"www.scala-ide.org\">Scala IDE</a>和idea，两者各有优劣，总的来说，idea要好用一些，虽然我是老牌eclipse用户，但我还是转向了idea。</p>\n<p>去idea官网下载idea的tar.gz包，解压就行。运行idea，安装scala插件。</p>\n<p>###3.8 生成idea项目文件<br>在源码根目录，使用如下命令</p>\n<pre><code>./sbt/sbt gen-idea\n</code></pre><p>就生成了idea项目文件。</p>\n<p>###3.9 Open Project<br>使用 idea，点击<code>File-&gt;Open project</code>，浏览到 <code>incubator-spark</code>文件夹，打开项目，就可以修改Spark代码了。</p>\n","excerpt":"<p><strong>软件版本</strong>：Spark 0.9</p>\n<p>配置Spark开发环境，其实分为三个层次，一种是针对运维人员，把Spark安装部署到集群；一种是针对普通开发者，引入Spark的jar包，调用Spark提供的接口，编写分布式程序，写好后编译成jar，就可以提交到Spark集群去运行了；第三种是针对Spark开发者，为了给Spark贡献代码，需要git clone Spark的代码，然后导入IDE，为Spark开发代码。</p>\n<p>##1 部署Spark集群<br>这种是运维人员在生产环境下，搭建起一个Spark集群。</p>\n<p>###（可选）创建新用户 Spark<br>一般我倾向于把需要启动daemon进程，对外提供服务的程序，即服务器类的程序，安装在单独的用户下面。这样可以做到隔离，运维方面，安全性也提高了。</p>\n<p>创建一个新的group,</p>\n<pre><code>$ sudo groupadd spark\n</code></pre><p>创建一个新的用户，并加入group,</p>\n<pre><code>$ sudo useradd -g spark spark\n</code></pre><p>给新用户设置密码，</p>\n<pre><code>$ sudo passwd spark\n</code></pre><p>在每台机器上创建 spark 新用户，并配置好SSH无密码，参考我的另一篇博客，<a href=\"http://www.yanjiuyanjiu.com/blog/20120102/\">SSH无密码登录的配置</a></p>\n<p>假设有三台机器，hostname分别是 master, worker01, worker02。</p>\n<p>###1.1 下载 Spark 预编译好的二进制包<br>如果你需要用到HDFS，则要针对Hadoop 1.x 和Hadoop 2.x 选择不同的版本。这里我选择 Hadoop 2.x 版。</p>\n<pre><code>spark@master $ wget http://d3kbcqa49mib13.cloudfront.net/spark-0.9.0-incubating-bin-hadoop1.tgz\nspark@master $ tar zxf spark-0.9.0-incubating-bin-hadoop1.tgz -C ~/local/opt\n</code></pre><p>###1.2 将tgz压缩包scp到所有机器，解压到相同的路径</p>\n<pre><code>spark@master $ scp spark-0.9.0-incubating-bin-hadoop1.tgz spark@worker01:~\nspark@master $ ssh worker01\nspark@worker01 $ tar zxf spark-0.9.0-incubating-bin-hadoop1.tgz -C ~/local/opt\nspark@worker01 $ exit\nspark@master $ scp spark-0.9.0-incubating-bin-hadoop1.tgz spark@worker02:~\nspark@master $ ssh worker02\nspark@worker02 $ tar zxf spark-0.9.0-incubating-bin-hadoop1.tgz -C ~/local/opt\nspark@worker02 $ exit\n</code></pre><p>###1.3 修改配置文件<br>Spark 0.9 以后，配置文件简单多了，只有一个必须要配置，就是 <code>conf/slaves</code> 这个文件。在这个文件里添加slave的hostname。</p>\n<p>###1.4 拷贝配置文件到所有slave</p>\n<pre><code>spark@master $ spark@master $ scp ./conf/slaves spark@worker01:~/local/opt/spark-0.9.0-incubating-bin-hadoop1/conf\nspark@master $ spark@master $ scp ./conf/slaves spark@worker02:~/local/opt/spark-0.9.0-incubating-bin-hadoop1/conf\n</code></pre><p>###1.5 启动Spark集群</p>\n<pre><code>spark@master $ ./sbin/start-all.sh\n</code></pre>","more":"<p>也可以一台一台启动，先启动 master</p>\n<pre><code>spark@master $ ./sbin/start-master.sh\n</code></pre><p>启动两台 slave，</p>\n<pre><code>spark@worker01 $ ./sbin/start-slave.sh 1 spark://master:7077\nspark@worker02 $ ./sbin/start-slave.sh 2 spark://master:7077\n</code></pre><p>其中，<code>1</code>, <code>2</code> 是 worker的编号，可以是任意数字，只要不重复即可，<code>spark://master:7077</code> 是 master 的地址。以后向集群提交作业的时候，也需要这个地址。</p>\n<p>###1.6 测试一下，向集群提交一个作业</p>\n<pre><code>spark@master $ ./bin/run-example org.apache.spark.examples.SparkPi spark://master:7077\n</code></pre><p>##2 配置普通开发环境<br>TODO</p>\n<p>##3 配置Spark开发环境<br>当你需要修改Spark的代码，或给Spark添加代码，就需要阅读本节了。</p>\n<h3 id=\"3-1-git-clone-代码\"><a href=\"#3-1-git-clone-代码\" class=\"headerlink\" title=\"3.1 git clone 代码\"></a>3.1 git clone 代码</h3><pre><code>git clone git@github.com:apache/incubator-spark.git\n</code></pre><p>###3.2 编译<br>Spark脚本会自动下载对应版本的sbt和scala编译器，因此机器事先不需要安装sbt和scala</p>\n<p>按照 github 官方repo首页的文档，输入如下一行命令即可开始编译，</p>\n<pre><code>./sbt/sbt assembly\n</code></pre><p>###3.3 运行一个例子</p>\n<pre><code>./run-example org.apache.spark.examples.SparkPi local\n</code></pre><p>说明安装成功了。</p>\n<p>###3.4 试用 spark shell<br><!-- more --></p>\n<p>./spark-shell</p>\n<p>会出现<code>scala&gt;</code>提示符号，可见spark脚本自动下载了scala编译器，其实就是一个jar，例如<code>scala-compiler-2.10.3.jar</code>。</p>\n<p>###3.5 安装scala<br>开发Spark的时候，由于Intellij Idea 需要调用外部的sbt和scala，因此机器上还是需要安装scala和sbt。</p>\n<p>打开 <code>projects/SparkBuild.scala</code>，搜索<code>scalaVersion</code>，获得spark所使用的scala编译器版本，然后去scala官网<a href=\"http://www.scala-lang.org/\">http://www.scala-lang.org/</a>，下载该版本的scala编译器，并设置<code>SCALA_HOME</code>环境变量，将bin目录加入PATH。例如下载scala-2.10.3.tgz，解压到/opt，设置环境变量如下：</p>\n<pre><code>sudo vim /etc/profile\nexport SCALA_HOME=/opt/scala-2.10.3\nexport PATH=$PATH:$SCALA_HOME/bin\n</code></pre><p>###3.6 安装sbt</p>\n<p>打开<code>projects/build.properties</code>，可以看到spark所使用的sbt版本号，去<br>官网<a href=\"http://www.scala-sbt.org/\">http://www.scala-sbt.org/</a>下载该版本的sbt，双击安装。并设置<code>SBT_HOME</code>环境变量，将bin目录加入PATH。</p>\n<p>###3.7 下载并安装idea</p>\n<p>Spark核心团队的hashjoin曾在我博客上留言，说他们都使用idea在开发spark，我用过<a href=\"www.scala-ide.org\">Scala IDE</a>和idea，两者各有优劣，总的来说，idea要好用一些，虽然我是老牌eclipse用户，但我还是转向了idea。</p>\n<p>去idea官网下载idea的tar.gz包，解压就行。运行idea，安装scala插件。</p>\n<p>###3.8 生成idea项目文件<br>在源码根目录，使用如下命令</p>\n<pre><code>./sbt/sbt gen-idea\n</code></pre><p>就生成了idea项目文件。</p>\n<p>###3.9 Open Project<br>使用 idea，点击<code>File-&gt;Open project</code>，浏览到 <code>incubator-spark</code>文件夹，打开项目，就可以修改Spark代码了。</p>"},{"layout":"post","title":"我的Ansible playbook","date":"2014-01-29T22:08:00.000Z","comments":1,"_content":"\n**前提**，安装好Ansible，参考我的上一篇博客，[Ansible 快速入门](http://www.yanjiuyanjiu.com/blog/20140127)\n\n    ---\n    - hosts: all\n      sudo: True\n      remote_user: work\n      vars:\n        ant_version: 1.9.3\n        maven_version: 3.1.1\n        scala_version: 2.10.3\n        sbt_version: 0.12.4\n    \n      tasks:\n      ########## for CentOS and RedHat ##########\n        - name: Install the libselinux-python package  # because ansible needs it\n          yum: name=libselinux-python state=installed\n          when: ansible_distribution == 'CentOS' or ansible_distribution == 'Red Hat Enterprise Linux'\n    \n        - name: Disable SELinux in conf file\n          selinux: state=disabled\n          when: ansible_distribution == 'CentOS' or ansible_distribution == 'Red Hat Enterprise Linux'\n    \n        - name: update YUM repositories\n          shell: 'yum -y update'\n          when: ansible_distribution == 'CentOS' or ansible_distribution == 'Red Hat Enterprise Linux'\n    \n        - name: Install OpenJDK\n          yum: name=java-1.7.0-openjdk-devel state=present\n          when: ansible_distribution == 'CentOS' or ansible_distribution == 'Red Hat Enterprise Linux'\n    \n        - name: Set JAVA_HOME environment variable\n          lineinfile: dest='/etc/profile' regexp='^#?\\s*export JAVA_HOME=(.*)$' line='export JAVA_HOME=/usr/lib/jvm/java' state=present\n          when: ansible_distribution == 'CentOS' or ansible_distribution == 'Red Hat Enterprise Linux'\n    \n        - name: install the 'Development tools' package group\n          yum: name=\"@Development tools\" state=present\n          when: ansible_distribution == 'CentOS' or ansible_distribution == 'Red Hat Enterprise Linux'\n    \n        - name: upgrade all packages\n          shell: 'yum -y upgrade'\n          when: ansible_distribution == 'CentOS' or ansible_distribution == 'Red Hat Enterprise Linux'\n    \n    \n      ########## for Ubuntu and Debian ##########\n        - name: Run \"apt-get update\" to update the source list\n          apt: update_cache=yes\n          when: ansible_distribution == 'Debian' or ansible_distribution == 'Ubuntu'\n    \n        - name: Install OpenJDK\n          apt: pkg=openjdk-7-jdk state=present\n          when: ansible_distribution == 'Debian' or ansible_distribution == 'Ubuntu'\n    \n        - name: Set JAVA_HOME environment variable\n          lineinfile: dest='/etc/profile' regexp='^#?\\s*export JAVA_HOME=(.*)$' line='export JAVA_HOME=/usr/lib/jvm/java-1.7.0-openjdk-amd64' state=present\n          when: ansible_distribution == 'Debian' or ansible_distribution == 'Ubuntu'\n    \n        - name: Install build-essential\n          apt: pkg=build-essential state=present\n          when: ansible_distribution == 'Debian' or ansible_distribution == 'Ubuntu'\n    \n        - name: Update all packages to the latest version\n          apt: upgrade=dist\n          when: ansible_distribution == 'Debian' or ansible_distribution == 'Ubuntu'\n    \n    \n      ########## Common opreations for all OS ##########\n        # Create local directories\n        - file: path=~/local/bin state=directory\n          sudo: no\n        - file: path=~/local/sbin state=directory\n          sudo: no\n        - file: path=~/local/src state=directory\n          sudo: no\n        - file: path=~/local/opt state=directory\n          sudo: no\n        - file: path=~/local/var state=directory\n          sudo: no\n        - lineinfile: dest=~/.bashrc regexp='^#?\\s*export PATH=(.*)/local/bin(.*)$' line=\"export PATH=$PATH:$HOME/local/bin\" state=present\n          sudo: no\n        - lineinfile: dest=~/.bashrc regexp='^#?\\s*export PATH=(.*)/local/sbin(.*)$' line=\"export PATH=$PATH:$HOME/local/sbin\" state=present\n          sudo: no\n    \n        - name: Set CLASSPATH and PATH environment variables\n          lineinfile: $item\n          with_items:\n            - dest='/etc/profile' regexp='^#?\\s*export CLASSPATH=(.*)$' line='export CLASSPATH=.:$JAVA_HOME/lib/*.jar:$JAVA_HOME/jre/lib/*.jar' state=present\n            - dest='/etc/profile' regexp='^#?\\s*export PATH=(.*)JAVA_HOME(.*)$' line=\"export PATH=$PATH:$JAVA_HOME/bin\" state=present\n    \n        ###### Since Ant in yum and apt is too old, download the .tar.bz2 file and install it\n        # Install Apache Ant\n        - name: Download Apache Ant\n          get_url: url=http://mirror.cc.columbia.edu/pub/software/apache//ant/binaries/apache-ant-{{ant_version}}-bin.tar.bz2 dest=/tmp/apache-ant-{{ant_version}}-bin.tar.bz2\n        - name: Untar Ant\n          shell: chdir=/tmp creates=/opt/apache-ant-{{ant_version}} tar -jxf apache-ant-{{ant_version}}-bin.tar.bz2 -C /opt\n        - lineinfile: dest=/etc/profile regexp='^#?\\s*export ANT_HOME=(.*)$' line='export ANT_HOME=/opt/apache-ant-{{ant_version}}' state=present\n        - lineinfile: dest=/etc/profile regexp='^#?\\s*export PATH=(.*)ANT_HOME(.*)$' line=\"export PATH=$PATH:$ANT_HOME/bin\" state=present\n    \n        # Install Apache Maven, since there is no Maven package in yum and apt repo\n        - name: Download Apache Maven\n          get_url: url=http://apache.claz.org/maven/maven-3/3.1.1/binaries/apache-maven-{{maven_version}}-bin.tar.gz dest=/tmp/apache-maven-{{maven_version}}-bin.tar.gz\n        - name: Untar Maven\n          shell: chdir=/tmp creates=/opt/apache-maven-{{maven_version}} tar -zxf apache-maven-{{maven_version}}-bin.tar.gz -C /opt\n        - lineinfile: dest=/etc/profile regexp='^#?\\s*export MAVEN_HOME=(.*)$' line='export MAVEN_HOME=/opt/apache-maven-{{maven_version}}' state=present\n        - lineinfile: dest=/etc/profile regexp='^#?\\s*export PATH=(.*)MAVEN_HOME(.*)$' line=\"export PATH=$PATH:$MAVEN_HOME/bin\" state=present\n    \n        # Install the scala compiler, because the scala compiler in yum and apt repo is too old\n        - name: Download Scala\n          get_url: url=http://www.scala-lang.org/files/archive/scala-{{scala_version}}.tgz dest=/tmp/scala-{{scala_version}}.tgz\n        - name: Untar Scala\n          shell: chdir=/tmp creates=/opt/scala-{{scala_version}} tar -zxf scala-{{scala_version}}.tgz -C /opt\n        - lineinfile: dest=/etc/profile regexp='^#?\\s*export SCALA_HOME=(.*)$' line='export SCALA_HOME=/opt/scala-{{scala_version}}' state=present\n        - lineinfile: dest=/etc/profile regexp='^#?\\s*export PATH=(.*)SCALA_HOME(.*)$' line=\"export PATH=$PATH:$SCALA_HOME/bin\" state=present\n    \n        # Install sbt\n        - name: Download sbt\n          get_url: url=http://repo.scala-sbt.org/scalasbt/sbt-native-packages/org/scala-sbt/sbt//{{sbt_version}}/sbt.tgz dest=/tmp/sbt-{{sbt_version}}.tgz\n        - name: Untar sbt\n          shell: chdir=/tmp creates=/opt/sbt-{{sbt_version}} tar -zxf sbt-{{sbt_version}}.tgz -C /opt\n        - name: Rename sbt directory\n          shell: chdir=/opt creates=/opt/sbt-{{sbt_version}} mv sbt/ sbt-{{sbt_version}}/\n        - lineinfile: dest=/etc/profile regexp='^#?\\s*export SBT_HOME=(.*)$' line='export SBT_HOME=/opt/sbt-{{sbt_version}}' state=present\n        - lineinfile: dest=/etc/profile regexp='^#?\\s*export PATH=(.*)SBT_HOME(.*)$' line=\"export PATH=$PATH:$SBT_HOME/bin\" state=present\n    \n        # Install Go\n        - name: Download Go\n          get_url: url=https://go.googlecode.com/files/go1.2.linux-amd64.tar.gz dest=/tmp/go1.2.linux-amd64.tar.gz\n        - name: Untar Go\n          shell: chdir=/tmp creates=/opt/go tar -zxf go1.2.linux-amd64.tar.gz -C /opt\n        - lineinfile: dest=/etc/profile regexp='^#?\\s*export GOROOT=(.*)$' line='export GOROOT=/opt/go' state=present\n        - lineinfile: dest=/etc/profile regexp='^#?\\s*export PATH=(.*)GOROOT(.*)$' line=\"export PATH=$PATH:$GOROOT/bin\" state=present\n\n","source":"_posts/2014-01-29-my-ansible-playbook.md","raw":"---\nlayout: post\ntitle: \"我的Ansible playbook\"\ndate: 2014-01-29 22:08\ncomments: true\ncategories: DevOps\n---\n\n**前提**，安装好Ansible，参考我的上一篇博客，[Ansible 快速入门](http://www.yanjiuyanjiu.com/blog/20140127)\n\n    ---\n    - hosts: all\n      sudo: True\n      remote_user: work\n      vars:\n        ant_version: 1.9.3\n        maven_version: 3.1.1\n        scala_version: 2.10.3\n        sbt_version: 0.12.4\n    \n      tasks:\n      ########## for CentOS and RedHat ##########\n        - name: Install the libselinux-python package  # because ansible needs it\n          yum: name=libselinux-python state=installed\n          when: ansible_distribution == 'CentOS' or ansible_distribution == 'Red Hat Enterprise Linux'\n    \n        - name: Disable SELinux in conf file\n          selinux: state=disabled\n          when: ansible_distribution == 'CentOS' or ansible_distribution == 'Red Hat Enterprise Linux'\n    \n        - name: update YUM repositories\n          shell: 'yum -y update'\n          when: ansible_distribution == 'CentOS' or ansible_distribution == 'Red Hat Enterprise Linux'\n    \n        - name: Install OpenJDK\n          yum: name=java-1.7.0-openjdk-devel state=present\n          when: ansible_distribution == 'CentOS' or ansible_distribution == 'Red Hat Enterprise Linux'\n    \n        - name: Set JAVA_HOME environment variable\n          lineinfile: dest='/etc/profile' regexp='^#?\\s*export JAVA_HOME=(.*)$' line='export JAVA_HOME=/usr/lib/jvm/java' state=present\n          when: ansible_distribution == 'CentOS' or ansible_distribution == 'Red Hat Enterprise Linux'\n    \n        - name: install the 'Development tools' package group\n          yum: name=\"@Development tools\" state=present\n          when: ansible_distribution == 'CentOS' or ansible_distribution == 'Red Hat Enterprise Linux'\n    \n        - name: upgrade all packages\n          shell: 'yum -y upgrade'\n          when: ansible_distribution == 'CentOS' or ansible_distribution == 'Red Hat Enterprise Linux'\n    \n    \n      ########## for Ubuntu and Debian ##########\n        - name: Run \"apt-get update\" to update the source list\n          apt: update_cache=yes\n          when: ansible_distribution == 'Debian' or ansible_distribution == 'Ubuntu'\n    \n        - name: Install OpenJDK\n          apt: pkg=openjdk-7-jdk state=present\n          when: ansible_distribution == 'Debian' or ansible_distribution == 'Ubuntu'\n    \n        - name: Set JAVA_HOME environment variable\n          lineinfile: dest='/etc/profile' regexp='^#?\\s*export JAVA_HOME=(.*)$' line='export JAVA_HOME=/usr/lib/jvm/java-1.7.0-openjdk-amd64' state=present\n          when: ansible_distribution == 'Debian' or ansible_distribution == 'Ubuntu'\n    \n        - name: Install build-essential\n          apt: pkg=build-essential state=present\n          when: ansible_distribution == 'Debian' or ansible_distribution == 'Ubuntu'\n    \n        - name: Update all packages to the latest version\n          apt: upgrade=dist\n          when: ansible_distribution == 'Debian' or ansible_distribution == 'Ubuntu'\n    \n    \n      ########## Common opreations for all OS ##########\n        # Create local directories\n        - file: path=~/local/bin state=directory\n          sudo: no\n        - file: path=~/local/sbin state=directory\n          sudo: no\n        - file: path=~/local/src state=directory\n          sudo: no\n        - file: path=~/local/opt state=directory\n          sudo: no\n        - file: path=~/local/var state=directory\n          sudo: no\n        - lineinfile: dest=~/.bashrc regexp='^#?\\s*export PATH=(.*)/local/bin(.*)$' line=\"export PATH=$PATH:$HOME/local/bin\" state=present\n          sudo: no\n        - lineinfile: dest=~/.bashrc regexp='^#?\\s*export PATH=(.*)/local/sbin(.*)$' line=\"export PATH=$PATH:$HOME/local/sbin\" state=present\n          sudo: no\n    \n        - name: Set CLASSPATH and PATH environment variables\n          lineinfile: $item\n          with_items:\n            - dest='/etc/profile' regexp='^#?\\s*export CLASSPATH=(.*)$' line='export CLASSPATH=.:$JAVA_HOME/lib/*.jar:$JAVA_HOME/jre/lib/*.jar' state=present\n            - dest='/etc/profile' regexp='^#?\\s*export PATH=(.*)JAVA_HOME(.*)$' line=\"export PATH=$PATH:$JAVA_HOME/bin\" state=present\n    \n        ###### Since Ant in yum and apt is too old, download the .tar.bz2 file and install it\n        # Install Apache Ant\n        - name: Download Apache Ant\n          get_url: url=http://mirror.cc.columbia.edu/pub/software/apache//ant/binaries/apache-ant-{{ant_version}}-bin.tar.bz2 dest=/tmp/apache-ant-{{ant_version}}-bin.tar.bz2\n        - name: Untar Ant\n          shell: chdir=/tmp creates=/opt/apache-ant-{{ant_version}} tar -jxf apache-ant-{{ant_version}}-bin.tar.bz2 -C /opt\n        - lineinfile: dest=/etc/profile regexp='^#?\\s*export ANT_HOME=(.*)$' line='export ANT_HOME=/opt/apache-ant-{{ant_version}}' state=present\n        - lineinfile: dest=/etc/profile regexp='^#?\\s*export PATH=(.*)ANT_HOME(.*)$' line=\"export PATH=$PATH:$ANT_HOME/bin\" state=present\n    \n        # Install Apache Maven, since there is no Maven package in yum and apt repo\n        - name: Download Apache Maven\n          get_url: url=http://apache.claz.org/maven/maven-3/3.1.1/binaries/apache-maven-{{maven_version}}-bin.tar.gz dest=/tmp/apache-maven-{{maven_version}}-bin.tar.gz\n        - name: Untar Maven\n          shell: chdir=/tmp creates=/opt/apache-maven-{{maven_version}} tar -zxf apache-maven-{{maven_version}}-bin.tar.gz -C /opt\n        - lineinfile: dest=/etc/profile regexp='^#?\\s*export MAVEN_HOME=(.*)$' line='export MAVEN_HOME=/opt/apache-maven-{{maven_version}}' state=present\n        - lineinfile: dest=/etc/profile regexp='^#?\\s*export PATH=(.*)MAVEN_HOME(.*)$' line=\"export PATH=$PATH:$MAVEN_HOME/bin\" state=present\n    \n        # Install the scala compiler, because the scala compiler in yum and apt repo is too old\n        - name: Download Scala\n          get_url: url=http://www.scala-lang.org/files/archive/scala-{{scala_version}}.tgz dest=/tmp/scala-{{scala_version}}.tgz\n        - name: Untar Scala\n          shell: chdir=/tmp creates=/opt/scala-{{scala_version}} tar -zxf scala-{{scala_version}}.tgz -C /opt\n        - lineinfile: dest=/etc/profile regexp='^#?\\s*export SCALA_HOME=(.*)$' line='export SCALA_HOME=/opt/scala-{{scala_version}}' state=present\n        - lineinfile: dest=/etc/profile regexp='^#?\\s*export PATH=(.*)SCALA_HOME(.*)$' line=\"export PATH=$PATH:$SCALA_HOME/bin\" state=present\n    \n        # Install sbt\n        - name: Download sbt\n          get_url: url=http://repo.scala-sbt.org/scalasbt/sbt-native-packages/org/scala-sbt/sbt//{{sbt_version}}/sbt.tgz dest=/tmp/sbt-{{sbt_version}}.tgz\n        - name: Untar sbt\n          shell: chdir=/tmp creates=/opt/sbt-{{sbt_version}} tar -zxf sbt-{{sbt_version}}.tgz -C /opt\n        - name: Rename sbt directory\n          shell: chdir=/opt creates=/opt/sbt-{{sbt_version}} mv sbt/ sbt-{{sbt_version}}/\n        - lineinfile: dest=/etc/profile regexp='^#?\\s*export SBT_HOME=(.*)$' line='export SBT_HOME=/opt/sbt-{{sbt_version}}' state=present\n        - lineinfile: dest=/etc/profile regexp='^#?\\s*export PATH=(.*)SBT_HOME(.*)$' line=\"export PATH=$PATH:$SBT_HOME/bin\" state=present\n    \n        # Install Go\n        - name: Download Go\n          get_url: url=https://go.googlecode.com/files/go1.2.linux-amd64.tar.gz dest=/tmp/go1.2.linux-amd64.tar.gz\n        - name: Untar Go\n          shell: chdir=/tmp creates=/opt/go tar -zxf go1.2.linux-amd64.tar.gz -C /opt\n        - lineinfile: dest=/etc/profile regexp='^#?\\s*export GOROOT=(.*)$' line='export GOROOT=/opt/go' state=present\n        - lineinfile: dest=/etc/profile regexp='^#?\\s*export PATH=(.*)GOROOT(.*)$' line=\"export PATH=$PATH:$GOROOT/bin\" state=present\n\n","slug":"2014-01-29-my-ansible-playbook","published":1,"updated":"2016-08-18T09:21:04.000Z","photos":[],"link":"","_id":"cis07pf4c003001pqi7u8mewr","content":"<p><strong>前提</strong>，安装好Ansible，参考我的上一篇博客，<a href=\"http://www.yanjiuyanjiu.com/blog/20140127\" target=\"_blank\" rel=\"external\">Ansible 快速入门</a></p>\n<pre><code>---\n- hosts: all\n  sudo: True\n  remote_user: work\n  vars:\n    ant_version: 1.9.3\n    maven_version: 3.1.1\n    scala_version: 2.10.3\n    sbt_version: 0.12.4\n\n  tasks:\n  ########## for CentOS and RedHat ##########\n    - name: Install the libselinux-python package  # because ansible needs it\n      yum: name=libselinux-python state=installed\n      when: ansible_distribution == &apos;CentOS&apos; or ansible_distribution == &apos;Red Hat Enterprise Linux&apos;\n\n    - name: Disable SELinux in conf file\n      selinux: state=disabled\n      when: ansible_distribution == &apos;CentOS&apos; or ansible_distribution == &apos;Red Hat Enterprise Linux&apos;\n\n    - name: update YUM repositories\n      shell: &apos;yum -y update&apos;\n      when: ansible_distribution == &apos;CentOS&apos; or ansible_distribution == &apos;Red Hat Enterprise Linux&apos;\n\n    - name: Install OpenJDK\n      yum: name=java-1.7.0-openjdk-devel state=present\n      when: ansible_distribution == &apos;CentOS&apos; or ansible_distribution == &apos;Red Hat Enterprise Linux&apos;\n\n    - name: Set JAVA_HOME environment variable\n      lineinfile: dest=&apos;/etc/profile&apos; regexp=&apos;^#?\\s*export JAVA_HOME=(.*)$&apos; line=&apos;export JAVA_HOME=/usr/lib/jvm/java&apos; state=present\n      when: ansible_distribution == &apos;CentOS&apos; or ansible_distribution == &apos;Red Hat Enterprise Linux&apos;\n\n    - name: install the &apos;Development tools&apos; package group\n      yum: name=&quot;@Development tools&quot; state=present\n      when: ansible_distribution == &apos;CentOS&apos; or ansible_distribution == &apos;Red Hat Enterprise Linux&apos;\n\n    - name: upgrade all packages\n      shell: &apos;yum -y upgrade&apos;\n      when: ansible_distribution == &apos;CentOS&apos; or ansible_distribution == &apos;Red Hat Enterprise Linux&apos;\n\n\n  ########## for Ubuntu and Debian ##########\n    - name: Run &quot;apt-get update&quot; to update the source list\n      apt: update_cache=yes\n      when: ansible_distribution == &apos;Debian&apos; or ansible_distribution == &apos;Ubuntu&apos;\n\n    - name: Install OpenJDK\n      apt: pkg=openjdk-7-jdk state=present\n      when: ansible_distribution == &apos;Debian&apos; or ansible_distribution == &apos;Ubuntu&apos;\n\n    - name: Set JAVA_HOME environment variable\n      lineinfile: dest=&apos;/etc/profile&apos; regexp=&apos;^#?\\s*export JAVA_HOME=(.*)$&apos; line=&apos;export JAVA_HOME=/usr/lib/jvm/java-1.7.0-openjdk-amd64&apos; state=present\n      when: ansible_distribution == &apos;Debian&apos; or ansible_distribution == &apos;Ubuntu&apos;\n\n    - name: Install build-essential\n      apt: pkg=build-essential state=present\n      when: ansible_distribution == &apos;Debian&apos; or ansible_distribution == &apos;Ubuntu&apos;\n\n    - name: Update all packages to the latest version\n      apt: upgrade=dist\n      when: ansible_distribution == &apos;Debian&apos; or ansible_distribution == &apos;Ubuntu&apos;\n\n\n  ########## Common opreations for all OS ##########\n    # Create local directories\n    - file: path=~/local/bin state=directory\n      sudo: no\n    - file: path=~/local/sbin state=directory\n      sudo: no\n    - file: path=~/local/src state=directory\n      sudo: no\n    - file: path=~/local/opt state=directory\n      sudo: no\n    - file: path=~/local/var state=directory\n      sudo: no\n    - lineinfile: dest=~/.bashrc regexp=&apos;^#?\\s*export PATH=(.*)/local/bin(.*)$&apos; line=&quot;export PATH=$PATH:$HOME/local/bin&quot; state=present\n      sudo: no\n    - lineinfile: dest=~/.bashrc regexp=&apos;^#?\\s*export PATH=(.*)/local/sbin(.*)$&apos; line=&quot;export PATH=$PATH:$HOME/local/sbin&quot; state=present\n      sudo: no\n\n    - name: Set CLASSPATH and PATH environment variables\n      lineinfile: $item\n      with_items:\n        - dest=&apos;/etc/profile&apos; regexp=&apos;^#?\\s*export CLASSPATH=(.*)$&apos; line=&apos;export CLASSPATH=.:$JAVA_HOME/lib/*.jar:$JAVA_HOME/jre/lib/*.jar&apos; state=present\n        - dest=&apos;/etc/profile&apos; regexp=&apos;^#?\\s*export PATH=(.*)JAVA_HOME(.*)$&apos; line=&quot;export PATH=$PATH:$JAVA_HOME/bin&quot; state=present\n\n    ###### Since Ant in yum and apt is too old, download the .tar.bz2 file and install it\n    # Install Apache Ant\n    - name: Download Apache Ant\n      get_url: url=http://mirror.cc.columbia.edu/pub/software/apache//ant/binaries/apache-ant-{{ant_version}}-bin.tar.bz2 dest=/tmp/apache-ant-{{ant_version}}-bin.tar.bz2\n    - name: Untar Ant\n      shell: chdir=/tmp creates=/opt/apache-ant-{{ant_version}} tar -jxf apache-ant-{{ant_version}}-bin.tar.bz2 -C /opt\n    - lineinfile: dest=/etc/profile regexp=&apos;^#?\\s*export ANT_HOME=(.*)$&apos; line=&apos;export ANT_HOME=/opt/apache-ant-{{ant_version}}&apos; state=present\n    - lineinfile: dest=/etc/profile regexp=&apos;^#?\\s*export PATH=(.*)ANT_HOME(.*)$&apos; line=&quot;export PATH=$PATH:$ANT_HOME/bin&quot; state=present\n\n    # Install Apache Maven, since there is no Maven package in yum and apt repo\n    - name: Download Apache Maven\n      get_url: url=http://apache.claz.org/maven/maven-3/3.1.1/binaries/apache-maven-{{maven_version}}-bin.tar.gz dest=/tmp/apache-maven-{{maven_version}}-bin.tar.gz\n    - name: Untar Maven\n      shell: chdir=/tmp creates=/opt/apache-maven-{{maven_version}} tar -zxf apache-maven-{{maven_version}}-bin.tar.gz -C /opt\n    - lineinfile: dest=/etc/profile regexp=&apos;^#?\\s*export MAVEN_HOME=(.*)$&apos; line=&apos;export MAVEN_HOME=/opt/apache-maven-{{maven_version}}&apos; state=present\n    - lineinfile: dest=/etc/profile regexp=&apos;^#?\\s*export PATH=(.*)MAVEN_HOME(.*)$&apos; line=&quot;export PATH=$PATH:$MAVEN_HOME/bin&quot; state=present\n\n    # Install the scala compiler, because the scala compiler in yum and apt repo is too old\n    - name: Download Scala\n      get_url: url=http://www.scala-lang.org/files/archive/scala-{{scala_version}}.tgz dest=/tmp/scala-{{scala_version}}.tgz\n    - name: Untar Scala\n      shell: chdir=/tmp creates=/opt/scala-{{scala_version}} tar -zxf scala-{{scala_version}}.tgz -C /opt\n    - lineinfile: dest=/etc/profile regexp=&apos;^#?\\s*export SCALA_HOME=(.*)$&apos; line=&apos;export SCALA_HOME=/opt/scala-{{scala_version}}&apos; state=present\n    - lineinfile: dest=/etc/profile regexp=&apos;^#?\\s*export PATH=(.*)SCALA_HOME(.*)$&apos; line=&quot;export PATH=$PATH:$SCALA_HOME/bin&quot; state=present\n\n    # Install sbt\n    - name: Download sbt\n      get_url: url=http://repo.scala-sbt.org/scalasbt/sbt-native-packages/org/scala-sbt/sbt//{{sbt_version}}/sbt.tgz dest=/tmp/sbt-{{sbt_version}}.tgz\n    - name: Untar sbt\n      shell: chdir=/tmp creates=/opt/sbt-{{sbt_version}} tar -zxf sbt-{{sbt_version}}.tgz -C /opt\n    - name: Rename sbt directory\n      shell: chdir=/opt creates=/opt/sbt-{{sbt_version}} mv sbt/ sbt-{{sbt_version}}/\n    - lineinfile: dest=/etc/profile regexp=&apos;^#?\\s*export SBT_HOME=(.*)$&apos; line=&apos;export SBT_HOME=/opt/sbt-{{sbt_version}}&apos; state=present\n    - lineinfile: dest=/etc/profile regexp=&apos;^#?\\s*export PATH=(.*)SBT_HOME(.*)$&apos; line=&quot;export PATH=$PATH:$SBT_HOME/bin&quot; state=present\n\n    # Install Go\n    - name: Download Go\n      get_url: url=https://go.googlecode.com/files/go1.2.linux-amd64.tar.gz dest=/tmp/go1.2.linux-amd64.tar.gz\n    - name: Untar Go\n      shell: chdir=/tmp creates=/opt/go tar -zxf go1.2.linux-amd64.tar.gz -C /opt\n    - lineinfile: dest=/etc/profile regexp=&apos;^#?\\s*export GOROOT=(.*)$&apos; line=&apos;export GOROOT=/opt/go&apos; state=present\n    - lineinfile: dest=/etc/profile regexp=&apos;^#?\\s*export PATH=(.*)GOROOT(.*)$&apos; line=&quot;export PATH=$PATH:$GOROOT/bin&quot; state=present\n</code></pre>","excerpt":"","more":"<p><strong>前提</strong>，安装好Ansible，参考我的上一篇博客，<a href=\"http://www.yanjiuyanjiu.com/blog/20140127\">Ansible 快速入门</a></p>\n<pre><code>---\n- hosts: all\n  sudo: True\n  remote_user: work\n  vars:\n    ant_version: 1.9.3\n    maven_version: 3.1.1\n    scala_version: 2.10.3\n    sbt_version: 0.12.4\n\n  tasks:\n  ########## for CentOS and RedHat ##########\n    - name: Install the libselinux-python package  # because ansible needs it\n      yum: name=libselinux-python state=installed\n      when: ansible_distribution == &apos;CentOS&apos; or ansible_distribution == &apos;Red Hat Enterprise Linux&apos;\n\n    - name: Disable SELinux in conf file\n      selinux: state=disabled\n      when: ansible_distribution == &apos;CentOS&apos; or ansible_distribution == &apos;Red Hat Enterprise Linux&apos;\n\n    - name: update YUM repositories\n      shell: &apos;yum -y update&apos;\n      when: ansible_distribution == &apos;CentOS&apos; or ansible_distribution == &apos;Red Hat Enterprise Linux&apos;\n\n    - name: Install OpenJDK\n      yum: name=java-1.7.0-openjdk-devel state=present\n      when: ansible_distribution == &apos;CentOS&apos; or ansible_distribution == &apos;Red Hat Enterprise Linux&apos;\n\n    - name: Set JAVA_HOME environment variable\n      lineinfile: dest=&apos;/etc/profile&apos; regexp=&apos;^#?\\s*export JAVA_HOME=(.*)$&apos; line=&apos;export JAVA_HOME=/usr/lib/jvm/java&apos; state=present\n      when: ansible_distribution == &apos;CentOS&apos; or ansible_distribution == &apos;Red Hat Enterprise Linux&apos;\n\n    - name: install the &apos;Development tools&apos; package group\n      yum: name=&quot;@Development tools&quot; state=present\n      when: ansible_distribution == &apos;CentOS&apos; or ansible_distribution == &apos;Red Hat Enterprise Linux&apos;\n\n    - name: upgrade all packages\n      shell: &apos;yum -y upgrade&apos;\n      when: ansible_distribution == &apos;CentOS&apos; or ansible_distribution == &apos;Red Hat Enterprise Linux&apos;\n\n\n  ########## for Ubuntu and Debian ##########\n    - name: Run &quot;apt-get update&quot; to update the source list\n      apt: update_cache=yes\n      when: ansible_distribution == &apos;Debian&apos; or ansible_distribution == &apos;Ubuntu&apos;\n\n    - name: Install OpenJDK\n      apt: pkg=openjdk-7-jdk state=present\n      when: ansible_distribution == &apos;Debian&apos; or ansible_distribution == &apos;Ubuntu&apos;\n\n    - name: Set JAVA_HOME environment variable\n      lineinfile: dest=&apos;/etc/profile&apos; regexp=&apos;^#?\\s*export JAVA_HOME=(.*)$&apos; line=&apos;export JAVA_HOME=/usr/lib/jvm/java-1.7.0-openjdk-amd64&apos; state=present\n      when: ansible_distribution == &apos;Debian&apos; or ansible_distribution == &apos;Ubuntu&apos;\n\n    - name: Install build-essential\n      apt: pkg=build-essential state=present\n      when: ansible_distribution == &apos;Debian&apos; or ansible_distribution == &apos;Ubuntu&apos;\n\n    - name: Update all packages to the latest version\n      apt: upgrade=dist\n      when: ansible_distribution == &apos;Debian&apos; or ansible_distribution == &apos;Ubuntu&apos;\n\n\n  ########## Common opreations for all OS ##########\n    # Create local directories\n    - file: path=~/local/bin state=directory\n      sudo: no\n    - file: path=~/local/sbin state=directory\n      sudo: no\n    - file: path=~/local/src state=directory\n      sudo: no\n    - file: path=~/local/opt state=directory\n      sudo: no\n    - file: path=~/local/var state=directory\n      sudo: no\n    - lineinfile: dest=~/.bashrc regexp=&apos;^#?\\s*export PATH=(.*)/local/bin(.*)$&apos; line=&quot;export PATH=$PATH:$HOME/local/bin&quot; state=present\n      sudo: no\n    - lineinfile: dest=~/.bashrc regexp=&apos;^#?\\s*export PATH=(.*)/local/sbin(.*)$&apos; line=&quot;export PATH=$PATH:$HOME/local/sbin&quot; state=present\n      sudo: no\n\n    - name: Set CLASSPATH and PATH environment variables\n      lineinfile: $item\n      with_items:\n        - dest=&apos;/etc/profile&apos; regexp=&apos;^#?\\s*export CLASSPATH=(.*)$&apos; line=&apos;export CLASSPATH=.:$JAVA_HOME/lib/*.jar:$JAVA_HOME/jre/lib/*.jar&apos; state=present\n        - dest=&apos;/etc/profile&apos; regexp=&apos;^#?\\s*export PATH=(.*)JAVA_HOME(.*)$&apos; line=&quot;export PATH=$PATH:$JAVA_HOME/bin&quot; state=present\n\n    ###### Since Ant in yum and apt is too old, download the .tar.bz2 file and install it\n    # Install Apache Ant\n    - name: Download Apache Ant\n      get_url: url=http://mirror.cc.columbia.edu/pub/software/apache//ant/binaries/apache-ant-{{ant_version}}-bin.tar.bz2 dest=/tmp/apache-ant-{{ant_version}}-bin.tar.bz2\n    - name: Untar Ant\n      shell: chdir=/tmp creates=/opt/apache-ant-{{ant_version}} tar -jxf apache-ant-{{ant_version}}-bin.tar.bz2 -C /opt\n    - lineinfile: dest=/etc/profile regexp=&apos;^#?\\s*export ANT_HOME=(.*)$&apos; line=&apos;export ANT_HOME=/opt/apache-ant-{{ant_version}}&apos; state=present\n    - lineinfile: dest=/etc/profile regexp=&apos;^#?\\s*export PATH=(.*)ANT_HOME(.*)$&apos; line=&quot;export PATH=$PATH:$ANT_HOME/bin&quot; state=present\n\n    # Install Apache Maven, since there is no Maven package in yum and apt repo\n    - name: Download Apache Maven\n      get_url: url=http://apache.claz.org/maven/maven-3/3.1.1/binaries/apache-maven-{{maven_version}}-bin.tar.gz dest=/tmp/apache-maven-{{maven_version}}-bin.tar.gz\n    - name: Untar Maven\n      shell: chdir=/tmp creates=/opt/apache-maven-{{maven_version}} tar -zxf apache-maven-{{maven_version}}-bin.tar.gz -C /opt\n    - lineinfile: dest=/etc/profile regexp=&apos;^#?\\s*export MAVEN_HOME=(.*)$&apos; line=&apos;export MAVEN_HOME=/opt/apache-maven-{{maven_version}}&apos; state=present\n    - lineinfile: dest=/etc/profile regexp=&apos;^#?\\s*export PATH=(.*)MAVEN_HOME(.*)$&apos; line=&quot;export PATH=$PATH:$MAVEN_HOME/bin&quot; state=present\n\n    # Install the scala compiler, because the scala compiler in yum and apt repo is too old\n    - name: Download Scala\n      get_url: url=http://www.scala-lang.org/files/archive/scala-{{scala_version}}.tgz dest=/tmp/scala-{{scala_version}}.tgz\n    - name: Untar Scala\n      shell: chdir=/tmp creates=/opt/scala-{{scala_version}} tar -zxf scala-{{scala_version}}.tgz -C /opt\n    - lineinfile: dest=/etc/profile regexp=&apos;^#?\\s*export SCALA_HOME=(.*)$&apos; line=&apos;export SCALA_HOME=/opt/scala-{{scala_version}}&apos; state=present\n    - lineinfile: dest=/etc/profile regexp=&apos;^#?\\s*export PATH=(.*)SCALA_HOME(.*)$&apos; line=&quot;export PATH=$PATH:$SCALA_HOME/bin&quot; state=present\n\n    # Install sbt\n    - name: Download sbt\n      get_url: url=http://repo.scala-sbt.org/scalasbt/sbt-native-packages/org/scala-sbt/sbt//{{sbt_version}}/sbt.tgz dest=/tmp/sbt-{{sbt_version}}.tgz\n    - name: Untar sbt\n      shell: chdir=/tmp creates=/opt/sbt-{{sbt_version}} tar -zxf sbt-{{sbt_version}}.tgz -C /opt\n    - name: Rename sbt directory\n      shell: chdir=/opt creates=/opt/sbt-{{sbt_version}} mv sbt/ sbt-{{sbt_version}}/\n    - lineinfile: dest=/etc/profile regexp=&apos;^#?\\s*export SBT_HOME=(.*)$&apos; line=&apos;export SBT_HOME=/opt/sbt-{{sbt_version}}&apos; state=present\n    - lineinfile: dest=/etc/profile regexp=&apos;^#?\\s*export PATH=(.*)SBT_HOME(.*)$&apos; line=&quot;export PATH=$PATH:$SBT_HOME/bin&quot; state=present\n\n    # Install Go\n    - name: Download Go\n      get_url: url=https://go.googlecode.com/files/go1.2.linux-amd64.tar.gz dest=/tmp/go1.2.linux-amd64.tar.gz\n    - name: Untar Go\n      shell: chdir=/tmp creates=/opt/go tar -zxf go1.2.linux-amd64.tar.gz -C /opt\n    - lineinfile: dest=/etc/profile regexp=&apos;^#?\\s*export GOROOT=(.*)$&apos; line=&apos;export GOROOT=/opt/go&apos; state=present\n    - lineinfile: dest=/etc/profile regexp=&apos;^#?\\s*export PATH=(.*)GOROOT(.*)$&apos; line=&quot;export PATH=$PATH:$GOROOT/bin&quot; state=present\n</code></pre>"},{"layout":"post","title":"Nutch 快速入门(Nutch 2.2.1)","date":"2014-02-01T04:11:00.000Z","comments":1,"_content":"本文主要参考[Nutch 2.x Tutorial](http://wiki.apache.org/nutch/Nutch2Tutorial)\n\nNutch 2.x 与 Nutch 1.x 相比，剥离出了存储层，放到了gora中，可以使用多种数据库，例如HBase, Cassandra, MySql来存储数据了。Nutch 1.7 则是把数据直接存储在HDFS上。\n\n##1. 安装并运行HBase\n为了简单起见，使用Standalone模式，参考 [HBase Quick start](http://hbase.apache.org/book/quickstart.html)\n\n###1.1 下载，解压\n\n    wget http://archive.apache.org/dist/hbase/hbase-0.90.4/hbase-0.90.4.tar.gz\n    tar zxf hbase-0.90.4.tar.gz\n\n###1.2 修改 conf/hbase-site.xml\n内容如下\n\n    <configuration>\n      <property>\n        <name>hbase.rootdir</name>\n        <value>file:///DIRECTORY/hbase</value>\n      </property>\n      <property>\n        <name>hbase.zookeeper.property.dataDir</name>\n        <value>/DIRECTORY/zookeeper</value>\n      </property>\n    </configuration>\n\n`hbase.rootdir`目录是用来存放HBase的相关信息的，默认值是`/tmp/hbase-${user.name}/hbase`； `hbase.zookeeper.property.dataDir`目录是用来存放zookeeper（HBase内置了zookeeper）的相关信息的，默认值是`/tmp/hbase-${user.name}/zookeeper`。\n\n###1.3 启动\n\n    $ ./bin/start-hbase.sh\n    starting Master, logging to logs/hbase-user-master-example.org.out\n\n<!-- more -->\n\n###1.4 试用一下shell\n$ ./bin/hbase shell\nHBase Shell; enter 'help<RETURN>' for list of supported commands.\nType \"exit<RETURN>\" to leave the HBase Shell\nVersion 0.90.4, r1150278, Sun Jul 24 15:53:29 PDT 2011\n\nhbase(main):001:0>\n\n创建一张名字为`test`的表，只有一个列，名为`cf`。为了验证创建是否成功，用`list`命令查看所有的table，并用`put`命令插入一些值。\n\n    hbase(main):003:0> create 'test', 'cf'\n    0 row(s) in 1.2200 seconds\n    hbase(main):003:0> list 'test'\n    ..\n    1 row(s) in 0.0550 seconds\n    hbase(main):004:0> put 'test', 'row1', 'cf:a', 'value1'\n    0 row(s) in 0.0560 seconds\n    hbase(main):005:0> put 'test', 'row2', 'cf:b', 'value2'\n    0 row(s) in 0.0370 seconds\n    hbase(main):006:0> put 'test', 'row3', 'cf:c', 'value3'\n    0 row(s) in 0.0450 seconds\n\n用`scan`命令扫描table，验证一下刚才的插入是否成功。\n\n    hbase(main):007:0> scan 'test'\n    ROW        COLUMN+CELL\n    row1       column=cf:a, timestamp=1288380727188, value=value1\n    row2       column=cf:b, timestamp=1288380738440, value=value2\n    row3       column=cf:c, timestamp=1288380747365, value=value3\n    3 row(s) in 0.0590 seconds\n\n现在，disable并drop掉你的表，这会把上面的所有操作清零。\n\n    hbase(main):012:0> disable 'test'\n    0 row(s) in 1.0930 seconds\n    hbase(main):013:0> drop 'test'\n    0 row(s) in 0.0770 seconds \n\n退出shell，\n\n    hbase(main):014:0> exit\n\n###1.5 停止\n\n    $ ./bin/stop-hbase.sh\n    stopping hbase...............\n\n###1.6 再次启动\n后面运行Nutch，需要把数据存储到HBase，因此需要启动HBase。\n\n    $ ./bin/start-hbase.sh\n    starting Master, logging to logs/hbase-user-master-example.org.out\n\n##2 编译Nutch 2.2.1\n\n###2.1 下载，解压\n    wget http://www.apache.org/dyn/closer.cgi/nutch/2.2.1/apache-nutch-2.2.1-src.tar.gz\n    tar zxf apache-nutch-2.2.1-src.tar.gz\n\n###2.2 修改配置文件\n参考[Nutch 2.0 Tutorial](http://wiki.apache.org/nutch/Nutch2Tutorial)\n\n修改 `conf/nutch-site.xml`\n\n    <property>\n      <name>storage.data.store.class</name>\n      <value>org.apache.gora.hbase.store.HBaseStore</value>\n      <description>Default class for storing data</description>\n    </property>\n\n修改`ivy/ivy.xml`\n\n    <!-- Uncomment this to use HBase as Gora backend. -->\n    <dependency org=\"org.apache.gora\" name=\"gora-hbase\" rev=\"0.3\" conf=\"*->default\" />\n    \n修改 `conf/gora.properties`，确保`HBaseStore`被设置为默认的存储，\n\n    gora.datastore.default=org.apache.gora.hbase.store.HBaseStore\n\n###2.3 编译\n\n    ant runtime\n\n刚开始会下载很多jar，需要等待一段时间。\n\n有可能你会得到如下错误：\n\n    Trying to override old definition of task javac\n      [taskdef] Could not load definitions from resource org/sonar/ant/antlib.xml. It could not be found.\n    \n    ivy-probe-antlib:\n    \n    ivy-download:\n      [taskdef] Could not load definitions from resource org/sonar/ant/antlib.xml. It could not be found.\n\n无所谓，不用管它。\n\n要等一会儿才能编译结束。编译完后，多出来了 build 和 runtime两个文件夹。\n\n第3、4、5、6步与另一篇博客[Nutch 快速入门(Nutch 1.7)]()中的第3、4、5、6步骤一模一样。\n\n##3 添加种子URL\n\n    mkdir ~/urls\n    vim ～/urls/seed.txt\n    http://movie.douban.com/subject/5323968/\n\n##4 设置URL过滤规则\n如果只想抓取某种类型的URL，可以在 `conf/regex-urlfilter.txt`设置正则表达式，于是，只有匹配这些正则表达式的URL才会被抓取。\n\n例如，我只想抓取豆瓣电影的数据，可以这样设置：\n    \n    #注释掉这一行\n    # skip URLs containing certain characters as probable queries, etc.\n    #-[?*!@=]\n    # accept anything else\n    #注释掉这行\n    #+.\n    +^http:\\/\\/movie\\.douban\\.com\\/subject\\/[0-9]+\\/(\\?.+)?$\n\n##5 设置agent名字\n\nconf/nutch-site.xml:\n\n    <property>\n      <name>http.agent.name</name>\n      <value>My Nutch Spider</value>\n    </property>\n\n这一步是从这本书上看到的，[Web Crawling and Data Mining with Apache Nutch](http://www.packtpub.com/web-crawling-and-data-mining-with-apache-nutch/book)，第14页。\n\n##6 安装Solr\n由于建索引的时候需要使用Solr，因此我们需要安装并启动一个Solr服务器。\n\n参考[Nutch Tutorial](http://wiki.apache.org/nutch/NutchTutorial) 第4、5、6步，以及[Solr Tutorial](http://lucene.apache.org/solr/4_6_1/tutorial.html)。\n\n###6.1 下载，解压\n\nwget http://mirrors.cnnic.cn/apache/lucene/solr/4.6.1/solr-4.6.1.tgz\ntar -zxf solr-4.6.1.tgz\n\n###6.2 运行Solr\n\n    cd example\n    java -jar start.jar\n\n验证是否启动成功\n\n用浏览器打开 <http://localhost:8983/solr/admin/>，如果能看到页面，说明启动成功。\n\n###6.3 将Nutch与Solr集成在一起\n\n将`NUTCH_DIR/conf/schema-solr4.xml`拷贝到`SOLR_DIR/solr/collection1/conf/`，重命名为schema.xml，并在`<fields>...</fields>`最后添加一行(具体解释见[Solr 4.2 - what is _version_field?](http://stackoverflow.com/questions/15527380/solr-4-2-what-is-version-field))，\n\n    <field name=\"_version_\" type=\"long\" indexed=\"true\" stored=\"true\" multiValued=\"false\"/>\n\n重启Solr，\n\n    # Ctrl+C to stop Solr\n    java -jar start.jar\n\n第7步和第8步也和Nutch 1.7那篇博客中的7、8步很类似。主要区别在于，Nutch 2.x的所有数据，不再以文件和目录的形式存放在硬盘上，而是存放到HBase里。\n\n##7 一步一步使用单个命令抓取网页\nTODO\n\n##8 使用crawl脚本一键抓取\n刚才我们是手工敲入多个命令，一个一个步骤，来完成抓取的，其实Nutch自带了一个脚本，`./bin/crawl`，把抓取的各个步骤合并成一个命令，看一下它的用法\n\n    $ ./bin/crawl \n    Missing seedDir : crawl <seedDir> <crawlID> <solrURL> <numberOfRounds>\n\n**注意**，这里是`crawlId`，不再是`crawlDir`。\n\n先删除第7节产生的数据，使用HBase shell，用`disable`删除表。\n\n###8.1 抓取网页\n\n    $ ./bin/crawl ~/urls/ TestCrawl http://localhost:8983/solr/ 2\n\n* `～/urls` 是存放了种子url的目录\n* TestCrawl 是crawlId，这会在HBase中创建一张以crawlId为前缀的表，例如TestCrawl_Webpage。\n* http://localhost:8983/solr/ , 这是Solr服务器\n* 2，numberOfRounds，迭代的次数\n\n过了一会儿，屏幕上出现了一大堆url，可以看到爬虫正在抓取！\n\n    fetching http://music.douban.com/subject/25811077/ (queue crawl delay=5000ms)\n    fetching http://read.douban.com/ebook/1919781 (queue crawl delay=5000ms)\n    fetching http://www.douban.com/online/11670861/ (queue crawl delay=5000ms)\n    fetching http://book.douban.com/tag/绘本 (queue crawl delay=5000ms)\n    fetching http://movie.douban.com/tag/科幻 (queue crawl delay=5000ms)\n    49/50 spinwaiting/active, 56 pages, 0 errors, 0.9 1 pages/s, 332 245 kb/s, 131 URLs in 5 queues\n    fetching http://music.douban.com/subject/25762454/ (queue crawl delay=5000ms)\n    fetching http://read.douban.com/reader/ebook/1951242/ (queue crawl delay=5000ms)\n    fetching http://www.douban.com/mobile/read-notes (queue crawl delay=5000ms)\n    fetching http://book.douban.com/tag/诗歌 (queue crawl delay=5000ms)\n    50/50 spinwaiting/active, 61 pages, 0 errors, 0.9 1 pages/s, 334 366 kb/s, 127 URLs in 5 queues\n\n###8.2 查看结果\n\n    ./bin/nutch readdb -crawlId TestCrawl -stats\n\n也可以进HBase shell 查看，\n\n    cd ~/hbase-0.90.4\n    ./bin/hbase shell\n    hbase(main):001:0> scan 'TestCrawl_webpage'\n\n屏幕开始不断输出内容，可以用Ctrl+C 结束。\n\n在运行scan查看表中内容时，对于列的含义不确定时可以查看`conf/gora-hbase-mapping.xml`文件，该文件定义了列族及列的含义。\n\n##相关文章\n[Nutch 快速入门(Nutch 1.7)](http://www.yanjiuyanjiu.com/blog/20140121/)\n\n\n","source":"_posts/2014-02-01-nutch-tutorial.md","raw":"---\nlayout: post\ntitle: \"Nutch 快速入门(Nutch 2.2.1)\"\ndate: 2014-02-01 04:11\ncomments: true\ncategories: Search-Engine\n---\n本文主要参考[Nutch 2.x Tutorial](http://wiki.apache.org/nutch/Nutch2Tutorial)\n\nNutch 2.x 与 Nutch 1.x 相比，剥离出了存储层，放到了gora中，可以使用多种数据库，例如HBase, Cassandra, MySql来存储数据了。Nutch 1.7 则是把数据直接存储在HDFS上。\n\n##1. 安装并运行HBase\n为了简单起见，使用Standalone模式，参考 [HBase Quick start](http://hbase.apache.org/book/quickstart.html)\n\n###1.1 下载，解压\n\n    wget http://archive.apache.org/dist/hbase/hbase-0.90.4/hbase-0.90.4.tar.gz\n    tar zxf hbase-0.90.4.tar.gz\n\n###1.2 修改 conf/hbase-site.xml\n内容如下\n\n    <configuration>\n      <property>\n        <name>hbase.rootdir</name>\n        <value>file:///DIRECTORY/hbase</value>\n      </property>\n      <property>\n        <name>hbase.zookeeper.property.dataDir</name>\n        <value>/DIRECTORY/zookeeper</value>\n      </property>\n    </configuration>\n\n`hbase.rootdir`目录是用来存放HBase的相关信息的，默认值是`/tmp/hbase-${user.name}/hbase`； `hbase.zookeeper.property.dataDir`目录是用来存放zookeeper（HBase内置了zookeeper）的相关信息的，默认值是`/tmp/hbase-${user.name}/zookeeper`。\n\n###1.3 启动\n\n    $ ./bin/start-hbase.sh\n    starting Master, logging to logs/hbase-user-master-example.org.out\n\n<!-- more -->\n\n###1.4 试用一下shell\n$ ./bin/hbase shell\nHBase Shell; enter 'help<RETURN>' for list of supported commands.\nType \"exit<RETURN>\" to leave the HBase Shell\nVersion 0.90.4, r1150278, Sun Jul 24 15:53:29 PDT 2011\n\nhbase(main):001:0>\n\n创建一张名字为`test`的表，只有一个列，名为`cf`。为了验证创建是否成功，用`list`命令查看所有的table，并用`put`命令插入一些值。\n\n    hbase(main):003:0> create 'test', 'cf'\n    0 row(s) in 1.2200 seconds\n    hbase(main):003:0> list 'test'\n    ..\n    1 row(s) in 0.0550 seconds\n    hbase(main):004:0> put 'test', 'row1', 'cf:a', 'value1'\n    0 row(s) in 0.0560 seconds\n    hbase(main):005:0> put 'test', 'row2', 'cf:b', 'value2'\n    0 row(s) in 0.0370 seconds\n    hbase(main):006:0> put 'test', 'row3', 'cf:c', 'value3'\n    0 row(s) in 0.0450 seconds\n\n用`scan`命令扫描table，验证一下刚才的插入是否成功。\n\n    hbase(main):007:0> scan 'test'\n    ROW        COLUMN+CELL\n    row1       column=cf:a, timestamp=1288380727188, value=value1\n    row2       column=cf:b, timestamp=1288380738440, value=value2\n    row3       column=cf:c, timestamp=1288380747365, value=value3\n    3 row(s) in 0.0590 seconds\n\n现在，disable并drop掉你的表，这会把上面的所有操作清零。\n\n    hbase(main):012:0> disable 'test'\n    0 row(s) in 1.0930 seconds\n    hbase(main):013:0> drop 'test'\n    0 row(s) in 0.0770 seconds \n\n退出shell，\n\n    hbase(main):014:0> exit\n\n###1.5 停止\n\n    $ ./bin/stop-hbase.sh\n    stopping hbase...............\n\n###1.6 再次启动\n后面运行Nutch，需要把数据存储到HBase，因此需要启动HBase。\n\n    $ ./bin/start-hbase.sh\n    starting Master, logging to logs/hbase-user-master-example.org.out\n\n##2 编译Nutch 2.2.1\n\n###2.1 下载，解压\n    wget http://www.apache.org/dyn/closer.cgi/nutch/2.2.1/apache-nutch-2.2.1-src.tar.gz\n    tar zxf apache-nutch-2.2.1-src.tar.gz\n\n###2.2 修改配置文件\n参考[Nutch 2.0 Tutorial](http://wiki.apache.org/nutch/Nutch2Tutorial)\n\n修改 `conf/nutch-site.xml`\n\n    <property>\n      <name>storage.data.store.class</name>\n      <value>org.apache.gora.hbase.store.HBaseStore</value>\n      <description>Default class for storing data</description>\n    </property>\n\n修改`ivy/ivy.xml`\n\n    <!-- Uncomment this to use HBase as Gora backend. -->\n    <dependency org=\"org.apache.gora\" name=\"gora-hbase\" rev=\"0.3\" conf=\"*->default\" />\n    \n修改 `conf/gora.properties`，确保`HBaseStore`被设置为默认的存储，\n\n    gora.datastore.default=org.apache.gora.hbase.store.HBaseStore\n\n###2.3 编译\n\n    ant runtime\n\n刚开始会下载很多jar，需要等待一段时间。\n\n有可能你会得到如下错误：\n\n    Trying to override old definition of task javac\n      [taskdef] Could not load definitions from resource org/sonar/ant/antlib.xml. It could not be found.\n    \n    ivy-probe-antlib:\n    \n    ivy-download:\n      [taskdef] Could not load definitions from resource org/sonar/ant/antlib.xml. It could not be found.\n\n无所谓，不用管它。\n\n要等一会儿才能编译结束。编译完后，多出来了 build 和 runtime两个文件夹。\n\n第3、4、5、6步与另一篇博客[Nutch 快速入门(Nutch 1.7)]()中的第3、4、5、6步骤一模一样。\n\n##3 添加种子URL\n\n    mkdir ~/urls\n    vim ～/urls/seed.txt\n    http://movie.douban.com/subject/5323968/\n\n##4 设置URL过滤规则\n如果只想抓取某种类型的URL，可以在 `conf/regex-urlfilter.txt`设置正则表达式，于是，只有匹配这些正则表达式的URL才会被抓取。\n\n例如，我只想抓取豆瓣电影的数据，可以这样设置：\n    \n    #注释掉这一行\n    # skip URLs containing certain characters as probable queries, etc.\n    #-[?*!@=]\n    # accept anything else\n    #注释掉这行\n    #+.\n    +^http:\\/\\/movie\\.douban\\.com\\/subject\\/[0-9]+\\/(\\?.+)?$\n\n##5 设置agent名字\n\nconf/nutch-site.xml:\n\n    <property>\n      <name>http.agent.name</name>\n      <value>My Nutch Spider</value>\n    </property>\n\n这一步是从这本书上看到的，[Web Crawling and Data Mining with Apache Nutch](http://www.packtpub.com/web-crawling-and-data-mining-with-apache-nutch/book)，第14页。\n\n##6 安装Solr\n由于建索引的时候需要使用Solr，因此我们需要安装并启动一个Solr服务器。\n\n参考[Nutch Tutorial](http://wiki.apache.org/nutch/NutchTutorial) 第4、5、6步，以及[Solr Tutorial](http://lucene.apache.org/solr/4_6_1/tutorial.html)。\n\n###6.1 下载，解压\n\nwget http://mirrors.cnnic.cn/apache/lucene/solr/4.6.1/solr-4.6.1.tgz\ntar -zxf solr-4.6.1.tgz\n\n###6.2 运行Solr\n\n    cd example\n    java -jar start.jar\n\n验证是否启动成功\n\n用浏览器打开 <http://localhost:8983/solr/admin/>，如果能看到页面，说明启动成功。\n\n###6.3 将Nutch与Solr集成在一起\n\n将`NUTCH_DIR/conf/schema-solr4.xml`拷贝到`SOLR_DIR/solr/collection1/conf/`，重命名为schema.xml，并在`<fields>...</fields>`最后添加一行(具体解释见[Solr 4.2 - what is _version_field?](http://stackoverflow.com/questions/15527380/solr-4-2-what-is-version-field))，\n\n    <field name=\"_version_\" type=\"long\" indexed=\"true\" stored=\"true\" multiValued=\"false\"/>\n\n重启Solr，\n\n    # Ctrl+C to stop Solr\n    java -jar start.jar\n\n第7步和第8步也和Nutch 1.7那篇博客中的7、8步很类似。主要区别在于，Nutch 2.x的所有数据，不再以文件和目录的形式存放在硬盘上，而是存放到HBase里。\n\n##7 一步一步使用单个命令抓取网页\nTODO\n\n##8 使用crawl脚本一键抓取\n刚才我们是手工敲入多个命令，一个一个步骤，来完成抓取的，其实Nutch自带了一个脚本，`./bin/crawl`，把抓取的各个步骤合并成一个命令，看一下它的用法\n\n    $ ./bin/crawl \n    Missing seedDir : crawl <seedDir> <crawlID> <solrURL> <numberOfRounds>\n\n**注意**，这里是`crawlId`，不再是`crawlDir`。\n\n先删除第7节产生的数据，使用HBase shell，用`disable`删除表。\n\n###8.1 抓取网页\n\n    $ ./bin/crawl ~/urls/ TestCrawl http://localhost:8983/solr/ 2\n\n* `～/urls` 是存放了种子url的目录\n* TestCrawl 是crawlId，这会在HBase中创建一张以crawlId为前缀的表，例如TestCrawl_Webpage。\n* http://localhost:8983/solr/ , 这是Solr服务器\n* 2，numberOfRounds，迭代的次数\n\n过了一会儿，屏幕上出现了一大堆url，可以看到爬虫正在抓取！\n\n    fetching http://music.douban.com/subject/25811077/ (queue crawl delay=5000ms)\n    fetching http://read.douban.com/ebook/1919781 (queue crawl delay=5000ms)\n    fetching http://www.douban.com/online/11670861/ (queue crawl delay=5000ms)\n    fetching http://book.douban.com/tag/绘本 (queue crawl delay=5000ms)\n    fetching http://movie.douban.com/tag/科幻 (queue crawl delay=5000ms)\n    49/50 spinwaiting/active, 56 pages, 0 errors, 0.9 1 pages/s, 332 245 kb/s, 131 URLs in 5 queues\n    fetching http://music.douban.com/subject/25762454/ (queue crawl delay=5000ms)\n    fetching http://read.douban.com/reader/ebook/1951242/ (queue crawl delay=5000ms)\n    fetching http://www.douban.com/mobile/read-notes (queue crawl delay=5000ms)\n    fetching http://book.douban.com/tag/诗歌 (queue crawl delay=5000ms)\n    50/50 spinwaiting/active, 61 pages, 0 errors, 0.9 1 pages/s, 334 366 kb/s, 127 URLs in 5 queues\n\n###8.2 查看结果\n\n    ./bin/nutch readdb -crawlId TestCrawl -stats\n\n也可以进HBase shell 查看，\n\n    cd ~/hbase-0.90.4\n    ./bin/hbase shell\n    hbase(main):001:0> scan 'TestCrawl_webpage'\n\n屏幕开始不断输出内容，可以用Ctrl+C 结束。\n\n在运行scan查看表中内容时，对于列的含义不确定时可以查看`conf/gora-hbase-mapping.xml`文件，该文件定义了列族及列的含义。\n\n##相关文章\n[Nutch 快速入门(Nutch 1.7)](http://www.yanjiuyanjiu.com/blog/20140121/)\n\n\n","slug":"2014-02-01-nutch-tutorial","published":1,"updated":"2016-08-18T09:21:04.000Z","photos":[],"link":"","_id":"cis07pf4d003201pqxphvm1n1","content":"<p>本文主要参考<a href=\"http://wiki.apache.org/nutch/Nutch2Tutorial\" target=\"_blank\" rel=\"external\">Nutch 2.x Tutorial</a></p>\n<p>Nutch 2.x 与 Nutch 1.x 相比，剥离出了存储层，放到了gora中，可以使用多种数据库，例如HBase, Cassandra, MySql来存储数据了。Nutch 1.7 则是把数据直接存储在HDFS上。</p>\n<p>##1. 安装并运行HBase<br>为了简单起见，使用Standalone模式，参考 <a href=\"http://hbase.apache.org/book/quickstart.html\" target=\"_blank\" rel=\"external\">HBase Quick start</a></p>\n<p>###1.1 下载，解压</p>\n<pre><code>wget http://archive.apache.org/dist/hbase/hbase-0.90.4/hbase-0.90.4.tar.gz\ntar zxf hbase-0.90.4.tar.gz\n</code></pre><p>###1.2 修改 conf/hbase-site.xml<br>内容如下</p>\n<pre><code>&lt;configuration&gt;\n  &lt;property&gt;\n    &lt;name&gt;hbase.rootdir&lt;/name&gt;\n    &lt;value&gt;file:///DIRECTORY/hbase&lt;/value&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;hbase.zookeeper.property.dataDir&lt;/name&gt;\n    &lt;value&gt;/DIRECTORY/zookeeper&lt;/value&gt;\n  &lt;/property&gt;\n&lt;/configuration&gt;\n</code></pre><p><code>hbase.rootdir</code>目录是用来存放HBase的相关信息的，默认值是<code>/tmp/hbase-${user.name}/hbase</code>； <code>hbase.zookeeper.property.dataDir</code>目录是用来存放zookeeper（HBase内置了zookeeper）的相关信息的，默认值是<code>/tmp/hbase-${user.name}/zookeeper</code>。</p>\n<p>###1.3 启动</p>\n<pre><code>$ ./bin/start-hbase.sh\nstarting Master, logging to logs/hbase-user-master-example.org.out\n</code></pre><a id=\"more\"></a>\n<p>###1.4 试用一下shell<br>$ ./bin/hbase shell<br>HBase Shell; enter ‘help<return>‘ for list of supported commands.<br>Type “exit<return>“ to leave the HBase Shell<br>Version 0.90.4, r1150278, Sun Jul 24 15:53:29 PDT 2011</return></return></p>\n<p>hbase(main):001:0&gt;</p>\n<p>创建一张名字为<code>test</code>的表，只有一个列，名为<code>cf</code>。为了验证创建是否成功，用<code>list</code>命令查看所有的table，并用<code>put</code>命令插入一些值。</p>\n<pre><code>hbase(main):003:0&gt; create &apos;test&apos;, &apos;cf&apos;\n0 row(s) in 1.2200 seconds\nhbase(main):003:0&gt; list &apos;test&apos;\n..\n1 row(s) in 0.0550 seconds\nhbase(main):004:0&gt; put &apos;test&apos;, &apos;row1&apos;, &apos;cf:a&apos;, &apos;value1&apos;\n0 row(s) in 0.0560 seconds\nhbase(main):005:0&gt; put &apos;test&apos;, &apos;row2&apos;, &apos;cf:b&apos;, &apos;value2&apos;\n0 row(s) in 0.0370 seconds\nhbase(main):006:0&gt; put &apos;test&apos;, &apos;row3&apos;, &apos;cf:c&apos;, &apos;value3&apos;\n0 row(s) in 0.0450 seconds\n</code></pre><p>用<code>scan</code>命令扫描table，验证一下刚才的插入是否成功。</p>\n<pre><code>hbase(main):007:0&gt; scan &apos;test&apos;\nROW        COLUMN+CELL\nrow1       column=cf:a, timestamp=1288380727188, value=value1\nrow2       column=cf:b, timestamp=1288380738440, value=value2\nrow3       column=cf:c, timestamp=1288380747365, value=value3\n3 row(s) in 0.0590 seconds\n</code></pre><p>现在，disable并drop掉你的表，这会把上面的所有操作清零。</p>\n<pre><code>hbase(main):012:0&gt; disable &apos;test&apos;\n0 row(s) in 1.0930 seconds\nhbase(main):013:0&gt; drop &apos;test&apos;\n0 row(s) in 0.0770 seconds \n</code></pre><p>退出shell，</p>\n<pre><code>hbase(main):014:0&gt; exit\n</code></pre><p>###1.5 停止</p>\n<pre><code>$ ./bin/stop-hbase.sh\nstopping hbase...............\n</code></pre><p>###1.6 再次启动<br>后面运行Nutch，需要把数据存储到HBase，因此需要启动HBase。</p>\n<pre><code>$ ./bin/start-hbase.sh\nstarting Master, logging to logs/hbase-user-master-example.org.out\n</code></pre><p>##2 编译Nutch 2.2.1</p>\n<p>###2.1 下载，解压<br>    wget <a href=\"http://www.apache.org/dyn/closer.cgi/nutch/2.2.1/apache-nutch-2.2.1-src.tar.gz\" target=\"_blank\" rel=\"external\">http://www.apache.org/dyn/closer.cgi/nutch/2.2.1/apache-nutch-2.2.1-src.tar.gz</a><br>    tar zxf apache-nutch-2.2.1-src.tar.gz</p>\n<p>###2.2 修改配置文件<br>参考<a href=\"http://wiki.apache.org/nutch/Nutch2Tutorial\" target=\"_blank\" rel=\"external\">Nutch 2.0 Tutorial</a></p>\n<p>修改 <code>conf/nutch-site.xml</code></p>\n<pre><code>&lt;property&gt;\n  &lt;name&gt;storage.data.store.class&lt;/name&gt;\n  &lt;value&gt;org.apache.gora.hbase.store.HBaseStore&lt;/value&gt;\n  &lt;description&gt;Default class for storing data&lt;/description&gt;\n&lt;/property&gt;\n</code></pre><p>修改<code>ivy/ivy.xml</code></p>\n<pre><code>&lt;!-- Uncomment this to use HBase as Gora backend. --&gt;\n&lt;dependency org=&quot;org.apache.gora&quot; name=&quot;gora-hbase&quot; rev=&quot;0.3&quot; conf=&quot;*-&gt;default&quot; /&gt;\n</code></pre><p>修改 <code>conf/gora.properties</code>，确保<code>HBaseStore</code>被设置为默认的存储，</p>\n<pre><code>gora.datastore.default=org.apache.gora.hbase.store.HBaseStore\n</code></pre><p>###2.3 编译</p>\n<pre><code>ant runtime\n</code></pre><p>刚开始会下载很多jar，需要等待一段时间。</p>\n<p>有可能你会得到如下错误：</p>\n<pre><code>Trying to override old definition of task javac\n  [taskdef] Could not load definitions from resource org/sonar/ant/antlib.xml. It could not be found.\n\nivy-probe-antlib:\n\nivy-download:\n  [taskdef] Could not load definitions from resource org/sonar/ant/antlib.xml. It could not be found.\n</code></pre><p>无所谓，不用管它。</p>\n<p>要等一会儿才能编译结束。编译完后，多出来了 build 和 runtime两个文件夹。</p>\n<p>第3、4、5、6步与另一篇博客<a href=\"\">Nutch 快速入门(Nutch 1.7)</a>中的第3、4、5、6步骤一模一样。</p>\n<p>##3 添加种子URL</p>\n<pre><code>mkdir ~/urls\nvim ～/urls/seed.txt\nhttp://movie.douban.com/subject/5323968/\n</code></pre><p>##4 设置URL过滤规则<br>如果只想抓取某种类型的URL，可以在 <code>conf/regex-urlfilter.txt</code>设置正则表达式，于是，只有匹配这些正则表达式的URL才会被抓取。</p>\n<p>例如，我只想抓取豆瓣电影的数据，可以这样设置：</p>\n<pre><code>#注释掉这一行\n# skip URLs containing certain characters as probable queries, etc.\n#-[?*!@=]\n# accept anything else\n#注释掉这行\n#+.\n+^http:\\/\\/movie\\.douban\\.com\\/subject\\/[0-9]+\\/(\\?.+)?$\n</code></pre><p>##5 设置agent名字</p>\n<p>conf/nutch-site.xml:</p>\n<pre><code>&lt;property&gt;\n  &lt;name&gt;http.agent.name&lt;/name&gt;\n  &lt;value&gt;My Nutch Spider&lt;/value&gt;\n&lt;/property&gt;\n</code></pre><p>这一步是从这本书上看到的，<a href=\"http://www.packtpub.com/web-crawling-and-data-mining-with-apache-nutch/book\" target=\"_blank\" rel=\"external\">Web Crawling and Data Mining with Apache Nutch</a>，第14页。</p>\n<p>##6 安装Solr<br>由于建索引的时候需要使用Solr，因此我们需要安装并启动一个Solr服务器。</p>\n<p>参考<a href=\"http://wiki.apache.org/nutch/NutchTutorial\" target=\"_blank\" rel=\"external\">Nutch Tutorial</a> 第4、5、6步，以及<a href=\"http://lucene.apache.org/solr/4_6_1/tutorial.html\" target=\"_blank\" rel=\"external\">Solr Tutorial</a>。</p>\n<p>###6.1 下载，解压</p>\n<p>wget <a href=\"http://mirrors.cnnic.cn/apache/lucene/solr/4.6.1/solr-4.6.1.tgz\" target=\"_blank\" rel=\"external\">http://mirrors.cnnic.cn/apache/lucene/solr/4.6.1/solr-4.6.1.tgz</a><br>tar -zxf solr-4.6.1.tgz</p>\n<p>###6.2 运行Solr</p>\n<pre><code>cd example\njava -jar start.jar\n</code></pre><p>验证是否启动成功</p>\n<p>用浏览器打开 <a href=\"http://localhost:8983/solr/admin/\" target=\"_blank\" rel=\"external\">http://localhost:8983/solr/admin/</a>，如果能看到页面，说明启动成功。</p>\n<p>###6.3 将Nutch与Solr集成在一起</p>\n<p>将<code>NUTCH_DIR/conf/schema-solr4.xml</code>拷贝到<code>SOLR_DIR/solr/collection1/conf/</code>，重命名为schema.xml，并在<code>&lt;fields&gt;...&lt;/fields&gt;</code>最后添加一行(具体解释见<a href=\"http://stackoverflow.com/questions/15527380/solr-4-2-what-is-version-field\" target=\"_blank\" rel=\"external\">Solr 4.2 - what is _version_field?</a>)，</p>\n<pre><code>&lt;field name=&quot;_version_&quot; type=&quot;long&quot; indexed=&quot;true&quot; stored=&quot;true&quot; multiValued=&quot;false&quot;/&gt;\n</code></pre><p>重启Solr，</p>\n<pre><code># Ctrl+C to stop Solr\njava -jar start.jar\n</code></pre><p>第7步和第8步也和Nutch 1.7那篇博客中的7、8步很类似。主要区别在于，Nutch 2.x的所有数据，不再以文件和目录的形式存放在硬盘上，而是存放到HBase里。</p>\n<p>##7 一步一步使用单个命令抓取网页<br>TODO</p>\n<p>##8 使用crawl脚本一键抓取<br>刚才我们是手工敲入多个命令，一个一个步骤，来完成抓取的，其实Nutch自带了一个脚本，<code>./bin/crawl</code>，把抓取的各个步骤合并成一个命令，看一下它的用法</p>\n<pre><code>$ ./bin/crawl \nMissing seedDir : crawl &lt;seedDir&gt; &lt;crawlID&gt; &lt;solrURL&gt; &lt;numberOfRounds&gt;\n</code></pre><p><strong>注意</strong>，这里是<code>crawlId</code>，不再是<code>crawlDir</code>。</p>\n<p>先删除第7节产生的数据，使用HBase shell，用<code>disable</code>删除表。</p>\n<p>###8.1 抓取网页</p>\n<pre><code>$ ./bin/crawl ~/urls/ TestCrawl http://localhost:8983/solr/ 2\n</code></pre><ul>\n<li><code>～/urls</code> 是存放了种子url的目录</li>\n<li>TestCrawl 是crawlId，这会在HBase中创建一张以crawlId为前缀的表，例如TestCrawl_Webpage。</li>\n<li><a href=\"http://localhost:8983/solr/\" target=\"_blank\" rel=\"external\">http://localhost:8983/solr/</a> , 这是Solr服务器</li>\n<li>2，numberOfRounds，迭代的次数</li>\n</ul>\n<p>过了一会儿，屏幕上出现了一大堆url，可以看到爬虫正在抓取！</p>\n<pre><code>fetching http://music.douban.com/subject/25811077/ (queue crawl delay=5000ms)\nfetching http://read.douban.com/ebook/1919781 (queue crawl delay=5000ms)\nfetching http://www.douban.com/online/11670861/ (queue crawl delay=5000ms)\nfetching http://book.douban.com/tag/绘本 (queue crawl delay=5000ms)\nfetching http://movie.douban.com/tag/科幻 (queue crawl delay=5000ms)\n49/50 spinwaiting/active, 56 pages, 0 errors, 0.9 1 pages/s, 332 245 kb/s, 131 URLs in 5 queues\nfetching http://music.douban.com/subject/25762454/ (queue crawl delay=5000ms)\nfetching http://read.douban.com/reader/ebook/1951242/ (queue crawl delay=5000ms)\nfetching http://www.douban.com/mobile/read-notes (queue crawl delay=5000ms)\nfetching http://book.douban.com/tag/诗歌 (queue crawl delay=5000ms)\n50/50 spinwaiting/active, 61 pages, 0 errors, 0.9 1 pages/s, 334 366 kb/s, 127 URLs in 5 queues\n</code></pre><p>###8.2 查看结果</p>\n<pre><code>./bin/nutch readdb -crawlId TestCrawl -stats\n</code></pre><p>也可以进HBase shell 查看，</p>\n<pre><code>cd ~/hbase-0.90.4\n./bin/hbase shell\nhbase(main):001:0&gt; scan &apos;TestCrawl_webpage&apos;\n</code></pre><p>屏幕开始不断输出内容，可以用Ctrl+C 结束。</p>\n<p>在运行scan查看表中内容时，对于列的含义不确定时可以查看<code>conf/gora-hbase-mapping.xml</code>文件，该文件定义了列族及列的含义。</p>\n<p>##相关文章<br><a href=\"http://www.yanjiuyanjiu.com/blog/20140121/\" target=\"_blank\" rel=\"external\">Nutch 快速入门(Nutch 1.7)</a></p>\n","excerpt":"<p>本文主要参考<a href=\"http://wiki.apache.org/nutch/Nutch2Tutorial\">Nutch 2.x Tutorial</a></p>\n<p>Nutch 2.x 与 Nutch 1.x 相比，剥离出了存储层，放到了gora中，可以使用多种数据库，例如HBase, Cassandra, MySql来存储数据了。Nutch 1.7 则是把数据直接存储在HDFS上。</p>\n<p>##1. 安装并运行HBase<br>为了简单起见，使用Standalone模式，参考 <a href=\"http://hbase.apache.org/book/quickstart.html\">HBase Quick start</a></p>\n<p>###1.1 下载，解压</p>\n<pre><code>wget http://archive.apache.org/dist/hbase/hbase-0.90.4/hbase-0.90.4.tar.gz\ntar zxf hbase-0.90.4.tar.gz\n</code></pre><p>###1.2 修改 conf/hbase-site.xml<br>内容如下</p>\n<pre><code>&lt;configuration&gt;\n  &lt;property&gt;\n    &lt;name&gt;hbase.rootdir&lt;/name&gt;\n    &lt;value&gt;file:///DIRECTORY/hbase&lt;/value&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;hbase.zookeeper.property.dataDir&lt;/name&gt;\n    &lt;value&gt;/DIRECTORY/zookeeper&lt;/value&gt;\n  &lt;/property&gt;\n&lt;/configuration&gt;\n</code></pre><p><code>hbase.rootdir</code>目录是用来存放HBase的相关信息的，默认值是<code>/tmp/hbase-${user.name}/hbase</code>； <code>hbase.zookeeper.property.dataDir</code>目录是用来存放zookeeper（HBase内置了zookeeper）的相关信息的，默认值是<code>/tmp/hbase-${user.name}/zookeeper</code>。</p>\n<p>###1.3 启动</p>\n<pre><code>$ ./bin/start-hbase.sh\nstarting Master, logging to logs/hbase-user-master-example.org.out\n</code></pre>","more":"<p>###1.4 试用一下shell<br>$ ./bin/hbase shell<br>HBase Shell; enter ‘help<RETURN>‘ for list of supported commands.<br>Type “exit<RETURN>“ to leave the HBase Shell<br>Version 0.90.4, r1150278, Sun Jul 24 15:53:29 PDT 2011</p>\n<p>hbase(main):001:0&gt;</p>\n<p>创建一张名字为<code>test</code>的表，只有一个列，名为<code>cf</code>。为了验证创建是否成功，用<code>list</code>命令查看所有的table，并用<code>put</code>命令插入一些值。</p>\n<pre><code>hbase(main):003:0&gt; create &apos;test&apos;, &apos;cf&apos;\n0 row(s) in 1.2200 seconds\nhbase(main):003:0&gt; list &apos;test&apos;\n..\n1 row(s) in 0.0550 seconds\nhbase(main):004:0&gt; put &apos;test&apos;, &apos;row1&apos;, &apos;cf:a&apos;, &apos;value1&apos;\n0 row(s) in 0.0560 seconds\nhbase(main):005:0&gt; put &apos;test&apos;, &apos;row2&apos;, &apos;cf:b&apos;, &apos;value2&apos;\n0 row(s) in 0.0370 seconds\nhbase(main):006:0&gt; put &apos;test&apos;, &apos;row3&apos;, &apos;cf:c&apos;, &apos;value3&apos;\n0 row(s) in 0.0450 seconds\n</code></pre><p>用<code>scan</code>命令扫描table，验证一下刚才的插入是否成功。</p>\n<pre><code>hbase(main):007:0&gt; scan &apos;test&apos;\nROW        COLUMN+CELL\nrow1       column=cf:a, timestamp=1288380727188, value=value1\nrow2       column=cf:b, timestamp=1288380738440, value=value2\nrow3       column=cf:c, timestamp=1288380747365, value=value3\n3 row(s) in 0.0590 seconds\n</code></pre><p>现在，disable并drop掉你的表，这会把上面的所有操作清零。</p>\n<pre><code>hbase(main):012:0&gt; disable &apos;test&apos;\n0 row(s) in 1.0930 seconds\nhbase(main):013:0&gt; drop &apos;test&apos;\n0 row(s) in 0.0770 seconds \n</code></pre><p>退出shell，</p>\n<pre><code>hbase(main):014:0&gt; exit\n</code></pre><p>###1.5 停止</p>\n<pre><code>$ ./bin/stop-hbase.sh\nstopping hbase...............\n</code></pre><p>###1.6 再次启动<br>后面运行Nutch，需要把数据存储到HBase，因此需要启动HBase。</p>\n<pre><code>$ ./bin/start-hbase.sh\nstarting Master, logging to logs/hbase-user-master-example.org.out\n</code></pre><p>##2 编译Nutch 2.2.1</p>\n<p>###2.1 下载，解压<br>    wget <a href=\"http://www.apache.org/dyn/closer.cgi/nutch/2.2.1/apache-nutch-2.2.1-src.tar.gz\">http://www.apache.org/dyn/closer.cgi/nutch/2.2.1/apache-nutch-2.2.1-src.tar.gz</a><br>    tar zxf apache-nutch-2.2.1-src.tar.gz</p>\n<p>###2.2 修改配置文件<br>参考<a href=\"http://wiki.apache.org/nutch/Nutch2Tutorial\">Nutch 2.0 Tutorial</a></p>\n<p>修改 <code>conf/nutch-site.xml</code></p>\n<pre><code>&lt;property&gt;\n  &lt;name&gt;storage.data.store.class&lt;/name&gt;\n  &lt;value&gt;org.apache.gora.hbase.store.HBaseStore&lt;/value&gt;\n  &lt;description&gt;Default class for storing data&lt;/description&gt;\n&lt;/property&gt;\n</code></pre><p>修改<code>ivy/ivy.xml</code></p>\n<pre><code>&lt;!-- Uncomment this to use HBase as Gora backend. --&gt;\n&lt;dependency org=&quot;org.apache.gora&quot; name=&quot;gora-hbase&quot; rev=&quot;0.3&quot; conf=&quot;*-&gt;default&quot; /&gt;\n</code></pre><p>修改 <code>conf/gora.properties</code>，确保<code>HBaseStore</code>被设置为默认的存储，</p>\n<pre><code>gora.datastore.default=org.apache.gora.hbase.store.HBaseStore\n</code></pre><p>###2.3 编译</p>\n<pre><code>ant runtime\n</code></pre><p>刚开始会下载很多jar，需要等待一段时间。</p>\n<p>有可能你会得到如下错误：</p>\n<pre><code>Trying to override old definition of task javac\n  [taskdef] Could not load definitions from resource org/sonar/ant/antlib.xml. It could not be found.\n\nivy-probe-antlib:\n\nivy-download:\n  [taskdef] Could not load definitions from resource org/sonar/ant/antlib.xml. It could not be found.\n</code></pre><p>无所谓，不用管它。</p>\n<p>要等一会儿才能编译结束。编译完后，多出来了 build 和 runtime两个文件夹。</p>\n<p>第3、4、5、6步与另一篇博客<a href=\"\">Nutch 快速入门(Nutch 1.7)</a>中的第3、4、5、6步骤一模一样。</p>\n<p>##3 添加种子URL</p>\n<pre><code>mkdir ~/urls\nvim ～/urls/seed.txt\nhttp://movie.douban.com/subject/5323968/\n</code></pre><p>##4 设置URL过滤规则<br>如果只想抓取某种类型的URL，可以在 <code>conf/regex-urlfilter.txt</code>设置正则表达式，于是，只有匹配这些正则表达式的URL才会被抓取。</p>\n<p>例如，我只想抓取豆瓣电影的数据，可以这样设置：</p>\n<pre><code>#注释掉这一行\n# skip URLs containing certain characters as probable queries, etc.\n#-[?*!@=]\n# accept anything else\n#注释掉这行\n#+.\n+^http:\\/\\/movie\\.douban\\.com\\/subject\\/[0-9]+\\/(\\?.+)?$\n</code></pre><p>##5 设置agent名字</p>\n<p>conf/nutch-site.xml:</p>\n<pre><code>&lt;property&gt;\n  &lt;name&gt;http.agent.name&lt;/name&gt;\n  &lt;value&gt;My Nutch Spider&lt;/value&gt;\n&lt;/property&gt;\n</code></pre><p>这一步是从这本书上看到的，<a href=\"http://www.packtpub.com/web-crawling-and-data-mining-with-apache-nutch/book\">Web Crawling and Data Mining with Apache Nutch</a>，第14页。</p>\n<p>##6 安装Solr<br>由于建索引的时候需要使用Solr，因此我们需要安装并启动一个Solr服务器。</p>\n<p>参考<a href=\"http://wiki.apache.org/nutch/NutchTutorial\">Nutch Tutorial</a> 第4、5、6步，以及<a href=\"http://lucene.apache.org/solr/4_6_1/tutorial.html\">Solr Tutorial</a>。</p>\n<p>###6.1 下载，解压</p>\n<p>wget <a href=\"http://mirrors.cnnic.cn/apache/lucene/solr/4.6.1/solr-4.6.1.tgz\">http://mirrors.cnnic.cn/apache/lucene/solr/4.6.1/solr-4.6.1.tgz</a><br>tar -zxf solr-4.6.1.tgz</p>\n<p>###6.2 运行Solr</p>\n<pre><code>cd example\njava -jar start.jar\n</code></pre><p>验证是否启动成功</p>\n<p>用浏览器打开 <a href=\"http://localhost:8983/solr/admin/\">http://localhost:8983/solr/admin/</a>，如果能看到页面，说明启动成功。</p>\n<p>###6.3 将Nutch与Solr集成在一起</p>\n<p>将<code>NUTCH_DIR/conf/schema-solr4.xml</code>拷贝到<code>SOLR_DIR/solr/collection1/conf/</code>，重命名为schema.xml，并在<code>&lt;fields&gt;...&lt;/fields&gt;</code>最后添加一行(具体解释见<a href=\"http://stackoverflow.com/questions/15527380/solr-4-2-what-is-version-field\">Solr 4.2 - what is _version_field?</a>)，</p>\n<pre><code>&lt;field name=&quot;_version_&quot; type=&quot;long&quot; indexed=&quot;true&quot; stored=&quot;true&quot; multiValued=&quot;false&quot;/&gt;\n</code></pre><p>重启Solr，</p>\n<pre><code># Ctrl+C to stop Solr\njava -jar start.jar\n</code></pre><p>第7步和第8步也和Nutch 1.7那篇博客中的7、8步很类似。主要区别在于，Nutch 2.x的所有数据，不再以文件和目录的形式存放在硬盘上，而是存放到HBase里。</p>\n<p>##7 一步一步使用单个命令抓取网页<br>TODO</p>\n<p>##8 使用crawl脚本一键抓取<br>刚才我们是手工敲入多个命令，一个一个步骤，来完成抓取的，其实Nutch自带了一个脚本，<code>./bin/crawl</code>，把抓取的各个步骤合并成一个命令，看一下它的用法</p>\n<pre><code>$ ./bin/crawl \nMissing seedDir : crawl &lt;seedDir&gt; &lt;crawlID&gt; &lt;solrURL&gt; &lt;numberOfRounds&gt;\n</code></pre><p><strong>注意</strong>，这里是<code>crawlId</code>，不再是<code>crawlDir</code>。</p>\n<p>先删除第7节产生的数据，使用HBase shell，用<code>disable</code>删除表。</p>\n<p>###8.1 抓取网页</p>\n<pre><code>$ ./bin/crawl ~/urls/ TestCrawl http://localhost:8983/solr/ 2\n</code></pre><ul>\n<li><code>～/urls</code> 是存放了种子url的目录</li>\n<li>TestCrawl 是crawlId，这会在HBase中创建一张以crawlId为前缀的表，例如TestCrawl_Webpage。</li>\n<li><a href=\"http://localhost:8983/solr/\">http://localhost:8983/solr/</a> , 这是Solr服务器</li>\n<li>2，numberOfRounds，迭代的次数</li>\n</ul>\n<p>过了一会儿，屏幕上出现了一大堆url，可以看到爬虫正在抓取！</p>\n<pre><code>fetching http://music.douban.com/subject/25811077/ (queue crawl delay=5000ms)\nfetching http://read.douban.com/ebook/1919781 (queue crawl delay=5000ms)\nfetching http://www.douban.com/online/11670861/ (queue crawl delay=5000ms)\nfetching http://book.douban.com/tag/绘本 (queue crawl delay=5000ms)\nfetching http://movie.douban.com/tag/科幻 (queue crawl delay=5000ms)\n49/50 spinwaiting/active, 56 pages, 0 errors, 0.9 1 pages/s, 332 245 kb/s, 131 URLs in 5 queues\nfetching http://music.douban.com/subject/25762454/ (queue crawl delay=5000ms)\nfetching http://read.douban.com/reader/ebook/1951242/ (queue crawl delay=5000ms)\nfetching http://www.douban.com/mobile/read-notes (queue crawl delay=5000ms)\nfetching http://book.douban.com/tag/诗歌 (queue crawl delay=5000ms)\n50/50 spinwaiting/active, 61 pages, 0 errors, 0.9 1 pages/s, 334 366 kb/s, 127 URLs in 5 queues\n</code></pre><p>###8.2 查看结果</p>\n<pre><code>./bin/nutch readdb -crawlId TestCrawl -stats\n</code></pre><p>也可以进HBase shell 查看，</p>\n<pre><code>cd ~/hbase-0.90.4\n./bin/hbase shell\nhbase(main):001:0&gt; scan &apos;TestCrawl_webpage&apos;\n</code></pre><p>屏幕开始不断输出内容，可以用Ctrl+C 结束。</p>\n<p>在运行scan查看表中内容时，对于列的含义不确定时可以查看<code>conf/gora-hbase-mapping.xml</code>文件，该文件定义了列族及列的含义。</p>\n<p>##相关文章<br><a href=\"http://www.yanjiuyanjiu.com/blog/20140121/\">Nutch 快速入门(Nutch 1.7)</a></p>"},{"layout":"post","title":"Hadoop多用户的配置(Hadoop 1.x)","date":"2014-02-03T10:05:00.000Z","comments":1,"_content":"假设我们以名为hadoop的用户，建好了集群，见[在CentOS上安装Hadoop集群](http://www.yanjiuyanjiu.com/blog/20140202)。通常，我们会把这个集群共享给多个用户，而不是让大家都登录为hadoop，这样做有几个好处：\n\n* 一个用户不能修改另一个用户的的文件\n* 在hadoop web管理页面，可以很方便的看到不同的用户的job\n\n现在集群中有一台机器，上面有一个用户名为 hbase 的用户，他想要使用hadoop集群，怎么配置呢？\n\n##1. 安装hadoop客户端\n\n###1.1 下载，解压\n下载跟hadoop集群一样的hadoop软件包，并解压，\n\n    $ wget http://mirror.olnevhost.net/pub/apache/hadoop/common/stable1/hadoop-1.2.1-bin.tar.gz\n    $ tar -zxf hadoop-1.2.1-bin.tar.gz -C ~/local/opt\n    $ cd ~/local/opt/hadoop-1.2.1\n\n###1.2 配置\n在客户端只需配置集群namenode 和 jobtracker 的相关信息, 把namenode和jobtracker的信息告诉客户端即可。\n\n把hadoop用户下的`conf/core-site.xml`和`conf/mapred-site.xml`拷贝到本用户的conf/目录下\n\n\n    $ scp hadoop@localhost:~/local/opt/hadoop-1.2.1/conf/core-site.xml ./conf/\n    $ scp hadoop@localhost:~/local/opt/hadoop-1.2.1/conf/mapred-site.xml ./conf/\n\n修改conf/mapred-site.xml中的`mapred.local.dir`，改为本机上的某个目录，确保这个目录存在且有写入。因为这个目录是本地目录，每台机器都可以不同。例如我的是：\n\n    <property>\n      <name>mapred.local.dir</name>\n      <value>/home/soulmachine/local/var/hadoop/mapred/local</value>\n    </property>\n\n确保这个目录存在，\n\n    $ mkdir -p ~/local/var/hadoop/mapred/local\n\n<!-- more -->\n\n还有另一种方法，由于`mapred.local.dir`默认值是`${hadoop.tmp.dir}/mapred/local`，也可以通过修改`hadoop.tmp.dir`达到目的，在`core-site.xml`中，确保`${hadoop.tmp.dir}/mapred/local`存在且有写权限。\n\n\n##2. 在master上配置权限\n以下操作均在hadoop集群的 namenode 这台机器上进行，且登录为hadoop，因为hadoop这个用户是整个hadoop集群权限最高的用户（但对于Linux系统本身，这个用户其实没有sudo权限）。\n\nHadoop关于用户权限方面，有很多高级的配置，这里我们简单的利用HDFS本身的文件权限检查机制，来配置多用户。\n\nHDFS本身没有提供用户名、用户组的创建，在客户端调用hadoop 的文件操作命令时，hadoop 识别出执行命令所在进程的linux系统的用户名和用户组，然后使用这个用户名和组来检查文件权限。 用户名=linux命令中的`whoami`，而组名等于`groups`。 \n\n启动hadoop hdfs系统的用户即为超级用户（在这里就是名为hadoop的这个用户），可以进行任意的操作。\n\n在客户端机器上，用gropus命令看一下hbase所在的组，\n\n    $ groups\n    hbase\n\n说明hbase这个用户所在的组为hbase。\n\n###2.1 为客户端用户创建home文件夹\n\n    $ hadoop fs -mkdir /user/hbase\n    $ hadoop fs -chown hbase /user/hbase\n    $ hadoop fs -chgrp hbase /user/hbase\n\n###2.2 为客户端用户创建hadoop.tmp.dir文件夹\n`hadoop.tmp.dir`既是一个本地目录，也是HDFS上的一个目录，参考[What should be hadoop.tmp.dir?](http://stackoverflow.com/questions/2354525/what-should-be-hadoop-tmp-dir)。默认是`/tmp/hadoop-${user.name}`（参考官方表格，[core-default](http://hadoop.apache.org/docs/r1.2.1/core-default.html)），所以我们需要为用户创建这个文件夹，\n\n    $ hadoop fs -mkdir /tmp/hadoop-hbase\n    $ hadoop fs -chown hbase /tmp/hadoop-hbase\n    $ hadoop fs -chgrp hbase /tmp/hadoop-hbase\n\n补充说明一下各个常见目录的相关知识，\n\n* `dfs.name.dir`和`dfs.data.dir`都是本地目录，它们是HDFS的基础，所以只可能是本地目录\n* `mapred.local.dir`是本地目录，当客户端向集群提交了一个任务后，该job相关的文件（jar包和配置文件）会存放在HDFS上，各个slave从HDFS把这些文件下载到本地，然后开始执行。\n* `mapred.system.dir`是一个HDFS目录，存放了一个job的控制信息，被多个slave所共享，所以只能是HDFS目录。\n* `mapred.temp.dir`是一个HDFS目录，存放着一个job的临时文件，job结束后会被自动删除。\n\n###2.3 设置mapreduce.jobtracker.staging.root.dir\n客户端向集群提交任务时，需要把该job需要的文件打包，拷贝到HDFS上。在拷贝之前，得先确定这些资源文件存放在HDFS的什么地方。JobTracker设置有一个工作目录(Staging area, 也称数据中转站)，用来存储与每个job相关的数据。这个目录的前缀由`mapreduce.jobtracker.staging.root.dir` 参数来指定，默认是`${hadoop.tmp.dir}/mapred/staging`，每个client user可以提交多个job，在这个目录后就得附加user name的信息。所以这个工作目录(Staging area)默认是`${hadoop.tmp.dir}/mapred/staging/denny/.staging/`。\n\n一般把前缀设置为`/user`，这是官方推荐的，见 [mapred-default.xml](http://hadoop.apache.org/docs/r1.2.1/mapred-default.html) 里的`mapreduce.jobtracker.staging.root.dir`处：\n\n> The root of the staging area for users' job files In practice, this should be the directory where users' home directories are located (usually /user)\n\n    #以hadoop用户登录jobtracker机器\n    $ vim conf/mapred-site.xml\n    <property>\n      <name>mapreduce.jobtracker.staging.root.dir</name>\n      <value>/user</value>\n    </property>\n\n###2.4 重启hadoop集群\n将配置文件scp到所有机器，然后重启集群，\n\n    $ bin/stop-all.sh\n    $ bin/start-all.sh\n\n##3. 测试一下\n回到客户端机器。\n\n将输入数据拷贝到分布式文件系统中:\n\n    $ bin/hadoop fs -put conf input\n    $ bin/hadoop fs -ls input\n\n运行 Hadoop 自带的例子:\n\n    $ bin/hadoop jar hadoop-examples-*.jar wordcount input output\n\n查看输出文件:\n\n    $ bin/hadoop fs -ls output\n    $ bin/hadoop fs -cat output/part-r-00000\n\n如果能看到结果，说明这个例子运行成功。\n\n###4 （可选）设置别名，名称为hadoop，指向bin/hadoop\n这样就不用每次都cd到Hadoop目录，执行命令了。\n\n在 `~/.bashrc`中添加如下4行：\n\n\tunalias hadoop &> /dev/null\n\talias hadoop=\"$HOME/local/opt/hadoop-1.2.1/bin/hadoop\"\n\tunalias hls &> /dev/null\n\talias hls=\"hadoop fs -ls\"\n\nsource使之立刻生效，\n\n\t$ source ~/.bashrc\n\n##参考资料\n\n1. [hadoop远程客户端安装配置、多用户权限配置](http://blog.csdn.net/j3smile/article/details/7887826)\n1. [hadoop如何创建多用户](http://blog.csdn.net/a999wt/article/details/8718707)\n1. [关于多用户时hadoop的权限问题](http://blog.sina.com.cn/s/blog_605f5b4f0101897z.html)\n1. [MapReduce: Job提交过程](http://langyu.iteye.com/blog/909170)\n1. [hadoop中的dfs.name.dir,mapred.local.dir,mapred.system.dir和hadoop.tmp.dir说明](http://www.hadoopor.com/archiver/tid-481.html)\n1. [Hadoop 參數設定 – mapred-site.xml](http://fenriswolf.me/2012/08/06/hadoop-%E5%8F%83%E6%95%B8%E8%A8%AD%E5%AE%9A-mapred-site-xml/)\n\n","source":"_posts/2014-02-03-hadoop-multiple-users.md","raw":"---\nlayout: post\ntitle: \"Hadoop多用户的配置(Hadoop 1.x)\"\ndate: 2014-02-03 10:05\ncomments: true\ncategories: Hadoop\n---\n假设我们以名为hadoop的用户，建好了集群，见[在CentOS上安装Hadoop集群](http://www.yanjiuyanjiu.com/blog/20140202)。通常，我们会把这个集群共享给多个用户，而不是让大家都登录为hadoop，这样做有几个好处：\n\n* 一个用户不能修改另一个用户的的文件\n* 在hadoop web管理页面，可以很方便的看到不同的用户的job\n\n现在集群中有一台机器，上面有一个用户名为 hbase 的用户，他想要使用hadoop集群，怎么配置呢？\n\n##1. 安装hadoop客户端\n\n###1.1 下载，解压\n下载跟hadoop集群一样的hadoop软件包，并解压，\n\n    $ wget http://mirror.olnevhost.net/pub/apache/hadoop/common/stable1/hadoop-1.2.1-bin.tar.gz\n    $ tar -zxf hadoop-1.2.1-bin.tar.gz -C ~/local/opt\n    $ cd ~/local/opt/hadoop-1.2.1\n\n###1.2 配置\n在客户端只需配置集群namenode 和 jobtracker 的相关信息, 把namenode和jobtracker的信息告诉客户端即可。\n\n把hadoop用户下的`conf/core-site.xml`和`conf/mapred-site.xml`拷贝到本用户的conf/目录下\n\n\n    $ scp hadoop@localhost:~/local/opt/hadoop-1.2.1/conf/core-site.xml ./conf/\n    $ scp hadoop@localhost:~/local/opt/hadoop-1.2.1/conf/mapred-site.xml ./conf/\n\n修改conf/mapred-site.xml中的`mapred.local.dir`，改为本机上的某个目录，确保这个目录存在且有写入。因为这个目录是本地目录，每台机器都可以不同。例如我的是：\n\n    <property>\n      <name>mapred.local.dir</name>\n      <value>/home/soulmachine/local/var/hadoop/mapred/local</value>\n    </property>\n\n确保这个目录存在，\n\n    $ mkdir -p ~/local/var/hadoop/mapred/local\n\n<!-- more -->\n\n还有另一种方法，由于`mapred.local.dir`默认值是`${hadoop.tmp.dir}/mapred/local`，也可以通过修改`hadoop.tmp.dir`达到目的，在`core-site.xml`中，确保`${hadoop.tmp.dir}/mapred/local`存在且有写权限。\n\n\n##2. 在master上配置权限\n以下操作均在hadoop集群的 namenode 这台机器上进行，且登录为hadoop，因为hadoop这个用户是整个hadoop集群权限最高的用户（但对于Linux系统本身，这个用户其实没有sudo权限）。\n\nHadoop关于用户权限方面，有很多高级的配置，这里我们简单的利用HDFS本身的文件权限检查机制，来配置多用户。\n\nHDFS本身没有提供用户名、用户组的创建，在客户端调用hadoop 的文件操作命令时，hadoop 识别出执行命令所在进程的linux系统的用户名和用户组，然后使用这个用户名和组来检查文件权限。 用户名=linux命令中的`whoami`，而组名等于`groups`。 \n\n启动hadoop hdfs系统的用户即为超级用户（在这里就是名为hadoop的这个用户），可以进行任意的操作。\n\n在客户端机器上，用gropus命令看一下hbase所在的组，\n\n    $ groups\n    hbase\n\n说明hbase这个用户所在的组为hbase。\n\n###2.1 为客户端用户创建home文件夹\n\n    $ hadoop fs -mkdir /user/hbase\n    $ hadoop fs -chown hbase /user/hbase\n    $ hadoop fs -chgrp hbase /user/hbase\n\n###2.2 为客户端用户创建hadoop.tmp.dir文件夹\n`hadoop.tmp.dir`既是一个本地目录，也是HDFS上的一个目录，参考[What should be hadoop.tmp.dir?](http://stackoverflow.com/questions/2354525/what-should-be-hadoop-tmp-dir)。默认是`/tmp/hadoop-${user.name}`（参考官方表格，[core-default](http://hadoop.apache.org/docs/r1.2.1/core-default.html)），所以我们需要为用户创建这个文件夹，\n\n    $ hadoop fs -mkdir /tmp/hadoop-hbase\n    $ hadoop fs -chown hbase /tmp/hadoop-hbase\n    $ hadoop fs -chgrp hbase /tmp/hadoop-hbase\n\n补充说明一下各个常见目录的相关知识，\n\n* `dfs.name.dir`和`dfs.data.dir`都是本地目录，它们是HDFS的基础，所以只可能是本地目录\n* `mapred.local.dir`是本地目录，当客户端向集群提交了一个任务后，该job相关的文件（jar包和配置文件）会存放在HDFS上，各个slave从HDFS把这些文件下载到本地，然后开始执行。\n* `mapred.system.dir`是一个HDFS目录，存放了一个job的控制信息，被多个slave所共享，所以只能是HDFS目录。\n* `mapred.temp.dir`是一个HDFS目录，存放着一个job的临时文件，job结束后会被自动删除。\n\n###2.3 设置mapreduce.jobtracker.staging.root.dir\n客户端向集群提交任务时，需要把该job需要的文件打包，拷贝到HDFS上。在拷贝之前，得先确定这些资源文件存放在HDFS的什么地方。JobTracker设置有一个工作目录(Staging area, 也称数据中转站)，用来存储与每个job相关的数据。这个目录的前缀由`mapreduce.jobtracker.staging.root.dir` 参数来指定，默认是`${hadoop.tmp.dir}/mapred/staging`，每个client user可以提交多个job，在这个目录后就得附加user name的信息。所以这个工作目录(Staging area)默认是`${hadoop.tmp.dir}/mapred/staging/denny/.staging/`。\n\n一般把前缀设置为`/user`，这是官方推荐的，见 [mapred-default.xml](http://hadoop.apache.org/docs/r1.2.1/mapred-default.html) 里的`mapreduce.jobtracker.staging.root.dir`处：\n\n> The root of the staging area for users' job files In practice, this should be the directory where users' home directories are located (usually /user)\n\n    #以hadoop用户登录jobtracker机器\n    $ vim conf/mapred-site.xml\n    <property>\n      <name>mapreduce.jobtracker.staging.root.dir</name>\n      <value>/user</value>\n    </property>\n\n###2.4 重启hadoop集群\n将配置文件scp到所有机器，然后重启集群，\n\n    $ bin/stop-all.sh\n    $ bin/start-all.sh\n\n##3. 测试一下\n回到客户端机器。\n\n将输入数据拷贝到分布式文件系统中:\n\n    $ bin/hadoop fs -put conf input\n    $ bin/hadoop fs -ls input\n\n运行 Hadoop 自带的例子:\n\n    $ bin/hadoop jar hadoop-examples-*.jar wordcount input output\n\n查看输出文件:\n\n    $ bin/hadoop fs -ls output\n    $ bin/hadoop fs -cat output/part-r-00000\n\n如果能看到结果，说明这个例子运行成功。\n\n###4 （可选）设置别名，名称为hadoop，指向bin/hadoop\n这样就不用每次都cd到Hadoop目录，执行命令了。\n\n在 `~/.bashrc`中添加如下4行：\n\n\tunalias hadoop &> /dev/null\n\talias hadoop=\"$HOME/local/opt/hadoop-1.2.1/bin/hadoop\"\n\tunalias hls &> /dev/null\n\talias hls=\"hadoop fs -ls\"\n\nsource使之立刻生效，\n\n\t$ source ~/.bashrc\n\n##参考资料\n\n1. [hadoop远程客户端安装配置、多用户权限配置](http://blog.csdn.net/j3smile/article/details/7887826)\n1. [hadoop如何创建多用户](http://blog.csdn.net/a999wt/article/details/8718707)\n1. [关于多用户时hadoop的权限问题](http://blog.sina.com.cn/s/blog_605f5b4f0101897z.html)\n1. [MapReduce: Job提交过程](http://langyu.iteye.com/blog/909170)\n1. [hadoop中的dfs.name.dir,mapred.local.dir,mapred.system.dir和hadoop.tmp.dir说明](http://www.hadoopor.com/archiver/tid-481.html)\n1. [Hadoop 參數設定 – mapred-site.xml](http://fenriswolf.me/2012/08/06/hadoop-%E5%8F%83%E6%95%B8%E8%A8%AD%E5%AE%9A-mapred-site-xml/)\n\n","slug":"2014-02-03-hadoop-multiple-users","published":1,"updated":"2016-08-18T09:21:04.000Z","photos":[],"link":"","_id":"cis07pf4e003401pqabqqjd6y","content":"<p>假设我们以名为hadoop的用户，建好了集群，见<a href=\"http://www.yanjiuyanjiu.com/blog/20140202\" target=\"_blank\" rel=\"external\">在CentOS上安装Hadoop集群</a>。通常，我们会把这个集群共享给多个用户，而不是让大家都登录为hadoop，这样做有几个好处：</p>\n<ul>\n<li>一个用户不能修改另一个用户的的文件</li>\n<li>在hadoop web管理页面，可以很方便的看到不同的用户的job</li>\n</ul>\n<p>现在集群中有一台机器，上面有一个用户名为 hbase 的用户，他想要使用hadoop集群，怎么配置呢？</p>\n<p>##1. 安装hadoop客户端</p>\n<p>###1.1 下载，解压<br>下载跟hadoop集群一样的hadoop软件包，并解压，</p>\n<pre><code>$ wget http://mirror.olnevhost.net/pub/apache/hadoop/common/stable1/hadoop-1.2.1-bin.tar.gz\n$ tar -zxf hadoop-1.2.1-bin.tar.gz -C ~/local/opt\n$ cd ~/local/opt/hadoop-1.2.1\n</code></pre><p>###1.2 配置<br>在客户端只需配置集群namenode 和 jobtracker 的相关信息, 把namenode和jobtracker的信息告诉客户端即可。</p>\n<p>把hadoop用户下的<code>conf/core-site.xml</code>和<code>conf/mapred-site.xml</code>拷贝到本用户的conf/目录下</p>\n<pre><code>$ scp hadoop@localhost:~/local/opt/hadoop-1.2.1/conf/core-site.xml ./conf/\n$ scp hadoop@localhost:~/local/opt/hadoop-1.2.1/conf/mapred-site.xml ./conf/\n</code></pre><p>修改conf/mapred-site.xml中的<code>mapred.local.dir</code>，改为本机上的某个目录，确保这个目录存在且有写入。因为这个目录是本地目录，每台机器都可以不同。例如我的是：</p>\n<pre><code>&lt;property&gt;\n  &lt;name&gt;mapred.local.dir&lt;/name&gt;\n  &lt;value&gt;/home/soulmachine/local/var/hadoop/mapred/local&lt;/value&gt;\n&lt;/property&gt;\n</code></pre><p>确保这个目录存在，</p>\n<pre><code>$ mkdir -p ~/local/var/hadoop/mapred/local\n</code></pre><a id=\"more\"></a>\n<p>还有另一种方法，由于<code>mapred.local.dir</code>默认值是<code>${hadoop.tmp.dir}/mapred/local</code>，也可以通过修改<code>hadoop.tmp.dir</code>达到目的，在<code>core-site.xml</code>中，确保<code>${hadoop.tmp.dir}/mapred/local</code>存在且有写权限。</p>\n<p>##2. 在master上配置权限<br>以下操作均在hadoop集群的 namenode 这台机器上进行，且登录为hadoop，因为hadoop这个用户是整个hadoop集群权限最高的用户（但对于Linux系统本身，这个用户其实没有sudo权限）。</p>\n<p>Hadoop关于用户权限方面，有很多高级的配置，这里我们简单的利用HDFS本身的文件权限检查机制，来配置多用户。</p>\n<p>HDFS本身没有提供用户名、用户组的创建，在客户端调用hadoop 的文件操作命令时，hadoop 识别出执行命令所在进程的linux系统的用户名和用户组，然后使用这个用户名和组来检查文件权限。 用户名=linux命令中的<code>whoami</code>，而组名等于<code>groups</code>。 </p>\n<p>启动hadoop hdfs系统的用户即为超级用户（在这里就是名为hadoop的这个用户），可以进行任意的操作。</p>\n<p>在客户端机器上，用gropus命令看一下hbase所在的组，</p>\n<pre><code>$ groups\nhbase\n</code></pre><p>说明hbase这个用户所在的组为hbase。</p>\n<p>###2.1 为客户端用户创建home文件夹</p>\n<pre><code>$ hadoop fs -mkdir /user/hbase\n$ hadoop fs -chown hbase /user/hbase\n$ hadoop fs -chgrp hbase /user/hbase\n</code></pre><p>###2.2 为客户端用户创建hadoop.tmp.dir文件夹<br><code>hadoop.tmp.dir</code>既是一个本地目录，也是HDFS上的一个目录，参考<a href=\"http://stackoverflow.com/questions/2354525/what-should-be-hadoop-tmp-dir\" target=\"_blank\" rel=\"external\">What should be hadoop.tmp.dir?</a>。默认是<code>/tmp/hadoop-${user.name}</code>（参考官方表格，<a href=\"http://hadoop.apache.org/docs/r1.2.1/core-default.html\" target=\"_blank\" rel=\"external\">core-default</a>），所以我们需要为用户创建这个文件夹，</p>\n<pre><code>$ hadoop fs -mkdir /tmp/hadoop-hbase\n$ hadoop fs -chown hbase /tmp/hadoop-hbase\n$ hadoop fs -chgrp hbase /tmp/hadoop-hbase\n</code></pre><p>补充说明一下各个常见目录的相关知识，</p>\n<ul>\n<li><code>dfs.name.dir</code>和<code>dfs.data.dir</code>都是本地目录，它们是HDFS的基础，所以只可能是本地目录</li>\n<li><code>mapred.local.dir</code>是本地目录，当客户端向集群提交了一个任务后，该job相关的文件（jar包和配置文件）会存放在HDFS上，各个slave从HDFS把这些文件下载到本地，然后开始执行。</li>\n<li><code>mapred.system.dir</code>是一个HDFS目录，存放了一个job的控制信息，被多个slave所共享，所以只能是HDFS目录。</li>\n<li><code>mapred.temp.dir</code>是一个HDFS目录，存放着一个job的临时文件，job结束后会被自动删除。</li>\n</ul>\n<p>###2.3 设置mapreduce.jobtracker.staging.root.dir<br>客户端向集群提交任务时，需要把该job需要的文件打包，拷贝到HDFS上。在拷贝之前，得先确定这些资源文件存放在HDFS的什么地方。JobTracker设置有一个工作目录(Staging area, 也称数据中转站)，用来存储与每个job相关的数据。这个目录的前缀由<code>mapreduce.jobtracker.staging.root.dir</code> 参数来指定，默认是<code>${hadoop.tmp.dir}/mapred/staging</code>，每个client user可以提交多个job，在这个目录后就得附加user name的信息。所以这个工作目录(Staging area)默认是<code>${hadoop.tmp.dir}/mapred/staging/denny/.staging/</code>。</p>\n<p>一般把前缀设置为<code>/user</code>，这是官方推荐的，见 <a href=\"http://hadoop.apache.org/docs/r1.2.1/mapred-default.html\" target=\"_blank\" rel=\"external\">mapred-default.xml</a> 里的<code>mapreduce.jobtracker.staging.root.dir</code>处：</p>\n<blockquote>\n<p>The root of the staging area for users’ job files In practice, this should be the directory where users’ home directories are located (usually /user)</p>\n</blockquote>\n<pre><code>#以hadoop用户登录jobtracker机器\n$ vim conf/mapred-site.xml\n&lt;property&gt;\n  &lt;name&gt;mapreduce.jobtracker.staging.root.dir&lt;/name&gt;\n  &lt;value&gt;/user&lt;/value&gt;\n&lt;/property&gt;\n</code></pre><p>###2.4 重启hadoop集群<br>将配置文件scp到所有机器，然后重启集群，</p>\n<pre><code>$ bin/stop-all.sh\n$ bin/start-all.sh\n</code></pre><p>##3. 测试一下<br>回到客户端机器。</p>\n<p>将输入数据拷贝到分布式文件系统中:</p>\n<pre><code>$ bin/hadoop fs -put conf input\n$ bin/hadoop fs -ls input\n</code></pre><p>运行 Hadoop 自带的例子:</p>\n<pre><code>$ bin/hadoop jar hadoop-examples-*.jar wordcount input output\n</code></pre><p>查看输出文件:</p>\n<pre><code>$ bin/hadoop fs -ls output\n$ bin/hadoop fs -cat output/part-r-00000\n</code></pre><p>如果能看到结果，说明这个例子运行成功。</p>\n<p>###4 （可选）设置别名，名称为hadoop，指向bin/hadoop<br>这样就不用每次都cd到Hadoop目录，执行命令了。</p>\n<p>在 <code>~/.bashrc</code>中添加如下4行：</p>\n<pre><code>unalias hadoop &amp;&gt; /dev/null\nalias hadoop=&quot;$HOME/local/opt/hadoop-1.2.1/bin/hadoop&quot;\nunalias hls &amp;&gt; /dev/null\nalias hls=&quot;hadoop fs -ls&quot;\n</code></pre><p>source使之立刻生效，</p>\n<pre><code>$ source ~/.bashrc\n</code></pre><p>##参考资料</p>\n<ol>\n<li><a href=\"http://blog.csdn.net/j3smile/article/details/7887826\" target=\"_blank\" rel=\"external\">hadoop远程客户端安装配置、多用户权限配置</a></li>\n<li><a href=\"http://blog.csdn.net/a999wt/article/details/8718707\" target=\"_blank\" rel=\"external\">hadoop如何创建多用户</a></li>\n<li><a href=\"http://blog.sina.com.cn/s/blog_605f5b4f0101897z.html\" target=\"_blank\" rel=\"external\">关于多用户时hadoop的权限问题</a></li>\n<li><a href=\"http://langyu.iteye.com/blog/909170\" target=\"_blank\" rel=\"external\">MapReduce: Job提交过程</a></li>\n<li><a href=\"http://www.hadoopor.com/archiver/tid-481.html\" target=\"_blank\" rel=\"external\">hadoop中的dfs.name.dir,mapred.local.dir,mapred.system.dir和hadoop.tmp.dir说明</a></li>\n<li><a href=\"http://fenriswolf.me/2012/08/06/hadoop-%E5%8F%83%E6%95%B8%E8%A8%AD%E5%AE%9A-mapred-site-xml/\" target=\"_blank\" rel=\"external\">Hadoop 參數設定 – mapred-site.xml</a></li>\n</ol>\n","excerpt":"<p>假设我们以名为hadoop的用户，建好了集群，见<a href=\"http://www.yanjiuyanjiu.com/blog/20140202\">在CentOS上安装Hadoop集群</a>。通常，我们会把这个集群共享给多个用户，而不是让大家都登录为hadoop，这样做有几个好处：</p>\n<ul>\n<li>一个用户不能修改另一个用户的的文件</li>\n<li>在hadoop web管理页面，可以很方便的看到不同的用户的job</li>\n</ul>\n<p>现在集群中有一台机器，上面有一个用户名为 hbase 的用户，他想要使用hadoop集群，怎么配置呢？</p>\n<p>##1. 安装hadoop客户端</p>\n<p>###1.1 下载，解压<br>下载跟hadoop集群一样的hadoop软件包，并解压，</p>\n<pre><code>$ wget http://mirror.olnevhost.net/pub/apache/hadoop/common/stable1/hadoop-1.2.1-bin.tar.gz\n$ tar -zxf hadoop-1.2.1-bin.tar.gz -C ~/local/opt\n$ cd ~/local/opt/hadoop-1.2.1\n</code></pre><p>###1.2 配置<br>在客户端只需配置集群namenode 和 jobtracker 的相关信息, 把namenode和jobtracker的信息告诉客户端即可。</p>\n<p>把hadoop用户下的<code>conf/core-site.xml</code>和<code>conf/mapred-site.xml</code>拷贝到本用户的conf/目录下</p>\n<pre><code>$ scp hadoop@localhost:~/local/opt/hadoop-1.2.1/conf/core-site.xml ./conf/\n$ scp hadoop@localhost:~/local/opt/hadoop-1.2.1/conf/mapred-site.xml ./conf/\n</code></pre><p>修改conf/mapred-site.xml中的<code>mapred.local.dir</code>，改为本机上的某个目录，确保这个目录存在且有写入。因为这个目录是本地目录，每台机器都可以不同。例如我的是：</p>\n<pre><code>&lt;property&gt;\n  &lt;name&gt;mapred.local.dir&lt;/name&gt;\n  &lt;value&gt;/home/soulmachine/local/var/hadoop/mapred/local&lt;/value&gt;\n&lt;/property&gt;\n</code></pre><p>确保这个目录存在，</p>\n<pre><code>$ mkdir -p ~/local/var/hadoop/mapred/local\n</code></pre>","more":"<p>还有另一种方法，由于<code>mapred.local.dir</code>默认值是<code>${hadoop.tmp.dir}/mapred/local</code>，也可以通过修改<code>hadoop.tmp.dir</code>达到目的，在<code>core-site.xml</code>中，确保<code>${hadoop.tmp.dir}/mapred/local</code>存在且有写权限。</p>\n<p>##2. 在master上配置权限<br>以下操作均在hadoop集群的 namenode 这台机器上进行，且登录为hadoop，因为hadoop这个用户是整个hadoop集群权限最高的用户（但对于Linux系统本身，这个用户其实没有sudo权限）。</p>\n<p>Hadoop关于用户权限方面，有很多高级的配置，这里我们简单的利用HDFS本身的文件权限检查机制，来配置多用户。</p>\n<p>HDFS本身没有提供用户名、用户组的创建，在客户端调用hadoop 的文件操作命令时，hadoop 识别出执行命令所在进程的linux系统的用户名和用户组，然后使用这个用户名和组来检查文件权限。 用户名=linux命令中的<code>whoami</code>，而组名等于<code>groups</code>。 </p>\n<p>启动hadoop hdfs系统的用户即为超级用户（在这里就是名为hadoop的这个用户），可以进行任意的操作。</p>\n<p>在客户端机器上，用gropus命令看一下hbase所在的组，</p>\n<pre><code>$ groups\nhbase\n</code></pre><p>说明hbase这个用户所在的组为hbase。</p>\n<p>###2.1 为客户端用户创建home文件夹</p>\n<pre><code>$ hadoop fs -mkdir /user/hbase\n$ hadoop fs -chown hbase /user/hbase\n$ hadoop fs -chgrp hbase /user/hbase\n</code></pre><p>###2.2 为客户端用户创建hadoop.tmp.dir文件夹<br><code>hadoop.tmp.dir</code>既是一个本地目录，也是HDFS上的一个目录，参考<a href=\"http://stackoverflow.com/questions/2354525/what-should-be-hadoop-tmp-dir\">What should be hadoop.tmp.dir?</a>。默认是<code>/tmp/hadoop-${user.name}</code>（参考官方表格，<a href=\"http://hadoop.apache.org/docs/r1.2.1/core-default.html\">core-default</a>），所以我们需要为用户创建这个文件夹，</p>\n<pre><code>$ hadoop fs -mkdir /tmp/hadoop-hbase\n$ hadoop fs -chown hbase /tmp/hadoop-hbase\n$ hadoop fs -chgrp hbase /tmp/hadoop-hbase\n</code></pre><p>补充说明一下各个常见目录的相关知识，</p>\n<ul>\n<li><code>dfs.name.dir</code>和<code>dfs.data.dir</code>都是本地目录，它们是HDFS的基础，所以只可能是本地目录</li>\n<li><code>mapred.local.dir</code>是本地目录，当客户端向集群提交了一个任务后，该job相关的文件（jar包和配置文件）会存放在HDFS上，各个slave从HDFS把这些文件下载到本地，然后开始执行。</li>\n<li><code>mapred.system.dir</code>是一个HDFS目录，存放了一个job的控制信息，被多个slave所共享，所以只能是HDFS目录。</li>\n<li><code>mapred.temp.dir</code>是一个HDFS目录，存放着一个job的临时文件，job结束后会被自动删除。</li>\n</ul>\n<p>###2.3 设置mapreduce.jobtracker.staging.root.dir<br>客户端向集群提交任务时，需要把该job需要的文件打包，拷贝到HDFS上。在拷贝之前，得先确定这些资源文件存放在HDFS的什么地方。JobTracker设置有一个工作目录(Staging area, 也称数据中转站)，用来存储与每个job相关的数据。这个目录的前缀由<code>mapreduce.jobtracker.staging.root.dir</code> 参数来指定，默认是<code>${hadoop.tmp.dir}/mapred/staging</code>，每个client user可以提交多个job，在这个目录后就得附加user name的信息。所以这个工作目录(Staging area)默认是<code>${hadoop.tmp.dir}/mapred/staging/denny/.staging/</code>。</p>\n<p>一般把前缀设置为<code>/user</code>，这是官方推荐的，见 <a href=\"http://hadoop.apache.org/docs/r1.2.1/mapred-default.html\">mapred-default.xml</a> 里的<code>mapreduce.jobtracker.staging.root.dir</code>处：</p>\n<blockquote>\n<p>The root of the staging area for users’ job files In practice, this should be the directory where users’ home directories are located (usually /user)</p>\n</blockquote>\n<pre><code>#以hadoop用户登录jobtracker机器\n$ vim conf/mapred-site.xml\n&lt;property&gt;\n  &lt;name&gt;mapreduce.jobtracker.staging.root.dir&lt;/name&gt;\n  &lt;value&gt;/user&lt;/value&gt;\n&lt;/property&gt;\n</code></pre><p>###2.4 重启hadoop集群<br>将配置文件scp到所有机器，然后重启集群，</p>\n<pre><code>$ bin/stop-all.sh\n$ bin/start-all.sh\n</code></pre><p>##3. 测试一下<br>回到客户端机器。</p>\n<p>将输入数据拷贝到分布式文件系统中:</p>\n<pre><code>$ bin/hadoop fs -put conf input\n$ bin/hadoop fs -ls input\n</code></pre><p>运行 Hadoop 自带的例子:</p>\n<pre><code>$ bin/hadoop jar hadoop-examples-*.jar wordcount input output\n</code></pre><p>查看输出文件:</p>\n<pre><code>$ bin/hadoop fs -ls output\n$ bin/hadoop fs -cat output/part-r-00000\n</code></pre><p>如果能看到结果，说明这个例子运行成功。</p>\n<p>###4 （可选）设置别名，名称为hadoop，指向bin/hadoop<br>这样就不用每次都cd到Hadoop目录，执行命令了。</p>\n<p>在 <code>~/.bashrc</code>中添加如下4行：</p>\n<pre><code>unalias hadoop &amp;&gt; /dev/null\nalias hadoop=&quot;$HOME/local/opt/hadoop-1.2.1/bin/hadoop&quot;\nunalias hls &amp;&gt; /dev/null\nalias hls=&quot;hadoop fs -ls&quot;\n</code></pre><p>source使之立刻生效，</p>\n<pre><code>$ source ~/.bashrc\n</code></pre><p>##参考资料</p>\n<ol>\n<li><a href=\"http://blog.csdn.net/j3smile/article/details/7887826\">hadoop远程客户端安装配置、多用户权限配置</a></li>\n<li><a href=\"http://blog.csdn.net/a999wt/article/details/8718707\">hadoop如何创建多用户</a></li>\n<li><a href=\"http://blog.sina.com.cn/s/blog_605f5b4f0101897z.html\">关于多用户时hadoop的权限问题</a></li>\n<li><a href=\"http://langyu.iteye.com/blog/909170\">MapReduce: Job提交过程</a></li>\n<li><a href=\"http://www.hadoopor.com/archiver/tid-481.html\">hadoop中的dfs.name.dir,mapred.local.dir,mapred.system.dir和hadoop.tmp.dir说明</a></li>\n<li><a href=\"http://fenriswolf.me/2012/08/06/hadoop-%E5%8F%83%E6%95%B8%E8%A8%AD%E5%AE%9A-mapred-site-xml/\">Hadoop 參數設定 – mapred-site.xml</a></li>\n</ol>"},{"layout":"post","title":"把Nutch爬虫部署到Hadoop集群上","date":"2014-02-04T22:36:00.000Z","comments":1,"_content":"\n软件版本：Nutch 1.7, Hadoop 1.2.1, CentOS 6.5, JDK 1.7\n\n前面的3篇文章中，[Nutch 快速入门(Nutch 1.7)](http://www.yanjiuyanjiu.com/blog/20140121)，[Nutch 快速入门(Nutch 2.2.1)](http://www.yanjiuyanjiu.com/blog/20140201)，[在Eclipse里运行Nutch](http://www.yanjiuyanjiu.com/blog/20140120)，Nutch都是跑在单机上，本文把Nutch部署到Hadoop集群上，在真正的分布式Hadoop集群上跑。\n\n\n##前提\n\n* 学会了搭建一个分布式Hadoop集群，见[在CentOS上安装Hadoop集群](http://www.yanjiuyanjiu.com/blog/20140202)\n* 学会了单机跑Nutch，见[Nutch 快速入门(Nutch 1.7)](http://www.yanjiuyanjiu.com/blog/20140121)\n\n##1 启动Hadoop集群\n伪分布式或真分布式的Hadoop集群都可以，无所谓。\n\n选择一台配置好了的Hadoop客户端的机器（见[Hadoop多用户的配置](http://www.yanjiuyanjiu.com/blog/20140203)），作为客户机，以下操作均在这台客户机上进行。\n\n##2 下载Nutch源码\n有两种方法，\n\n1. 去官网首页下载apache-nutch-1.7-src.tar.gz\n1. 用svn checkout\n\n        $ svn co https://svn.apache.org/repos/asf/nutch/tags/release-1.7\n\n##3 把Hadoop的6个配置文件拷贝到Nutch的conf/目录\n将Hadoop的六个配置文件，拷贝到Nutch的conf/目录，相当于把Hadoop集群的配置信息告诉Nutch，\n\n<!-- more -->\n\n在伪分布式模式下，\n\n    $ cd ~/local/opt/hadoop-1.2.1/conf\n    $ cp hadoop-env.sh core-site.xml hdfs-site.xml mapred-site.xml masters slaves /home/soulmachine/local/src/apache-nutch-1.7/conf\n\n在分布式模式下，\n\n    $ ssh hadoop@localhost\n    $ cd ~/local/opt/hadoop-1.2.1/conf\n    $ scp hadoop-env.sh core-site.xml hdfs-site.xml mapred-site.xml masters slaves soulmachine@localhost:~/local/src/apache-nutch-1.7/conf\n    $ exit\n\n\n##4 修改Nutch的配置文件\n修改 conf/nutch-site.xml:\n\n    <property>\n      <name>http.agent.name</name>\n      <value>My Nutch Spider</value>\n    </property>\n\n修改 `regex-urlfilter.txt`, 见[Nutch 快速入门(Nutch 1.7)](http://www.yanjiuyanjiu.com/blog/20140121/) 第4节，\n\n    #注释掉这一行\n    # skip URLs containing certain characters as probable queries, etc.\n    #-[?*!@=]\n    # accept anything else\n    #注释掉这行\n    #+.\n    +^http:\\/\\/movie\\.douban\\.com\\/subject\\/[0-9]+\\/(\\?.+)?$\n\n##5 重新编译Nutch\n每次修改了`$NUTCH_HOME/conf`下的的文件，都需要重新编译Nutch，重新打包生成一个nutch-x.x.x.job文件，见这里，[Running Nutch in (pseudo) distributed-mode](http://wiki.apache.org/nutch/NutchHadoopSingleNodeTutorial)。也可以打开build.xml看看里面的\"runtime\"这个task干了什么，就明白了。\n\n    $ ant runtime\n\n这会在`runtime/deploy`下生成一个Job文件，`apache-nutch-1.7.job`，它本质上是一个zip压缩包，可以打开看一下它里面的内容。可以看到它包含了很多编译好的class文件，以及从conf/目录下的拷贝出来的xml配置文件。\n\n##6 向Hadoop集群提交Job，进行抓取\n\n首先，要在con/hadoop-env.sh 添加`HADOOP_CLASSPATH`，让Hadoop知道去哪里找Nutch所依赖的jar包，\n\n    export HADOOP_CLASSPATH=/home/soulmachine/local/opt/apache-nutch-1.7/runtime/local/lib/*.jar\n\n上传种子URL列表，\n\n    $ hadoop fs -put ~/urls urls\n    $ hadoop fs -lsr urls\n\n提交Job,\n\n    $ hadoop jar ./runtime/deploy/apache-nutch-1.7.job org.apache.nutch.crawl.Crawl urls -dir TestCrawl -depth 1 -topN 5\n\n可以打开web页面监控job的进度，\n\n* Jobtracer: <http://master:50030>\n* Namenode: <http://master:50070>\n\n把Nutch运行在伪分布式Hadoop集群上，比Standalone模式要好，因为可以通过web页面监控job。\n\n查看结果\n\n    $ hadoop fs -ls TestCrawl\n\n    Found 3 items\n    drwxr-xr-x   - soulmachine supergroup          0 2014-02-04 02:17 /user/soulmachine/TestCrawl/crawldb\n    drwxr-xr-x   - soulmachine supergroup          0 2014-02-04 02:18 /user/soulmachine/TestCrawl/linkdb\n    drwxr-xr-x   - soulmachine supergroup          0 2014-02-04 02:16 /user/soulmachine/TestCrawl/segments\n\n##7 注意\n如果出现`java.io.IOException: No valid local directories in property: mapred.local.dir`的错误，说明你的客户机的mapred-site.xml是从hadoop集群拷贝过来的，没有修改过，`mapred.local.dir`是一个本地目录，集群上的机器有这个目录，但是你的本机上没有，所以出现了这个错误。解决办法是，在本地新建一个目录，然后把`mapred.local.dir`设置为这个路径。\n\n如果出现`org.apache.hadoop.security.AccessControlException: Permission denied: user=soulmachine, access=WRITE, inode=\"tmp\"`的错误，多半是因为你没有给这个用户创建`hadoop.tmp.dir`文件夹，见[Hadoop多用户的配置](http://www.yanjiuyanjiu.com/blog/20140203)第2.2节。\n\n##8 把Nutch 1.7 爬虫部署到Hadoop 2.x集群上\n事实证明是完全可行的，Hadoop 2.x 向后兼容。\n\n把hadoop 2.x的配置文件，全部拷贝到 nutch 的conf目录下\n\n    cp ~/local/opt/hadoop-2.2.0/etc/hadoop* ~/local/src/apache-nutch-1.7/conf\n\n然后编译，\n\n    ant runtime\n\n把种子列表上传到hdfs,\n\n    $ hdfs dfs -put ~/urls urls\n    $ hdfs dfs -lsr urls\n\n提交Job,\n\n    $ hadoop jar ./runtime/deploy/apache-nutch-1.7.job org.apache.nutch.crawl.Crawl urls -dir TestCrawl -depth 2\n\n查看结果，\n\n    $ cd runtime/deploy\n    $ ./bin/readdb hdfs://localhost/user/soulmachine/TestCrawl/crawldb/ -stats\n    14/02/14 16:51:07 INFO crawl.CrawlDbReader: Statistics for CrawlDb: hdfs://localhost/user/soulmachine/TestCrawl/crawldb/\n    14/02/14 16:51:07 INFO crawl.CrawlDbReader: TOTAL urls:\t70\n    14/02/14 16:51:07 INFO crawl.CrawlDbReader: retry 0:\t70\n    14/02/14 16:51:07 INFO crawl.CrawlDbReader: min score:\t0.006\n    14/02/14 16:51:07 INFO crawl.CrawlDbReader: avg score:\t0.03972857\n    14/02/14 16:51:07 INFO crawl.CrawlDbReader: max score:\t1.2\n    14/02/14 16:51:07 INFO crawl.CrawlDbReader: status 1 (db_unfetched):\t59\n    14/02/14 16:51:07 INFO crawl.CrawlDbReader: status 2 (db_fetched):\t11\n    14/02/14 16:51:07 INFO crawl.CrawlDbReader: CrawlDb statistics: done\n\n\n##参考资料\n1. [Web Crawling and Data Mining with Apache Nutch 的第3.2节](http://packtlib.packtpub.com/library/web-crawling-and-data-mining-with-apache-nutch/ch03lvl1sec20)\n1. [Install Nutch 1.7 and Hadoop 1.2.0](http://nutchhadoop.blogspot.com/)\n\n1. [hadoop mapred(hive)执行目录 文件权限问题](http://blog.csdn.net/azhao_dn/article/details/6921398)\n\n\n##废弃的资料\n1. [Nutch and Hadoop Tutorial](http://wiki.apache.org/nutch/NutchHadoopTutorial)，讲的是Nutch 1.3的，太老了，完全不适用Nutch 1.7\n\n1. [Running Nutch in (pseudo) distributed-mode](http://wiki.apache.org/nutch/NutchHadoopSingleNodeTutorial)，太短了，没什么内容\n","source":"_posts/2014-02-04-running-nutch-on-hadoop-cluster.md","raw":"---\nlayout: post\ntitle: \"把Nutch爬虫部署到Hadoop集群上\"\ndate: 2014-02-04 22:36\ncomments: true\ncategories: Search-Engine\n---\n\n软件版本：Nutch 1.7, Hadoop 1.2.1, CentOS 6.5, JDK 1.7\n\n前面的3篇文章中，[Nutch 快速入门(Nutch 1.7)](http://www.yanjiuyanjiu.com/blog/20140121)，[Nutch 快速入门(Nutch 2.2.1)](http://www.yanjiuyanjiu.com/blog/20140201)，[在Eclipse里运行Nutch](http://www.yanjiuyanjiu.com/blog/20140120)，Nutch都是跑在单机上，本文把Nutch部署到Hadoop集群上，在真正的分布式Hadoop集群上跑。\n\n\n##前提\n\n* 学会了搭建一个分布式Hadoop集群，见[在CentOS上安装Hadoop集群](http://www.yanjiuyanjiu.com/blog/20140202)\n* 学会了单机跑Nutch，见[Nutch 快速入门(Nutch 1.7)](http://www.yanjiuyanjiu.com/blog/20140121)\n\n##1 启动Hadoop集群\n伪分布式或真分布式的Hadoop集群都可以，无所谓。\n\n选择一台配置好了的Hadoop客户端的机器（见[Hadoop多用户的配置](http://www.yanjiuyanjiu.com/blog/20140203)），作为客户机，以下操作均在这台客户机上进行。\n\n##2 下载Nutch源码\n有两种方法，\n\n1. 去官网首页下载apache-nutch-1.7-src.tar.gz\n1. 用svn checkout\n\n        $ svn co https://svn.apache.org/repos/asf/nutch/tags/release-1.7\n\n##3 把Hadoop的6个配置文件拷贝到Nutch的conf/目录\n将Hadoop的六个配置文件，拷贝到Nutch的conf/目录，相当于把Hadoop集群的配置信息告诉Nutch，\n\n<!-- more -->\n\n在伪分布式模式下，\n\n    $ cd ~/local/opt/hadoop-1.2.1/conf\n    $ cp hadoop-env.sh core-site.xml hdfs-site.xml mapred-site.xml masters slaves /home/soulmachine/local/src/apache-nutch-1.7/conf\n\n在分布式模式下，\n\n    $ ssh hadoop@localhost\n    $ cd ~/local/opt/hadoop-1.2.1/conf\n    $ scp hadoop-env.sh core-site.xml hdfs-site.xml mapred-site.xml masters slaves soulmachine@localhost:~/local/src/apache-nutch-1.7/conf\n    $ exit\n\n\n##4 修改Nutch的配置文件\n修改 conf/nutch-site.xml:\n\n    <property>\n      <name>http.agent.name</name>\n      <value>My Nutch Spider</value>\n    </property>\n\n修改 `regex-urlfilter.txt`, 见[Nutch 快速入门(Nutch 1.7)](http://www.yanjiuyanjiu.com/blog/20140121/) 第4节，\n\n    #注释掉这一行\n    # skip URLs containing certain characters as probable queries, etc.\n    #-[?*!@=]\n    # accept anything else\n    #注释掉这行\n    #+.\n    +^http:\\/\\/movie\\.douban\\.com\\/subject\\/[0-9]+\\/(\\?.+)?$\n\n##5 重新编译Nutch\n每次修改了`$NUTCH_HOME/conf`下的的文件，都需要重新编译Nutch，重新打包生成一个nutch-x.x.x.job文件，见这里，[Running Nutch in (pseudo) distributed-mode](http://wiki.apache.org/nutch/NutchHadoopSingleNodeTutorial)。也可以打开build.xml看看里面的\"runtime\"这个task干了什么，就明白了。\n\n    $ ant runtime\n\n这会在`runtime/deploy`下生成一个Job文件，`apache-nutch-1.7.job`，它本质上是一个zip压缩包，可以打开看一下它里面的内容。可以看到它包含了很多编译好的class文件，以及从conf/目录下的拷贝出来的xml配置文件。\n\n##6 向Hadoop集群提交Job，进行抓取\n\n首先，要在con/hadoop-env.sh 添加`HADOOP_CLASSPATH`，让Hadoop知道去哪里找Nutch所依赖的jar包，\n\n    export HADOOP_CLASSPATH=/home/soulmachine/local/opt/apache-nutch-1.7/runtime/local/lib/*.jar\n\n上传种子URL列表，\n\n    $ hadoop fs -put ~/urls urls\n    $ hadoop fs -lsr urls\n\n提交Job,\n\n    $ hadoop jar ./runtime/deploy/apache-nutch-1.7.job org.apache.nutch.crawl.Crawl urls -dir TestCrawl -depth 1 -topN 5\n\n可以打开web页面监控job的进度，\n\n* Jobtracer: <http://master:50030>\n* Namenode: <http://master:50070>\n\n把Nutch运行在伪分布式Hadoop集群上，比Standalone模式要好，因为可以通过web页面监控job。\n\n查看结果\n\n    $ hadoop fs -ls TestCrawl\n\n    Found 3 items\n    drwxr-xr-x   - soulmachine supergroup          0 2014-02-04 02:17 /user/soulmachine/TestCrawl/crawldb\n    drwxr-xr-x   - soulmachine supergroup          0 2014-02-04 02:18 /user/soulmachine/TestCrawl/linkdb\n    drwxr-xr-x   - soulmachine supergroup          0 2014-02-04 02:16 /user/soulmachine/TestCrawl/segments\n\n##7 注意\n如果出现`java.io.IOException: No valid local directories in property: mapred.local.dir`的错误，说明你的客户机的mapred-site.xml是从hadoop集群拷贝过来的，没有修改过，`mapred.local.dir`是一个本地目录，集群上的机器有这个目录，但是你的本机上没有，所以出现了这个错误。解决办法是，在本地新建一个目录，然后把`mapred.local.dir`设置为这个路径。\n\n如果出现`org.apache.hadoop.security.AccessControlException: Permission denied: user=soulmachine, access=WRITE, inode=\"tmp\"`的错误，多半是因为你没有给这个用户创建`hadoop.tmp.dir`文件夹，见[Hadoop多用户的配置](http://www.yanjiuyanjiu.com/blog/20140203)第2.2节。\n\n##8 把Nutch 1.7 爬虫部署到Hadoop 2.x集群上\n事实证明是完全可行的，Hadoop 2.x 向后兼容。\n\n把hadoop 2.x的配置文件，全部拷贝到 nutch 的conf目录下\n\n    cp ~/local/opt/hadoop-2.2.0/etc/hadoop* ~/local/src/apache-nutch-1.7/conf\n\n然后编译，\n\n    ant runtime\n\n把种子列表上传到hdfs,\n\n    $ hdfs dfs -put ~/urls urls\n    $ hdfs dfs -lsr urls\n\n提交Job,\n\n    $ hadoop jar ./runtime/deploy/apache-nutch-1.7.job org.apache.nutch.crawl.Crawl urls -dir TestCrawl -depth 2\n\n查看结果，\n\n    $ cd runtime/deploy\n    $ ./bin/readdb hdfs://localhost/user/soulmachine/TestCrawl/crawldb/ -stats\n    14/02/14 16:51:07 INFO crawl.CrawlDbReader: Statistics for CrawlDb: hdfs://localhost/user/soulmachine/TestCrawl/crawldb/\n    14/02/14 16:51:07 INFO crawl.CrawlDbReader: TOTAL urls:\t70\n    14/02/14 16:51:07 INFO crawl.CrawlDbReader: retry 0:\t70\n    14/02/14 16:51:07 INFO crawl.CrawlDbReader: min score:\t0.006\n    14/02/14 16:51:07 INFO crawl.CrawlDbReader: avg score:\t0.03972857\n    14/02/14 16:51:07 INFO crawl.CrawlDbReader: max score:\t1.2\n    14/02/14 16:51:07 INFO crawl.CrawlDbReader: status 1 (db_unfetched):\t59\n    14/02/14 16:51:07 INFO crawl.CrawlDbReader: status 2 (db_fetched):\t11\n    14/02/14 16:51:07 INFO crawl.CrawlDbReader: CrawlDb statistics: done\n\n\n##参考资料\n1. [Web Crawling and Data Mining with Apache Nutch 的第3.2节](http://packtlib.packtpub.com/library/web-crawling-and-data-mining-with-apache-nutch/ch03lvl1sec20)\n1. [Install Nutch 1.7 and Hadoop 1.2.0](http://nutchhadoop.blogspot.com/)\n\n1. [hadoop mapred(hive)执行目录 文件权限问题](http://blog.csdn.net/azhao_dn/article/details/6921398)\n\n\n##废弃的资料\n1. [Nutch and Hadoop Tutorial](http://wiki.apache.org/nutch/NutchHadoopTutorial)，讲的是Nutch 1.3的，太老了，完全不适用Nutch 1.7\n\n1. [Running Nutch in (pseudo) distributed-mode](http://wiki.apache.org/nutch/NutchHadoopSingleNodeTutorial)，太短了，没什么内容\n","slug":"2014-02-04-running-nutch-on-hadoop-cluster","published":1,"updated":"2016-08-18T09:21:04.000Z","photos":[],"link":"","_id":"cis07pf4e003601pqvr6qu9sk","content":"<p>软件版本：Nutch 1.7, Hadoop 1.2.1, CentOS 6.5, JDK 1.7</p>\n<p>前面的3篇文章中，<a href=\"http://www.yanjiuyanjiu.com/blog/20140121\" target=\"_blank\" rel=\"external\">Nutch 快速入门(Nutch 1.7)</a>，<a href=\"http://www.yanjiuyanjiu.com/blog/20140201\" target=\"_blank\" rel=\"external\">Nutch 快速入门(Nutch 2.2.1)</a>，<a href=\"http://www.yanjiuyanjiu.com/blog/20140120\" target=\"_blank\" rel=\"external\">在Eclipse里运行Nutch</a>，Nutch都是跑在单机上，本文把Nutch部署到Hadoop集群上，在真正的分布式Hadoop集群上跑。</p>\n<p>##前提</p>\n<ul>\n<li>学会了搭建一个分布式Hadoop集群，见<a href=\"http://www.yanjiuyanjiu.com/blog/20140202\" target=\"_blank\" rel=\"external\">在CentOS上安装Hadoop集群</a></li>\n<li>学会了单机跑Nutch，见<a href=\"http://www.yanjiuyanjiu.com/blog/20140121\" target=\"_blank\" rel=\"external\">Nutch 快速入门(Nutch 1.7)</a></li>\n</ul>\n<p>##1 启动Hadoop集群<br>伪分布式或真分布式的Hadoop集群都可以，无所谓。</p>\n<p>选择一台配置好了的Hadoop客户端的机器（见<a href=\"http://www.yanjiuyanjiu.com/blog/20140203\" target=\"_blank\" rel=\"external\">Hadoop多用户的配置</a>），作为客户机，以下操作均在这台客户机上进行。</p>\n<p>##2 下载Nutch源码<br>有两种方法，</p>\n<ol>\n<li>去官网首页下载apache-nutch-1.7-src.tar.gz</li>\n<li><p>用svn checkout</p>\n<pre><code>$ svn co https://svn.apache.org/repos/asf/nutch/tags/release-1.7\n</code></pre></li>\n</ol>\n<p>##3 把Hadoop的6个配置文件拷贝到Nutch的conf/目录<br>将Hadoop的六个配置文件，拷贝到Nutch的conf/目录，相当于把Hadoop集群的配置信息告诉Nutch，</p>\n<a id=\"more\"></a>\n<p>在伪分布式模式下，</p>\n<pre><code>$ cd ~/local/opt/hadoop-1.2.1/conf\n$ cp hadoop-env.sh core-site.xml hdfs-site.xml mapred-site.xml masters slaves /home/soulmachine/local/src/apache-nutch-1.7/conf\n</code></pre><p>在分布式模式下，</p>\n<pre><code>$ ssh hadoop@localhost\n$ cd ~/local/opt/hadoop-1.2.1/conf\n$ scp hadoop-env.sh core-site.xml hdfs-site.xml mapred-site.xml masters slaves soulmachine@localhost:~/local/src/apache-nutch-1.7/conf\n$ exit\n</code></pre><p>##4 修改Nutch的配置文件<br>修改 conf/nutch-site.xml:</p>\n<pre><code>&lt;property&gt;\n  &lt;name&gt;http.agent.name&lt;/name&gt;\n  &lt;value&gt;My Nutch Spider&lt;/value&gt;\n&lt;/property&gt;\n</code></pre><p>修改 <code>regex-urlfilter.txt</code>, 见<a href=\"http://www.yanjiuyanjiu.com/blog/20140121/\" target=\"_blank\" rel=\"external\">Nutch 快速入门(Nutch 1.7)</a> 第4节，</p>\n<pre><code>#注释掉这一行\n# skip URLs containing certain characters as probable queries, etc.\n#-[?*!@=]\n# accept anything else\n#注释掉这行\n#+.\n+^http:\\/\\/movie\\.douban\\.com\\/subject\\/[0-9]+\\/(\\?.+)?$\n</code></pre><p>##5 重新编译Nutch<br>每次修改了<code>$NUTCH_HOME/conf</code>下的的文件，都需要重新编译Nutch，重新打包生成一个nutch-x.x.x.job文件，见这里，<a href=\"http://wiki.apache.org/nutch/NutchHadoopSingleNodeTutorial\" target=\"_blank\" rel=\"external\">Running Nutch in (pseudo) distributed-mode</a>。也可以打开build.xml看看里面的”runtime”这个task干了什么，就明白了。</p>\n<pre><code>$ ant runtime\n</code></pre><p>这会在<code>runtime/deploy</code>下生成一个Job文件，<code>apache-nutch-1.7.job</code>，它本质上是一个zip压缩包，可以打开看一下它里面的内容。可以看到它包含了很多编译好的class文件，以及从conf/目录下的拷贝出来的xml配置文件。</p>\n<p>##6 向Hadoop集群提交Job，进行抓取</p>\n<p>首先，要在con/hadoop-env.sh 添加<code>HADOOP_CLASSPATH</code>，让Hadoop知道去哪里找Nutch所依赖的jar包，</p>\n<pre><code>export HADOOP_CLASSPATH=/home/soulmachine/local/opt/apache-nutch-1.7/runtime/local/lib/*.jar\n</code></pre><p>上传种子URL列表，</p>\n<pre><code>$ hadoop fs -put ~/urls urls\n$ hadoop fs -lsr urls\n</code></pre><p>提交Job,</p>\n<pre><code>$ hadoop jar ./runtime/deploy/apache-nutch-1.7.job org.apache.nutch.crawl.Crawl urls -dir TestCrawl -depth 1 -topN 5\n</code></pre><p>可以打开web页面监控job的进度，</p>\n<ul>\n<li>Jobtracer: <a href=\"http://master:50030\" target=\"_blank\" rel=\"external\">http://master:50030</a></li>\n<li>Namenode: <a href=\"http://master:50070\" target=\"_blank\" rel=\"external\">http://master:50070</a></li>\n</ul>\n<p>把Nutch运行在伪分布式Hadoop集群上，比Standalone模式要好，因为可以通过web页面监控job。</p>\n<p>查看结果</p>\n<pre><code>$ hadoop fs -ls TestCrawl\n\nFound 3 items\ndrwxr-xr-x   - soulmachine supergroup          0 2014-02-04 02:17 /user/soulmachine/TestCrawl/crawldb\ndrwxr-xr-x   - soulmachine supergroup          0 2014-02-04 02:18 /user/soulmachine/TestCrawl/linkdb\ndrwxr-xr-x   - soulmachine supergroup          0 2014-02-04 02:16 /user/soulmachine/TestCrawl/segments\n</code></pre><p>##7 注意<br>如果出现<code>java.io.IOException: No valid local directories in property: mapred.local.dir</code>的错误，说明你的客户机的mapred-site.xml是从hadoop集群拷贝过来的，没有修改过，<code>mapred.local.dir</code>是一个本地目录，集群上的机器有这个目录，但是你的本机上没有，所以出现了这个错误。解决办法是，在本地新建一个目录，然后把<code>mapred.local.dir</code>设置为这个路径。</p>\n<p>如果出现<code>org.apache.hadoop.security.AccessControlException: Permission denied: user=soulmachine, access=WRITE, inode=&quot;tmp&quot;</code>的错误，多半是因为你没有给这个用户创建<code>hadoop.tmp.dir</code>文件夹，见<a href=\"http://www.yanjiuyanjiu.com/blog/20140203\" target=\"_blank\" rel=\"external\">Hadoop多用户的配置</a>第2.2节。</p>\n<p>##8 把Nutch 1.7 爬虫部署到Hadoop 2.x集群上<br>事实证明是完全可行的，Hadoop 2.x 向后兼容。</p>\n<p>把hadoop 2.x的配置文件，全部拷贝到 nutch 的conf目录下</p>\n<pre><code>cp ~/local/opt/hadoop-2.2.0/etc/hadoop* ~/local/src/apache-nutch-1.7/conf\n</code></pre><p>然后编译，</p>\n<pre><code>ant runtime\n</code></pre><p>把种子列表上传到hdfs,</p>\n<pre><code>$ hdfs dfs -put ~/urls urls\n$ hdfs dfs -lsr urls\n</code></pre><p>提交Job,</p>\n<pre><code>$ hadoop jar ./runtime/deploy/apache-nutch-1.7.job org.apache.nutch.crawl.Crawl urls -dir TestCrawl -depth 2\n</code></pre><p>查看结果，</p>\n<pre><code>$ cd runtime/deploy\n$ ./bin/readdb hdfs://localhost/user/soulmachine/TestCrawl/crawldb/ -stats\n14/02/14 16:51:07 INFO crawl.CrawlDbReader: Statistics for CrawlDb: hdfs://localhost/user/soulmachine/TestCrawl/crawldb/\n14/02/14 16:51:07 INFO crawl.CrawlDbReader: TOTAL urls:    70\n14/02/14 16:51:07 INFO crawl.CrawlDbReader: retry 0:    70\n14/02/14 16:51:07 INFO crawl.CrawlDbReader: min score:    0.006\n14/02/14 16:51:07 INFO crawl.CrawlDbReader: avg score:    0.03972857\n14/02/14 16:51:07 INFO crawl.CrawlDbReader: max score:    1.2\n14/02/14 16:51:07 INFO crawl.CrawlDbReader: status 1 (db_unfetched):    59\n14/02/14 16:51:07 INFO crawl.CrawlDbReader: status 2 (db_fetched):    11\n14/02/14 16:51:07 INFO crawl.CrawlDbReader: CrawlDb statistics: done\n</code></pre><p>##参考资料</p>\n<ol>\n<li><a href=\"http://packtlib.packtpub.com/library/web-crawling-and-data-mining-with-apache-nutch/ch03lvl1sec20\" target=\"_blank\" rel=\"external\">Web Crawling and Data Mining with Apache Nutch 的第3.2节</a></li>\n<li><p><a href=\"http://nutchhadoop.blogspot.com/\" target=\"_blank\" rel=\"external\">Install Nutch 1.7 and Hadoop 1.2.0</a></p>\n</li>\n<li><p><a href=\"http://blog.csdn.net/azhao_dn/article/details/6921398\" target=\"_blank\" rel=\"external\">hadoop mapred(hive)执行目录 文件权限问题</a></p>\n</li>\n</ol>\n<p>##废弃的资料</p>\n<ol>\n<li><p><a href=\"http://wiki.apache.org/nutch/NutchHadoopTutorial\" target=\"_blank\" rel=\"external\">Nutch and Hadoop Tutorial</a>，讲的是Nutch 1.3的，太老了，完全不适用Nutch 1.7</p>\n</li>\n<li><p><a href=\"http://wiki.apache.org/nutch/NutchHadoopSingleNodeTutorial\" target=\"_blank\" rel=\"external\">Running Nutch in (pseudo) distributed-mode</a>，太短了，没什么内容</p>\n</li>\n</ol>\n","excerpt":"<p>软件版本：Nutch 1.7, Hadoop 1.2.1, CentOS 6.5, JDK 1.7</p>\n<p>前面的3篇文章中，<a href=\"http://www.yanjiuyanjiu.com/blog/20140121\">Nutch 快速入门(Nutch 1.7)</a>，<a href=\"http://www.yanjiuyanjiu.com/blog/20140201\">Nutch 快速入门(Nutch 2.2.1)</a>，<a href=\"http://www.yanjiuyanjiu.com/blog/20140120\">在Eclipse里运行Nutch</a>，Nutch都是跑在单机上，本文把Nutch部署到Hadoop集群上，在真正的分布式Hadoop集群上跑。</p>\n<p>##前提</p>\n<ul>\n<li>学会了搭建一个分布式Hadoop集群，见<a href=\"http://www.yanjiuyanjiu.com/blog/20140202\">在CentOS上安装Hadoop集群</a></li>\n<li>学会了单机跑Nutch，见<a href=\"http://www.yanjiuyanjiu.com/blog/20140121\">Nutch 快速入门(Nutch 1.7)</a></li>\n</ul>\n<p>##1 启动Hadoop集群<br>伪分布式或真分布式的Hadoop集群都可以，无所谓。</p>\n<p>选择一台配置好了的Hadoop客户端的机器（见<a href=\"http://www.yanjiuyanjiu.com/blog/20140203\">Hadoop多用户的配置</a>），作为客户机，以下操作均在这台客户机上进行。</p>\n<p>##2 下载Nutch源码<br>有两种方法，</p>\n<ol>\n<li>去官网首页下载apache-nutch-1.7-src.tar.gz</li>\n<li><p>用svn checkout</p>\n<pre><code>$ svn co https://svn.apache.org/repos/asf/nutch/tags/release-1.7\n</code></pre></li>\n</ol>\n<p>##3 把Hadoop的6个配置文件拷贝到Nutch的conf/目录<br>将Hadoop的六个配置文件，拷贝到Nutch的conf/目录，相当于把Hadoop集群的配置信息告诉Nutch，</p>","more":"<p>在伪分布式模式下，</p>\n<pre><code>$ cd ~/local/opt/hadoop-1.2.1/conf\n$ cp hadoop-env.sh core-site.xml hdfs-site.xml mapred-site.xml masters slaves /home/soulmachine/local/src/apache-nutch-1.7/conf\n</code></pre><p>在分布式模式下，</p>\n<pre><code>$ ssh hadoop@localhost\n$ cd ~/local/opt/hadoop-1.2.1/conf\n$ scp hadoop-env.sh core-site.xml hdfs-site.xml mapred-site.xml masters slaves soulmachine@localhost:~/local/src/apache-nutch-1.7/conf\n$ exit\n</code></pre><p>##4 修改Nutch的配置文件<br>修改 conf/nutch-site.xml:</p>\n<pre><code>&lt;property&gt;\n  &lt;name&gt;http.agent.name&lt;/name&gt;\n  &lt;value&gt;My Nutch Spider&lt;/value&gt;\n&lt;/property&gt;\n</code></pre><p>修改 <code>regex-urlfilter.txt</code>, 见<a href=\"http://www.yanjiuyanjiu.com/blog/20140121/\">Nutch 快速入门(Nutch 1.7)</a> 第4节，</p>\n<pre><code>#注释掉这一行\n# skip URLs containing certain characters as probable queries, etc.\n#-[?*!@=]\n# accept anything else\n#注释掉这行\n#+.\n+^http:\\/\\/movie\\.douban\\.com\\/subject\\/[0-9]+\\/(\\?.+)?$\n</code></pre><p>##5 重新编译Nutch<br>每次修改了<code>$NUTCH_HOME/conf</code>下的的文件，都需要重新编译Nutch，重新打包生成一个nutch-x.x.x.job文件，见这里，<a href=\"http://wiki.apache.org/nutch/NutchHadoopSingleNodeTutorial\">Running Nutch in (pseudo) distributed-mode</a>。也可以打开build.xml看看里面的”runtime”这个task干了什么，就明白了。</p>\n<pre><code>$ ant runtime\n</code></pre><p>这会在<code>runtime/deploy</code>下生成一个Job文件，<code>apache-nutch-1.7.job</code>，它本质上是一个zip压缩包，可以打开看一下它里面的内容。可以看到它包含了很多编译好的class文件，以及从conf/目录下的拷贝出来的xml配置文件。</p>\n<p>##6 向Hadoop集群提交Job，进行抓取</p>\n<p>首先，要在con/hadoop-env.sh 添加<code>HADOOP_CLASSPATH</code>，让Hadoop知道去哪里找Nutch所依赖的jar包，</p>\n<pre><code>export HADOOP_CLASSPATH=/home/soulmachine/local/opt/apache-nutch-1.7/runtime/local/lib/*.jar\n</code></pre><p>上传种子URL列表，</p>\n<pre><code>$ hadoop fs -put ~/urls urls\n$ hadoop fs -lsr urls\n</code></pre><p>提交Job,</p>\n<pre><code>$ hadoop jar ./runtime/deploy/apache-nutch-1.7.job org.apache.nutch.crawl.Crawl urls -dir TestCrawl -depth 1 -topN 5\n</code></pre><p>可以打开web页面监控job的进度，</p>\n<ul>\n<li>Jobtracer: <a href=\"http://master:50030\">http://master:50030</a></li>\n<li>Namenode: <a href=\"http://master:50070\">http://master:50070</a></li>\n</ul>\n<p>把Nutch运行在伪分布式Hadoop集群上，比Standalone模式要好，因为可以通过web页面监控job。</p>\n<p>查看结果</p>\n<pre><code>$ hadoop fs -ls TestCrawl\n\nFound 3 items\ndrwxr-xr-x   - soulmachine supergroup          0 2014-02-04 02:17 /user/soulmachine/TestCrawl/crawldb\ndrwxr-xr-x   - soulmachine supergroup          0 2014-02-04 02:18 /user/soulmachine/TestCrawl/linkdb\ndrwxr-xr-x   - soulmachine supergroup          0 2014-02-04 02:16 /user/soulmachine/TestCrawl/segments\n</code></pre><p>##7 注意<br>如果出现<code>java.io.IOException: No valid local directories in property: mapred.local.dir</code>的错误，说明你的客户机的mapred-site.xml是从hadoop集群拷贝过来的，没有修改过，<code>mapred.local.dir</code>是一个本地目录，集群上的机器有这个目录，但是你的本机上没有，所以出现了这个错误。解决办法是，在本地新建一个目录，然后把<code>mapred.local.dir</code>设置为这个路径。</p>\n<p>如果出现<code>org.apache.hadoop.security.AccessControlException: Permission denied: user=soulmachine, access=WRITE, inode=&quot;tmp&quot;</code>的错误，多半是因为你没有给这个用户创建<code>hadoop.tmp.dir</code>文件夹，见<a href=\"http://www.yanjiuyanjiu.com/blog/20140203\">Hadoop多用户的配置</a>第2.2节。</p>\n<p>##8 把Nutch 1.7 爬虫部署到Hadoop 2.x集群上<br>事实证明是完全可行的，Hadoop 2.x 向后兼容。</p>\n<p>把hadoop 2.x的配置文件，全部拷贝到 nutch 的conf目录下</p>\n<pre><code>cp ~/local/opt/hadoop-2.2.0/etc/hadoop* ~/local/src/apache-nutch-1.7/conf\n</code></pre><p>然后编译，</p>\n<pre><code>ant runtime\n</code></pre><p>把种子列表上传到hdfs,</p>\n<pre><code>$ hdfs dfs -put ~/urls urls\n$ hdfs dfs -lsr urls\n</code></pre><p>提交Job,</p>\n<pre><code>$ hadoop jar ./runtime/deploy/apache-nutch-1.7.job org.apache.nutch.crawl.Crawl urls -dir TestCrawl -depth 2\n</code></pre><p>查看结果，</p>\n<pre><code>$ cd runtime/deploy\n$ ./bin/readdb hdfs://localhost/user/soulmachine/TestCrawl/crawldb/ -stats\n14/02/14 16:51:07 INFO crawl.CrawlDbReader: Statistics for CrawlDb: hdfs://localhost/user/soulmachine/TestCrawl/crawldb/\n14/02/14 16:51:07 INFO crawl.CrawlDbReader: TOTAL urls:    70\n14/02/14 16:51:07 INFO crawl.CrawlDbReader: retry 0:    70\n14/02/14 16:51:07 INFO crawl.CrawlDbReader: min score:    0.006\n14/02/14 16:51:07 INFO crawl.CrawlDbReader: avg score:    0.03972857\n14/02/14 16:51:07 INFO crawl.CrawlDbReader: max score:    1.2\n14/02/14 16:51:07 INFO crawl.CrawlDbReader: status 1 (db_unfetched):    59\n14/02/14 16:51:07 INFO crawl.CrawlDbReader: status 2 (db_fetched):    11\n14/02/14 16:51:07 INFO crawl.CrawlDbReader: CrawlDb statistics: done\n</code></pre><p>##参考资料</p>\n<ol>\n<li><a href=\"http://packtlib.packtpub.com/library/web-crawling-and-data-mining-with-apache-nutch/ch03lvl1sec20\">Web Crawling and Data Mining with Apache Nutch 的第3.2节</a></li>\n<li><p><a href=\"http://nutchhadoop.blogspot.com/\">Install Nutch 1.7 and Hadoop 1.2.0</a></p>\n</li>\n<li><p><a href=\"http://blog.csdn.net/azhao_dn/article/details/6921398\">hadoop mapred(hive)执行目录 文件权限问题</a></p>\n</li>\n</ol>\n<p>##废弃的资料</p>\n<ol>\n<li><p><a href=\"http://wiki.apache.org/nutch/NutchHadoopTutorial\">Nutch and Hadoop Tutorial</a>，讲的是Nutch 1.3的，太老了，完全不适用Nutch 1.7</p>\n</li>\n<li><p><a href=\"http://wiki.apache.org/nutch/NutchHadoopSingleNodeTutorial\">Running Nutch in (pseudo) distributed-mode</a>，太短了，没什么内容</p>\n</li>\n</ol>"},{"layout":"post","title":"在CentOS上安装Hadoop 2.x 集群","date":"2014-02-05T12:39:00.000Z","comments":1,"_content":"\n**环境**：CentOS 6.5, OPenJDK 1.7, Hadoop 2.2.0\n\n本文主要参考官网的文档，[Hadoop 2.2.0 Single Node Setup](http://hadoop.apache.org/docs/r2.2.0/hadoop-project-dist/hadoop-common/SingleCluster.html)， [Hadoop 2.2.0  Cluster Setup](http://hadoop.apache.org/docs/r2.2.0/hadoop-project-dist/hadoop-common/ClusterSetup.html)\n\n##（可选）创建新用户\n一般我倾向于把需要启动daemon进程，对外提供服务的程序，简单的说，就是服务器类程序，安装在单独的用户下面。这样可以做到隔离，运维方面，安全性也提高了。\n\n创建一个新的group,\n\n    $ sudo groupadd hadoop\n\n创建一个新的用户，并加入group,\n\n    $ sudo useradd -g hadoop hadoop\n\n给新用户设置密码，\n\n    $ sudo passwd hadoop\n\n##1 伪分布式模式(Pseudo-Distributed Mode)\nHadoop能在单台机器上以伪分布式模式运行，即每个Hadoop模块运行在单独的java进程里。\n\n###1.1 设置SSH无密码登录localhost\n先检查一下是能够无密码登录本机，\n\n    ssh localhost\n\n如果提示输入密码，说明不能，按如下步骤设置。\n\n    $ ssh-keygen -t dsa -P '' -f ~/.ssh/id_dsa \n    $ cat ~/.ssh/id_dsa.pub >> ~/.ssh/authorized_keys\n\n###1.2 下载已经编译好的二进制包，解压\n用浏览器下载或wget,\n\n    $ wget http://mirrors.hust.edu.cn/apache/hadoop/common/hadoop-2.2.0/hadoop-2.2.0.tar.gz\n    $ tar -zxf hadoop-2.2.0.tar.gz -C ~/local/opt\n    $ cd ~/local/opt/hadoop-2.2.0\n\n###1.3 设置环境变量\n\n    $ vim ~/.bashrc\n    export HADOOP_PREFIX=$HOME/local/opt/hadoop-2.2.0\n    export HADOOP_COMMON_HOME=$HADOOP_PREFIX\n    export HADOOP_HDFS_HOME=$HADOOP_PREFIX\n    export HADOOP_MAPRED_HOME=$HADOOP_PREFIX\n    export HADOOP_YARN_HOME=$HADOOP_PREFIX\n    export HADOOP_CONF_DIR=$HADOOP_PREFIX/etc/hadoop\n    export PATH=$PATH:$HADOOP_PREFIX/bin:$HADOOP_PREFIX/sbin\n\n<!-- more -->\n\n###1.4 修改配置文件\n配置文件的位置在 `$HADOOP_PREIFIX/etc/hadoop`下面。\n\n###1.4.1 hadoop-env.sh\n在这个文件中要告诉hadoop JDK 安装在了哪里\n\n    $ echo $JAVA_HOME\n    /usr/lib/jvm/java\n    $ vim conf/hadoop-env.sh\n\n取消`JAVA_HOME`那一行的注释，设置正确的JDK位置\n\n    export JAVA_HOME=/usr/lib/jvm/java\n\n####1.4.2 HDFS的配置\n为了简单，我们仍采用Hadoop 1.x中的HDFS工作模式（不配置HDFS Federation）。\n\ncore-site.xml:\n\n    <configuration>\n      <property>\n        <name>fs.defaultFS</name>\n        <value>hdfs://localhost</value>\n      </property>\n    </configuration>\n\nhdfs-site.xml:\n\n    <configuration>\n      <property>\n        <name>dfs.datanode.data.dir</name>\n        <value>file:///home/hadoop/local/var/hadoop/hdfs/datanode</value>\n      </property>\n      <property>\n        <name>dfs.namenode.name.dir</name>\n        <value>file:///home/hadoop/local/var/hadoop/hdfs/namenode</value>\n      </property>\n      <property>\n        <name>dfs.namenode.checkpoint.dir</name>\n        <value>file:///home/hadoop/local/var/hadoop/hdfs/namesecondary</value>\n      </property>\n      <property>\n        <name>dfs.replication</name>\n        <value>1</value>\n      </property>\n    </configuration>\n\nHadoop会自动创建目录。\n\n####1.4.3 YARN的配置\nyarn-site.xml，不用修改，保持为空。\n\n####1.4.4 MapReduce的配置\nYarn不仅仅只支持MapReduce这种计算模式，还支持Spar, Tez, MPI等框架，因此，要显式地配置Yarn，使其支持mapreduce。在Hadoop 1.x中，只支持MapReduce，因此需要而且必须配置mapred-site.xml，到了Hadoop 2.x，MapReduce的配置是可选的。\n\n在yarn-site.xml中添加：\n\n    <property>\n       <name>yarn.nodemanager.aux-services</name>\n       <value>mapreduce_shuffle</value>\n    </property>\n\n**解释**：为了能够运行MapReduce程序，需要让各个NodeManager在启动时加载shuffle server，shuffle server实际上是Jetty/Netty Server，Reduce Task通过该server从各个NodeManager上远程拷贝Map Task产生的中间结果。上面增加的这个配置用于指定shuffle server。\n\n将 mapred-site.xml.template 复制一份，重命名为mapred-site.xml。\n\nmapred-site.xml:\n\n    <property>\n       <name>mapreduce.framework.name</name>\n       <value>yarn</value>\n    </property>\n\n**解释**：用mapreduce.framework.name指定采用的框架名称，默认是将作业提交到MRv1的JobTracker端。\n\n###1.5 测试\n\n####1.5.1 启动HDFS\n\n    $ hdfs namenode -format\n    $ start-dfs.sh\n\n####1.5.2 启动Yarn\n\n    $ start-yarn.sh\n\n####1.5.3 启动MapReduce\n在Hadoop 2.x中，MapReduce Job不需要额外的daemon进程，在MapReduce Application Master启动的时候会自动启动JobTracker和TaskTracker进程，Job结束的时候会自动被关闭。\n\n####1.5.4 运行一个DistributedShell的例子\n运行一个Hadoop自带的例子，名称为`DistributedShell`，可以同时在多台机器上运行shell命令。\n\n    $ hadoop jar $HADOOP_PREFIX/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.2.0.jar org.apache.hadoop.yarn.applications.distributedshell.Client --jar $HADOOP_PREFIX/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.2.0.jar --shell_command date --num_containers 2\n\n运行完成后，看看倒数第三行，有类似与`application_1391783685869_0001`的字符串，这是application ID。查看该application的每个container的输出，执行下面的命令，\n\n    $ grep \"\" $HADOOP_PREFIX/logs/userlogs/<APPLICATION ID>/**/stdout\n\n####1.5.5 运行wordcount\n\n    $ cd $HADOOP_PREFIX\n    $ hdfs dfs -put ./etc/hadoop/ input\n    $ hadoop jar $HADOOP_PREFIX/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.2.0.jar wordcount input output\n    $ hdfs dfs -lsr output\n    $ hdfs dfs -cat output/part-r-00000\n\n结束后，关闭 Hadoop:\n\n    $ stop-dfs.sh\n    $ stop-yarn.sh\n\n\n##2 分布式模式(Fully-Distributed Mode)\n\n###2.1 准备3台机器\n如果你已经有了三台机器，这一步可以省略。\n\n如果没有，则可以用VMware Workstation 或 VirtualBox创建3台虚拟机。首先用vmware workstation 新建一台CentOS 6.5，装好操作系统，选择 Basic Server，安装JDK，参考我的另一篇博客，[安装和配置CentOS服务器的详细步骤](http://www.yanjiuyanjiu.com/blog/20120423/)。安装好后然后用**浅拷贝**`Create a linked clone` 克隆出2台，这样有了3台虚拟机。启动3台机器，假设IP分别为`192.168.1.131, 192.168.1.132, 192.168.1.133`, 131做为NameNode,JobTracker和SecondaryNameNode，身兼3个角色，这3个角色应该放到3台不同的机器上，这里为了简化，用一台机器来做3个角色；132和133为 slave。假设三台机器上的用户名是`hadoop`，也可以用其他用户名，但必须三台机器都相同。\n\n####2.1.1 关闭防火墙\n临时关闭防火墙\n\n\t$ sudo service iptables stop\n\n下次开机后，防火墙还是会启动。\n\n永久关闭防火墙\n\n\t$ sudo chkconfig iptables off\n\n由于这几台虚拟机是开发机，不是生产环境，因此不必考虑安全性，可以永久关闭防火墙，还能给开发阶段带来很多便利。\n\n####2.1.2 修改hostname\n如果集群中的每一台机器事先已经有了hostname，则这一步可以跳过。\n\n这一步看起来貌似不必要，其实是必须的，否则最后运行wordcount等例子时，会出现“Too many fetch-failures”。因为HDFS用hostname而不是IP，来相互之间进行通信（见后面的注意1）。\n\n在CentOS上修改hostname，包含两个步骤(假设将hostname1改为hostname2，参考[这里](http://www.ichiayi.com/wiki/tech/linux_hostname)，但不需要第一步)：\n\n1. 将 `/etc/sysconfig/network` 內的 HOSTNAME 改成 yourhostname\n2. 用`hostname`命令，临时修改机器名， `sudo hostname yourhostname`\n\n用`exit`命令退出shell，再次登录，命令提示字符串就会变成`[username@yourhostname ~]$`。\n\n用上述方法，将131改名为master，132改名为slave01，133改名为slave02。\n\n**注意**，对于有的Ubuntu/Debia 系统，会把本机的hostname解析成 127.0.1.1，例如：\n\n    127.0.0.1       localhost\n    127.0.1.1       master\n\n将第二行改为(参考[利用Cloudera实现Hadoop](http://wiki.ubuntu.org.cn/%E5%88%A9%E7%94%A8Cloudera%E5%AE%9E%E7%8E%B0Hadoop))\n\n    127.0.0.1       master\n\n####2.1.3 修改所有机器的`/etc/hosts`文件\n在所有机器的`/etc/hosts`文件中，添加所有hostname对应的IP，一般在一台机器上设置好，然后scp到所有机器。例如\n\n\t192.168.1.131 master\n\t192.168.1.132 slave01\n\t192.168.1.133 slave02\n\n###2.2 配置 master 无密码登陆到所有机器（包括master自己登陆自己）\n参考我的另一篇博客，[SSH无密码登录的配置](http://www.yanjiuyanjiu.com/blog/20120102/)\n\n###2.3 把Hadoop压缩包上传到所有机器，并解压\n将 hadoop-1.2.1-bin.tar.gz 上传到所有机器，然后解压。**注意，所有机器的hadoop路径必须一致，因为master会登陆到slave上执行命令，master认为slave的hadoop路径与自己一样。**\n\n下面开始配置，配置好了后，把`./etc/hadoop`目录scp到所有其他机器。\n\n###2.4 修改配置文件\n在第1节的基础上，增加下列修改。\n\n####2.4.1 指定NameNode\n在core-site.xml中，`fs.defaultFS`要改为运行NameNode的那台机器的hostname，不再是localhost。\n\n    <configuration>\n      <property>\n        <name>fs.defaultFS</name>\n        <value>hdfs://master</value>\n      </property>\n    </configuration>\n    \n####2.4.2 指定ResourceManager\n在yarn-site.xml中增加，\n\n    <property>\n       <name>yarn.resourcemanager.hostname</name>\n       <value>master</value>\n    </property>\n\n####2.4.3 添加Slave，即NodeManager\n在 `etc/hadoop/slaves`中添加，\n\n\tslave01\n\tslave02\n\n####2.4.4 设置 hadoop.tmp.dir\n在core-site.xml里添加：\n\n    <property>\n      <name>hadoop.tmp.dir</name>\n      <value>/home/hadoop/local/var/hadoop/tmp/hadoop-${user.name}</value>\n    </property>\n\n####2.4.4 修改mapred-site.xml\n添加如下内容：\n\n    <property>\n        <name>mapreduce.jobtracker.staging.root.dir</name>\n        <value>/user</value>\n    </property>\n\n这是为以后的多用户支持做准备。\n\n####2.4.4 设置pid文件的存放位置\n在hadoop-env.sh中添加\n\n    export HADOOP_MAPRED_PID_DIR=/home/hadoop/local/var/hadoop/pids\n\n在 mapred-env.sh中添加\n\n    export HADOOP_PID_DIR=/home/hadoop/local/var/hadoop/pids\n\n####2.4.5 将dfs.replication设置为slave的个数\n我们这里有2台slave，就设置为2。在hdfs-site.xml里添加：\n\n    <property>\n        <name>dfs.replication</name>\n        <value>2</value>\n    </property>\n\n####2.4.6 将配置文件拷贝到所有slaves\n\n    $ cd $HADOOP_PREFIX/etc/hadoop\n    $ scp hadoop-env.sh mapred-env.sh core-site.xml hdfs-site.xml mapred-site.xml yarn-site.xml slaves hadoop@slave01:$HADOOP_PREFIX/etc/hadoop\n    $ scp hadoop-env.sh mapred-env.sh core-site.xml hdfs-site.xml mapred-site.xml yarn-site.xml slaves hadoop@slave02:$HADOOP_PREFIX/etc/hadoop\n\n###2.5 设置环境变量\n在所有机器上添加环境变量，与第1.3节相同。\n\n###2.6 启动 hadoop\n\n####2.6.1 启动HDFS\n在NameNode这个机器（在这里是master）上执行下列命令，\n\n    #只需一次，下次启动不再需要格式化，只需 start-dfs.sh\n    $ hdfs namenode -format\n    $ start-dfs.sh\n\n####2.6.2 启动Yarn\n在ResourceManager这台机器（在这里仍然是master）上执行，\n\n    $ start-yarn.sh\n\n####2.6.3 启动MapReduce\n在Hadoop 2.x中，MapReduce Job不需要额外的daemon进程，在Job开始的时候，NodeManager会启动一个MapReduce Application Master（相当与一个精简的JobTracker），Job结束的时候自动被关闭。\n\n####2.6.4 检查是否启动成功\n用`jps`查看java进程。\n\n在master上，应该有三个进程，NameNode, SecondaryNameNode, ResourceManger；在每台slave上，应该有两个进程，DataNode, NodeManager。\n\n####2.6.5 Web UI\n可以用浏览器打开NameNode, ResourceManager和各个NodeManager的web界面，\n\n* NameNode web UI, <http://master:50070/>\n* ResourceManager web UI, <http://master:8088/>\n* NodeManager web UI, <http://slave01:8042>\n\n还可以启动JobHistory Server，能够通过Web页面查看集群的历史Job，执行如下命令：\n\n    mr-jobhistory-daemon.sh start historyserver\n\n默认使用19888端口，通过访问<http://master:19888/>查看历史信息。\n\n终止JobHistory Server，执行如下命令：\n\n    mr-jobhistory-daemon.sh stop historyserver\n\n###2.8 运行wordcount\n将输入数据拷贝到HDFS中:\n\n\t$ cd $HADOOP_PREFIX\n\t$ hdfs dfs -put ./etc/hadoop input\n\n这一步会报错，\"No such file or directory\", 用`hdfs dfs -ls /`查看，是空的，难怪了。我们需要手动建立\"/user/hadoop\"目录，\n\n    $ hdfs dfs -mkdir /user/hadoop\n\n再上传文件，就可以了。\n\n运行WordCount:\n\n\t$ hadoop jar $HADOOP_PREFIX/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.2.0.jar wordcount input output\n\n查看结果：\n\n    $ hdfs dfs -lsr output\n    $ hdfs dfs -cat output/part-r-00000\n\n如果能看到结果，说明这个例子运行成功。\n\n###2.9 停止 hadoop集群\n在master上执行：\n\n    $ stop-yarn.sh\n    $ stop-hdfs.sh\n\n##4. 排除错误\n本文已经尽可能的把步骤详细列出来了，但是我相信大部分人不会一次成功。这时候，查找错误就很重要了。查找错误最重要的手段是查看hadoop的日志，一般在logs目录下。把错误消息复制粘贴到google，搜索一下，慢慢找错误。\n\n\n##参考资料\n\n1. [core-default](http://hadoop.apache.org/docs/r2.2.0/hadoop-project-dist/hadoop-common/core-default.xml), [hdfs-default](http://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/hdfs-default.xml), [yarn-default](http://hadoop.apache.org/docs/current/hadoop-yarn/hadoop-yarn-common/yarn-default.xml), [mapred-default](http://hadoop.apache.org/docs/stable/hadoop-mapreduce-client/hadoop-mapreduce-client-core/mapred-default.xml)\n1. [Hadoop YARN安装部署初探](http://dongxicheng.org/mapreduce-nextgen/hadoop-yarn-install/)\n1. [Hadoop YARN Installation: The definitive guide](http://www.alexjf.net/blog/distributed-systems/hadoop-yarn-installation-definitive-guide)\n1. [Setup newest Hadoop 2.x (2.2.0) on Ubuntu](http://codesfusion.blogspot.com/2013/10/setup-hadoop-2x-220-on-ubuntu.html)\n1. [Hadoop-2.2.0集群安装配置实践](http://shiyanjun.cn/archives/561.html)\n1. [Hadoop YARN配置参数剖析(1)—RM与NM相关参数](http://dongxicheng.org/mapreduce-nextgen/hadoop-yarn-configurations-resourcemanager-nodemanager/)\n\n##相关文章\n\n1. [在CentOS上安装Hadoop集群](http://www.yanjiuyanjiu.com/blog/20140202)\n1. [在Ubuntu上安装Hadoop](http://www.yanjiuyanjiu.com/blog/20120103/)\n\n","source":"_posts/2014-02-05-hadoop-2-installatioin-on-centos.md","raw":"---\nlayout: post\ntitle: \"在CentOS上安装Hadoop 2.x 集群\"\ndate: 2014-02-05 12:39\ncomments: true\ncategories: Hadoop\n---\n\n**环境**：CentOS 6.5, OPenJDK 1.7, Hadoop 2.2.0\n\n本文主要参考官网的文档，[Hadoop 2.2.0 Single Node Setup](http://hadoop.apache.org/docs/r2.2.0/hadoop-project-dist/hadoop-common/SingleCluster.html)， [Hadoop 2.2.0  Cluster Setup](http://hadoop.apache.org/docs/r2.2.0/hadoop-project-dist/hadoop-common/ClusterSetup.html)\n\n##（可选）创建新用户\n一般我倾向于把需要启动daemon进程，对外提供服务的程序，简单的说，就是服务器类程序，安装在单独的用户下面。这样可以做到隔离，运维方面，安全性也提高了。\n\n创建一个新的group,\n\n    $ sudo groupadd hadoop\n\n创建一个新的用户，并加入group,\n\n    $ sudo useradd -g hadoop hadoop\n\n给新用户设置密码，\n\n    $ sudo passwd hadoop\n\n##1 伪分布式模式(Pseudo-Distributed Mode)\nHadoop能在单台机器上以伪分布式模式运行，即每个Hadoop模块运行在单独的java进程里。\n\n###1.1 设置SSH无密码登录localhost\n先检查一下是能够无密码登录本机，\n\n    ssh localhost\n\n如果提示输入密码，说明不能，按如下步骤设置。\n\n    $ ssh-keygen -t dsa -P '' -f ~/.ssh/id_dsa \n    $ cat ~/.ssh/id_dsa.pub >> ~/.ssh/authorized_keys\n\n###1.2 下载已经编译好的二进制包，解压\n用浏览器下载或wget,\n\n    $ wget http://mirrors.hust.edu.cn/apache/hadoop/common/hadoop-2.2.0/hadoop-2.2.0.tar.gz\n    $ tar -zxf hadoop-2.2.0.tar.gz -C ~/local/opt\n    $ cd ~/local/opt/hadoop-2.2.0\n\n###1.3 设置环境变量\n\n    $ vim ~/.bashrc\n    export HADOOP_PREFIX=$HOME/local/opt/hadoop-2.2.0\n    export HADOOP_COMMON_HOME=$HADOOP_PREFIX\n    export HADOOP_HDFS_HOME=$HADOOP_PREFIX\n    export HADOOP_MAPRED_HOME=$HADOOP_PREFIX\n    export HADOOP_YARN_HOME=$HADOOP_PREFIX\n    export HADOOP_CONF_DIR=$HADOOP_PREFIX/etc/hadoop\n    export PATH=$PATH:$HADOOP_PREFIX/bin:$HADOOP_PREFIX/sbin\n\n<!-- more -->\n\n###1.4 修改配置文件\n配置文件的位置在 `$HADOOP_PREIFIX/etc/hadoop`下面。\n\n###1.4.1 hadoop-env.sh\n在这个文件中要告诉hadoop JDK 安装在了哪里\n\n    $ echo $JAVA_HOME\n    /usr/lib/jvm/java\n    $ vim conf/hadoop-env.sh\n\n取消`JAVA_HOME`那一行的注释，设置正确的JDK位置\n\n    export JAVA_HOME=/usr/lib/jvm/java\n\n####1.4.2 HDFS的配置\n为了简单，我们仍采用Hadoop 1.x中的HDFS工作模式（不配置HDFS Federation）。\n\ncore-site.xml:\n\n    <configuration>\n      <property>\n        <name>fs.defaultFS</name>\n        <value>hdfs://localhost</value>\n      </property>\n    </configuration>\n\nhdfs-site.xml:\n\n    <configuration>\n      <property>\n        <name>dfs.datanode.data.dir</name>\n        <value>file:///home/hadoop/local/var/hadoop/hdfs/datanode</value>\n      </property>\n      <property>\n        <name>dfs.namenode.name.dir</name>\n        <value>file:///home/hadoop/local/var/hadoop/hdfs/namenode</value>\n      </property>\n      <property>\n        <name>dfs.namenode.checkpoint.dir</name>\n        <value>file:///home/hadoop/local/var/hadoop/hdfs/namesecondary</value>\n      </property>\n      <property>\n        <name>dfs.replication</name>\n        <value>1</value>\n      </property>\n    </configuration>\n\nHadoop会自动创建目录。\n\n####1.4.3 YARN的配置\nyarn-site.xml，不用修改，保持为空。\n\n####1.4.4 MapReduce的配置\nYarn不仅仅只支持MapReduce这种计算模式，还支持Spar, Tez, MPI等框架，因此，要显式地配置Yarn，使其支持mapreduce。在Hadoop 1.x中，只支持MapReduce，因此需要而且必须配置mapred-site.xml，到了Hadoop 2.x，MapReduce的配置是可选的。\n\n在yarn-site.xml中添加：\n\n    <property>\n       <name>yarn.nodemanager.aux-services</name>\n       <value>mapreduce_shuffle</value>\n    </property>\n\n**解释**：为了能够运行MapReduce程序，需要让各个NodeManager在启动时加载shuffle server，shuffle server实际上是Jetty/Netty Server，Reduce Task通过该server从各个NodeManager上远程拷贝Map Task产生的中间结果。上面增加的这个配置用于指定shuffle server。\n\n将 mapred-site.xml.template 复制一份，重命名为mapred-site.xml。\n\nmapred-site.xml:\n\n    <property>\n       <name>mapreduce.framework.name</name>\n       <value>yarn</value>\n    </property>\n\n**解释**：用mapreduce.framework.name指定采用的框架名称，默认是将作业提交到MRv1的JobTracker端。\n\n###1.5 测试\n\n####1.5.1 启动HDFS\n\n    $ hdfs namenode -format\n    $ start-dfs.sh\n\n####1.5.2 启动Yarn\n\n    $ start-yarn.sh\n\n####1.5.3 启动MapReduce\n在Hadoop 2.x中，MapReduce Job不需要额外的daemon进程，在MapReduce Application Master启动的时候会自动启动JobTracker和TaskTracker进程，Job结束的时候会自动被关闭。\n\n####1.5.4 运行一个DistributedShell的例子\n运行一个Hadoop自带的例子，名称为`DistributedShell`，可以同时在多台机器上运行shell命令。\n\n    $ hadoop jar $HADOOP_PREFIX/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.2.0.jar org.apache.hadoop.yarn.applications.distributedshell.Client --jar $HADOOP_PREFIX/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.2.0.jar --shell_command date --num_containers 2\n\n运行完成后，看看倒数第三行，有类似与`application_1391783685869_0001`的字符串，这是application ID。查看该application的每个container的输出，执行下面的命令，\n\n    $ grep \"\" $HADOOP_PREFIX/logs/userlogs/<APPLICATION ID>/**/stdout\n\n####1.5.5 运行wordcount\n\n    $ cd $HADOOP_PREFIX\n    $ hdfs dfs -put ./etc/hadoop/ input\n    $ hadoop jar $HADOOP_PREFIX/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.2.0.jar wordcount input output\n    $ hdfs dfs -lsr output\n    $ hdfs dfs -cat output/part-r-00000\n\n结束后，关闭 Hadoop:\n\n    $ stop-dfs.sh\n    $ stop-yarn.sh\n\n\n##2 分布式模式(Fully-Distributed Mode)\n\n###2.1 准备3台机器\n如果你已经有了三台机器，这一步可以省略。\n\n如果没有，则可以用VMware Workstation 或 VirtualBox创建3台虚拟机。首先用vmware workstation 新建一台CentOS 6.5，装好操作系统，选择 Basic Server，安装JDK，参考我的另一篇博客，[安装和配置CentOS服务器的详细步骤](http://www.yanjiuyanjiu.com/blog/20120423/)。安装好后然后用**浅拷贝**`Create a linked clone` 克隆出2台，这样有了3台虚拟机。启动3台机器，假设IP分别为`192.168.1.131, 192.168.1.132, 192.168.1.133`, 131做为NameNode,JobTracker和SecondaryNameNode，身兼3个角色，这3个角色应该放到3台不同的机器上，这里为了简化，用一台机器来做3个角色；132和133为 slave。假设三台机器上的用户名是`hadoop`，也可以用其他用户名，但必须三台机器都相同。\n\n####2.1.1 关闭防火墙\n临时关闭防火墙\n\n\t$ sudo service iptables stop\n\n下次开机后，防火墙还是会启动。\n\n永久关闭防火墙\n\n\t$ sudo chkconfig iptables off\n\n由于这几台虚拟机是开发机，不是生产环境，因此不必考虑安全性，可以永久关闭防火墙，还能给开发阶段带来很多便利。\n\n####2.1.2 修改hostname\n如果集群中的每一台机器事先已经有了hostname，则这一步可以跳过。\n\n这一步看起来貌似不必要，其实是必须的，否则最后运行wordcount等例子时，会出现“Too many fetch-failures”。因为HDFS用hostname而不是IP，来相互之间进行通信（见后面的注意1）。\n\n在CentOS上修改hostname，包含两个步骤(假设将hostname1改为hostname2，参考[这里](http://www.ichiayi.com/wiki/tech/linux_hostname)，但不需要第一步)：\n\n1. 将 `/etc/sysconfig/network` 內的 HOSTNAME 改成 yourhostname\n2. 用`hostname`命令，临时修改机器名， `sudo hostname yourhostname`\n\n用`exit`命令退出shell，再次登录，命令提示字符串就会变成`[username@yourhostname ~]$`。\n\n用上述方法，将131改名为master，132改名为slave01，133改名为slave02。\n\n**注意**，对于有的Ubuntu/Debia 系统，会把本机的hostname解析成 127.0.1.1，例如：\n\n    127.0.0.1       localhost\n    127.0.1.1       master\n\n将第二行改为(参考[利用Cloudera实现Hadoop](http://wiki.ubuntu.org.cn/%E5%88%A9%E7%94%A8Cloudera%E5%AE%9E%E7%8E%B0Hadoop))\n\n    127.0.0.1       master\n\n####2.1.3 修改所有机器的`/etc/hosts`文件\n在所有机器的`/etc/hosts`文件中，添加所有hostname对应的IP，一般在一台机器上设置好，然后scp到所有机器。例如\n\n\t192.168.1.131 master\n\t192.168.1.132 slave01\n\t192.168.1.133 slave02\n\n###2.2 配置 master 无密码登陆到所有机器（包括master自己登陆自己）\n参考我的另一篇博客，[SSH无密码登录的配置](http://www.yanjiuyanjiu.com/blog/20120102/)\n\n###2.3 把Hadoop压缩包上传到所有机器，并解压\n将 hadoop-1.2.1-bin.tar.gz 上传到所有机器，然后解压。**注意，所有机器的hadoop路径必须一致，因为master会登陆到slave上执行命令，master认为slave的hadoop路径与自己一样。**\n\n下面开始配置，配置好了后，把`./etc/hadoop`目录scp到所有其他机器。\n\n###2.4 修改配置文件\n在第1节的基础上，增加下列修改。\n\n####2.4.1 指定NameNode\n在core-site.xml中，`fs.defaultFS`要改为运行NameNode的那台机器的hostname，不再是localhost。\n\n    <configuration>\n      <property>\n        <name>fs.defaultFS</name>\n        <value>hdfs://master</value>\n      </property>\n    </configuration>\n    \n####2.4.2 指定ResourceManager\n在yarn-site.xml中增加，\n\n    <property>\n       <name>yarn.resourcemanager.hostname</name>\n       <value>master</value>\n    </property>\n\n####2.4.3 添加Slave，即NodeManager\n在 `etc/hadoop/slaves`中添加，\n\n\tslave01\n\tslave02\n\n####2.4.4 设置 hadoop.tmp.dir\n在core-site.xml里添加：\n\n    <property>\n      <name>hadoop.tmp.dir</name>\n      <value>/home/hadoop/local/var/hadoop/tmp/hadoop-${user.name}</value>\n    </property>\n\n####2.4.4 修改mapred-site.xml\n添加如下内容：\n\n    <property>\n        <name>mapreduce.jobtracker.staging.root.dir</name>\n        <value>/user</value>\n    </property>\n\n这是为以后的多用户支持做准备。\n\n####2.4.4 设置pid文件的存放位置\n在hadoop-env.sh中添加\n\n    export HADOOP_MAPRED_PID_DIR=/home/hadoop/local/var/hadoop/pids\n\n在 mapred-env.sh中添加\n\n    export HADOOP_PID_DIR=/home/hadoop/local/var/hadoop/pids\n\n####2.4.5 将dfs.replication设置为slave的个数\n我们这里有2台slave，就设置为2。在hdfs-site.xml里添加：\n\n    <property>\n        <name>dfs.replication</name>\n        <value>2</value>\n    </property>\n\n####2.4.6 将配置文件拷贝到所有slaves\n\n    $ cd $HADOOP_PREFIX/etc/hadoop\n    $ scp hadoop-env.sh mapred-env.sh core-site.xml hdfs-site.xml mapred-site.xml yarn-site.xml slaves hadoop@slave01:$HADOOP_PREFIX/etc/hadoop\n    $ scp hadoop-env.sh mapred-env.sh core-site.xml hdfs-site.xml mapred-site.xml yarn-site.xml slaves hadoop@slave02:$HADOOP_PREFIX/etc/hadoop\n\n###2.5 设置环境变量\n在所有机器上添加环境变量，与第1.3节相同。\n\n###2.6 启动 hadoop\n\n####2.6.1 启动HDFS\n在NameNode这个机器（在这里是master）上执行下列命令，\n\n    #只需一次，下次启动不再需要格式化，只需 start-dfs.sh\n    $ hdfs namenode -format\n    $ start-dfs.sh\n\n####2.6.2 启动Yarn\n在ResourceManager这台机器（在这里仍然是master）上执行，\n\n    $ start-yarn.sh\n\n####2.6.3 启动MapReduce\n在Hadoop 2.x中，MapReduce Job不需要额外的daemon进程，在Job开始的时候，NodeManager会启动一个MapReduce Application Master（相当与一个精简的JobTracker），Job结束的时候自动被关闭。\n\n####2.6.4 检查是否启动成功\n用`jps`查看java进程。\n\n在master上，应该有三个进程，NameNode, SecondaryNameNode, ResourceManger；在每台slave上，应该有两个进程，DataNode, NodeManager。\n\n####2.6.5 Web UI\n可以用浏览器打开NameNode, ResourceManager和各个NodeManager的web界面，\n\n* NameNode web UI, <http://master:50070/>\n* ResourceManager web UI, <http://master:8088/>\n* NodeManager web UI, <http://slave01:8042>\n\n还可以启动JobHistory Server，能够通过Web页面查看集群的历史Job，执行如下命令：\n\n    mr-jobhistory-daemon.sh start historyserver\n\n默认使用19888端口，通过访问<http://master:19888/>查看历史信息。\n\n终止JobHistory Server，执行如下命令：\n\n    mr-jobhistory-daemon.sh stop historyserver\n\n###2.8 运行wordcount\n将输入数据拷贝到HDFS中:\n\n\t$ cd $HADOOP_PREFIX\n\t$ hdfs dfs -put ./etc/hadoop input\n\n这一步会报错，\"No such file or directory\", 用`hdfs dfs -ls /`查看，是空的，难怪了。我们需要手动建立\"/user/hadoop\"目录，\n\n    $ hdfs dfs -mkdir /user/hadoop\n\n再上传文件，就可以了。\n\n运行WordCount:\n\n\t$ hadoop jar $HADOOP_PREFIX/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.2.0.jar wordcount input output\n\n查看结果：\n\n    $ hdfs dfs -lsr output\n    $ hdfs dfs -cat output/part-r-00000\n\n如果能看到结果，说明这个例子运行成功。\n\n###2.9 停止 hadoop集群\n在master上执行：\n\n    $ stop-yarn.sh\n    $ stop-hdfs.sh\n\n##4. 排除错误\n本文已经尽可能的把步骤详细列出来了，但是我相信大部分人不会一次成功。这时候，查找错误就很重要了。查找错误最重要的手段是查看hadoop的日志，一般在logs目录下。把错误消息复制粘贴到google，搜索一下，慢慢找错误。\n\n\n##参考资料\n\n1. [core-default](http://hadoop.apache.org/docs/r2.2.0/hadoop-project-dist/hadoop-common/core-default.xml), [hdfs-default](http://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/hdfs-default.xml), [yarn-default](http://hadoop.apache.org/docs/current/hadoop-yarn/hadoop-yarn-common/yarn-default.xml), [mapred-default](http://hadoop.apache.org/docs/stable/hadoop-mapreduce-client/hadoop-mapreduce-client-core/mapred-default.xml)\n1. [Hadoop YARN安装部署初探](http://dongxicheng.org/mapreduce-nextgen/hadoop-yarn-install/)\n1. [Hadoop YARN Installation: The definitive guide](http://www.alexjf.net/blog/distributed-systems/hadoop-yarn-installation-definitive-guide)\n1. [Setup newest Hadoop 2.x (2.2.0) on Ubuntu](http://codesfusion.blogspot.com/2013/10/setup-hadoop-2x-220-on-ubuntu.html)\n1. [Hadoop-2.2.0集群安装配置实践](http://shiyanjun.cn/archives/561.html)\n1. [Hadoop YARN配置参数剖析(1)—RM与NM相关参数](http://dongxicheng.org/mapreduce-nextgen/hadoop-yarn-configurations-resourcemanager-nodemanager/)\n\n##相关文章\n\n1. [在CentOS上安装Hadoop集群](http://www.yanjiuyanjiu.com/blog/20140202)\n1. [在Ubuntu上安装Hadoop](http://www.yanjiuyanjiu.com/blog/20120103/)\n\n","slug":"2014-02-05-hadoop-2-installatioin-on-centos","published":1,"updated":"2016-08-18T09:21:04.000Z","photos":[],"link":"","_id":"cis07pf4g003801pqyvy2uthc","content":"<p><strong>环境</strong>：CentOS 6.5, OPenJDK 1.7, Hadoop 2.2.0</p>\n<p>本文主要参考官网的文档，<a href=\"http://hadoop.apache.org/docs/r2.2.0/hadoop-project-dist/hadoop-common/SingleCluster.html\" target=\"_blank\" rel=\"external\">Hadoop 2.2.0 Single Node Setup</a>， <a href=\"http://hadoop.apache.org/docs/r2.2.0/hadoop-project-dist/hadoop-common/ClusterSetup.html\" target=\"_blank\" rel=\"external\">Hadoop 2.2.0  Cluster Setup</a></p>\n<p>##（可选）创建新用户<br>一般我倾向于把需要启动daemon进程，对外提供服务的程序，简单的说，就是服务器类程序，安装在单独的用户下面。这样可以做到隔离，运维方面，安全性也提高了。</p>\n<p>创建一个新的group,</p>\n<pre><code>$ sudo groupadd hadoop\n</code></pre><p>创建一个新的用户，并加入group,</p>\n<pre><code>$ sudo useradd -g hadoop hadoop\n</code></pre><p>给新用户设置密码，</p>\n<pre><code>$ sudo passwd hadoop\n</code></pre><p>##1 伪分布式模式(Pseudo-Distributed Mode)<br>Hadoop能在单台机器上以伪分布式模式运行，即每个Hadoop模块运行在单独的java进程里。</p>\n<p>###1.1 设置SSH无密码登录localhost<br>先检查一下是能够无密码登录本机，</p>\n<pre><code>ssh localhost\n</code></pre><p>如果提示输入密码，说明不能，按如下步骤设置。</p>\n<pre><code>$ ssh-keygen -t dsa -P &apos;&apos; -f ~/.ssh/id_dsa \n$ cat ~/.ssh/id_dsa.pub &gt;&gt; ~/.ssh/authorized_keys\n</code></pre><p>###1.2 下载已经编译好的二进制包，解压<br>用浏览器下载或wget,</p>\n<pre><code>$ wget http://mirrors.hust.edu.cn/apache/hadoop/common/hadoop-2.2.0/hadoop-2.2.0.tar.gz\n$ tar -zxf hadoop-2.2.0.tar.gz -C ~/local/opt\n$ cd ~/local/opt/hadoop-2.2.0\n</code></pre><p>###1.3 设置环境变量</p>\n<pre><code>$ vim ~/.bashrc\nexport HADOOP_PREFIX=$HOME/local/opt/hadoop-2.2.0\nexport HADOOP_COMMON_HOME=$HADOOP_PREFIX\nexport HADOOP_HDFS_HOME=$HADOOP_PREFIX\nexport HADOOP_MAPRED_HOME=$HADOOP_PREFIX\nexport HADOOP_YARN_HOME=$HADOOP_PREFIX\nexport HADOOP_CONF_DIR=$HADOOP_PREFIX/etc/hadoop\nexport PATH=$PATH:$HADOOP_PREFIX/bin:$HADOOP_PREFIX/sbin\n</code></pre><a id=\"more\"></a>\n<p>###1.4 修改配置文件<br>配置文件的位置在 <code>$HADOOP_PREIFIX/etc/hadoop</code>下面。</p>\n<p>###1.4.1 hadoop-env.sh<br>在这个文件中要告诉hadoop JDK 安装在了哪里</p>\n<pre><code>$ echo $JAVA_HOME\n/usr/lib/jvm/java\n$ vim conf/hadoop-env.sh\n</code></pre><p>取消<code>JAVA_HOME</code>那一行的注释，设置正确的JDK位置</p>\n<pre><code>export JAVA_HOME=/usr/lib/jvm/java\n</code></pre><p>####1.4.2 HDFS的配置<br>为了简单，我们仍采用Hadoop 1.x中的HDFS工作模式（不配置HDFS Federation）。</p>\n<p>core-site.xml:</p>\n<pre><code>&lt;configuration&gt;\n  &lt;property&gt;\n    &lt;name&gt;fs.defaultFS&lt;/name&gt;\n    &lt;value&gt;hdfs://localhost&lt;/value&gt;\n  &lt;/property&gt;\n&lt;/configuration&gt;\n</code></pre><p>hdfs-site.xml:</p>\n<pre><code>&lt;configuration&gt;\n  &lt;property&gt;\n    &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;\n    &lt;value&gt;file:///home/hadoop/local/var/hadoop/hdfs/datanode&lt;/value&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;\n    &lt;value&gt;file:///home/hadoop/local/var/hadoop/hdfs/namenode&lt;/value&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;dfs.namenode.checkpoint.dir&lt;/name&gt;\n    &lt;value&gt;file:///home/hadoop/local/var/hadoop/hdfs/namesecondary&lt;/value&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;dfs.replication&lt;/name&gt;\n    &lt;value&gt;1&lt;/value&gt;\n  &lt;/property&gt;\n&lt;/configuration&gt;\n</code></pre><p>Hadoop会自动创建目录。</p>\n<p>####1.4.3 YARN的配置<br>yarn-site.xml，不用修改，保持为空。</p>\n<p>####1.4.4 MapReduce的配置<br>Yarn不仅仅只支持MapReduce这种计算模式，还支持Spar, Tez, MPI等框架，因此，要显式地配置Yarn，使其支持mapreduce。在Hadoop 1.x中，只支持MapReduce，因此需要而且必须配置mapred-site.xml，到了Hadoop 2.x，MapReduce的配置是可选的。</p>\n<p>在yarn-site.xml中添加：</p>\n<pre><code>&lt;property&gt;\n   &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;\n   &lt;value&gt;mapreduce_shuffle&lt;/value&gt;\n&lt;/property&gt;\n</code></pre><p><strong>解释</strong>：为了能够运行MapReduce程序，需要让各个NodeManager在启动时加载shuffle server，shuffle server实际上是Jetty/Netty Server，Reduce Task通过该server从各个NodeManager上远程拷贝Map Task产生的中间结果。上面增加的这个配置用于指定shuffle server。</p>\n<p>将 mapred-site.xml.template 复制一份，重命名为mapred-site.xml。</p>\n<p>mapred-site.xml:</p>\n<pre><code>&lt;property&gt;\n   &lt;name&gt;mapreduce.framework.name&lt;/name&gt;\n   &lt;value&gt;yarn&lt;/value&gt;\n&lt;/property&gt;\n</code></pre><p><strong>解释</strong>：用mapreduce.framework.name指定采用的框架名称，默认是将作业提交到MRv1的JobTracker端。</p>\n<p>###1.5 测试</p>\n<p>####1.5.1 启动HDFS</p>\n<pre><code>$ hdfs namenode -format\n$ start-dfs.sh\n</code></pre><p>####1.5.2 启动Yarn</p>\n<pre><code>$ start-yarn.sh\n</code></pre><p>####1.5.3 启动MapReduce<br>在Hadoop 2.x中，MapReduce Job不需要额外的daemon进程，在MapReduce Application Master启动的时候会自动启动JobTracker和TaskTracker进程，Job结束的时候会自动被关闭。</p>\n<p>####1.5.4 运行一个DistributedShell的例子<br>运行一个Hadoop自带的例子，名称为<code>DistributedShell</code>，可以同时在多台机器上运行shell命令。</p>\n<pre><code>$ hadoop jar $HADOOP_PREFIX/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.2.0.jar org.apache.hadoop.yarn.applications.distributedshell.Client --jar $HADOOP_PREFIX/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.2.0.jar --shell_command date --num_containers 2\n</code></pre><p>运行完成后，看看倒数第三行，有类似与<code>application_1391783685869_0001</code>的字符串，这是application ID。查看该application的每个container的输出，执行下面的命令，</p>\n<pre><code>$ grep &quot;&quot; $HADOOP_PREFIX/logs/userlogs/&lt;APPLICATION ID&gt;/**/stdout\n</code></pre><p>####1.5.5 运行wordcount</p>\n<pre><code>$ cd $HADOOP_PREFIX\n$ hdfs dfs -put ./etc/hadoop/ input\n$ hadoop jar $HADOOP_PREFIX/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.2.0.jar wordcount input output\n$ hdfs dfs -lsr output\n$ hdfs dfs -cat output/part-r-00000\n</code></pre><p>结束后，关闭 Hadoop:</p>\n<pre><code>$ stop-dfs.sh\n$ stop-yarn.sh\n</code></pre><p>##2 分布式模式(Fully-Distributed Mode)</p>\n<p>###2.1 准备3台机器<br>如果你已经有了三台机器，这一步可以省略。</p>\n<p>如果没有，则可以用VMware Workstation 或 VirtualBox创建3台虚拟机。首先用vmware workstation 新建一台CentOS 6.5，装好操作系统，选择 Basic Server，安装JDK，参考我的另一篇博客，<a href=\"http://www.yanjiuyanjiu.com/blog/20120423/\" target=\"_blank\" rel=\"external\">安装和配置CentOS服务器的详细步骤</a>。安装好后然后用<strong>浅拷贝</strong><code>Create a linked clone</code> 克隆出2台，这样有了3台虚拟机。启动3台机器，假设IP分别为<code>192.168.1.131, 192.168.1.132, 192.168.1.133</code>, 131做为NameNode,JobTracker和SecondaryNameNode，身兼3个角色，这3个角色应该放到3台不同的机器上，这里为了简化，用一台机器来做3个角色；132和133为 slave。假设三台机器上的用户名是<code>hadoop</code>，也可以用其他用户名，但必须三台机器都相同。</p>\n<p>####2.1.1 关闭防火墙<br>临时关闭防火墙</p>\n<pre><code>$ sudo service iptables stop\n</code></pre><p>下次开机后，防火墙还是会启动。</p>\n<p>永久关闭防火墙</p>\n<pre><code>$ sudo chkconfig iptables off\n</code></pre><p>由于这几台虚拟机是开发机，不是生产环境，因此不必考虑安全性，可以永久关闭防火墙，还能给开发阶段带来很多便利。</p>\n<p>####2.1.2 修改hostname<br>如果集群中的每一台机器事先已经有了hostname，则这一步可以跳过。</p>\n<p>这一步看起来貌似不必要，其实是必须的，否则最后运行wordcount等例子时，会出现“Too many fetch-failures”。因为HDFS用hostname而不是IP，来相互之间进行通信（见后面的注意1）。</p>\n<p>在CentOS上修改hostname，包含两个步骤(假设将hostname1改为hostname2，参考<a href=\"http://www.ichiayi.com/wiki/tech/linux_hostname\" target=\"_blank\" rel=\"external\">这里</a>，但不需要第一步)：</p>\n<ol>\n<li>将 <code>/etc/sysconfig/network</code> 內的 HOSTNAME 改成 yourhostname</li>\n<li>用<code>hostname</code>命令，临时修改机器名， <code>sudo hostname yourhostname</code></li>\n</ol>\n<p>用<code>exit</code>命令退出shell，再次登录，命令提示字符串就会变成<code>[username@yourhostname ~]$</code>。</p>\n<p>用上述方法，将131改名为master，132改名为slave01，133改名为slave02。</p>\n<p><strong>注意</strong>，对于有的Ubuntu/Debia 系统，会把本机的hostname解析成 127.0.1.1，例如：</p>\n<pre><code>127.0.0.1       localhost\n127.0.1.1       master\n</code></pre><p>将第二行改为(参考<a href=\"http://wiki.ubuntu.org.cn/%E5%88%A9%E7%94%A8Cloudera%E5%AE%9E%E7%8E%B0Hadoop\" target=\"_blank\" rel=\"external\">利用Cloudera实现Hadoop</a>)</p>\n<pre><code>127.0.0.1       master\n</code></pre><p>####2.1.3 修改所有机器的<code>/etc/hosts</code>文件<br>在所有机器的<code>/etc/hosts</code>文件中，添加所有hostname对应的IP，一般在一台机器上设置好，然后scp到所有机器。例如</p>\n<pre><code>192.168.1.131 master\n192.168.1.132 slave01\n192.168.1.133 slave02\n</code></pre><p>###2.2 配置 master 无密码登陆到所有机器（包括master自己登陆自己）<br>参考我的另一篇博客，<a href=\"http://www.yanjiuyanjiu.com/blog/20120102/\" target=\"_blank\" rel=\"external\">SSH无密码登录的配置</a></p>\n<p>###2.3 把Hadoop压缩包上传到所有机器，并解压<br>将 hadoop-1.2.1-bin.tar.gz 上传到所有机器，然后解压。<strong>注意，所有机器的hadoop路径必须一致，因为master会登陆到slave上执行命令，master认为slave的hadoop路径与自己一样。</strong></p>\n<p>下面开始配置，配置好了后，把<code>./etc/hadoop</code>目录scp到所有其他机器。</p>\n<p>###2.4 修改配置文件<br>在第1节的基础上，增加下列修改。</p>\n<p>####2.4.1 指定NameNode<br>在core-site.xml中，<code>fs.defaultFS</code>要改为运行NameNode的那台机器的hostname，不再是localhost。</p>\n<pre><code>&lt;configuration&gt;\n  &lt;property&gt;\n    &lt;name&gt;fs.defaultFS&lt;/name&gt;\n    &lt;value&gt;hdfs://master&lt;/value&gt;\n  &lt;/property&gt;\n&lt;/configuration&gt;\n</code></pre><p>####2.4.2 指定ResourceManager<br>在yarn-site.xml中增加，</p>\n<pre><code>&lt;property&gt;\n   &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt;\n   &lt;value&gt;master&lt;/value&gt;\n&lt;/property&gt;\n</code></pre><p>####2.4.3 添加Slave，即NodeManager<br>在 <code>etc/hadoop/slaves</code>中添加，</p>\n<pre><code>slave01\nslave02\n</code></pre><p>####2.4.4 设置 hadoop.tmp.dir<br>在core-site.xml里添加：</p>\n<pre><code>&lt;property&gt;\n  &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;\n  &lt;value&gt;/home/hadoop/local/var/hadoop/tmp/hadoop-${user.name}&lt;/value&gt;\n&lt;/property&gt;\n</code></pre><p>####2.4.4 修改mapred-site.xml<br>添加如下内容：</p>\n<pre><code>&lt;property&gt;\n    &lt;name&gt;mapreduce.jobtracker.staging.root.dir&lt;/name&gt;\n    &lt;value&gt;/user&lt;/value&gt;\n&lt;/property&gt;\n</code></pre><p>这是为以后的多用户支持做准备。</p>\n<p>####2.4.4 设置pid文件的存放位置<br>在hadoop-env.sh中添加</p>\n<pre><code>export HADOOP_MAPRED_PID_DIR=/home/hadoop/local/var/hadoop/pids\n</code></pre><p>在 mapred-env.sh中添加</p>\n<pre><code>export HADOOP_PID_DIR=/home/hadoop/local/var/hadoop/pids\n</code></pre><p>####2.4.5 将dfs.replication设置为slave的个数<br>我们这里有2台slave，就设置为2。在hdfs-site.xml里添加：</p>\n<pre><code>&lt;property&gt;\n    &lt;name&gt;dfs.replication&lt;/name&gt;\n    &lt;value&gt;2&lt;/value&gt;\n&lt;/property&gt;\n</code></pre><p>####2.4.6 将配置文件拷贝到所有slaves</p>\n<pre><code>$ cd $HADOOP_PREFIX/etc/hadoop\n$ scp hadoop-env.sh mapred-env.sh core-site.xml hdfs-site.xml mapred-site.xml yarn-site.xml slaves hadoop@slave01:$HADOOP_PREFIX/etc/hadoop\n$ scp hadoop-env.sh mapred-env.sh core-site.xml hdfs-site.xml mapred-site.xml yarn-site.xml slaves hadoop@slave02:$HADOOP_PREFIX/etc/hadoop\n</code></pre><p>###2.5 设置环境变量<br>在所有机器上添加环境变量，与第1.3节相同。</p>\n<p>###2.6 启动 hadoop</p>\n<p>####2.6.1 启动HDFS<br>在NameNode这个机器（在这里是master）上执行下列命令，</p>\n<pre><code>#只需一次，下次启动不再需要格式化，只需 start-dfs.sh\n$ hdfs namenode -format\n$ start-dfs.sh\n</code></pre><p>####2.6.2 启动Yarn<br>在ResourceManager这台机器（在这里仍然是master）上执行，</p>\n<pre><code>$ start-yarn.sh\n</code></pre><p>####2.6.3 启动MapReduce<br>在Hadoop 2.x中，MapReduce Job不需要额外的daemon进程，在Job开始的时候，NodeManager会启动一个MapReduce Application Master（相当与一个精简的JobTracker），Job结束的时候自动被关闭。</p>\n<p>####2.6.4 检查是否启动成功<br>用<code>jps</code>查看java进程。</p>\n<p>在master上，应该有三个进程，NameNode, SecondaryNameNode, ResourceManger；在每台slave上，应该有两个进程，DataNode, NodeManager。</p>\n<p>####2.6.5 Web UI<br>可以用浏览器打开NameNode, ResourceManager和各个NodeManager的web界面，</p>\n<ul>\n<li>NameNode web UI, <a href=\"http://master:50070/\" target=\"_blank\" rel=\"external\">http://master:50070/</a></li>\n<li>ResourceManager web UI, <a href=\"http://master:8088/\" target=\"_blank\" rel=\"external\">http://master:8088/</a></li>\n<li>NodeManager web UI, <a href=\"http://slave01:8042\" target=\"_blank\" rel=\"external\">http://slave01:8042</a></li>\n</ul>\n<p>还可以启动JobHistory Server，能够通过Web页面查看集群的历史Job，执行如下命令：</p>\n<pre><code>mr-jobhistory-daemon.sh start historyserver\n</code></pre><p>默认使用19888端口，通过访问<a href=\"http://master:19888/\" target=\"_blank\" rel=\"external\">http://master:19888/</a>查看历史信息。</p>\n<p>终止JobHistory Server，执行如下命令：</p>\n<pre><code>mr-jobhistory-daemon.sh stop historyserver\n</code></pre><p>###2.8 运行wordcount<br>将输入数据拷贝到HDFS中:</p>\n<pre><code>$ cd $HADOOP_PREFIX\n$ hdfs dfs -put ./etc/hadoop input\n</code></pre><p>这一步会报错，”No such file or directory”, 用<code>hdfs dfs -ls /</code>查看，是空的，难怪了。我们需要手动建立”/user/hadoop”目录，</p>\n<pre><code>$ hdfs dfs -mkdir /user/hadoop\n</code></pre><p>再上传文件，就可以了。</p>\n<p>运行WordCount:</p>\n<pre><code>$ hadoop jar $HADOOP_PREFIX/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.2.0.jar wordcount input output\n</code></pre><p>查看结果：</p>\n<pre><code>$ hdfs dfs -lsr output\n$ hdfs dfs -cat output/part-r-00000\n</code></pre><p>如果能看到结果，说明这个例子运行成功。</p>\n<p>###2.9 停止 hadoop集群<br>在master上执行：</p>\n<pre><code>$ stop-yarn.sh\n$ stop-hdfs.sh\n</code></pre><p>##4. 排除错误<br>本文已经尽可能的把步骤详细列出来了，但是我相信大部分人不会一次成功。这时候，查找错误就很重要了。查找错误最重要的手段是查看hadoop的日志，一般在logs目录下。把错误消息复制粘贴到google，搜索一下，慢慢找错误。</p>\n<p>##参考资料</p>\n<ol>\n<li><a href=\"http://hadoop.apache.org/docs/r2.2.0/hadoop-project-dist/hadoop-common/core-default.xml\" target=\"_blank\" rel=\"external\">core-default</a>, <a href=\"http://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/hdfs-default.xml\" target=\"_blank\" rel=\"external\">hdfs-default</a>, <a href=\"http://hadoop.apache.org/docs/current/hadoop-yarn/hadoop-yarn-common/yarn-default.xml\" target=\"_blank\" rel=\"external\">yarn-default</a>, <a href=\"http://hadoop.apache.org/docs/stable/hadoop-mapreduce-client/hadoop-mapreduce-client-core/mapred-default.xml\" target=\"_blank\" rel=\"external\">mapred-default</a></li>\n<li><a href=\"http://dongxicheng.org/mapreduce-nextgen/hadoop-yarn-install/\" target=\"_blank\" rel=\"external\">Hadoop YARN安装部署初探</a></li>\n<li><a href=\"http://www.alexjf.net/blog/distributed-systems/hadoop-yarn-installation-definitive-guide\" target=\"_blank\" rel=\"external\">Hadoop YARN Installation: The definitive guide</a></li>\n<li><a href=\"http://codesfusion.blogspot.com/2013/10/setup-hadoop-2x-220-on-ubuntu.html\" target=\"_blank\" rel=\"external\">Setup newest Hadoop 2.x (2.2.0) on Ubuntu</a></li>\n<li><a href=\"http://shiyanjun.cn/archives/561.html\" target=\"_blank\" rel=\"external\">Hadoop-2.2.0集群安装配置实践</a></li>\n<li><a href=\"http://dongxicheng.org/mapreduce-nextgen/hadoop-yarn-configurations-resourcemanager-nodemanager/\" target=\"_blank\" rel=\"external\">Hadoop YARN配置参数剖析(1)—RM与NM相关参数</a></li>\n</ol>\n<p>##相关文章</p>\n<ol>\n<li><a href=\"http://www.yanjiuyanjiu.com/blog/20140202\" target=\"_blank\" rel=\"external\">在CentOS上安装Hadoop集群</a></li>\n<li><a href=\"http://www.yanjiuyanjiu.com/blog/20120103/\" target=\"_blank\" rel=\"external\">在Ubuntu上安装Hadoop</a></li>\n</ol>\n","excerpt":"<p><strong>环境</strong>：CentOS 6.5, OPenJDK 1.7, Hadoop 2.2.0</p>\n<p>本文主要参考官网的文档，<a href=\"http://hadoop.apache.org/docs/r2.2.0/hadoop-project-dist/hadoop-common/SingleCluster.html\">Hadoop 2.2.0 Single Node Setup</a>， <a href=\"http://hadoop.apache.org/docs/r2.2.0/hadoop-project-dist/hadoop-common/ClusterSetup.html\">Hadoop 2.2.0  Cluster Setup</a></p>\n<p>##（可选）创建新用户<br>一般我倾向于把需要启动daemon进程，对外提供服务的程序，简单的说，就是服务器类程序，安装在单独的用户下面。这样可以做到隔离，运维方面，安全性也提高了。</p>\n<p>创建一个新的group,</p>\n<pre><code>$ sudo groupadd hadoop\n</code></pre><p>创建一个新的用户，并加入group,</p>\n<pre><code>$ sudo useradd -g hadoop hadoop\n</code></pre><p>给新用户设置密码，</p>\n<pre><code>$ sudo passwd hadoop\n</code></pre><p>##1 伪分布式模式(Pseudo-Distributed Mode)<br>Hadoop能在单台机器上以伪分布式模式运行，即每个Hadoop模块运行在单独的java进程里。</p>\n<p>###1.1 设置SSH无密码登录localhost<br>先检查一下是能够无密码登录本机，</p>\n<pre><code>ssh localhost\n</code></pre><p>如果提示输入密码，说明不能，按如下步骤设置。</p>\n<pre><code>$ ssh-keygen -t dsa -P &apos;&apos; -f ~/.ssh/id_dsa \n$ cat ~/.ssh/id_dsa.pub &gt;&gt; ~/.ssh/authorized_keys\n</code></pre><p>###1.2 下载已经编译好的二进制包，解压<br>用浏览器下载或wget,</p>\n<pre><code>$ wget http://mirrors.hust.edu.cn/apache/hadoop/common/hadoop-2.2.0/hadoop-2.2.0.tar.gz\n$ tar -zxf hadoop-2.2.0.tar.gz -C ~/local/opt\n$ cd ~/local/opt/hadoop-2.2.0\n</code></pre><p>###1.3 设置环境变量</p>\n<pre><code>$ vim ~/.bashrc\nexport HADOOP_PREFIX=$HOME/local/opt/hadoop-2.2.0\nexport HADOOP_COMMON_HOME=$HADOOP_PREFIX\nexport HADOOP_HDFS_HOME=$HADOOP_PREFIX\nexport HADOOP_MAPRED_HOME=$HADOOP_PREFIX\nexport HADOOP_YARN_HOME=$HADOOP_PREFIX\nexport HADOOP_CONF_DIR=$HADOOP_PREFIX/etc/hadoop\nexport PATH=$PATH:$HADOOP_PREFIX/bin:$HADOOP_PREFIX/sbin\n</code></pre>","more":"<p>###1.4 修改配置文件<br>配置文件的位置在 <code>$HADOOP_PREIFIX/etc/hadoop</code>下面。</p>\n<p>###1.4.1 hadoop-env.sh<br>在这个文件中要告诉hadoop JDK 安装在了哪里</p>\n<pre><code>$ echo $JAVA_HOME\n/usr/lib/jvm/java\n$ vim conf/hadoop-env.sh\n</code></pre><p>取消<code>JAVA_HOME</code>那一行的注释，设置正确的JDK位置</p>\n<pre><code>export JAVA_HOME=/usr/lib/jvm/java\n</code></pre><p>####1.4.2 HDFS的配置<br>为了简单，我们仍采用Hadoop 1.x中的HDFS工作模式（不配置HDFS Federation）。</p>\n<p>core-site.xml:</p>\n<pre><code>&lt;configuration&gt;\n  &lt;property&gt;\n    &lt;name&gt;fs.defaultFS&lt;/name&gt;\n    &lt;value&gt;hdfs://localhost&lt;/value&gt;\n  &lt;/property&gt;\n&lt;/configuration&gt;\n</code></pre><p>hdfs-site.xml:</p>\n<pre><code>&lt;configuration&gt;\n  &lt;property&gt;\n    &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;\n    &lt;value&gt;file:///home/hadoop/local/var/hadoop/hdfs/datanode&lt;/value&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;\n    &lt;value&gt;file:///home/hadoop/local/var/hadoop/hdfs/namenode&lt;/value&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;dfs.namenode.checkpoint.dir&lt;/name&gt;\n    &lt;value&gt;file:///home/hadoop/local/var/hadoop/hdfs/namesecondary&lt;/value&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;dfs.replication&lt;/name&gt;\n    &lt;value&gt;1&lt;/value&gt;\n  &lt;/property&gt;\n&lt;/configuration&gt;\n</code></pre><p>Hadoop会自动创建目录。</p>\n<p>####1.4.3 YARN的配置<br>yarn-site.xml，不用修改，保持为空。</p>\n<p>####1.4.4 MapReduce的配置<br>Yarn不仅仅只支持MapReduce这种计算模式，还支持Spar, Tez, MPI等框架，因此，要显式地配置Yarn，使其支持mapreduce。在Hadoop 1.x中，只支持MapReduce，因此需要而且必须配置mapred-site.xml，到了Hadoop 2.x，MapReduce的配置是可选的。</p>\n<p>在yarn-site.xml中添加：</p>\n<pre><code>&lt;property&gt;\n   &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;\n   &lt;value&gt;mapreduce_shuffle&lt;/value&gt;\n&lt;/property&gt;\n</code></pre><p><strong>解释</strong>：为了能够运行MapReduce程序，需要让各个NodeManager在启动时加载shuffle server，shuffle server实际上是Jetty/Netty Server，Reduce Task通过该server从各个NodeManager上远程拷贝Map Task产生的中间结果。上面增加的这个配置用于指定shuffle server。</p>\n<p>将 mapred-site.xml.template 复制一份，重命名为mapred-site.xml。</p>\n<p>mapred-site.xml:</p>\n<pre><code>&lt;property&gt;\n   &lt;name&gt;mapreduce.framework.name&lt;/name&gt;\n   &lt;value&gt;yarn&lt;/value&gt;\n&lt;/property&gt;\n</code></pre><p><strong>解释</strong>：用mapreduce.framework.name指定采用的框架名称，默认是将作业提交到MRv1的JobTracker端。</p>\n<p>###1.5 测试</p>\n<p>####1.5.1 启动HDFS</p>\n<pre><code>$ hdfs namenode -format\n$ start-dfs.sh\n</code></pre><p>####1.5.2 启动Yarn</p>\n<pre><code>$ start-yarn.sh\n</code></pre><p>####1.5.3 启动MapReduce<br>在Hadoop 2.x中，MapReduce Job不需要额外的daemon进程，在MapReduce Application Master启动的时候会自动启动JobTracker和TaskTracker进程，Job结束的时候会自动被关闭。</p>\n<p>####1.5.4 运行一个DistributedShell的例子<br>运行一个Hadoop自带的例子，名称为<code>DistributedShell</code>，可以同时在多台机器上运行shell命令。</p>\n<pre><code>$ hadoop jar $HADOOP_PREFIX/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.2.0.jar org.apache.hadoop.yarn.applications.distributedshell.Client --jar $HADOOP_PREFIX/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.2.0.jar --shell_command date --num_containers 2\n</code></pre><p>运行完成后，看看倒数第三行，有类似与<code>application_1391783685869_0001</code>的字符串，这是application ID。查看该application的每个container的输出，执行下面的命令，</p>\n<pre><code>$ grep &quot;&quot; $HADOOP_PREFIX/logs/userlogs/&lt;APPLICATION ID&gt;/**/stdout\n</code></pre><p>####1.5.5 运行wordcount</p>\n<pre><code>$ cd $HADOOP_PREFIX\n$ hdfs dfs -put ./etc/hadoop/ input\n$ hadoop jar $HADOOP_PREFIX/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.2.0.jar wordcount input output\n$ hdfs dfs -lsr output\n$ hdfs dfs -cat output/part-r-00000\n</code></pre><p>结束后，关闭 Hadoop:</p>\n<pre><code>$ stop-dfs.sh\n$ stop-yarn.sh\n</code></pre><p>##2 分布式模式(Fully-Distributed Mode)</p>\n<p>###2.1 准备3台机器<br>如果你已经有了三台机器，这一步可以省略。</p>\n<p>如果没有，则可以用VMware Workstation 或 VirtualBox创建3台虚拟机。首先用vmware workstation 新建一台CentOS 6.5，装好操作系统，选择 Basic Server，安装JDK，参考我的另一篇博客，<a href=\"http://www.yanjiuyanjiu.com/blog/20120423/\">安装和配置CentOS服务器的详细步骤</a>。安装好后然后用<strong>浅拷贝</strong><code>Create a linked clone</code> 克隆出2台，这样有了3台虚拟机。启动3台机器，假设IP分别为<code>192.168.1.131, 192.168.1.132, 192.168.1.133</code>, 131做为NameNode,JobTracker和SecondaryNameNode，身兼3个角色，这3个角色应该放到3台不同的机器上，这里为了简化，用一台机器来做3个角色；132和133为 slave。假设三台机器上的用户名是<code>hadoop</code>，也可以用其他用户名，但必须三台机器都相同。</p>\n<p>####2.1.1 关闭防火墙<br>临时关闭防火墙</p>\n<pre><code>$ sudo service iptables stop\n</code></pre><p>下次开机后，防火墙还是会启动。</p>\n<p>永久关闭防火墙</p>\n<pre><code>$ sudo chkconfig iptables off\n</code></pre><p>由于这几台虚拟机是开发机，不是生产环境，因此不必考虑安全性，可以永久关闭防火墙，还能给开发阶段带来很多便利。</p>\n<p>####2.1.2 修改hostname<br>如果集群中的每一台机器事先已经有了hostname，则这一步可以跳过。</p>\n<p>这一步看起来貌似不必要，其实是必须的，否则最后运行wordcount等例子时，会出现“Too many fetch-failures”。因为HDFS用hostname而不是IP，来相互之间进行通信（见后面的注意1）。</p>\n<p>在CentOS上修改hostname，包含两个步骤(假设将hostname1改为hostname2，参考<a href=\"http://www.ichiayi.com/wiki/tech/linux_hostname\">这里</a>，但不需要第一步)：</p>\n<ol>\n<li>将 <code>/etc/sysconfig/network</code> 內的 HOSTNAME 改成 yourhostname</li>\n<li>用<code>hostname</code>命令，临时修改机器名， <code>sudo hostname yourhostname</code></li>\n</ol>\n<p>用<code>exit</code>命令退出shell，再次登录，命令提示字符串就会变成<code>[username@yourhostname ~]$</code>。</p>\n<p>用上述方法，将131改名为master，132改名为slave01，133改名为slave02。</p>\n<p><strong>注意</strong>，对于有的Ubuntu/Debia 系统，会把本机的hostname解析成 127.0.1.1，例如：</p>\n<pre><code>127.0.0.1       localhost\n127.0.1.1       master\n</code></pre><p>将第二行改为(参考<a href=\"http://wiki.ubuntu.org.cn/%E5%88%A9%E7%94%A8Cloudera%E5%AE%9E%E7%8E%B0Hadoop\">利用Cloudera实现Hadoop</a>)</p>\n<pre><code>127.0.0.1       master\n</code></pre><p>####2.1.3 修改所有机器的<code>/etc/hosts</code>文件<br>在所有机器的<code>/etc/hosts</code>文件中，添加所有hostname对应的IP，一般在一台机器上设置好，然后scp到所有机器。例如</p>\n<pre><code>192.168.1.131 master\n192.168.1.132 slave01\n192.168.1.133 slave02\n</code></pre><p>###2.2 配置 master 无密码登陆到所有机器（包括master自己登陆自己）<br>参考我的另一篇博客，<a href=\"http://www.yanjiuyanjiu.com/blog/20120102/\">SSH无密码登录的配置</a></p>\n<p>###2.3 把Hadoop压缩包上传到所有机器，并解压<br>将 hadoop-1.2.1-bin.tar.gz 上传到所有机器，然后解压。<strong>注意，所有机器的hadoop路径必须一致，因为master会登陆到slave上执行命令，master认为slave的hadoop路径与自己一样。</strong></p>\n<p>下面开始配置，配置好了后，把<code>./etc/hadoop</code>目录scp到所有其他机器。</p>\n<p>###2.4 修改配置文件<br>在第1节的基础上，增加下列修改。</p>\n<p>####2.4.1 指定NameNode<br>在core-site.xml中，<code>fs.defaultFS</code>要改为运行NameNode的那台机器的hostname，不再是localhost。</p>\n<pre><code>&lt;configuration&gt;\n  &lt;property&gt;\n    &lt;name&gt;fs.defaultFS&lt;/name&gt;\n    &lt;value&gt;hdfs://master&lt;/value&gt;\n  &lt;/property&gt;\n&lt;/configuration&gt;\n</code></pre><p>####2.4.2 指定ResourceManager<br>在yarn-site.xml中增加，</p>\n<pre><code>&lt;property&gt;\n   &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt;\n   &lt;value&gt;master&lt;/value&gt;\n&lt;/property&gt;\n</code></pre><p>####2.4.3 添加Slave，即NodeManager<br>在 <code>etc/hadoop/slaves</code>中添加，</p>\n<pre><code>slave01\nslave02\n</code></pre><p>####2.4.4 设置 hadoop.tmp.dir<br>在core-site.xml里添加：</p>\n<pre><code>&lt;property&gt;\n  &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;\n  &lt;value&gt;/home/hadoop/local/var/hadoop/tmp/hadoop-${user.name}&lt;/value&gt;\n&lt;/property&gt;\n</code></pre><p>####2.4.4 修改mapred-site.xml<br>添加如下内容：</p>\n<pre><code>&lt;property&gt;\n    &lt;name&gt;mapreduce.jobtracker.staging.root.dir&lt;/name&gt;\n    &lt;value&gt;/user&lt;/value&gt;\n&lt;/property&gt;\n</code></pre><p>这是为以后的多用户支持做准备。</p>\n<p>####2.4.4 设置pid文件的存放位置<br>在hadoop-env.sh中添加</p>\n<pre><code>export HADOOP_MAPRED_PID_DIR=/home/hadoop/local/var/hadoop/pids\n</code></pre><p>在 mapred-env.sh中添加</p>\n<pre><code>export HADOOP_PID_DIR=/home/hadoop/local/var/hadoop/pids\n</code></pre><p>####2.4.5 将dfs.replication设置为slave的个数<br>我们这里有2台slave，就设置为2。在hdfs-site.xml里添加：</p>\n<pre><code>&lt;property&gt;\n    &lt;name&gt;dfs.replication&lt;/name&gt;\n    &lt;value&gt;2&lt;/value&gt;\n&lt;/property&gt;\n</code></pre><p>####2.4.6 将配置文件拷贝到所有slaves</p>\n<pre><code>$ cd $HADOOP_PREFIX/etc/hadoop\n$ scp hadoop-env.sh mapred-env.sh core-site.xml hdfs-site.xml mapred-site.xml yarn-site.xml slaves hadoop@slave01:$HADOOP_PREFIX/etc/hadoop\n$ scp hadoop-env.sh mapred-env.sh core-site.xml hdfs-site.xml mapred-site.xml yarn-site.xml slaves hadoop@slave02:$HADOOP_PREFIX/etc/hadoop\n</code></pre><p>###2.5 设置环境变量<br>在所有机器上添加环境变量，与第1.3节相同。</p>\n<p>###2.6 启动 hadoop</p>\n<p>####2.6.1 启动HDFS<br>在NameNode这个机器（在这里是master）上执行下列命令，</p>\n<pre><code>#只需一次，下次启动不再需要格式化，只需 start-dfs.sh\n$ hdfs namenode -format\n$ start-dfs.sh\n</code></pre><p>####2.6.2 启动Yarn<br>在ResourceManager这台机器（在这里仍然是master）上执行，</p>\n<pre><code>$ start-yarn.sh\n</code></pre><p>####2.6.3 启动MapReduce<br>在Hadoop 2.x中，MapReduce Job不需要额外的daemon进程，在Job开始的时候，NodeManager会启动一个MapReduce Application Master（相当与一个精简的JobTracker），Job结束的时候自动被关闭。</p>\n<p>####2.6.4 检查是否启动成功<br>用<code>jps</code>查看java进程。</p>\n<p>在master上，应该有三个进程，NameNode, SecondaryNameNode, ResourceManger；在每台slave上，应该有两个进程，DataNode, NodeManager。</p>\n<p>####2.6.5 Web UI<br>可以用浏览器打开NameNode, ResourceManager和各个NodeManager的web界面，</p>\n<ul>\n<li>NameNode web UI, <a href=\"http://master:50070/\">http://master:50070/</a></li>\n<li>ResourceManager web UI, <a href=\"http://master:8088/\">http://master:8088/</a></li>\n<li>NodeManager web UI, <a href=\"http://slave01:8042\">http://slave01:8042</a></li>\n</ul>\n<p>还可以启动JobHistory Server，能够通过Web页面查看集群的历史Job，执行如下命令：</p>\n<pre><code>mr-jobhistory-daemon.sh start historyserver\n</code></pre><p>默认使用19888端口，通过访问<a href=\"http://master:19888/\">http://master:19888/</a>查看历史信息。</p>\n<p>终止JobHistory Server，执行如下命令：</p>\n<pre><code>mr-jobhistory-daemon.sh stop historyserver\n</code></pre><p>###2.8 运行wordcount<br>将输入数据拷贝到HDFS中:</p>\n<pre><code>$ cd $HADOOP_PREFIX\n$ hdfs dfs -put ./etc/hadoop input\n</code></pre><p>这一步会报错，”No such file or directory”, 用<code>hdfs dfs -ls /</code>查看，是空的，难怪了。我们需要手动建立”/user/hadoop”目录，</p>\n<pre><code>$ hdfs dfs -mkdir /user/hadoop\n</code></pre><p>再上传文件，就可以了。</p>\n<p>运行WordCount:</p>\n<pre><code>$ hadoop jar $HADOOP_PREFIX/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.2.0.jar wordcount input output\n</code></pre><p>查看结果：</p>\n<pre><code>$ hdfs dfs -lsr output\n$ hdfs dfs -cat output/part-r-00000\n</code></pre><p>如果能看到结果，说明这个例子运行成功。</p>\n<p>###2.9 停止 hadoop集群<br>在master上执行：</p>\n<pre><code>$ stop-yarn.sh\n$ stop-hdfs.sh\n</code></pre><p>##4. 排除错误<br>本文已经尽可能的把步骤详细列出来了，但是我相信大部分人不会一次成功。这时候，查找错误就很重要了。查找错误最重要的手段是查看hadoop的日志，一般在logs目录下。把错误消息复制粘贴到google，搜索一下，慢慢找错误。</p>\n<p>##参考资料</p>\n<ol>\n<li><a href=\"http://hadoop.apache.org/docs/r2.2.0/hadoop-project-dist/hadoop-common/core-default.xml\">core-default</a>, <a href=\"http://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/hdfs-default.xml\">hdfs-default</a>, <a href=\"http://hadoop.apache.org/docs/current/hadoop-yarn/hadoop-yarn-common/yarn-default.xml\">yarn-default</a>, <a href=\"http://hadoop.apache.org/docs/stable/hadoop-mapreduce-client/hadoop-mapreduce-client-core/mapred-default.xml\">mapred-default</a></li>\n<li><a href=\"http://dongxicheng.org/mapreduce-nextgen/hadoop-yarn-install/\">Hadoop YARN安装部署初探</a></li>\n<li><a href=\"http://www.alexjf.net/blog/distributed-systems/hadoop-yarn-installation-definitive-guide\">Hadoop YARN Installation: The definitive guide</a></li>\n<li><a href=\"http://codesfusion.blogspot.com/2013/10/setup-hadoop-2x-220-on-ubuntu.html\">Setup newest Hadoop 2.x (2.2.0) on Ubuntu</a></li>\n<li><a href=\"http://shiyanjun.cn/archives/561.html\">Hadoop-2.2.0集群安装配置实践</a></li>\n<li><a href=\"http://dongxicheng.org/mapreduce-nextgen/hadoop-yarn-configurations-resourcemanager-nodemanager/\">Hadoop YARN配置参数剖析(1)—RM与NM相关参数</a></li>\n</ol>\n<p>##相关文章</p>\n<ol>\n<li><a href=\"http://www.yanjiuyanjiu.com/blog/20140202\">在CentOS上安装Hadoop集群</a></li>\n<li><a href=\"http://www.yanjiuyanjiu.com/blog/20120103/\">在Ubuntu上安装Hadoop</a></li>\n</ol>"},{"layout":"post","title":"Hadoop多用户的配置(Hadoop 2.x)","date":"2014-02-06T10:05:00.000Z","comments":1,"_content":"假设我们以名为hadoop的用户，建好了集群，见[在CentOS上安装Hadoop 2.x 集群](http://www.yanjiuyanjiu.com/blog/20140205/)。通常，我们会把这个集群共享给多个用户，而不是让大家都登录为hadoop，这样做有几个好处：\n\n* 一个用户不能修改另一个用户的的文件\n* 在hadoop web管理页面，可以很方便的看到不同的用户的job\n\n现在集群中有一台机器，上面有一个用户名为 hbase 的用户，他想要使用hadoop集群，怎么配置呢？\n\n##1. 安装hadoop客户端\n\n###1.1 下载，解压\n下载跟hadoop集群一样的hadoop软件包，并解压，\n\n    $ wget http://mirrors.hust.edu.cn/apache/hadoop/common/hadoop-2.2.0/hadoop-2.2.0.tar.gz\n    $ tar -zxf hadoop-2.2.0.tar.gz -C ~/local/opt\n    $ cd ~/local/opt/hadoop-2.2.0\n\n###1.2 拷贝Hadoop集群的配置文件\n将Hadoop集群的配置文件全部拷贝到客户端，相当与把集群的信息告诉客户端。\n\n    $ scp -r hadoop@localhost:~/local/opt/hadoop-2.2.0/etc/hadoop ./etc/\n\n修改conf/mapred-site.xml中的`mapreduce.cluster.local.dir`，改为本机上的某个目录，确保这个目录存在且有写权限。因为这个目录是本地目录，每台机器都可以不同。例如我的是：\n\n    <property>\n      <name>mapreduce.cluster.local.dir</name>\n      <value>/home/soulmachine/local/var/hadoop/mapred/local</value>\n    </property>\n\n确保这个目录存在，\n\n    $ mkdir -p ~/local/var/hadoop/mapred/local\n\n<!-- more -->\n\n还有另一种方法，由于`mapreduce.cluster.local.dir`默认值是`${hadoop.tmp.dir}/mapred/local`，也可以通过修改`hadoop.tmp.dir`达到目的，在`core-site.xml`中，确保`${hadoop.tmp.dir}/mapred/local`存在且有写权限。\n\n\n##2. 在master上配置权限\n以下操作均在hadoop集群的 namenode 这台机器上进行，且登录为hadoop，因为hadoop这个用户是整个hadoop集群权限最高的用户（但对于Linux系统本身，这个用户其实没有sudo权限）。\n\nHadoop关于用户权限方面，有很多高级的配置，这里我们简单的利用HDFS本身的文件权限检查机制，来配置多用户。\n\nHDFS本身没有提供用户名、用户组的创建，在客户端调用hadoop 的文件操作命令时，hadoop 识别出执行命令所在进程的linux系统的用户名和用户组，然后使用这个用户名和组来检查文件权限。 用户名=linux命令中的`whoami`，而组名等于`groups`。 \n\n启动hadoop hdfs系统的用户即为超级用户（在这里就是名为hadoop的这个用户），可以进行任意的操作。\n\n在客户端机器上，用gropus命令看一下hbase所在的组，\n\n    $ groups\n    hbase\n\n说明hbase这个用户所在的组为hbase。\n\n###2.1 为客户端用户创建home文件夹\n\n    $ hdfs dfs -mkdir /user/hbase\n    $ hdfs dfs -chown hbase /user/hbase\n    $ hdfs dfs -chgrp hbase /user/hbase\n\n###2.2 设置HDFS上的/tmp目录的权限\n客户端提交job的时候，需要往/tmp里写入文件，因此最好把/tmp设置为所有用户都有可读、可写和可执行的权限。 \n\n    $ hdfs dfs -chmod -R 777 /tmp\n\n###2.3 设置mapreduce.jobtracker.staging.root.dir\n客户端向集群提交任务时，需要把该job需要的文件打包，拷贝到HDFS上。在拷贝之前，得先确定这些资源文件存放在HDFS的什么地方。JobTracker设置有一个工作目录(Staging area, 也称数据中转站)，用来存储与每个job相关的数据。这个目录的前缀由`mapreduce.jobtracker.staging.root.dir` 参数来指定，默认是`${hadoop.tmp.dir}/mapred/staging`，每个client user可以提交多个job，在这个目录后就得附加user name的信息。所以这个工作目录(Staging area)默认是`${hadoop.tmp.dir}/mapred/staging/denny/.staging/`。\n\n一般把前缀设置为`/user`，这是官方推荐的，见 [mapred-default.xml](http://hadoop.apache.org/docs/stable/hadoop-mapreduce-client/hadoop-mapreduce-client-core/mapred-default.xml) 里的`mapreduce.jobtracker.staging.root.dir`处：\n\n> The root of the staging area for users' job files In practice, this should be the directory where users' home directories are located (usually /user)\n\n    #以hadoop用户登录jobtracker机器\n    $ vim conf/mapred-site.xml\n    <property>\n      <name>mapreduce.jobtracker.staging.root.dir</name>\n      <value>/user</value>\n    </property>\n\n###2.4 重启hadoop集群\n将配置文件scp到所有机器，然后重启集群，\n\n    $ ./sbin/stop-yarn.sh\n    $ ./sbin/start-yarn.sh\n    $ ./sbin/stop-dfs.sh\n    $ ./sbin/start-dfs.sh\n\n##3. 测试一下\n回到客户端机器。\n\n将输入数据拷贝到分布式文件系统中:\n\n    $ ./bin/hdfs dfs -put /etc/hadoop input\n    $ ./bin/hdfs dfs -ls input\n\n运行 Hadoop 自带的例子:\n\n    $ ./bin/$ hadoop jar $HADOOP_PREFIX/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.2.0.jar wordcount input output\n\n查看输出文件:\n\n    $ hdfs dfs -lsr output\n    $ hdfs dfs -cat output/part-r-00000\n\n如果能看到结果，说明这个例子运行成功。\n\n###4 （可选）将bin目录加入PATH\n这样就不用每次都cd到Hadoop目录，执行命令了。\n\n在 `~/.bashrc`中添加如下4行：\n\n    export HADOOP_PREFIX=$HOME/local/opt/hadoop-2.2.0\n    export PATH=$PATH:$HADOOP_PREFIX/bin\n    alias hls=\"hdfs dfs -ls\"\n\nsource使之立刻生效，\n\n\t$ source ~/.bashrc\n\n##参考资料\n\n1. [hadoop远程客户端安装配置、多用户权限配置](http://blog.csdn.net/j3smile/article/details/7887826)\n1. [hadoop如何创建多用户](http://blog.csdn.net/a999wt/article/details/8718707)\n1. [关于多用户时hadoop的权限问题](http://blog.sina.com.cn/s/blog_605f5b4f0101897z.html)\n1. [MapReduce: Job提交过程](http://langyu.iteye.com/blog/909170)\n1. [hadoop中的dfs.name.dir,mapred.local.dir,mapred.system.dir和hadoop.tmp.dir说明](http://www.hadoopor.com/archiver/tid-481.html)\n1. [Hadoop 參數設定 – mapred-site.xml](http://fenriswolf.me/2012/08/06/hadoop-%E5%8F%83%E6%95%B8%E8%A8%AD%E5%AE%9A-mapred-site-xml/)\n\n","source":"_posts/2014-02-06-hadoop-multiple-users.md","raw":"---\nlayout: post\ntitle: \"Hadoop多用户的配置(Hadoop 2.x)\"\ndate: 2014-02-06 10:05\ncomments: true\ncategories: Hadoop\n---\n假设我们以名为hadoop的用户，建好了集群，见[在CentOS上安装Hadoop 2.x 集群](http://www.yanjiuyanjiu.com/blog/20140205/)。通常，我们会把这个集群共享给多个用户，而不是让大家都登录为hadoop，这样做有几个好处：\n\n* 一个用户不能修改另一个用户的的文件\n* 在hadoop web管理页面，可以很方便的看到不同的用户的job\n\n现在集群中有一台机器，上面有一个用户名为 hbase 的用户，他想要使用hadoop集群，怎么配置呢？\n\n##1. 安装hadoop客户端\n\n###1.1 下载，解压\n下载跟hadoop集群一样的hadoop软件包，并解压，\n\n    $ wget http://mirrors.hust.edu.cn/apache/hadoop/common/hadoop-2.2.0/hadoop-2.2.0.tar.gz\n    $ tar -zxf hadoop-2.2.0.tar.gz -C ~/local/opt\n    $ cd ~/local/opt/hadoop-2.2.0\n\n###1.2 拷贝Hadoop集群的配置文件\n将Hadoop集群的配置文件全部拷贝到客户端，相当与把集群的信息告诉客户端。\n\n    $ scp -r hadoop@localhost:~/local/opt/hadoop-2.2.0/etc/hadoop ./etc/\n\n修改conf/mapred-site.xml中的`mapreduce.cluster.local.dir`，改为本机上的某个目录，确保这个目录存在且有写权限。因为这个目录是本地目录，每台机器都可以不同。例如我的是：\n\n    <property>\n      <name>mapreduce.cluster.local.dir</name>\n      <value>/home/soulmachine/local/var/hadoop/mapred/local</value>\n    </property>\n\n确保这个目录存在，\n\n    $ mkdir -p ~/local/var/hadoop/mapred/local\n\n<!-- more -->\n\n还有另一种方法，由于`mapreduce.cluster.local.dir`默认值是`${hadoop.tmp.dir}/mapred/local`，也可以通过修改`hadoop.tmp.dir`达到目的，在`core-site.xml`中，确保`${hadoop.tmp.dir}/mapred/local`存在且有写权限。\n\n\n##2. 在master上配置权限\n以下操作均在hadoop集群的 namenode 这台机器上进行，且登录为hadoop，因为hadoop这个用户是整个hadoop集群权限最高的用户（但对于Linux系统本身，这个用户其实没有sudo权限）。\n\nHadoop关于用户权限方面，有很多高级的配置，这里我们简单的利用HDFS本身的文件权限检查机制，来配置多用户。\n\nHDFS本身没有提供用户名、用户组的创建，在客户端调用hadoop 的文件操作命令时，hadoop 识别出执行命令所在进程的linux系统的用户名和用户组，然后使用这个用户名和组来检查文件权限。 用户名=linux命令中的`whoami`，而组名等于`groups`。 \n\n启动hadoop hdfs系统的用户即为超级用户（在这里就是名为hadoop的这个用户），可以进行任意的操作。\n\n在客户端机器上，用gropus命令看一下hbase所在的组，\n\n    $ groups\n    hbase\n\n说明hbase这个用户所在的组为hbase。\n\n###2.1 为客户端用户创建home文件夹\n\n    $ hdfs dfs -mkdir /user/hbase\n    $ hdfs dfs -chown hbase /user/hbase\n    $ hdfs dfs -chgrp hbase /user/hbase\n\n###2.2 设置HDFS上的/tmp目录的权限\n客户端提交job的时候，需要往/tmp里写入文件，因此最好把/tmp设置为所有用户都有可读、可写和可执行的权限。 \n\n    $ hdfs dfs -chmod -R 777 /tmp\n\n###2.3 设置mapreduce.jobtracker.staging.root.dir\n客户端向集群提交任务时，需要把该job需要的文件打包，拷贝到HDFS上。在拷贝之前，得先确定这些资源文件存放在HDFS的什么地方。JobTracker设置有一个工作目录(Staging area, 也称数据中转站)，用来存储与每个job相关的数据。这个目录的前缀由`mapreduce.jobtracker.staging.root.dir` 参数来指定，默认是`${hadoop.tmp.dir}/mapred/staging`，每个client user可以提交多个job，在这个目录后就得附加user name的信息。所以这个工作目录(Staging area)默认是`${hadoop.tmp.dir}/mapred/staging/denny/.staging/`。\n\n一般把前缀设置为`/user`，这是官方推荐的，见 [mapred-default.xml](http://hadoop.apache.org/docs/stable/hadoop-mapreduce-client/hadoop-mapreduce-client-core/mapred-default.xml) 里的`mapreduce.jobtracker.staging.root.dir`处：\n\n> The root of the staging area for users' job files In practice, this should be the directory where users' home directories are located (usually /user)\n\n    #以hadoop用户登录jobtracker机器\n    $ vim conf/mapred-site.xml\n    <property>\n      <name>mapreduce.jobtracker.staging.root.dir</name>\n      <value>/user</value>\n    </property>\n\n###2.4 重启hadoop集群\n将配置文件scp到所有机器，然后重启集群，\n\n    $ ./sbin/stop-yarn.sh\n    $ ./sbin/start-yarn.sh\n    $ ./sbin/stop-dfs.sh\n    $ ./sbin/start-dfs.sh\n\n##3. 测试一下\n回到客户端机器。\n\n将输入数据拷贝到分布式文件系统中:\n\n    $ ./bin/hdfs dfs -put /etc/hadoop input\n    $ ./bin/hdfs dfs -ls input\n\n运行 Hadoop 自带的例子:\n\n    $ ./bin/$ hadoop jar $HADOOP_PREFIX/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.2.0.jar wordcount input output\n\n查看输出文件:\n\n    $ hdfs dfs -lsr output\n    $ hdfs dfs -cat output/part-r-00000\n\n如果能看到结果，说明这个例子运行成功。\n\n###4 （可选）将bin目录加入PATH\n这样就不用每次都cd到Hadoop目录，执行命令了。\n\n在 `~/.bashrc`中添加如下4行：\n\n    export HADOOP_PREFIX=$HOME/local/opt/hadoop-2.2.0\n    export PATH=$PATH:$HADOOP_PREFIX/bin\n    alias hls=\"hdfs dfs -ls\"\n\nsource使之立刻生效，\n\n\t$ source ~/.bashrc\n\n##参考资料\n\n1. [hadoop远程客户端安装配置、多用户权限配置](http://blog.csdn.net/j3smile/article/details/7887826)\n1. [hadoop如何创建多用户](http://blog.csdn.net/a999wt/article/details/8718707)\n1. [关于多用户时hadoop的权限问题](http://blog.sina.com.cn/s/blog_605f5b4f0101897z.html)\n1. [MapReduce: Job提交过程](http://langyu.iteye.com/blog/909170)\n1. [hadoop中的dfs.name.dir,mapred.local.dir,mapred.system.dir和hadoop.tmp.dir说明](http://www.hadoopor.com/archiver/tid-481.html)\n1. [Hadoop 參數設定 – mapred-site.xml](http://fenriswolf.me/2012/08/06/hadoop-%E5%8F%83%E6%95%B8%E8%A8%AD%E5%AE%9A-mapred-site-xml/)\n\n","slug":"2014-02-06-hadoop-multiple-users","published":1,"updated":"2016-08-18T09:21:04.000Z","photos":[],"link":"","_id":"cis07pf4h003a01pq43firns7","content":"<p>假设我们以名为hadoop的用户，建好了集群，见<a href=\"http://www.yanjiuyanjiu.com/blog/20140205/\" target=\"_blank\" rel=\"external\">在CentOS上安装Hadoop 2.x 集群</a>。通常，我们会把这个集群共享给多个用户，而不是让大家都登录为hadoop，这样做有几个好处：</p>\n<ul>\n<li>一个用户不能修改另一个用户的的文件</li>\n<li>在hadoop web管理页面，可以很方便的看到不同的用户的job</li>\n</ul>\n<p>现在集群中有一台机器，上面有一个用户名为 hbase 的用户，他想要使用hadoop集群，怎么配置呢？</p>\n<p>##1. 安装hadoop客户端</p>\n<p>###1.1 下载，解压<br>下载跟hadoop集群一样的hadoop软件包，并解压，</p>\n<pre><code>$ wget http://mirrors.hust.edu.cn/apache/hadoop/common/hadoop-2.2.0/hadoop-2.2.0.tar.gz\n$ tar -zxf hadoop-2.2.0.tar.gz -C ~/local/opt\n$ cd ~/local/opt/hadoop-2.2.0\n</code></pre><p>###1.2 拷贝Hadoop集群的配置文件<br>将Hadoop集群的配置文件全部拷贝到客户端，相当与把集群的信息告诉客户端。</p>\n<pre><code>$ scp -r hadoop@localhost:~/local/opt/hadoop-2.2.0/etc/hadoop ./etc/\n</code></pre><p>修改conf/mapred-site.xml中的<code>mapreduce.cluster.local.dir</code>，改为本机上的某个目录，确保这个目录存在且有写权限。因为这个目录是本地目录，每台机器都可以不同。例如我的是：</p>\n<pre><code>&lt;property&gt;\n  &lt;name&gt;mapreduce.cluster.local.dir&lt;/name&gt;\n  &lt;value&gt;/home/soulmachine/local/var/hadoop/mapred/local&lt;/value&gt;\n&lt;/property&gt;\n</code></pre><p>确保这个目录存在，</p>\n<pre><code>$ mkdir -p ~/local/var/hadoop/mapred/local\n</code></pre><a id=\"more\"></a>\n<p>还有另一种方法，由于<code>mapreduce.cluster.local.dir</code>默认值是<code>${hadoop.tmp.dir}/mapred/local</code>，也可以通过修改<code>hadoop.tmp.dir</code>达到目的，在<code>core-site.xml</code>中，确保<code>${hadoop.tmp.dir}/mapred/local</code>存在且有写权限。</p>\n<p>##2. 在master上配置权限<br>以下操作均在hadoop集群的 namenode 这台机器上进行，且登录为hadoop，因为hadoop这个用户是整个hadoop集群权限最高的用户（但对于Linux系统本身，这个用户其实没有sudo权限）。</p>\n<p>Hadoop关于用户权限方面，有很多高级的配置，这里我们简单的利用HDFS本身的文件权限检查机制，来配置多用户。</p>\n<p>HDFS本身没有提供用户名、用户组的创建，在客户端调用hadoop 的文件操作命令时，hadoop 识别出执行命令所在进程的linux系统的用户名和用户组，然后使用这个用户名和组来检查文件权限。 用户名=linux命令中的<code>whoami</code>，而组名等于<code>groups</code>。 </p>\n<p>启动hadoop hdfs系统的用户即为超级用户（在这里就是名为hadoop的这个用户），可以进行任意的操作。</p>\n<p>在客户端机器上，用gropus命令看一下hbase所在的组，</p>\n<pre><code>$ groups\nhbase\n</code></pre><p>说明hbase这个用户所在的组为hbase。</p>\n<p>###2.1 为客户端用户创建home文件夹</p>\n<pre><code>$ hdfs dfs -mkdir /user/hbase\n$ hdfs dfs -chown hbase /user/hbase\n$ hdfs dfs -chgrp hbase /user/hbase\n</code></pre><p>###2.2 设置HDFS上的/tmp目录的权限<br>客户端提交job的时候，需要往/tmp里写入文件，因此最好把/tmp设置为所有用户都有可读、可写和可执行的权限。 </p>\n<pre><code>$ hdfs dfs -chmod -R 777 /tmp\n</code></pre><p>###2.3 设置mapreduce.jobtracker.staging.root.dir<br>客户端向集群提交任务时，需要把该job需要的文件打包，拷贝到HDFS上。在拷贝之前，得先确定这些资源文件存放在HDFS的什么地方。JobTracker设置有一个工作目录(Staging area, 也称数据中转站)，用来存储与每个job相关的数据。这个目录的前缀由<code>mapreduce.jobtracker.staging.root.dir</code> 参数来指定，默认是<code>${hadoop.tmp.dir}/mapred/staging</code>，每个client user可以提交多个job，在这个目录后就得附加user name的信息。所以这个工作目录(Staging area)默认是<code>${hadoop.tmp.dir}/mapred/staging/denny/.staging/</code>。</p>\n<p>一般把前缀设置为<code>/user</code>，这是官方推荐的，见 <a href=\"http://hadoop.apache.org/docs/stable/hadoop-mapreduce-client/hadoop-mapreduce-client-core/mapred-default.xml\" target=\"_blank\" rel=\"external\">mapred-default.xml</a> 里的<code>mapreduce.jobtracker.staging.root.dir</code>处：</p>\n<blockquote>\n<p>The root of the staging area for users’ job files In practice, this should be the directory where users’ home directories are located (usually /user)</p>\n</blockquote>\n<pre><code>#以hadoop用户登录jobtracker机器\n$ vim conf/mapred-site.xml\n&lt;property&gt;\n  &lt;name&gt;mapreduce.jobtracker.staging.root.dir&lt;/name&gt;\n  &lt;value&gt;/user&lt;/value&gt;\n&lt;/property&gt;\n</code></pre><p>###2.4 重启hadoop集群<br>将配置文件scp到所有机器，然后重启集群，</p>\n<pre><code>$ ./sbin/stop-yarn.sh\n$ ./sbin/start-yarn.sh\n$ ./sbin/stop-dfs.sh\n$ ./sbin/start-dfs.sh\n</code></pre><p>##3. 测试一下<br>回到客户端机器。</p>\n<p>将输入数据拷贝到分布式文件系统中:</p>\n<pre><code>$ ./bin/hdfs dfs -put /etc/hadoop input\n$ ./bin/hdfs dfs -ls input\n</code></pre><p>运行 Hadoop 自带的例子:</p>\n<pre><code>$ ./bin/$ hadoop jar $HADOOP_PREFIX/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.2.0.jar wordcount input output\n</code></pre><p>查看输出文件:</p>\n<pre><code>$ hdfs dfs -lsr output\n$ hdfs dfs -cat output/part-r-00000\n</code></pre><p>如果能看到结果，说明这个例子运行成功。</p>\n<p>###4 （可选）将bin目录加入PATH<br>这样就不用每次都cd到Hadoop目录，执行命令了。</p>\n<p>在 <code>~/.bashrc</code>中添加如下4行：</p>\n<pre><code>export HADOOP_PREFIX=$HOME/local/opt/hadoop-2.2.0\nexport PATH=$PATH:$HADOOP_PREFIX/bin\nalias hls=&quot;hdfs dfs -ls&quot;\n</code></pre><p>source使之立刻生效，</p>\n<pre><code>$ source ~/.bashrc\n</code></pre><p>##参考资料</p>\n<ol>\n<li><a href=\"http://blog.csdn.net/j3smile/article/details/7887826\" target=\"_blank\" rel=\"external\">hadoop远程客户端安装配置、多用户权限配置</a></li>\n<li><a href=\"http://blog.csdn.net/a999wt/article/details/8718707\" target=\"_blank\" rel=\"external\">hadoop如何创建多用户</a></li>\n<li><a href=\"http://blog.sina.com.cn/s/blog_605f5b4f0101897z.html\" target=\"_blank\" rel=\"external\">关于多用户时hadoop的权限问题</a></li>\n<li><a href=\"http://langyu.iteye.com/blog/909170\" target=\"_blank\" rel=\"external\">MapReduce: Job提交过程</a></li>\n<li><a href=\"http://www.hadoopor.com/archiver/tid-481.html\" target=\"_blank\" rel=\"external\">hadoop中的dfs.name.dir,mapred.local.dir,mapred.system.dir和hadoop.tmp.dir说明</a></li>\n<li><a href=\"http://fenriswolf.me/2012/08/06/hadoop-%E5%8F%83%E6%95%B8%E8%A8%AD%E5%AE%9A-mapred-site-xml/\" target=\"_blank\" rel=\"external\">Hadoop 參數設定 – mapred-site.xml</a></li>\n</ol>\n","excerpt":"<p>假设我们以名为hadoop的用户，建好了集群，见<a href=\"http://www.yanjiuyanjiu.com/blog/20140205/\">在CentOS上安装Hadoop 2.x 集群</a>。通常，我们会把这个集群共享给多个用户，而不是让大家都登录为hadoop，这样做有几个好处：</p>\n<ul>\n<li>一个用户不能修改另一个用户的的文件</li>\n<li>在hadoop web管理页面，可以很方便的看到不同的用户的job</li>\n</ul>\n<p>现在集群中有一台机器，上面有一个用户名为 hbase 的用户，他想要使用hadoop集群，怎么配置呢？</p>\n<p>##1. 安装hadoop客户端</p>\n<p>###1.1 下载，解压<br>下载跟hadoop集群一样的hadoop软件包，并解压，</p>\n<pre><code>$ wget http://mirrors.hust.edu.cn/apache/hadoop/common/hadoop-2.2.0/hadoop-2.2.0.tar.gz\n$ tar -zxf hadoop-2.2.0.tar.gz -C ~/local/opt\n$ cd ~/local/opt/hadoop-2.2.0\n</code></pre><p>###1.2 拷贝Hadoop集群的配置文件<br>将Hadoop集群的配置文件全部拷贝到客户端，相当与把集群的信息告诉客户端。</p>\n<pre><code>$ scp -r hadoop@localhost:~/local/opt/hadoop-2.2.0/etc/hadoop ./etc/\n</code></pre><p>修改conf/mapred-site.xml中的<code>mapreduce.cluster.local.dir</code>，改为本机上的某个目录，确保这个目录存在且有写权限。因为这个目录是本地目录，每台机器都可以不同。例如我的是：</p>\n<pre><code>&lt;property&gt;\n  &lt;name&gt;mapreduce.cluster.local.dir&lt;/name&gt;\n  &lt;value&gt;/home/soulmachine/local/var/hadoop/mapred/local&lt;/value&gt;\n&lt;/property&gt;\n</code></pre><p>确保这个目录存在，</p>\n<pre><code>$ mkdir -p ~/local/var/hadoop/mapred/local\n</code></pre>","more":"<p>还有另一种方法，由于<code>mapreduce.cluster.local.dir</code>默认值是<code>${hadoop.tmp.dir}/mapred/local</code>，也可以通过修改<code>hadoop.tmp.dir</code>达到目的，在<code>core-site.xml</code>中，确保<code>${hadoop.tmp.dir}/mapred/local</code>存在且有写权限。</p>\n<p>##2. 在master上配置权限<br>以下操作均在hadoop集群的 namenode 这台机器上进行，且登录为hadoop，因为hadoop这个用户是整个hadoop集群权限最高的用户（但对于Linux系统本身，这个用户其实没有sudo权限）。</p>\n<p>Hadoop关于用户权限方面，有很多高级的配置，这里我们简单的利用HDFS本身的文件权限检查机制，来配置多用户。</p>\n<p>HDFS本身没有提供用户名、用户组的创建，在客户端调用hadoop 的文件操作命令时，hadoop 识别出执行命令所在进程的linux系统的用户名和用户组，然后使用这个用户名和组来检查文件权限。 用户名=linux命令中的<code>whoami</code>，而组名等于<code>groups</code>。 </p>\n<p>启动hadoop hdfs系统的用户即为超级用户（在这里就是名为hadoop的这个用户），可以进行任意的操作。</p>\n<p>在客户端机器上，用gropus命令看一下hbase所在的组，</p>\n<pre><code>$ groups\nhbase\n</code></pre><p>说明hbase这个用户所在的组为hbase。</p>\n<p>###2.1 为客户端用户创建home文件夹</p>\n<pre><code>$ hdfs dfs -mkdir /user/hbase\n$ hdfs dfs -chown hbase /user/hbase\n$ hdfs dfs -chgrp hbase /user/hbase\n</code></pre><p>###2.2 设置HDFS上的/tmp目录的权限<br>客户端提交job的时候，需要往/tmp里写入文件，因此最好把/tmp设置为所有用户都有可读、可写和可执行的权限。 </p>\n<pre><code>$ hdfs dfs -chmod -R 777 /tmp\n</code></pre><p>###2.3 设置mapreduce.jobtracker.staging.root.dir<br>客户端向集群提交任务时，需要把该job需要的文件打包，拷贝到HDFS上。在拷贝之前，得先确定这些资源文件存放在HDFS的什么地方。JobTracker设置有一个工作目录(Staging area, 也称数据中转站)，用来存储与每个job相关的数据。这个目录的前缀由<code>mapreduce.jobtracker.staging.root.dir</code> 参数来指定，默认是<code>${hadoop.tmp.dir}/mapred/staging</code>，每个client user可以提交多个job，在这个目录后就得附加user name的信息。所以这个工作目录(Staging area)默认是<code>${hadoop.tmp.dir}/mapred/staging/denny/.staging/</code>。</p>\n<p>一般把前缀设置为<code>/user</code>，这是官方推荐的，见 <a href=\"http://hadoop.apache.org/docs/stable/hadoop-mapreduce-client/hadoop-mapreduce-client-core/mapred-default.xml\">mapred-default.xml</a> 里的<code>mapreduce.jobtracker.staging.root.dir</code>处：</p>\n<blockquote>\n<p>The root of the staging area for users’ job files In practice, this should be the directory where users’ home directories are located (usually /user)</p>\n</blockquote>\n<pre><code>#以hadoop用户登录jobtracker机器\n$ vim conf/mapred-site.xml\n&lt;property&gt;\n  &lt;name&gt;mapreduce.jobtracker.staging.root.dir&lt;/name&gt;\n  &lt;value&gt;/user&lt;/value&gt;\n&lt;/property&gt;\n</code></pre><p>###2.4 重启hadoop集群<br>将配置文件scp到所有机器，然后重启集群，</p>\n<pre><code>$ ./sbin/stop-yarn.sh\n$ ./sbin/start-yarn.sh\n$ ./sbin/stop-dfs.sh\n$ ./sbin/start-dfs.sh\n</code></pre><p>##3. 测试一下<br>回到客户端机器。</p>\n<p>将输入数据拷贝到分布式文件系统中:</p>\n<pre><code>$ ./bin/hdfs dfs -put /etc/hadoop input\n$ ./bin/hdfs dfs -ls input\n</code></pre><p>运行 Hadoop 自带的例子:</p>\n<pre><code>$ ./bin/$ hadoop jar $HADOOP_PREFIX/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.2.0.jar wordcount input output\n</code></pre><p>查看输出文件:</p>\n<pre><code>$ hdfs dfs -lsr output\n$ hdfs dfs -cat output/part-r-00000\n</code></pre><p>如果能看到结果，说明这个例子运行成功。</p>\n<p>###4 （可选）将bin目录加入PATH<br>这样就不用每次都cd到Hadoop目录，执行命令了。</p>\n<p>在 <code>~/.bashrc</code>中添加如下4行：</p>\n<pre><code>export HADOOP_PREFIX=$HOME/local/opt/hadoop-2.2.0\nexport PATH=$PATH:$HADOOP_PREFIX/bin\nalias hls=&quot;hdfs dfs -ls&quot;\n</code></pre><p>source使之立刻生效，</p>\n<pre><code>$ source ~/.bashrc\n</code></pre><p>##参考资料</p>\n<ol>\n<li><a href=\"http://blog.csdn.net/j3smile/article/details/7887826\">hadoop远程客户端安装配置、多用户权限配置</a></li>\n<li><a href=\"http://blog.csdn.net/a999wt/article/details/8718707\">hadoop如何创建多用户</a></li>\n<li><a href=\"http://blog.sina.com.cn/s/blog_605f5b4f0101897z.html\">关于多用户时hadoop的权限问题</a></li>\n<li><a href=\"http://langyu.iteye.com/blog/909170\">MapReduce: Job提交过程</a></li>\n<li><a href=\"http://www.hadoopor.com/archiver/tid-481.html\">hadoop中的dfs.name.dir,mapred.local.dir,mapred.system.dir和hadoop.tmp.dir说明</a></li>\n<li><a href=\"http://fenriswolf.me/2012/08/06/hadoop-%E5%8F%83%E6%95%B8%E8%A8%AD%E5%AE%9A-mapred-site-xml/\">Hadoop 參數設定 – mapred-site.xml</a></li>\n</ol>"},{"layout":"post","title":"在CentOS上安装ZooKeeper集群","date":"2014-02-07T23:40:00.000Z","comments":1,"_content":"\n环境：CentOS 6.5, jdk 1.7, ZooKeeper 3.4.5\n\n本文主要参考官网的[Getting Started](http://zookeeper.apache.org/doc/trunk/zookeeperStarted.html)\n\n\n##（可选）创建新用户\n一般我倾向于把需要启动daemon进程，对外提供服务的程序，即服务器类的程序，安装在单独的用户下面。这样可以做到隔离，运维方面，安全性也提高了。\n\n创建一个新的group,\n\n    $ sudo groupadd zookeeper\n\n创建一个新的用户，并加入group,\n\n    $ sudo useradd -g zookeeper zookeeper\n\n给新用户设置密码，\n\n    $ sudo passwd zookeeper\n\n\n##1. 单机模式(Standalone mode)\n单机模式在开发和调试阶段很有用。\n\n###1.1 下载，解压\n\n    $ wget http://mirror.bit.edu.cn/apache/zookeeper/zookeeper-3.4.5/zookeeper-3.4.5.tar.gz\n    $ tar zxf zookeeper-3.4.5.tar.gz -C ~/local/opt\n\n###1.2 启动\n默认就是单机模式，\n\n    $ mv conf/zoo_sample.cfg conf/zoo.cfg\n    $ ./bin/zdServer.sh start\n\n###1.3 使用java 客户端连接ZooKeeper\n\n    $ ./bin/zkCli.sh -server 127.0.0.1:2181\n\n然后就可以使用各种命令了，跟文件操作命令很类似，输入`help`可以看到所有命令。\n\n####1.4 关闭\n\n    $ ./bin/zdServer.sh stop\n\n##2. 分布式模式(Replicated mode)\n在生产环境中，要配置成分布式模式，才能发挥威力。\n\n<!-- more -->\n\nZooKeeper集群一般被称为ZooKeeper ensemble，或者  quorum.\n\n###2.1 准备3台机器\n假设有三台机器，hostname和ip对应关系是：\n\n\t192.168.1.131 zk01\n\t192.168.1.132 zk02\n\t192.168.1.133 zk03\n\nZooKeeper不存在明显的master/slave关系，各个节点都是服务器，leader挂了，会立马从follower中选举一个出来作为leader.\n\n由于没有主从关系，也不用配置SSH无密码登录了，各个zk服务器是自己启动的，互相之间通过TCP端口来交换数据。\n\n###2.2 修改配置文件conf/zoo.cfg\n\n\ttickTime=2000\n\tinitLimit=10\n\tsyncLimit=5\n\tdataDir=/home/zookeeper/local/var/zookeeper\n\tclientPort=2181\n\tserver.1=zk01:2888:3888\n\tserver.2=zk02:2888:3888\n\tserver.3=zk03:2888:3888\n\n我一般把服务器程序，即需要启动daemon进程的程序，放在单独的用户里安装；且用户的数据，放在`local/var`下面，所以我的dataDir是`/home/zookeeper/local/var/zookeeper`。\n\n###2.3 myid文件\n要在每台机器的dataDir下，新建一个myid文件，里面存放一个数字，用来标识当前主机。\n\n    zookeeper@zk01:$ echo \"1\" >> ~/local/var/zookeeper/myid\n    zookeeper@zk02:$ echo \"2\" >> ~/local/var/zookeeper/myid\n    zookeeper@zk03:$ echo \"3\" >> ~/local/var/zookeeper/myid\n\n###2.4 启动每台机器\n\n    zookeeper@zk01:$ ~/local/opt/zookeeper-3.4.5/bin/zkServer.sh start\n    zookeeper@zk02:$ ~/local/opt/zookeeper-3.4.5/bin/zkServer.sh start\n    zookeeper@zk03:$ ~/local/opt/zookeeper-3.4.5/bin/zkServer.sh start\n\n因为3个节点的启动是有顺序的，所以在陆续启动三个节点的时候，前面先启动的节点连接未启动的节点的时候会报出一些错误。可以忽略。\n\n###2.5 查看状态\n\n    $ ~/local/opt/zookeeper-3.4.5/bin/zkServer.sh status\n\n##3 使用java客户端连接ZooKeeper集群\n\n找一台机器，解压zookeeper压缩包，不用配置，就可以使用java客户端连接ZooKeeper集群中的任意一台服务器了。\n\n    $ ./bin/zkCli.sh -server zk01:2181\n    $ ./bin/zkCli.sh -server zk01:2181\n    $ ./bin/zkCli.sh -server zk01:2181\n\n连接上以后，就可以执行各种命令，使用`help`查看帮助。\n\n\n##参考资料\n\n1. [Getting Started](http://zookeeper.apache.org/doc/trunk/zookeeperStarted.html)\n1. [Zookeeper 3.4.5 集群安装笔记](http://blog.csdn.net/jmy99527/article/details/17582349)\n\n","source":"_posts/2014-02-07-install-zookeeper-on-centos.md","raw":"---\nlayout: post\ntitle: \"在CentOS上安装ZooKeeper集群\"\ndate: 2014-02-07 23:40\ncomments: true\ncategories: Hadoop\n---\n\n环境：CentOS 6.5, jdk 1.7, ZooKeeper 3.4.5\n\n本文主要参考官网的[Getting Started](http://zookeeper.apache.org/doc/trunk/zookeeperStarted.html)\n\n\n##（可选）创建新用户\n一般我倾向于把需要启动daemon进程，对外提供服务的程序，即服务器类的程序，安装在单独的用户下面。这样可以做到隔离，运维方面，安全性也提高了。\n\n创建一个新的group,\n\n    $ sudo groupadd zookeeper\n\n创建一个新的用户，并加入group,\n\n    $ sudo useradd -g zookeeper zookeeper\n\n给新用户设置密码，\n\n    $ sudo passwd zookeeper\n\n\n##1. 单机模式(Standalone mode)\n单机模式在开发和调试阶段很有用。\n\n###1.1 下载，解压\n\n    $ wget http://mirror.bit.edu.cn/apache/zookeeper/zookeeper-3.4.5/zookeeper-3.4.5.tar.gz\n    $ tar zxf zookeeper-3.4.5.tar.gz -C ~/local/opt\n\n###1.2 启动\n默认就是单机模式，\n\n    $ mv conf/zoo_sample.cfg conf/zoo.cfg\n    $ ./bin/zdServer.sh start\n\n###1.3 使用java 客户端连接ZooKeeper\n\n    $ ./bin/zkCli.sh -server 127.0.0.1:2181\n\n然后就可以使用各种命令了，跟文件操作命令很类似，输入`help`可以看到所有命令。\n\n####1.4 关闭\n\n    $ ./bin/zdServer.sh stop\n\n##2. 分布式模式(Replicated mode)\n在生产环境中，要配置成分布式模式，才能发挥威力。\n\n<!-- more -->\n\nZooKeeper集群一般被称为ZooKeeper ensemble，或者  quorum.\n\n###2.1 准备3台机器\n假设有三台机器，hostname和ip对应关系是：\n\n\t192.168.1.131 zk01\n\t192.168.1.132 zk02\n\t192.168.1.133 zk03\n\nZooKeeper不存在明显的master/slave关系，各个节点都是服务器，leader挂了，会立马从follower中选举一个出来作为leader.\n\n由于没有主从关系，也不用配置SSH无密码登录了，各个zk服务器是自己启动的，互相之间通过TCP端口来交换数据。\n\n###2.2 修改配置文件conf/zoo.cfg\n\n\ttickTime=2000\n\tinitLimit=10\n\tsyncLimit=5\n\tdataDir=/home/zookeeper/local/var/zookeeper\n\tclientPort=2181\n\tserver.1=zk01:2888:3888\n\tserver.2=zk02:2888:3888\n\tserver.3=zk03:2888:3888\n\n我一般把服务器程序，即需要启动daemon进程的程序，放在单独的用户里安装；且用户的数据，放在`local/var`下面，所以我的dataDir是`/home/zookeeper/local/var/zookeeper`。\n\n###2.3 myid文件\n要在每台机器的dataDir下，新建一个myid文件，里面存放一个数字，用来标识当前主机。\n\n    zookeeper@zk01:$ echo \"1\" >> ~/local/var/zookeeper/myid\n    zookeeper@zk02:$ echo \"2\" >> ~/local/var/zookeeper/myid\n    zookeeper@zk03:$ echo \"3\" >> ~/local/var/zookeeper/myid\n\n###2.4 启动每台机器\n\n    zookeeper@zk01:$ ~/local/opt/zookeeper-3.4.5/bin/zkServer.sh start\n    zookeeper@zk02:$ ~/local/opt/zookeeper-3.4.5/bin/zkServer.sh start\n    zookeeper@zk03:$ ~/local/opt/zookeeper-3.4.5/bin/zkServer.sh start\n\n因为3个节点的启动是有顺序的，所以在陆续启动三个节点的时候，前面先启动的节点连接未启动的节点的时候会报出一些错误。可以忽略。\n\n###2.5 查看状态\n\n    $ ~/local/opt/zookeeper-3.4.5/bin/zkServer.sh status\n\n##3 使用java客户端连接ZooKeeper集群\n\n找一台机器，解压zookeeper压缩包，不用配置，就可以使用java客户端连接ZooKeeper集群中的任意一台服务器了。\n\n    $ ./bin/zkCli.sh -server zk01:2181\n    $ ./bin/zkCli.sh -server zk01:2181\n    $ ./bin/zkCli.sh -server zk01:2181\n\n连接上以后，就可以执行各种命令，使用`help`查看帮助。\n\n\n##参考资料\n\n1. [Getting Started](http://zookeeper.apache.org/doc/trunk/zookeeperStarted.html)\n1. [Zookeeper 3.4.5 集群安装笔记](http://blog.csdn.net/jmy99527/article/details/17582349)\n\n","slug":"2014-02-07-install-zookeeper-on-centos","published":1,"updated":"2016-08-18T09:21:04.000Z","photos":[],"link":"","_id":"cis07pf4i003c01pq6i28gg07","content":"<p>环境：CentOS 6.5, jdk 1.7, ZooKeeper 3.4.5</p>\n<p>本文主要参考官网的<a href=\"http://zookeeper.apache.org/doc/trunk/zookeeperStarted.html\" target=\"_blank\" rel=\"external\">Getting Started</a></p>\n<p>##（可选）创建新用户<br>一般我倾向于把需要启动daemon进程，对外提供服务的程序，即服务器类的程序，安装在单独的用户下面。这样可以做到隔离，运维方面，安全性也提高了。</p>\n<p>创建一个新的group,</p>\n<pre><code>$ sudo groupadd zookeeper\n</code></pre><p>创建一个新的用户，并加入group,</p>\n<pre><code>$ sudo useradd -g zookeeper zookeeper\n</code></pre><p>给新用户设置密码，</p>\n<pre><code>$ sudo passwd zookeeper\n</code></pre><p>##1. 单机模式(Standalone mode)<br>单机模式在开发和调试阶段很有用。</p>\n<p>###1.1 下载，解压</p>\n<pre><code>$ wget http://mirror.bit.edu.cn/apache/zookeeper/zookeeper-3.4.5/zookeeper-3.4.5.tar.gz\n$ tar zxf zookeeper-3.4.5.tar.gz -C ~/local/opt\n</code></pre><p>###1.2 启动<br>默认就是单机模式，</p>\n<pre><code>$ mv conf/zoo_sample.cfg conf/zoo.cfg\n$ ./bin/zdServer.sh start\n</code></pre><p>###1.3 使用java 客户端连接ZooKeeper</p>\n<pre><code>$ ./bin/zkCli.sh -server 127.0.0.1:2181\n</code></pre><p>然后就可以使用各种命令了，跟文件操作命令很类似，输入<code>help</code>可以看到所有命令。</p>\n<p>####1.4 关闭</p>\n<pre><code>$ ./bin/zdServer.sh stop\n</code></pre><p>##2. 分布式模式(Replicated mode)<br>在生产环境中，要配置成分布式模式，才能发挥威力。</p>\n<a id=\"more\"></a>\n<p>ZooKeeper集群一般被称为ZooKeeper ensemble，或者  quorum.</p>\n<p>###2.1 准备3台机器<br>假设有三台机器，hostname和ip对应关系是：</p>\n<pre><code>192.168.1.131 zk01\n192.168.1.132 zk02\n192.168.1.133 zk03\n</code></pre><p>ZooKeeper不存在明显的master/slave关系，各个节点都是服务器，leader挂了，会立马从follower中选举一个出来作为leader.</p>\n<p>由于没有主从关系，也不用配置SSH无密码登录了，各个zk服务器是自己启动的，互相之间通过TCP端口来交换数据。</p>\n<p>###2.2 修改配置文件conf/zoo.cfg</p>\n<pre><code>tickTime=2000\ninitLimit=10\nsyncLimit=5\ndataDir=/home/zookeeper/local/var/zookeeper\nclientPort=2181\nserver.1=zk01:2888:3888\nserver.2=zk02:2888:3888\nserver.3=zk03:2888:3888\n</code></pre><p>我一般把服务器程序，即需要启动daemon进程的程序，放在单独的用户里安装；且用户的数据，放在<code>local/var</code>下面，所以我的dataDir是<code>/home/zookeeper/local/var/zookeeper</code>。</p>\n<p>###2.3 myid文件<br>要在每台机器的dataDir下，新建一个myid文件，里面存放一个数字，用来标识当前主机。</p>\n<pre><code>zookeeper@zk01:$ echo &quot;1&quot; &gt;&gt; ~/local/var/zookeeper/myid\nzookeeper@zk02:$ echo &quot;2&quot; &gt;&gt; ~/local/var/zookeeper/myid\nzookeeper@zk03:$ echo &quot;3&quot; &gt;&gt; ~/local/var/zookeeper/myid\n</code></pre><p>###2.4 启动每台机器</p>\n<pre><code>zookeeper@zk01:$ ~/local/opt/zookeeper-3.4.5/bin/zkServer.sh start\nzookeeper@zk02:$ ~/local/opt/zookeeper-3.4.5/bin/zkServer.sh start\nzookeeper@zk03:$ ~/local/opt/zookeeper-3.4.5/bin/zkServer.sh start\n</code></pre><p>因为3个节点的启动是有顺序的，所以在陆续启动三个节点的时候，前面先启动的节点连接未启动的节点的时候会报出一些错误。可以忽略。</p>\n<p>###2.5 查看状态</p>\n<pre><code>$ ~/local/opt/zookeeper-3.4.5/bin/zkServer.sh status\n</code></pre><p>##3 使用java客户端连接ZooKeeper集群</p>\n<p>找一台机器，解压zookeeper压缩包，不用配置，就可以使用java客户端连接ZooKeeper集群中的任意一台服务器了。</p>\n<pre><code>$ ./bin/zkCli.sh -server zk01:2181\n$ ./bin/zkCli.sh -server zk01:2181\n$ ./bin/zkCli.sh -server zk01:2181\n</code></pre><p>连接上以后，就可以执行各种命令，使用<code>help</code>查看帮助。</p>\n<p>##参考资料</p>\n<ol>\n<li><a href=\"http://zookeeper.apache.org/doc/trunk/zookeeperStarted.html\" target=\"_blank\" rel=\"external\">Getting Started</a></li>\n<li><a href=\"http://blog.csdn.net/jmy99527/article/details/17582349\" target=\"_blank\" rel=\"external\">Zookeeper 3.4.5 集群安装笔记</a></li>\n</ol>\n","excerpt":"<p>环境：CentOS 6.5, jdk 1.7, ZooKeeper 3.4.5</p>\n<p>本文主要参考官网的<a href=\"http://zookeeper.apache.org/doc/trunk/zookeeperStarted.html\">Getting Started</a></p>\n<p>##（可选）创建新用户<br>一般我倾向于把需要启动daemon进程，对外提供服务的程序，即服务器类的程序，安装在单独的用户下面。这样可以做到隔离，运维方面，安全性也提高了。</p>\n<p>创建一个新的group,</p>\n<pre><code>$ sudo groupadd zookeeper\n</code></pre><p>创建一个新的用户，并加入group,</p>\n<pre><code>$ sudo useradd -g zookeeper zookeeper\n</code></pre><p>给新用户设置密码，</p>\n<pre><code>$ sudo passwd zookeeper\n</code></pre><p>##1. 单机模式(Standalone mode)<br>单机模式在开发和调试阶段很有用。</p>\n<p>###1.1 下载，解压</p>\n<pre><code>$ wget http://mirror.bit.edu.cn/apache/zookeeper/zookeeper-3.4.5/zookeeper-3.4.5.tar.gz\n$ tar zxf zookeeper-3.4.5.tar.gz -C ~/local/opt\n</code></pre><p>###1.2 启动<br>默认就是单机模式，</p>\n<pre><code>$ mv conf/zoo_sample.cfg conf/zoo.cfg\n$ ./bin/zdServer.sh start\n</code></pre><p>###1.3 使用java 客户端连接ZooKeeper</p>\n<pre><code>$ ./bin/zkCli.sh -server 127.0.0.1:2181\n</code></pre><p>然后就可以使用各种命令了，跟文件操作命令很类似，输入<code>help</code>可以看到所有命令。</p>\n<p>####1.4 关闭</p>\n<pre><code>$ ./bin/zdServer.sh stop\n</code></pre><p>##2. 分布式模式(Replicated mode)<br>在生产环境中，要配置成分布式模式，才能发挥威力。</p>","more":"<p>ZooKeeper集群一般被称为ZooKeeper ensemble，或者  quorum.</p>\n<p>###2.1 准备3台机器<br>假设有三台机器，hostname和ip对应关系是：</p>\n<pre><code>192.168.1.131 zk01\n192.168.1.132 zk02\n192.168.1.133 zk03\n</code></pre><p>ZooKeeper不存在明显的master/slave关系，各个节点都是服务器，leader挂了，会立马从follower中选举一个出来作为leader.</p>\n<p>由于没有主从关系，也不用配置SSH无密码登录了，各个zk服务器是自己启动的，互相之间通过TCP端口来交换数据。</p>\n<p>###2.2 修改配置文件conf/zoo.cfg</p>\n<pre><code>tickTime=2000\ninitLimit=10\nsyncLimit=5\ndataDir=/home/zookeeper/local/var/zookeeper\nclientPort=2181\nserver.1=zk01:2888:3888\nserver.2=zk02:2888:3888\nserver.3=zk03:2888:3888\n</code></pre><p>我一般把服务器程序，即需要启动daemon进程的程序，放在单独的用户里安装；且用户的数据，放在<code>local/var</code>下面，所以我的dataDir是<code>/home/zookeeper/local/var/zookeeper</code>。</p>\n<p>###2.3 myid文件<br>要在每台机器的dataDir下，新建一个myid文件，里面存放一个数字，用来标识当前主机。</p>\n<pre><code>zookeeper@zk01:$ echo &quot;1&quot; &gt;&gt; ~/local/var/zookeeper/myid\nzookeeper@zk02:$ echo &quot;2&quot; &gt;&gt; ~/local/var/zookeeper/myid\nzookeeper@zk03:$ echo &quot;3&quot; &gt;&gt; ~/local/var/zookeeper/myid\n</code></pre><p>###2.4 启动每台机器</p>\n<pre><code>zookeeper@zk01:$ ~/local/opt/zookeeper-3.4.5/bin/zkServer.sh start\nzookeeper@zk02:$ ~/local/opt/zookeeper-3.4.5/bin/zkServer.sh start\nzookeeper@zk03:$ ~/local/opt/zookeeper-3.4.5/bin/zkServer.sh start\n</code></pre><p>因为3个节点的启动是有顺序的，所以在陆续启动三个节点的时候，前面先启动的节点连接未启动的节点的时候会报出一些错误。可以忽略。</p>\n<p>###2.5 查看状态</p>\n<pre><code>$ ~/local/opt/zookeeper-3.4.5/bin/zkServer.sh status\n</code></pre><p>##3 使用java客户端连接ZooKeeper集群</p>\n<p>找一台机器，解压zookeeper压缩包，不用配置，就可以使用java客户端连接ZooKeeper集群中的任意一台服务器了。</p>\n<pre><code>$ ./bin/zkCli.sh -server zk01:2181\n$ ./bin/zkCli.sh -server zk01:2181\n$ ./bin/zkCli.sh -server zk01:2181\n</code></pre><p>连接上以后，就可以执行各种命令，使用<code>help</code>查看帮助。</p>\n<p>##参考资料</p>\n<ol>\n<li><a href=\"http://zookeeper.apache.org/doc/trunk/zookeeperStarted.html\">Getting Started</a></li>\n<li><a href=\"http://blog.csdn.net/jmy99527/article/details/17582349\">Zookeeper 3.4.5 集群安装笔记</a></li>\n</ol>"},{"layout":"post","title":"install texlive 2013 iso","date":"2014-02-12T02:01:00.000Z","comments":1,"published":0,"_content":"\n下载光盘\n\nsudo mkdir /mnt/cdrom\nsudo mount -o loop path-to-iso /mnt/cdrom\n\ncd /mnt/cdrom\nsudo ./install-tl\n\n如果想图形界面安装，则先安装perl-tk\n\nsudo apt-get install perl-tk\n\n默认都是full-scheme安装的，即完整版\n\n默认安装在 /usr/local/texlive\n\n将/usr/local/texlive/2013/bin加入PATH\n\n\n\nsudo mkdir /usr/share/fonts/AdobeFonts\n拷贝四个字体文件到这个目录\nsudo chmod 644 /usr/share/fonts/AdobeFonts/*\n刷新字体缓存\n\n　　　　sudo  mkfontscale\n\n　　　　sudo mkfontdir\n\n　　　　sudo fc-cache -fsv\n\n首先，查看系统中安装的中文字体的名字。\n\n　　　　fc-list :lang=zh | sort\n\nhttp://blog.csdn.net/ustc_dylan/article/details/6196129\n\n\n","source":"_posts/2014-02-12-install-texlive-2013-iso.md","raw":"---\nlayout: post\ntitle: \"install texlive 2013 iso\"\ndate: 2014-02-12 02:01\ncomments: true\ncategories: Tools\npublished: false\n---\n\n下载光盘\n\nsudo mkdir /mnt/cdrom\nsudo mount -o loop path-to-iso /mnt/cdrom\n\ncd /mnt/cdrom\nsudo ./install-tl\n\n如果想图形界面安装，则先安装perl-tk\n\nsudo apt-get install perl-tk\n\n默认都是full-scheme安装的，即完整版\n\n默认安装在 /usr/local/texlive\n\n将/usr/local/texlive/2013/bin加入PATH\n\n\n\nsudo mkdir /usr/share/fonts/AdobeFonts\n拷贝四个字体文件到这个目录\nsudo chmod 644 /usr/share/fonts/AdobeFonts/*\n刷新字体缓存\n\n　　　　sudo  mkfontscale\n\n　　　　sudo mkfontdir\n\n　　　　sudo fc-cache -fsv\n\n首先，查看系统中安装的中文字体的名字。\n\n　　　　fc-list :lang=zh | sort\n\nhttp://blog.csdn.net/ustc_dylan/article/details/6196129\n\n\n","slug":"2014-02-12-install-texlive-2013-iso","updated":"2016-08-18T09:21:04.000Z","photos":[],"link":"","_id":"cis07pf4j003e01pqgmomq6mo","content":"<p>下载光盘</p>\n<p>sudo mkdir /mnt/cdrom<br>sudo mount -o loop path-to-iso /mnt/cdrom</p>\n<p>cd /mnt/cdrom<br>sudo ./install-tl</p>\n<p>如果想图形界面安装，则先安装perl-tk</p>\n<p>sudo apt-get install perl-tk</p>\n<p>默认都是full-scheme安装的，即完整版</p>\n<p>默认安装在 /usr/local/texlive</p>\n<p>将/usr/local/texlive/2013/bin加入PATH</p>\n<p>sudo mkdir /usr/share/fonts/AdobeFonts<br>拷贝四个字体文件到这个目录<br>sudo chmod 644 /usr/share/fonts/AdobeFonts/*<br>刷新字体缓存</p>\n<p>　　　　sudo  mkfontscale</p>\n<p>　　　　sudo mkfontdir</p>\n<p>　　　　sudo fc-cache -fsv</p>\n<p>首先，查看系统中安装的中文字体的名字。</p>\n<p>　　　　fc-list :lang=zh | sort</p>\n<p><a href=\"http://blog.csdn.net/ustc_dylan/article/details/6196129\" target=\"_blank\" rel=\"external\">http://blog.csdn.net/ustc_dylan/article/details/6196129</a></p>\n","excerpt":"","more":"<p>下载光盘</p>\n<p>sudo mkdir /mnt/cdrom<br>sudo mount -o loop path-to-iso /mnt/cdrom</p>\n<p>cd /mnt/cdrom<br>sudo ./install-tl</p>\n<p>如果想图形界面安装，则先安装perl-tk</p>\n<p>sudo apt-get install perl-tk</p>\n<p>默认都是full-scheme安装的，即完整版</p>\n<p>默认安装在 /usr/local/texlive</p>\n<p>将/usr/local/texlive/2013/bin加入PATH</p>\n<p>sudo mkdir /usr/share/fonts/AdobeFonts<br>拷贝四个字体文件到这个目录<br>sudo chmod 644 /usr/share/fonts/AdobeFonts/*<br>刷新字体缓存</p>\n<p>　　　　sudo  mkfontscale</p>\n<p>　　　　sudo mkfontdir</p>\n<p>　　　　sudo fc-cache -fsv</p>\n<p>首先，查看系统中安装的中文字体的名字。</p>\n<p>　　　　fc-list :lang=zh | sort</p>\n<p><a href=\"http://blog.csdn.net/ustc_dylan/article/details/6196129\">http://blog.csdn.net/ustc_dylan/article/details/6196129</a></p>\n"},{"layout":"post","title":"CentOS上编译 Hadoop 2.2.0","date":"2014-02-14T11:56:00.000Z","comments":1,"_content":"\n下载了Hadoop预编译好的二进制包，hadoop-2.2.0.tar.gz，启动起来后，总是出现这种警告：\n\n    WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n\n原因是apache官网提供的二进制包，里面的native库，是32位的，坑跌啊，现在服务器谁还有32位的啊。\n\n    $ file $HADOOP_PREFIX/lib/native/libhadoop.so.1.0.0\n    libhadoop.so.1.0.0: ELF 32-bit LSB shared object, Intel 80386, version 1 (SYSV), dynamically linked, BuildID[sha1]=0x9eb1d49b05f67d38454e42b216e053a27ae8bac9, not stripped\n\n我们需要下载Hadoop 2.2.0源码，在 64 位Linux下重新编译，然后把32位的native库用64位的native库替换。\n\n<!-- more -->\n\n##1. 下载Hadoop 2.2.0 源码包，并解压\n\n    $ wget http://mirrors.hust.edu.cn/apache/hadoop/common/hadoop-2.2.0/hadoop-2.2.0-src.tar.gz\n    $ tar zxf hadoop-2.2.0-src.tar.gz\n\n##2. 安装下面的软件\n\n     $ sudo yum install lzo-devel  zlib-devel  gcc autoconf automake libtool   ncurses-devel openssl-deve\n\n##3. 安装Maven\n不要使用最新的Maven 3.1.1。Hadoop 2.2.0的源码与Maven3.x存在兼容性问题，所以会出现\n\n    java.lang.NoClassDefFoundError: org/sonatype/aether/graph/DependencyFilter\n\n之类的错误。\n\n安装 Maven 3.0.5\n\n    $ wget http://mirror.esocc.com/apache/maven/maven-3/3.0.5/binaries/apache-maven-3.0.5-bin.tar.gz\n    $ sudo tar zxf apache-maven-3.0.5-bin.tar.gz -C /opt\n    $ sudo vim /etc/profile\n    export MAVEN_HOME=/opt/apache-maven-3.0.5\n    export PATH=$PATH:$MAVEN_HOME/bin\n\n注销并重新登录，让环境变量生效。\n\n##4. 安装Ant\n\n    $ wget http://apache.dataguru.cn//ant/binaries/apache-ant-1.9.3-bin.tar.gz\n    $ sudo tar zxf apache-ant-1.9.3-bin.tar.gz -C /opt\n    $ sudo vim /etc/profile\n    export ANT_HOME=/opt/apache-ant-1.9.3\n    export PATH=$PATH:$ANT_HOME/bin\n\n##5. 安装Findbugs\n\n    $ wget http://prdownloads.sourceforge.net/findbugs/findbugs-2.0.3.tar.gz?download\n    $ sudo tar zxf findbugs-2.0.3.tar.gz -C /opt\n    $ sudo vim /etc/profile\n    export FINDBUGS_HOME=/opt/findbugs-2.0.3\n    export PATH=$PATH:$FINDBUGS_HOME/bin\n\n##6. 安装protobuf\n编译Hadoop 2.2.0，需要protobuf的编译器protoc。一定需要protobuf 2.5.0以上，yum里的是2.3，太老了。因此下载源码，编译安装。\n\n    $ wget https://protobuf.googlecode.com/files/protobuf-2.5.0.tar.gz\n    $ tar zxf protobuf-2.5.0.tar.gz\n    $ cd protobuf-2.5.0\n    $ ./configure\n    $ make\n    $ sudo make install\n\n##7. 给Hadoop源码打一个patch\n最新的Hadoop 2.2.0 的Source Code 压缩包解压出来的code有个bug 需要patch后才能编译。否则编译hadoop-auth 会提示下面错误：\n\n    [ERROR] Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:2.5.1:testCompile (default-testCompile) on project hadoop-auth: Compilation failure: Compilation failure:\n    [ERROR] /home/chuan/trunk/hadoop-common-project/hadoop-auth/src/test/java/org/apache/hadoop/security/authentication/client/AuthenticatorTestCase.java:[84,13] cannot access org.mortbay.component.AbstractLifeCycle\n    [ERROR] class file for org.mortbay.component.AbstractLifeCycle not found\n\nPatch: <https://issues.apache.org/jira/browse/HADOOP-10110>\n\n##8. 编译 Hadoop\n\n    cd hadoop-2.2.0-src\n    mvn package -DskipTests -Pdist,native -Dtar\n\n##9. 替换掉32位的native库\n用 `hadoop-2.2.0-src/hadoop-dist/target/hadoop-2.2.0/lib/native` 替换掉 `hadoop-2.2.0/lib/native`。\n\n    rm -rf ~/local/opt/hadoop-2.2.0/lib/native\n    cp ./hadoop-dist/target/hadoop-2.2.0/lib/native ~/local/opt/hadoop-2.2.0/lib/\n\n然后重启Hadoop集群，会看到控制台下不再有警告信息了。\n    \n##10 解决Ubuntu下启动失败的问题\n在Ubuntu上，那就不是一点WARN了，而是启动不起来，会出错，原因在于，在`./sbin/start-dfs.sh`第55行，\n\n    NAMENODES=$($HADOOP_PREFIX/bin/hdfs getconf -namenodes)\n\n在shell里单独运行这样命令，\n\n    ./bin/hdfs getconf -namenodes\n\n    OpenJDK 64-Bit Server VM warning: You have loaded library /home/soulmachine/local/opt/hadoop-2.2.0/lib/native/libhadoop.so which might have disabled stack guard. The VM will try to fix the stack guard now.\n    It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.\n    14/02/14 13:14:50 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n    localhost\n    \n最后一行的localhost，才是有效的namenode，但是由于前面有一大堆warning，脚本把这一大堆字符串，按空格隔开，每个单词都看作是namenode，接下来就错的稀里哗啦。\n\n根本原因，还是因为32位native库。\n\n把自带的32位native目录删除，用编译好的64位native目录拷贝过去，再运行\n\n    ./bin/hdfs getconf -namenodes\n    localhost\n\n这下就对了！\n\n##参考资料\n\n1. [YARN加载本地库抛出Unable to load native-hadoop library解决办法](http://blog.csdn.net/lalaguozhe/article/details/10580727)\n1. [CentOS编译Hadoop 2.2.0 Pass 总结](http://blog.csdn.net/zwj0403/article/details/16855555)\n\n","source":"_posts/2014-02-14-compile-hadoop-220-on-centos.md","raw":"---\nlayout: post\ntitle: \"CentOS上编译 Hadoop 2.2.0\"\ndate: 2014-02-14 11:56\ncomments: true\ncategories: Hadoop\n---\n\n下载了Hadoop预编译好的二进制包，hadoop-2.2.0.tar.gz，启动起来后，总是出现这种警告：\n\n    WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n\n原因是apache官网提供的二进制包，里面的native库，是32位的，坑跌啊，现在服务器谁还有32位的啊。\n\n    $ file $HADOOP_PREFIX/lib/native/libhadoop.so.1.0.0\n    libhadoop.so.1.0.0: ELF 32-bit LSB shared object, Intel 80386, version 1 (SYSV), dynamically linked, BuildID[sha1]=0x9eb1d49b05f67d38454e42b216e053a27ae8bac9, not stripped\n\n我们需要下载Hadoop 2.2.0源码，在 64 位Linux下重新编译，然后把32位的native库用64位的native库替换。\n\n<!-- more -->\n\n##1. 下载Hadoop 2.2.0 源码包，并解压\n\n    $ wget http://mirrors.hust.edu.cn/apache/hadoop/common/hadoop-2.2.0/hadoop-2.2.0-src.tar.gz\n    $ tar zxf hadoop-2.2.0-src.tar.gz\n\n##2. 安装下面的软件\n\n     $ sudo yum install lzo-devel  zlib-devel  gcc autoconf automake libtool   ncurses-devel openssl-deve\n\n##3. 安装Maven\n不要使用最新的Maven 3.1.1。Hadoop 2.2.0的源码与Maven3.x存在兼容性问题，所以会出现\n\n    java.lang.NoClassDefFoundError: org/sonatype/aether/graph/DependencyFilter\n\n之类的错误。\n\n安装 Maven 3.0.5\n\n    $ wget http://mirror.esocc.com/apache/maven/maven-3/3.0.5/binaries/apache-maven-3.0.5-bin.tar.gz\n    $ sudo tar zxf apache-maven-3.0.5-bin.tar.gz -C /opt\n    $ sudo vim /etc/profile\n    export MAVEN_HOME=/opt/apache-maven-3.0.5\n    export PATH=$PATH:$MAVEN_HOME/bin\n\n注销并重新登录，让环境变量生效。\n\n##4. 安装Ant\n\n    $ wget http://apache.dataguru.cn//ant/binaries/apache-ant-1.9.3-bin.tar.gz\n    $ sudo tar zxf apache-ant-1.9.3-bin.tar.gz -C /opt\n    $ sudo vim /etc/profile\n    export ANT_HOME=/opt/apache-ant-1.9.3\n    export PATH=$PATH:$ANT_HOME/bin\n\n##5. 安装Findbugs\n\n    $ wget http://prdownloads.sourceforge.net/findbugs/findbugs-2.0.3.tar.gz?download\n    $ sudo tar zxf findbugs-2.0.3.tar.gz -C /opt\n    $ sudo vim /etc/profile\n    export FINDBUGS_HOME=/opt/findbugs-2.0.3\n    export PATH=$PATH:$FINDBUGS_HOME/bin\n\n##6. 安装protobuf\n编译Hadoop 2.2.0，需要protobuf的编译器protoc。一定需要protobuf 2.5.0以上，yum里的是2.3，太老了。因此下载源码，编译安装。\n\n    $ wget https://protobuf.googlecode.com/files/protobuf-2.5.0.tar.gz\n    $ tar zxf protobuf-2.5.0.tar.gz\n    $ cd protobuf-2.5.0\n    $ ./configure\n    $ make\n    $ sudo make install\n\n##7. 给Hadoop源码打一个patch\n最新的Hadoop 2.2.0 的Source Code 压缩包解压出来的code有个bug 需要patch后才能编译。否则编译hadoop-auth 会提示下面错误：\n\n    [ERROR] Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:2.5.1:testCompile (default-testCompile) on project hadoop-auth: Compilation failure: Compilation failure:\n    [ERROR] /home/chuan/trunk/hadoop-common-project/hadoop-auth/src/test/java/org/apache/hadoop/security/authentication/client/AuthenticatorTestCase.java:[84,13] cannot access org.mortbay.component.AbstractLifeCycle\n    [ERROR] class file for org.mortbay.component.AbstractLifeCycle not found\n\nPatch: <https://issues.apache.org/jira/browse/HADOOP-10110>\n\n##8. 编译 Hadoop\n\n    cd hadoop-2.2.0-src\n    mvn package -DskipTests -Pdist,native -Dtar\n\n##9. 替换掉32位的native库\n用 `hadoop-2.2.0-src/hadoop-dist/target/hadoop-2.2.0/lib/native` 替换掉 `hadoop-2.2.0/lib/native`。\n\n    rm -rf ~/local/opt/hadoop-2.2.0/lib/native\n    cp ./hadoop-dist/target/hadoop-2.2.0/lib/native ~/local/opt/hadoop-2.2.0/lib/\n\n然后重启Hadoop集群，会看到控制台下不再有警告信息了。\n    \n##10 解决Ubuntu下启动失败的问题\n在Ubuntu上，那就不是一点WARN了，而是启动不起来，会出错，原因在于，在`./sbin/start-dfs.sh`第55行，\n\n    NAMENODES=$($HADOOP_PREFIX/bin/hdfs getconf -namenodes)\n\n在shell里单独运行这样命令，\n\n    ./bin/hdfs getconf -namenodes\n\n    OpenJDK 64-Bit Server VM warning: You have loaded library /home/soulmachine/local/opt/hadoop-2.2.0/lib/native/libhadoop.so which might have disabled stack guard. The VM will try to fix the stack guard now.\n    It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.\n    14/02/14 13:14:50 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n    localhost\n    \n最后一行的localhost，才是有效的namenode，但是由于前面有一大堆warning，脚本把这一大堆字符串，按空格隔开，每个单词都看作是namenode，接下来就错的稀里哗啦。\n\n根本原因，还是因为32位native库。\n\n把自带的32位native目录删除，用编译好的64位native目录拷贝过去，再运行\n\n    ./bin/hdfs getconf -namenodes\n    localhost\n\n这下就对了！\n\n##参考资料\n\n1. [YARN加载本地库抛出Unable to load native-hadoop library解决办法](http://blog.csdn.net/lalaguozhe/article/details/10580727)\n1. [CentOS编译Hadoop 2.2.0 Pass 总结](http://blog.csdn.net/zwj0403/article/details/16855555)\n\n","slug":"2014-02-14-compile-hadoop-220-on-centos","published":1,"updated":"2016-08-18T09:21:04.000Z","photos":[],"link":"","_id":"cis07pf4k003g01pqdz2odcjo","content":"<p>下载了Hadoop预编译好的二进制包，hadoop-2.2.0.tar.gz，启动起来后，总是出现这种警告：</p>\n<pre><code>WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n</code></pre><p>原因是apache官网提供的二进制包，里面的native库，是32位的，坑跌啊，现在服务器谁还有32位的啊。</p>\n<pre><code>$ file $HADOOP_PREFIX/lib/native/libhadoop.so.1.0.0\nlibhadoop.so.1.0.0: ELF 32-bit LSB shared object, Intel 80386, version 1 (SYSV), dynamically linked, BuildID[sha1]=0x9eb1d49b05f67d38454e42b216e053a27ae8bac9, not stripped\n</code></pre><p>我们需要下载Hadoop 2.2.0源码，在 64 位Linux下重新编译，然后把32位的native库用64位的native库替换。</p>\n<a id=\"more\"></a>\n<p>##1. 下载Hadoop 2.2.0 源码包，并解压</p>\n<pre><code>$ wget http://mirrors.hust.edu.cn/apache/hadoop/common/hadoop-2.2.0/hadoop-2.2.0-src.tar.gz\n$ tar zxf hadoop-2.2.0-src.tar.gz\n</code></pre><p>##2. 安装下面的软件</p>\n<pre><code>$ sudo yum install lzo-devel  zlib-devel  gcc autoconf automake libtool   ncurses-devel openssl-deve\n</code></pre><p>##3. 安装Maven<br>不要使用最新的Maven 3.1.1。Hadoop 2.2.0的源码与Maven3.x存在兼容性问题，所以会出现</p>\n<pre><code>java.lang.NoClassDefFoundError: org/sonatype/aether/graph/DependencyFilter\n</code></pre><p>之类的错误。</p>\n<p>安装 Maven 3.0.5</p>\n<pre><code>$ wget http://mirror.esocc.com/apache/maven/maven-3/3.0.5/binaries/apache-maven-3.0.5-bin.tar.gz\n$ sudo tar zxf apache-maven-3.0.5-bin.tar.gz -C /opt\n$ sudo vim /etc/profile\nexport MAVEN_HOME=/opt/apache-maven-3.0.5\nexport PATH=$PATH:$MAVEN_HOME/bin\n</code></pre><p>注销并重新登录，让环境变量生效。</p>\n<p>##4. 安装Ant</p>\n<pre><code>$ wget http://apache.dataguru.cn//ant/binaries/apache-ant-1.9.3-bin.tar.gz\n$ sudo tar zxf apache-ant-1.9.3-bin.tar.gz -C /opt\n$ sudo vim /etc/profile\nexport ANT_HOME=/opt/apache-ant-1.9.3\nexport PATH=$PATH:$ANT_HOME/bin\n</code></pre><p>##5. 安装Findbugs</p>\n<pre><code>$ wget http://prdownloads.sourceforge.net/findbugs/findbugs-2.0.3.tar.gz?download\n$ sudo tar zxf findbugs-2.0.3.tar.gz -C /opt\n$ sudo vim /etc/profile\nexport FINDBUGS_HOME=/opt/findbugs-2.0.3\nexport PATH=$PATH:$FINDBUGS_HOME/bin\n</code></pre><p>##6. 安装protobuf<br>编译Hadoop 2.2.0，需要protobuf的编译器protoc。一定需要protobuf 2.5.0以上，yum里的是2.3，太老了。因此下载源码，编译安装。</p>\n<pre><code>$ wget https://protobuf.googlecode.com/files/protobuf-2.5.0.tar.gz\n$ tar zxf protobuf-2.5.0.tar.gz\n$ cd protobuf-2.5.0\n$ ./configure\n$ make\n$ sudo make install\n</code></pre><p>##7. 给Hadoop源码打一个patch<br>最新的Hadoop 2.2.0 的Source Code 压缩包解压出来的code有个bug 需要patch后才能编译。否则编译hadoop-auth 会提示下面错误：</p>\n<pre><code>[ERROR] Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:2.5.1:testCompile (default-testCompile) on project hadoop-auth: Compilation failure: Compilation failure:\n[ERROR] /home/chuan/trunk/hadoop-common-project/hadoop-auth/src/test/java/org/apache/hadoop/security/authentication/client/AuthenticatorTestCase.java:[84,13] cannot access org.mortbay.component.AbstractLifeCycle\n[ERROR] class file for org.mortbay.component.AbstractLifeCycle not found\n</code></pre><p>Patch: <a href=\"https://issues.apache.org/jira/browse/HADOOP-10110\" target=\"_blank\" rel=\"external\">https://issues.apache.org/jira/browse/HADOOP-10110</a></p>\n<p>##8. 编译 Hadoop</p>\n<pre><code>cd hadoop-2.2.0-src\nmvn package -DskipTests -Pdist,native -Dtar\n</code></pre><p>##9. 替换掉32位的native库<br>用 <code>hadoop-2.2.0-src/hadoop-dist/target/hadoop-2.2.0/lib/native</code> 替换掉 <code>hadoop-2.2.0/lib/native</code>。</p>\n<pre><code>rm -rf ~/local/opt/hadoop-2.2.0/lib/native\ncp ./hadoop-dist/target/hadoop-2.2.0/lib/native ~/local/opt/hadoop-2.2.0/lib/\n</code></pre><p>然后重启Hadoop集群，会看到控制台下不再有警告信息了。</p>\n<p>##10 解决Ubuntu下启动失败的问题<br>在Ubuntu上，那就不是一点WARN了，而是启动不起来，会出错，原因在于，在<code>./sbin/start-dfs.sh</code>第55行，</p>\n<pre><code>NAMENODES=$($HADOOP_PREFIX/bin/hdfs getconf -namenodes)\n</code></pre><p>在shell里单独运行这样命令，</p>\n<pre><code>./bin/hdfs getconf -namenodes\n\nOpenJDK 64-Bit Server VM warning: You have loaded library /home/soulmachine/local/opt/hadoop-2.2.0/lib/native/libhadoop.so which might have disabled stack guard. The VM will try to fix the stack guard now.\nIt&apos;s highly recommended that you fix the library with &apos;execstack -c &lt;libfile&gt;&apos;, or link it with &apos;-z noexecstack&apos;.\n14/02/14 13:14:50 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\nlocalhost\n</code></pre><p>最后一行的localhost，才是有效的namenode，但是由于前面有一大堆warning，脚本把这一大堆字符串，按空格隔开，每个单词都看作是namenode，接下来就错的稀里哗啦。</p>\n<p>根本原因，还是因为32位native库。</p>\n<p>把自带的32位native目录删除，用编译好的64位native目录拷贝过去，再运行</p>\n<pre><code>./bin/hdfs getconf -namenodes\nlocalhost\n</code></pre><p>这下就对了！</p>\n<p>##参考资料</p>\n<ol>\n<li><a href=\"http://blog.csdn.net/lalaguozhe/article/details/10580727\" target=\"_blank\" rel=\"external\">YARN加载本地库抛出Unable to load native-hadoop library解决办法</a></li>\n<li><a href=\"http://blog.csdn.net/zwj0403/article/details/16855555\" target=\"_blank\" rel=\"external\">CentOS编译Hadoop 2.2.0 Pass 总结</a></li>\n</ol>\n","excerpt":"<p>下载了Hadoop预编译好的二进制包，hadoop-2.2.0.tar.gz，启动起来后，总是出现这种警告：</p>\n<pre><code>WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n</code></pre><p>原因是apache官网提供的二进制包，里面的native库，是32位的，坑跌啊，现在服务器谁还有32位的啊。</p>\n<pre><code>$ file $HADOOP_PREFIX/lib/native/libhadoop.so.1.0.0\nlibhadoop.so.1.0.0: ELF 32-bit LSB shared object, Intel 80386, version 1 (SYSV), dynamically linked, BuildID[sha1]=0x9eb1d49b05f67d38454e42b216e053a27ae8bac9, not stripped\n</code></pre><p>我们需要下载Hadoop 2.2.0源码，在 64 位Linux下重新编译，然后把32位的native库用64位的native库替换。</p>","more":"<p>##1. 下载Hadoop 2.2.0 源码包，并解压</p>\n<pre><code>$ wget http://mirrors.hust.edu.cn/apache/hadoop/common/hadoop-2.2.0/hadoop-2.2.0-src.tar.gz\n$ tar zxf hadoop-2.2.0-src.tar.gz\n</code></pre><p>##2. 安装下面的软件</p>\n<pre><code>$ sudo yum install lzo-devel  zlib-devel  gcc autoconf automake libtool   ncurses-devel openssl-deve\n</code></pre><p>##3. 安装Maven<br>不要使用最新的Maven 3.1.1。Hadoop 2.2.0的源码与Maven3.x存在兼容性问题，所以会出现</p>\n<pre><code>java.lang.NoClassDefFoundError: org/sonatype/aether/graph/DependencyFilter\n</code></pre><p>之类的错误。</p>\n<p>安装 Maven 3.0.5</p>\n<pre><code>$ wget http://mirror.esocc.com/apache/maven/maven-3/3.0.5/binaries/apache-maven-3.0.5-bin.tar.gz\n$ sudo tar zxf apache-maven-3.0.5-bin.tar.gz -C /opt\n$ sudo vim /etc/profile\nexport MAVEN_HOME=/opt/apache-maven-3.0.5\nexport PATH=$PATH:$MAVEN_HOME/bin\n</code></pre><p>注销并重新登录，让环境变量生效。</p>\n<p>##4. 安装Ant</p>\n<pre><code>$ wget http://apache.dataguru.cn//ant/binaries/apache-ant-1.9.3-bin.tar.gz\n$ sudo tar zxf apache-ant-1.9.3-bin.tar.gz -C /opt\n$ sudo vim /etc/profile\nexport ANT_HOME=/opt/apache-ant-1.9.3\nexport PATH=$PATH:$ANT_HOME/bin\n</code></pre><p>##5. 安装Findbugs</p>\n<pre><code>$ wget http://prdownloads.sourceforge.net/findbugs/findbugs-2.0.3.tar.gz?download\n$ sudo tar zxf findbugs-2.0.3.tar.gz -C /opt\n$ sudo vim /etc/profile\nexport FINDBUGS_HOME=/opt/findbugs-2.0.3\nexport PATH=$PATH:$FINDBUGS_HOME/bin\n</code></pre><p>##6. 安装protobuf<br>编译Hadoop 2.2.0，需要protobuf的编译器protoc。一定需要protobuf 2.5.0以上，yum里的是2.3，太老了。因此下载源码，编译安装。</p>\n<pre><code>$ wget https://protobuf.googlecode.com/files/protobuf-2.5.0.tar.gz\n$ tar zxf protobuf-2.5.0.tar.gz\n$ cd protobuf-2.5.0\n$ ./configure\n$ make\n$ sudo make install\n</code></pre><p>##7. 给Hadoop源码打一个patch<br>最新的Hadoop 2.2.0 的Source Code 压缩包解压出来的code有个bug 需要patch后才能编译。否则编译hadoop-auth 会提示下面错误：</p>\n<pre><code>[ERROR] Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:2.5.1:testCompile (default-testCompile) on project hadoop-auth: Compilation failure: Compilation failure:\n[ERROR] /home/chuan/trunk/hadoop-common-project/hadoop-auth/src/test/java/org/apache/hadoop/security/authentication/client/AuthenticatorTestCase.java:[84,13] cannot access org.mortbay.component.AbstractLifeCycle\n[ERROR] class file for org.mortbay.component.AbstractLifeCycle not found\n</code></pre><p>Patch: <a href=\"https://issues.apache.org/jira/browse/HADOOP-10110\">https://issues.apache.org/jira/browse/HADOOP-10110</a></p>\n<p>##8. 编译 Hadoop</p>\n<pre><code>cd hadoop-2.2.0-src\nmvn package -DskipTests -Pdist,native -Dtar\n</code></pre><p>##9. 替换掉32位的native库<br>用 <code>hadoop-2.2.0-src/hadoop-dist/target/hadoop-2.2.0/lib/native</code> 替换掉 <code>hadoop-2.2.0/lib/native</code>。</p>\n<pre><code>rm -rf ~/local/opt/hadoop-2.2.0/lib/native\ncp ./hadoop-dist/target/hadoop-2.2.0/lib/native ~/local/opt/hadoop-2.2.0/lib/\n</code></pre><p>然后重启Hadoop集群，会看到控制台下不再有警告信息了。</p>\n<p>##10 解决Ubuntu下启动失败的问题<br>在Ubuntu上，那就不是一点WARN了，而是启动不起来，会出错，原因在于，在<code>./sbin/start-dfs.sh</code>第55行，</p>\n<pre><code>NAMENODES=$($HADOOP_PREFIX/bin/hdfs getconf -namenodes)\n</code></pre><p>在shell里单独运行这样命令，</p>\n<pre><code>./bin/hdfs getconf -namenodes\n\nOpenJDK 64-Bit Server VM warning: You have loaded library /home/soulmachine/local/opt/hadoop-2.2.0/lib/native/libhadoop.so which might have disabled stack guard. The VM will try to fix the stack guard now.\nIt&apos;s highly recommended that you fix the library with &apos;execstack -c &lt;libfile&gt;&apos;, or link it with &apos;-z noexecstack&apos;.\n14/02/14 13:14:50 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\nlocalhost\n</code></pre><p>最后一行的localhost，才是有效的namenode，但是由于前面有一大堆warning，脚本把这一大堆字符串，按空格隔开，每个单词都看作是namenode，接下来就错的稀里哗啦。</p>\n<p>根本原因，还是因为32位native库。</p>\n<p>把自带的32位native目录删除，用编译好的64位native目录拷贝过去，再运行</p>\n<pre><code>./bin/hdfs getconf -namenodes\nlocalhost\n</code></pre><p>这下就对了！</p>\n<p>##参考资料</p>\n<ol>\n<li><a href=\"http://blog.csdn.net/lalaguozhe/article/details/10580727\">YARN加载本地库抛出Unable to load native-hadoop library解决办法</a></li>\n<li><a href=\"http://blog.csdn.net/zwj0403/article/details/16855555\">CentOS编译Hadoop 2.2.0 Pass 总结</a></li>\n</ol>"},{"layout":"post","title":"在Windows上直接使用现成的 OS X 10.9 Mavericks VMware镜像","date":"2014-04-24T21:58:00.000Z","comments":1,"_content":"\n环境: Windows 7, VMware Workstation 10.0.2, Mac OS X 10.9 Mavericks\n\n本文主要参考了这篇英文博客，[Working OS X 10.9 Mavericks VMware Image For Windows OS and Intel Processor](http://www.sysprobs.com/working-os-x-10-9-mavericks-vmware-image-for-windows-os-intel-processor)\n\n**前提条件**：确保你的电脑支持`VT-x`技术，并在BIOS里启用它。\n\n##1. 下载别人做好的镜像\n由于版权原因，这篇英文博客的作者不再提供下载地址了，不过google一下 \"OS X Mavericks 10.9 Retail VMware Image\"，可以在海盗湾找到种子，[这里](http://thepiratebay.se/torrent/9012642/OS_X_Mavericks_10.9_Retail_VMware_Image)。用迅雷或BT客户端下载。还有一种用更快速的下载方法，用百度网盘的离线下载，把magnet链接复制粘贴到百度网盘，等百度网盘下载好了后，再用百度管家客户端下载下来。\n\n这个文件夹里，只有`OS X Mavericks 10.9 Retail VMware Image.7z`是有用的额，其他小工具可以分别去下载最新的版本。\n\n这个镜像就是别人制作好的“懒人版”，Google 搜索\"OS X Mavericks VMware 懒人版\"或\"OS X Mavericks VMware 整合驱动版\"，还可以搜到很多。\n\n##2. 给 VMware Workstation 打补丁\nWindows上的VMware Workstation在安装操作系统时不支持 Mac OS X，但 VMware Fusin(VMware Workstation在Mac上的等价物，叫做 VMware Fusion)是支持了，这两个软件基本是统一软件在不同操作系统上的版本，按道理VMware Workstation也支持Mac OS X，事实上的确如此，只需要给VMware Workstation打一个补丁，就可以支持Mac OS X了。\n\n补丁名字叫做VMware Unlocker for OS X，在[这里下载](http://www.insanelymac.com/forum/files/file/20-vmware-unlocker-for-os-x/)。\n\n下载完后，解压，浏览到`windows`，以管理员权限执行 `install.cmd`，然后启动VMware Workstation，就可以看到变化了。\n\n<!-- more -->\n\n打补丁之前，\n\n![](/images/before-unlocker.png)\n\n打补丁之后。\n\n![](/images/after-unlocker.png)\n\n##3. 启动虚拟机\n解压 `OS X Mavericks 10.9 Retail VMware Image.7z`，双击`.vmx`文件，就可以打开虚拟机了。\n\n在启动虚拟机之前，你可以修改一下虚拟机的设置，例如提高内存到4GB，设置CPU核数为2，视你的电脑硬件配置而定。\n\n启动虚拟机后，要做一些设置，例如键盘，icloud账户，设置密码等等。\n\n##4. 安装VMware Tools\nVMware Tools for OS X最新版来自 <http://softwareupdate.vmware.com/cds/vmw-desktop/fusion/> ，当前最新版是 6.0.3。下载`com.vmware.fusion.tools.darwin.zip.tar` ，解压出里面的 `darwin.iso` ，然后 mount 到 Mac OS X 虚拟机，一定要勾选\"已连接\"，然后 Mac OS X 虚拟机会自动弹出安装对话框。\n\n![](/images/mount-vmware-tools.png)\n\n##5. 安装显卡驱动\n点击全屏菜单，发现Mac OS X 虚拟机不能这是由于没有显卡驱动。去[vmsvga2官网](http://sourceforge.net/projects/vmsvga2/) 下载`VMsvga2_v1.2.5_OS_10.9.pkg`(显卡驱动)和`guestd_patches.pkg`(自动调整分辨率补丁)，然后安装，重启，再试试全屏，发现可以了。\n\n##6. 更新软件，关机并压缩打包\n点击左上角的苹果图标，选择\"Software update\"，更新所有，就会从 10.9 更新到 10.9.2。然后关机，用7z将整个虚拟机文件夹压缩成一个压缩包。\n\n可以将这个压缩包共享给别人，也可以作为一个备份，一旦虚拟机装新软件或其它操作弄坏了，可以从这个压缩包解压，以这个镜像为起点，重新开始，而不用从零重新开始。\n\n##参考资料\n1. [Working OS X 10.9 Mavericks VMware Image For Windows OS and Intel Processor](http://www.sysprobs.com/working-os-x-10-9-mavericks-vmware-image-for-windows-os-intel-processor)\n1. [超详细VMware Workstation 10安装OS X Mavericks](http://www.rshining.net/2013/10/%E8%B6%85%E8%AF%A6%E7%BB%86vmware-workstation-10%E5%AE%89%E8%A3%85os-x-mavericks/)\n","source":"_posts/2014-04-24-working-os-x-10-dot-9-mavericks-vmware-image-for-windows-os.md","raw":"---\nlayout: post\ntitle: \"在Windows上直接使用现成的 OS X 10.9 Mavericks VMware镜像\"\ndate: 2014-04-24 21:58\ncomments: true\ncategories: DevOps\n---\n\n环境: Windows 7, VMware Workstation 10.0.2, Mac OS X 10.9 Mavericks\n\n本文主要参考了这篇英文博客，[Working OS X 10.9 Mavericks VMware Image For Windows OS and Intel Processor](http://www.sysprobs.com/working-os-x-10-9-mavericks-vmware-image-for-windows-os-intel-processor)\n\n**前提条件**：确保你的电脑支持`VT-x`技术，并在BIOS里启用它。\n\n##1. 下载别人做好的镜像\n由于版权原因，这篇英文博客的作者不再提供下载地址了，不过google一下 \"OS X Mavericks 10.9 Retail VMware Image\"，可以在海盗湾找到种子，[这里](http://thepiratebay.se/torrent/9012642/OS_X_Mavericks_10.9_Retail_VMware_Image)。用迅雷或BT客户端下载。还有一种用更快速的下载方法，用百度网盘的离线下载，把magnet链接复制粘贴到百度网盘，等百度网盘下载好了后，再用百度管家客户端下载下来。\n\n这个文件夹里，只有`OS X Mavericks 10.9 Retail VMware Image.7z`是有用的额，其他小工具可以分别去下载最新的版本。\n\n这个镜像就是别人制作好的“懒人版”，Google 搜索\"OS X Mavericks VMware 懒人版\"或\"OS X Mavericks VMware 整合驱动版\"，还可以搜到很多。\n\n##2. 给 VMware Workstation 打补丁\nWindows上的VMware Workstation在安装操作系统时不支持 Mac OS X，但 VMware Fusin(VMware Workstation在Mac上的等价物，叫做 VMware Fusion)是支持了，这两个软件基本是统一软件在不同操作系统上的版本，按道理VMware Workstation也支持Mac OS X，事实上的确如此，只需要给VMware Workstation打一个补丁，就可以支持Mac OS X了。\n\n补丁名字叫做VMware Unlocker for OS X，在[这里下载](http://www.insanelymac.com/forum/files/file/20-vmware-unlocker-for-os-x/)。\n\n下载完后，解压，浏览到`windows`，以管理员权限执行 `install.cmd`，然后启动VMware Workstation，就可以看到变化了。\n\n<!-- more -->\n\n打补丁之前，\n\n![](/images/before-unlocker.png)\n\n打补丁之后。\n\n![](/images/after-unlocker.png)\n\n##3. 启动虚拟机\n解压 `OS X Mavericks 10.9 Retail VMware Image.7z`，双击`.vmx`文件，就可以打开虚拟机了。\n\n在启动虚拟机之前，你可以修改一下虚拟机的设置，例如提高内存到4GB，设置CPU核数为2，视你的电脑硬件配置而定。\n\n启动虚拟机后，要做一些设置，例如键盘，icloud账户，设置密码等等。\n\n##4. 安装VMware Tools\nVMware Tools for OS X最新版来自 <http://softwareupdate.vmware.com/cds/vmw-desktop/fusion/> ，当前最新版是 6.0.3。下载`com.vmware.fusion.tools.darwin.zip.tar` ，解压出里面的 `darwin.iso` ，然后 mount 到 Mac OS X 虚拟机，一定要勾选\"已连接\"，然后 Mac OS X 虚拟机会自动弹出安装对话框。\n\n![](/images/mount-vmware-tools.png)\n\n##5. 安装显卡驱动\n点击全屏菜单，发现Mac OS X 虚拟机不能这是由于没有显卡驱动。去[vmsvga2官网](http://sourceforge.net/projects/vmsvga2/) 下载`VMsvga2_v1.2.5_OS_10.9.pkg`(显卡驱动)和`guestd_patches.pkg`(自动调整分辨率补丁)，然后安装，重启，再试试全屏，发现可以了。\n\n##6. 更新软件，关机并压缩打包\n点击左上角的苹果图标，选择\"Software update\"，更新所有，就会从 10.9 更新到 10.9.2。然后关机，用7z将整个虚拟机文件夹压缩成一个压缩包。\n\n可以将这个压缩包共享给别人，也可以作为一个备份，一旦虚拟机装新软件或其它操作弄坏了，可以从这个压缩包解压，以这个镜像为起点，重新开始，而不用从零重新开始。\n\n##参考资料\n1. [Working OS X 10.9 Mavericks VMware Image For Windows OS and Intel Processor](http://www.sysprobs.com/working-os-x-10-9-mavericks-vmware-image-for-windows-os-intel-processor)\n1. [超详细VMware Workstation 10安装OS X Mavericks](http://www.rshining.net/2013/10/%E8%B6%85%E8%AF%A6%E7%BB%86vmware-workstation-10%E5%AE%89%E8%A3%85os-x-mavericks/)\n","slug":"2014-04-24-working-os-x-10-dot-9-mavericks-vmware-image-for-windows-os","published":1,"updated":"2016-08-18T09:21:04.000Z","photos":[],"link":"","_id":"cis07pf4l003i01pqbd5p02t1","content":"<p>环境: Windows 7, VMware Workstation 10.0.2, Mac OS X 10.9 Mavericks</p>\n<p>本文主要参考了这篇英文博客，<a href=\"http://www.sysprobs.com/working-os-x-10-9-mavericks-vmware-image-for-windows-os-intel-processor\" target=\"_blank\" rel=\"external\">Working OS X 10.9 Mavericks VMware Image For Windows OS and Intel Processor</a></p>\n<p><strong>前提条件</strong>：确保你的电脑支持<code>VT-x</code>技术，并在BIOS里启用它。</p>\n<p>##1. 下载别人做好的镜像<br>由于版权原因，这篇英文博客的作者不再提供下载地址了，不过google一下 “OS X Mavericks 10.9 Retail VMware Image”，可以在海盗湾找到种子，<a href=\"http://thepiratebay.se/torrent/9012642/OS_X_Mavericks_10.9_Retail_VMware_Image\" target=\"_blank\" rel=\"external\">这里</a>。用迅雷或BT客户端下载。还有一种用更快速的下载方法，用百度网盘的离线下载，把magnet链接复制粘贴到百度网盘，等百度网盘下载好了后，再用百度管家客户端下载下来。</p>\n<p>这个文件夹里，只有<code>OS X Mavericks 10.9 Retail VMware Image.7z</code>是有用的额，其他小工具可以分别去下载最新的版本。</p>\n<p>这个镜像就是别人制作好的“懒人版”，Google 搜索”OS X Mavericks VMware 懒人版”或”OS X Mavericks VMware 整合驱动版”，还可以搜到很多。</p>\n<p>##2. 给 VMware Workstation 打补丁<br>Windows上的VMware Workstation在安装操作系统时不支持 Mac OS X，但 VMware Fusin(VMware Workstation在Mac上的等价物，叫做 VMware Fusion)是支持了，这两个软件基本是统一软件在不同操作系统上的版本，按道理VMware Workstation也支持Mac OS X，事实上的确如此，只需要给VMware Workstation打一个补丁，就可以支持Mac OS X了。</p>\n<p>补丁名字叫做VMware Unlocker for OS X，在<a href=\"http://www.insanelymac.com/forum/files/file/20-vmware-unlocker-for-os-x/\" target=\"_blank\" rel=\"external\">这里下载</a>。</p>\n<p>下载完后，解压，浏览到<code>windows</code>，以管理员权限执行 <code>install.cmd</code>，然后启动VMware Workstation，就可以看到变化了。</p>\n<a id=\"more\"></a>\n<p>打补丁之前，</p>\n<p><img src=\"/images/before-unlocker.png\" alt=\"\"></p>\n<p>打补丁之后。</p>\n<p><img src=\"/images/after-unlocker.png\" alt=\"\"></p>\n<p>##3. 启动虚拟机<br>解压 <code>OS X Mavericks 10.9 Retail VMware Image.7z</code>，双击<code>.vmx</code>文件，就可以打开虚拟机了。</p>\n<p>在启动虚拟机之前，你可以修改一下虚拟机的设置，例如提高内存到4GB，设置CPU核数为2，视你的电脑硬件配置而定。</p>\n<p>启动虚拟机后，要做一些设置，例如键盘，icloud账户，设置密码等等。</p>\n<p>##4. 安装VMware Tools<br>VMware Tools for OS X最新版来自 <a href=\"http://softwareupdate.vmware.com/cds/vmw-desktop/fusion/\" target=\"_blank\" rel=\"external\">http://softwareupdate.vmware.com/cds/vmw-desktop/fusion/</a> ，当前最新版是 6.0.3。下载<code>com.vmware.fusion.tools.darwin.zip.tar</code> ，解压出里面的 <code>darwin.iso</code> ，然后 mount 到 Mac OS X 虚拟机，一定要勾选”已连接”，然后 Mac OS X 虚拟机会自动弹出安装对话框。</p>\n<p><img src=\"/images/mount-vmware-tools.png\" alt=\"\"></p>\n<p>##5. 安装显卡驱动<br>点击全屏菜单，发现Mac OS X 虚拟机不能这是由于没有显卡驱动。去<a href=\"http://sourceforge.net/projects/vmsvga2/\" target=\"_blank\" rel=\"external\">vmsvga2官网</a> 下载<code>VMsvga2_v1.2.5_OS_10.9.pkg</code>(显卡驱动)和<code>guestd_patches.pkg</code>(自动调整分辨率补丁)，然后安装，重启，再试试全屏，发现可以了。</p>\n<p>##6. 更新软件，关机并压缩打包<br>点击左上角的苹果图标，选择”Software update”，更新所有，就会从 10.9 更新到 10.9.2。然后关机，用7z将整个虚拟机文件夹压缩成一个压缩包。</p>\n<p>可以将这个压缩包共享给别人，也可以作为一个备份，一旦虚拟机装新软件或其它操作弄坏了，可以从这个压缩包解压，以这个镜像为起点，重新开始，而不用从零重新开始。</p>\n<p>##参考资料</p>\n<ol>\n<li><a href=\"http://www.sysprobs.com/working-os-x-10-9-mavericks-vmware-image-for-windows-os-intel-processor\" target=\"_blank\" rel=\"external\">Working OS X 10.9 Mavericks VMware Image For Windows OS and Intel Processor</a></li>\n<li><a href=\"http://www.rshining.net/2013/10/%E8%B6%85%E8%AF%A6%E7%BB%86vmware-workstation-10%E5%AE%89%E8%A3%85os-x-mavericks/\" target=\"_blank\" rel=\"external\">超详细VMware Workstation 10安装OS X Mavericks</a></li>\n</ol>\n","excerpt":"<p>环境: Windows 7, VMware Workstation 10.0.2, Mac OS X 10.9 Mavericks</p>\n<p>本文主要参考了这篇英文博客，<a href=\"http://www.sysprobs.com/working-os-x-10-9-mavericks-vmware-image-for-windows-os-intel-processor\">Working OS X 10.9 Mavericks VMware Image For Windows OS and Intel Processor</a></p>\n<p><strong>前提条件</strong>：确保你的电脑支持<code>VT-x</code>技术，并在BIOS里启用它。</p>\n<p>##1. 下载别人做好的镜像<br>由于版权原因，这篇英文博客的作者不再提供下载地址了，不过google一下 “OS X Mavericks 10.9 Retail VMware Image”，可以在海盗湾找到种子，<a href=\"http://thepiratebay.se/torrent/9012642/OS_X_Mavericks_10.9_Retail_VMware_Image\">这里</a>。用迅雷或BT客户端下载。还有一种用更快速的下载方法，用百度网盘的离线下载，把magnet链接复制粘贴到百度网盘，等百度网盘下载好了后，再用百度管家客户端下载下来。</p>\n<p>这个文件夹里，只有<code>OS X Mavericks 10.9 Retail VMware Image.7z</code>是有用的额，其他小工具可以分别去下载最新的版本。</p>\n<p>这个镜像就是别人制作好的“懒人版”，Google 搜索”OS X Mavericks VMware 懒人版”或”OS X Mavericks VMware 整合驱动版”，还可以搜到很多。</p>\n<p>##2. 给 VMware Workstation 打补丁<br>Windows上的VMware Workstation在安装操作系统时不支持 Mac OS X，但 VMware Fusin(VMware Workstation在Mac上的等价物，叫做 VMware Fusion)是支持了，这两个软件基本是统一软件在不同操作系统上的版本，按道理VMware Workstation也支持Mac OS X，事实上的确如此，只需要给VMware Workstation打一个补丁，就可以支持Mac OS X了。</p>\n<p>补丁名字叫做VMware Unlocker for OS X，在<a href=\"http://www.insanelymac.com/forum/files/file/20-vmware-unlocker-for-os-x/\">这里下载</a>。</p>\n<p>下载完后，解压，浏览到<code>windows</code>，以管理员权限执行 <code>install.cmd</code>，然后启动VMware Workstation，就可以看到变化了。</p>","more":"<p>打补丁之前，</p>\n<p><img src=\"/images/before-unlocker.png\" alt=\"\"></p>\n<p>打补丁之后。</p>\n<p><img src=\"/images/after-unlocker.png\" alt=\"\"></p>\n<p>##3. 启动虚拟机<br>解压 <code>OS X Mavericks 10.9 Retail VMware Image.7z</code>，双击<code>.vmx</code>文件，就可以打开虚拟机了。</p>\n<p>在启动虚拟机之前，你可以修改一下虚拟机的设置，例如提高内存到4GB，设置CPU核数为2，视你的电脑硬件配置而定。</p>\n<p>启动虚拟机后，要做一些设置，例如键盘，icloud账户，设置密码等等。</p>\n<p>##4. 安装VMware Tools<br>VMware Tools for OS X最新版来自 <a href=\"http://softwareupdate.vmware.com/cds/vmw-desktop/fusion/\">http://softwareupdate.vmware.com/cds/vmw-desktop/fusion/</a> ，当前最新版是 6.0.3。下载<code>com.vmware.fusion.tools.darwin.zip.tar</code> ，解压出里面的 <code>darwin.iso</code> ，然后 mount 到 Mac OS X 虚拟机，一定要勾选”已连接”，然后 Mac OS X 虚拟机会自动弹出安装对话框。</p>\n<p><img src=\"/images/mount-vmware-tools.png\" alt=\"\"></p>\n<p>##5. 安装显卡驱动<br>点击全屏菜单，发现Mac OS X 虚拟机不能这是由于没有显卡驱动。去<a href=\"http://sourceforge.net/projects/vmsvga2/\">vmsvga2官网</a> 下载<code>VMsvga2_v1.2.5_OS_10.9.pkg</code>(显卡驱动)和<code>guestd_patches.pkg</code>(自动调整分辨率补丁)，然后安装，重启，再试试全屏，发现可以了。</p>\n<p>##6. 更新软件，关机并压缩打包<br>点击左上角的苹果图标，选择”Software update”，更新所有，就会从 10.9 更新到 10.9.2。然后关机，用7z将整个虚拟机文件夹压缩成一个压缩包。</p>\n<p>可以将这个压缩包共享给别人，也可以作为一个备份，一旦虚拟机装新软件或其它操作弄坏了，可以从这个压缩包解压，以这个镜像为起点，重新开始，而不用从零重新开始。</p>\n<p>##参考资料</p>\n<ol>\n<li><a href=\"http://www.sysprobs.com/working-os-x-10-9-mavericks-vmware-image-for-windows-os-intel-processor\">Working OS X 10.9 Mavericks VMware Image For Windows OS and Intel Processor</a></li>\n<li><a href=\"http://www.rshining.net/2013/10/%E8%B6%85%E8%AF%A6%E7%BB%86vmware-workstation-10%E5%AE%89%E8%A3%85os-x-mavericks/\">超详细VMware Workstation 10安装OS X Mavericks</a></li>\n</ol>"},{"layout":"post","title":"编写Nutch插件","date":"2014-02-20T16:53:00.000Z","comments":1,"_content":"\n软件版本：Nutch 1.7\n\nNutch Plugin的所有资料，都在官网这里, [PluginCentral](http://wiki.apache.org/nutch/PluginCentral)\n\n##前提\n[在Eclipse里运行Nutch](http://www.yanjiuyanjiu.com/blog/20140120)\n\n## Extension 和 Extension-point的关系\nExtension point类似与Java语言里的接口(interface), extension 则是具体的实现(implementation)。\n\n[About Plugins](http://wiki.apache.org/nutch/AboutPlugins)里有一句话，**Each extension-point defines an interface that must be implemented by the extension.**\n\n##Nutch里的各种概念\nExtension point, extension, plugin, 这些概念是什么意思？见 [Technical Concepts Behind the Nutch Plugin System](http://wiki.apache.org/nutch/WhichTechnicalConceptsAreBehindTheNutchPluginSystem)\n\n##Nutch 1.7 有哪些 Extension-point\n![](/images/extension-points.png)\n\nExtensionPoint 这个东西，本身也是一个插件，可以看看 `src/plugin/nutch-extensionpoints/plugin.xml`，里面定义了所有的扩展点，跟上图基本一致。\n\n[AboutPlugins](http://wiki.apache.org/nutch/AboutPlugins)这里列出来的是 Nuch 1.4的扩展点，有点过时了。\n\n##一个Nutch的组成文件\nbuild.xml, plugins.xml 等等\n\n##Nutch 插件例子\n\n1. [WritingPluginExample](http://wiki.apache.org/nutch/WritingPluginExample)\n1. [WritingPluginExample-1.2](http://wiki.apache.org/nutch/WritingPluginExample-1.2)，针对Nutch 1.2的，有点老，但是值得一看\n1. [Writing a plugin to add dates by Ryan Pfister](http://www.ryanpfister.com/2009/04/how-to-sort-by-date-with-nutch/)\n\n看来这3个例子，你应该就知道怎么开发插件了。\n\n##Nutch 的缺点\n在抓取的过程中，真正的难度在于, ip limit 和 user limit，可惜 Nutch 对这两个问题都没有解决方案。\n\n1. Nutch 的 [HttpPostAuthentication](http://wiki.apache.org/nutch/HttpPostAuthentication) 现在还没有开发完，导致无法抓取需要登录的网站，例如新浪微波，豆瓣等UGC网站，都是需要登录的。没有这个`HttpPostAuthentication`，Nutch其实只能抓取不需要登录的网页，适用范围大打折扣，现在是web 2.0时代，真正优质的内容，几乎都是需要登录的。\n1. 多个代理的管理。Nutch 没有提供多个代理的管理功能，只能在`nutch-site.xml`里配置一个代理。比如我在网上抓取了几百个免费的http代理，怎么让Nutch的各个线程均匀的使用这些代理，平能自动判断代理的速度，优先选择速度高的代理呢？","source":"_posts/2014-02-20-writing-nutch-plugins.md","raw":"---\nlayout: post\ntitle: \"编写Nutch插件\"\ndate: 2014-02-20 16:53\ncomments: true\ncategories: Search-Engine\n---\n\n软件版本：Nutch 1.7\n\nNutch Plugin的所有资料，都在官网这里, [PluginCentral](http://wiki.apache.org/nutch/PluginCentral)\n\n##前提\n[在Eclipse里运行Nutch](http://www.yanjiuyanjiu.com/blog/20140120)\n\n## Extension 和 Extension-point的关系\nExtension point类似与Java语言里的接口(interface), extension 则是具体的实现(implementation)。\n\n[About Plugins](http://wiki.apache.org/nutch/AboutPlugins)里有一句话，**Each extension-point defines an interface that must be implemented by the extension.**\n\n##Nutch里的各种概念\nExtension point, extension, plugin, 这些概念是什么意思？见 [Technical Concepts Behind the Nutch Plugin System](http://wiki.apache.org/nutch/WhichTechnicalConceptsAreBehindTheNutchPluginSystem)\n\n##Nutch 1.7 有哪些 Extension-point\n![](/images/extension-points.png)\n\nExtensionPoint 这个东西，本身也是一个插件，可以看看 `src/plugin/nutch-extensionpoints/plugin.xml`，里面定义了所有的扩展点，跟上图基本一致。\n\n[AboutPlugins](http://wiki.apache.org/nutch/AboutPlugins)这里列出来的是 Nuch 1.4的扩展点，有点过时了。\n\n##一个Nutch的组成文件\nbuild.xml, plugins.xml 等等\n\n##Nutch 插件例子\n\n1. [WritingPluginExample](http://wiki.apache.org/nutch/WritingPluginExample)\n1. [WritingPluginExample-1.2](http://wiki.apache.org/nutch/WritingPluginExample-1.2)，针对Nutch 1.2的，有点老，但是值得一看\n1. [Writing a plugin to add dates by Ryan Pfister](http://www.ryanpfister.com/2009/04/how-to-sort-by-date-with-nutch/)\n\n看来这3个例子，你应该就知道怎么开发插件了。\n\n##Nutch 的缺点\n在抓取的过程中，真正的难度在于, ip limit 和 user limit，可惜 Nutch 对这两个问题都没有解决方案。\n\n1. Nutch 的 [HttpPostAuthentication](http://wiki.apache.org/nutch/HttpPostAuthentication) 现在还没有开发完，导致无法抓取需要登录的网站，例如新浪微波，豆瓣等UGC网站，都是需要登录的。没有这个`HttpPostAuthentication`，Nutch其实只能抓取不需要登录的网页，适用范围大打折扣，现在是web 2.0时代，真正优质的内容，几乎都是需要登录的。\n1. 多个代理的管理。Nutch 没有提供多个代理的管理功能，只能在`nutch-site.xml`里配置一个代理。比如我在网上抓取了几百个免费的http代理，怎么让Nutch的各个线程均匀的使用这些代理，平能自动判断代理的速度，优先选择速度高的代理呢？","slug":"2014-02-20-writing-nutch-plugins","published":1,"updated":"2016-08-18T09:21:04.000Z","photos":[],"link":"","_id":"cis07pf4m003k01pq9dzandz2","content":"<p>软件版本：Nutch 1.7</p>\n<p>Nutch Plugin的所有资料，都在官网这里, <a href=\"http://wiki.apache.org/nutch/PluginCentral\" target=\"_blank\" rel=\"external\">PluginCentral</a></p>\n<p>##前提<br><a href=\"http://www.yanjiuyanjiu.com/blog/20140120\" target=\"_blank\" rel=\"external\">在Eclipse里运行Nutch</a></p>\n<h2 id=\"Extension-和-Extension-point的关系\"><a href=\"#Extension-和-Extension-point的关系\" class=\"headerlink\" title=\"Extension 和 Extension-point的关系\"></a>Extension 和 Extension-point的关系</h2><p>Extension point类似与Java语言里的接口(interface), extension 则是具体的实现(implementation)。</p>\n<p><a href=\"http://wiki.apache.org/nutch/AboutPlugins\" target=\"_blank\" rel=\"external\">About Plugins</a>里有一句话，<strong>Each extension-point defines an interface that must be implemented by the extension.</strong></p>\n<p>##Nutch里的各种概念<br>Extension point, extension, plugin, 这些概念是什么意思？见 <a href=\"http://wiki.apache.org/nutch/WhichTechnicalConceptsAreBehindTheNutchPluginSystem\" target=\"_blank\" rel=\"external\">Technical Concepts Behind the Nutch Plugin System</a></p>\n<p>##Nutch 1.7 有哪些 Extension-point<br><img src=\"/images/extension-points.png\" alt=\"\"></p>\n<p>ExtensionPoint 这个东西，本身也是一个插件，可以看看 <code>src/plugin/nutch-extensionpoints/plugin.xml</code>，里面定义了所有的扩展点，跟上图基本一致。</p>\n<p><a href=\"http://wiki.apache.org/nutch/AboutPlugins\" target=\"_blank\" rel=\"external\">AboutPlugins</a>这里列出来的是 Nuch 1.4的扩展点，有点过时了。</p>\n<p>##一个Nutch的组成文件<br>build.xml, plugins.xml 等等</p>\n<p>##Nutch 插件例子</p>\n<ol>\n<li><a href=\"http://wiki.apache.org/nutch/WritingPluginExample\" target=\"_blank\" rel=\"external\">WritingPluginExample</a></li>\n<li><a href=\"http://wiki.apache.org/nutch/WritingPluginExample-1.2\" target=\"_blank\" rel=\"external\">WritingPluginExample-1.2</a>，针对Nutch 1.2的，有点老，但是值得一看</li>\n<li><a href=\"http://www.ryanpfister.com/2009/04/how-to-sort-by-date-with-nutch/\" target=\"_blank\" rel=\"external\">Writing a plugin to add dates by Ryan Pfister</a></li>\n</ol>\n<p>看来这3个例子，你应该就知道怎么开发插件了。</p>\n<p>##Nutch 的缺点<br>在抓取的过程中，真正的难度在于, ip limit 和 user limit，可惜 Nutch 对这两个问题都没有解决方案。</p>\n<ol>\n<li>Nutch 的 <a href=\"http://wiki.apache.org/nutch/HttpPostAuthentication\" target=\"_blank\" rel=\"external\">HttpPostAuthentication</a> 现在还没有开发完，导致无法抓取需要登录的网站，例如新浪微波，豆瓣等UGC网站，都是需要登录的。没有这个<code>HttpPostAuthentication</code>，Nutch其实只能抓取不需要登录的网页，适用范围大打折扣，现在是web 2.0时代，真正优质的内容，几乎都是需要登录的。</li>\n<li>多个代理的管理。Nutch 没有提供多个代理的管理功能，只能在<code>nutch-site.xml</code>里配置一个代理。比如我在网上抓取了几百个免费的http代理，怎么让Nutch的各个线程均匀的使用这些代理，平能自动判断代理的速度，优先选择速度高的代理呢？</li>\n</ol>\n","excerpt":"","more":"<p>软件版本：Nutch 1.7</p>\n<p>Nutch Plugin的所有资料，都在官网这里, <a href=\"http://wiki.apache.org/nutch/PluginCentral\">PluginCentral</a></p>\n<p>##前提<br><a href=\"http://www.yanjiuyanjiu.com/blog/20140120\">在Eclipse里运行Nutch</a></p>\n<h2 id=\"Extension-和-Extension-point的关系\"><a href=\"#Extension-和-Extension-point的关系\" class=\"headerlink\" title=\"Extension 和 Extension-point的关系\"></a>Extension 和 Extension-point的关系</h2><p>Extension point类似与Java语言里的接口(interface), extension 则是具体的实现(implementation)。</p>\n<p><a href=\"http://wiki.apache.org/nutch/AboutPlugins\">About Plugins</a>里有一句话，<strong>Each extension-point defines an interface that must be implemented by the extension.</strong></p>\n<p>##Nutch里的各种概念<br>Extension point, extension, plugin, 这些概念是什么意思？见 <a href=\"http://wiki.apache.org/nutch/WhichTechnicalConceptsAreBehindTheNutchPluginSystem\">Technical Concepts Behind the Nutch Plugin System</a></p>\n<p>##Nutch 1.7 有哪些 Extension-point<br><img src=\"/images/extension-points.png\" alt=\"\"></p>\n<p>ExtensionPoint 这个东西，本身也是一个插件，可以看看 <code>src/plugin/nutch-extensionpoints/plugin.xml</code>，里面定义了所有的扩展点，跟上图基本一致。</p>\n<p><a href=\"http://wiki.apache.org/nutch/AboutPlugins\">AboutPlugins</a>这里列出来的是 Nuch 1.4的扩展点，有点过时了。</p>\n<p>##一个Nutch的组成文件<br>build.xml, plugins.xml 等等</p>\n<p>##Nutch 插件例子</p>\n<ol>\n<li><a href=\"http://wiki.apache.org/nutch/WritingPluginExample\">WritingPluginExample</a></li>\n<li><a href=\"http://wiki.apache.org/nutch/WritingPluginExample-1.2\">WritingPluginExample-1.2</a>，针对Nutch 1.2的，有点老，但是值得一看</li>\n<li><a href=\"http://www.ryanpfister.com/2009/04/how-to-sort-by-date-with-nutch/\">Writing a plugin to add dates by Ryan Pfister</a></li>\n</ol>\n<p>看来这3个例子，你应该就知道怎么开发插件了。</p>\n<p>##Nutch 的缺点<br>在抓取的过程中，真正的难度在于, ip limit 和 user limit，可惜 Nutch 对这两个问题都没有解决方案。</p>\n<ol>\n<li>Nutch 的 <a href=\"http://wiki.apache.org/nutch/HttpPostAuthentication\">HttpPostAuthentication</a> 现在还没有开发完，导致无法抓取需要登录的网站，例如新浪微波，豆瓣等UGC网站，都是需要登录的。没有这个<code>HttpPostAuthentication</code>，Nutch其实只能抓取不需要登录的网页，适用范围大打折扣，现在是web 2.0时代，真正优质的内容，几乎都是需要登录的。</li>\n<li>多个代理的管理。Nutch 没有提供多个代理的管理功能，只能在<code>nutch-site.xml</code>里配置一个代理。比如我在网上抓取了几百个免费的http代理，怎么让Nutch的各个线程均匀的使用这些代理，平能自动判断代理的速度，优先选择速度高的代理呢？</li>\n</ol>\n"},{"layout":"post","title":"在CentOS上安装HBase 0.96","date":"2014-02-08T16:42:00.000Z","comments":1,"_content":"\n环境：CentOS 6.5, jdk 1.7, HBase 0.96.1.1\n\n\n##（可选）创建新用户，并配置好SSH无密码登录\n一般我倾向于把需要启动daemon进程，对外提供服务的程序，即服务器类的程序，安装在单独的用户下面。这样可以做到隔离，运维方面，安全性也提高了。\n\n创建一个新的group,\n\n    $ sudo groupadd hbase\n\n创建一个新的用户，并加入group,\n\n    $ sudo useradd -g hbase hbase\n\n给新用户设置密码，\n\n    $ sudo passwd hbase\n\n在每台机器上创建hbase新用户，并配置好SSH无密码，参考我的另一篇博客，[SSH无密码登录的配置](http://www.yanjiuyanjiu.com/blog/20120102/)\n\n\n##1. 单机模式(Standalone mode)\n\n###1.1 下载，解压\n\n    $ wget wget http://mirror.esocc.com/apache/hbase/hbase-0.96.1.1/hbase-0.96.1.1-hadoop2-bin.tar.gz\n    $ tar zxf hbase-0.96.1.1-hadoop2-bin.tar.gz -C ~/local/opt\n\n###1.2 hbase-env.sh\n在这个文件中要指明JDK 安装在了哪里\n\n    $ echo $JAVA_HOME\n    /usr/lib/jvm/java\n    $ vim conf/hbase-env.sh\n\n取消`JAVA_HOME`那一行的注释，设置正确的JDK位置\n\n    export JAVA_HOME=/usr/lib/jvm/java\n\n###1.3 修改 conf/hbase-site.xml\n内容如下\n\n    <configuration>\n      <property>\n        <name>hbase.rootdir</name>\n        <value>/home/hbase/local/var/hbase</value>\n      </property>\n      <property>\n        <name>hbase.zookeeper.property.dataDir</name>\n        <value>/home/hbase/local/var/zookeeper</value>\n      </property>\n    </configuration>\n\n`hbase.rootdir`目录是用来存放HBase的相关信息的，默认值是`/tmp/hbase-${user.name}/hbase`； `hbase.zookeeper.property.dataDir`目录是用来存放zookeeper（HBase内置了zookeeper）的相关信息的，默认值是`/tmp/hbase-${user.name}/zookeeper`。\n\n###1.4 启动\n\n    $ ./bin/start-hbase.sh\n    starting Master, logging to logs/hbase-user-master-example.org.out\n\n<!-- more -->\n\n###1.5 试用一下HBase shell\n$ ./bin/hbase shell\n    2014-02-09 23:56:28,637 INFO  [main] Configuration.deprecation: hadoop.native.lib is deprecated. Instead, use io.native.lib.available\n    HBase Shell; enter 'help<RETURN>' for list of supported commands.\n    Type \"exit<RETURN>\" to leave the HBase Shell\n    Version 0.96.1.1-hadoop2, rUnknown, Tue Dec 17 12:22:12 PST 2013\n    \n    hbase(main):001:0>\n\n创建一张名字为`test`的表，只有一个列，名为`cf`。为了验证创建是否成功，用`list`命令查看所有的table，并用`put`命令插入一些值。\n\n    hbase(main):003:0> create 'test', 'cf'\n    0 row(s) in 1.2200 seconds\n    hbase(main):003:0> list 'test'\n    ..\n    1 row(s) in 0.0550 seconds\n    hbase(main):004:0> put 'test', 'row1', 'cf:a', 'value1'\n    0 row(s) in 0.0560 seconds\n    hbase(main):005:0> put 'test', 'row2', 'cf:b', 'value2'\n    0 row(s) in 0.0370 seconds\n    hbase(main):006:0> put 'test', 'row3', 'cf:c', 'value3'\n    0 row(s) in 0.0450 seconds\n\n用`scan`命令扫描table，验证一下刚才的插入是否成功。\n\n    hbase(main):007:0> scan 'test'\n    ROW        COLUMN+CELL\n    row1       column=cf:a, timestamp=1288380727188, value=value1\n    row2       column=cf:b, timestamp=1288380738440, value=value2\n    row3       column=cf:c, timestamp=1288380747365, value=value3\n    3 row(s) in 0.0590 seconds\n\n现在，disable并drop掉你的表，这会把上面的所有操作清零。\n\n    hbase(main):012:0> disable 'test'\n    0 row(s) in 1.0930 seconds\n    hbase(main):013:0> drop 'test'\n    0 row(s) in 0.0770 seconds \n\n退出shell，\n\n    hbase(main):014:0> exit\n\n###1.6 停止\n\n    $ ./bin/stop-hbase.sh\n    stopping hbase...............\n\n\n##2 伪分布式模式(Pseudo-distributed mode)\n\n###前提\n\nHBase集群需要一个正在运行的zookeeper集群，要么用自带的，要么用外部的。\n\n用自带的很方便，不需要任何其他操作。\n\n如果用外部的，要先安装并启动一个ZK集群，参考我的这篇博客，[在CentOS上安装ZooKeeper集群](http://www.yanjiuyanjiu.com/blog/20140207)。并在 conf/hbase-env.sh 里，设置`HBASE_MANAGES_ZK=false`。这个值默认为true，HBase自带了一个zk，启动HBase的时候也会先启动zk，如果把这个值设置为false，那么HBase就不会自己管理zk集群了。\n\n一般用外部的zk。因为一般情况下，公司会在集群上安装好zookeeper集群，然后多个项目共用一个zk集群，有利于提高资源利用率。\n\nHBase还需要一个正在运行的HDFS集群，如何搭建请参考我的这篇博客，[在CentOS上安装Hadoop 2.x 集群](http://www.yanjiuyanjiu.com/blog/20140205)。\n\n\n###2.1 设置SSH无密码登录localhost\n先检查一下是能够无密码登录本机，\n\n    ssh localhost\n\n如果提示输入密码，说明不能，按如下步骤设置。\n\n    $ ssh-keygen -t dsa -P '' -f ~/.ssh/id_dsa \n    $ cat ~/.ssh/id_dsa.pub >> ~/.ssh/authorized_keys\n\n###2.2 下载，解压\n\n    $ wget wget http://mirror.esocc.com/apache/hbase/hbase-0.96.1.1/hbase-0.96.1.1-hadoop2-bin.tar.gz\n    $ tar zxf hbase-0.96.1.1-hadoop2-bin.tar.gz -C ~/local/opt\n\n###2.3 hbase-env.sh\n在这个文件中要指明JDK 安装在了哪里\n\n    $ echo $JAVA_HOME\n    /usr/lib/jvm/java\n    $ vim conf/hbase-env.sh\n\n取消`JAVA_HOME`那一行的注释，设置正确的JDK位置\n\n    export JAVA_HOME=/usr/lib/jvm/java\n\n###2.4 conf/hbase-site.xml\n内容如下\n\n    <configuration>\n      <property>\n        <name>hbase.rootdir</name>\n        <value>/home/hadoop/local/var/hadoop/hbase</value>\n      </property>\n      <property>\n        <name>hbase.cluster.distributed</name>\n        <value>true</value>\n      </property>\n      \n      <property>\n        <name>hbase.zookeeper.property.clientPort</name>\n        <value>2181</value>\n      </property>\n      <property>\n        <name>hbase.zookeeper.quorum</name>\n        <value>zk01, zk02, zk03</value>\n      </property>\n      <property>\n        <name>hbase.zookeeper.property.dataDir</name>\n        <value>/home/zookeeper/local/var/zookeeper</value>\n      </property>\n    </configuration>\n\n\n`hbase.rootdir`是HBase存放数据的目录，这个值应该从Hadoop集群的core-site.xml里的`fs.defaultFS`或`fs.default.name`拷贝过来。\n\n接下来关于ZooKeeper的三项配置都是从ZooKeeper集群的zoo.cfg里拷贝过来的。\n\n\n###2.5 启动\n\n    $ ./bin/start-hbase.sh\n    starting Master, logging to logs/hbase-user-master-example.org.out\n\n查看一下进程，\n\n    $ jps\n    26142 HMaster\n    26255 HRegionServer\n    26360 Jps\n\n启动了一个HMaster和一个HRegionServer。\n\n###2.6 试用一下HBase shell\n见第1.5节。\n\n###2.7 停止\n\n    $ ./bin/stop-hbase.sh\n    stopping hbase...............\n\n\n##3 完全分布式模式(Fully-distributed mode)\n\n###3.1 准备3台机器\n跟这篇文章[在CentOS上安装Hadoop 2.x 集群](http://www.yanjiuyanjiu.com/blog/20140205/)的第2.1节很类似。\n\n设3台机器的hostname分别是master, slave01, slave02, master作为HMaster，而slave01,slave02作为HRegionServer。\n\n###3.2 配置 master 无密码登陆到所有机器（包括master自己登陆自己）\n参考我的另一篇博客，[SSH无密码登录的配置](http://www.yanjiuyanjiu.com/blog/20120102/)\n\n###3.3 把HBase压缩包上传到所有机器，并解压\n将 hbase-0.96.1.1-hadoop2-bin.tar.gz 上传到所有机器，然后解压。**注意，所有机器的hbase路径必须一致，因为master会登陆到slave上执行命令，master认为slave的hbase路径与自己一样。**\n\n下面开始配置，配置好了后，把`conf/`目录scp到所有其他机器。\n\n###3.4 修改配置文件\n在第2节的基础上，增加下列修改。\n\n####3.4.1 conf/regionservers\n在这个文件里面添加slave，一行一个。\n\n    slave01\n    slave01\n\n####3.4.2 将conf/目录拷贝到所有slaves\n\n    $ scp -r conf/ hbase@slave01:$HBASE_HOME/\n    $ scp -r conf/ hbase@slave02:$HBASE_HOME/\n\n###3.5 启动HBase集群\n\n####3.5.1 启动\n在master上执行：\n\n    $ ./bin/start-hbase.sh\n\n####3.5.2 检查是否启动成功\n用`jps`查看java进程。\n\n在master上，应该有一个HMaster进程，在每台slave上，应该有一个HRegionServer进程。\n\n####3.5.3 Web UI\n\n* HMaster: <http://master:60010>\n* HRegionServer: <http://slave:60030>\n\n\n##4 客户端\n想要在另一台机器，或者另一个用户下访问HBase，怎么办？把hbase的安装目录整个拷贝过来即可，不用任何配置（跟Hadoop想比简单多了）。\n\n运行`./bin/hbase shell`，就可以使用HBase集群了。\n\n\n##参考资料\n\n1. [1.2. Quick Start](http://hbase.apache.org/book/quickstart.html)\n1. [2.2 HBase run modes: Standalone and Distributed](http://hbase.apache.org/book/standalone_dist.html)\n1. [2.4. Example Configurations](http://hbase.apache.org/book/example_config.html)\n1. [Chapter 17. ZooKeeper](http://hbase.apache.org/book/zookeeper.html)\n1. [CentOS分布式环境安装HBase-0.96.0](http://blog.csdn.net/iam333/article/details/16358087)\n\n","source":"_posts/2014-02-08-install-hbase-on-centos.md","raw":"---\nlayout: post\ntitle: \"在CentOS上安装HBase 0.96\"\ndate: 2014-02-08 16:42\ncomments: true\ncategories: Hadoop\n---\n\n环境：CentOS 6.5, jdk 1.7, HBase 0.96.1.1\n\n\n##（可选）创建新用户，并配置好SSH无密码登录\n一般我倾向于把需要启动daemon进程，对外提供服务的程序，即服务器类的程序，安装在单独的用户下面。这样可以做到隔离，运维方面，安全性也提高了。\n\n创建一个新的group,\n\n    $ sudo groupadd hbase\n\n创建一个新的用户，并加入group,\n\n    $ sudo useradd -g hbase hbase\n\n给新用户设置密码，\n\n    $ sudo passwd hbase\n\n在每台机器上创建hbase新用户，并配置好SSH无密码，参考我的另一篇博客，[SSH无密码登录的配置](http://www.yanjiuyanjiu.com/blog/20120102/)\n\n\n##1. 单机模式(Standalone mode)\n\n###1.1 下载，解压\n\n    $ wget wget http://mirror.esocc.com/apache/hbase/hbase-0.96.1.1/hbase-0.96.1.1-hadoop2-bin.tar.gz\n    $ tar zxf hbase-0.96.1.1-hadoop2-bin.tar.gz -C ~/local/opt\n\n###1.2 hbase-env.sh\n在这个文件中要指明JDK 安装在了哪里\n\n    $ echo $JAVA_HOME\n    /usr/lib/jvm/java\n    $ vim conf/hbase-env.sh\n\n取消`JAVA_HOME`那一行的注释，设置正确的JDK位置\n\n    export JAVA_HOME=/usr/lib/jvm/java\n\n###1.3 修改 conf/hbase-site.xml\n内容如下\n\n    <configuration>\n      <property>\n        <name>hbase.rootdir</name>\n        <value>/home/hbase/local/var/hbase</value>\n      </property>\n      <property>\n        <name>hbase.zookeeper.property.dataDir</name>\n        <value>/home/hbase/local/var/zookeeper</value>\n      </property>\n    </configuration>\n\n`hbase.rootdir`目录是用来存放HBase的相关信息的，默认值是`/tmp/hbase-${user.name}/hbase`； `hbase.zookeeper.property.dataDir`目录是用来存放zookeeper（HBase内置了zookeeper）的相关信息的，默认值是`/tmp/hbase-${user.name}/zookeeper`。\n\n###1.4 启动\n\n    $ ./bin/start-hbase.sh\n    starting Master, logging to logs/hbase-user-master-example.org.out\n\n<!-- more -->\n\n###1.5 试用一下HBase shell\n$ ./bin/hbase shell\n    2014-02-09 23:56:28,637 INFO  [main] Configuration.deprecation: hadoop.native.lib is deprecated. Instead, use io.native.lib.available\n    HBase Shell; enter 'help<RETURN>' for list of supported commands.\n    Type \"exit<RETURN>\" to leave the HBase Shell\n    Version 0.96.1.1-hadoop2, rUnknown, Tue Dec 17 12:22:12 PST 2013\n    \n    hbase(main):001:0>\n\n创建一张名字为`test`的表，只有一个列，名为`cf`。为了验证创建是否成功，用`list`命令查看所有的table，并用`put`命令插入一些值。\n\n    hbase(main):003:0> create 'test', 'cf'\n    0 row(s) in 1.2200 seconds\n    hbase(main):003:0> list 'test'\n    ..\n    1 row(s) in 0.0550 seconds\n    hbase(main):004:0> put 'test', 'row1', 'cf:a', 'value1'\n    0 row(s) in 0.0560 seconds\n    hbase(main):005:0> put 'test', 'row2', 'cf:b', 'value2'\n    0 row(s) in 0.0370 seconds\n    hbase(main):006:0> put 'test', 'row3', 'cf:c', 'value3'\n    0 row(s) in 0.0450 seconds\n\n用`scan`命令扫描table，验证一下刚才的插入是否成功。\n\n    hbase(main):007:0> scan 'test'\n    ROW        COLUMN+CELL\n    row1       column=cf:a, timestamp=1288380727188, value=value1\n    row2       column=cf:b, timestamp=1288380738440, value=value2\n    row3       column=cf:c, timestamp=1288380747365, value=value3\n    3 row(s) in 0.0590 seconds\n\n现在，disable并drop掉你的表，这会把上面的所有操作清零。\n\n    hbase(main):012:0> disable 'test'\n    0 row(s) in 1.0930 seconds\n    hbase(main):013:0> drop 'test'\n    0 row(s) in 0.0770 seconds \n\n退出shell，\n\n    hbase(main):014:0> exit\n\n###1.6 停止\n\n    $ ./bin/stop-hbase.sh\n    stopping hbase...............\n\n\n##2 伪分布式模式(Pseudo-distributed mode)\n\n###前提\n\nHBase集群需要一个正在运行的zookeeper集群，要么用自带的，要么用外部的。\n\n用自带的很方便，不需要任何其他操作。\n\n如果用外部的，要先安装并启动一个ZK集群，参考我的这篇博客，[在CentOS上安装ZooKeeper集群](http://www.yanjiuyanjiu.com/blog/20140207)。并在 conf/hbase-env.sh 里，设置`HBASE_MANAGES_ZK=false`。这个值默认为true，HBase自带了一个zk，启动HBase的时候也会先启动zk，如果把这个值设置为false，那么HBase就不会自己管理zk集群了。\n\n一般用外部的zk。因为一般情况下，公司会在集群上安装好zookeeper集群，然后多个项目共用一个zk集群，有利于提高资源利用率。\n\nHBase还需要一个正在运行的HDFS集群，如何搭建请参考我的这篇博客，[在CentOS上安装Hadoop 2.x 集群](http://www.yanjiuyanjiu.com/blog/20140205)。\n\n\n###2.1 设置SSH无密码登录localhost\n先检查一下是能够无密码登录本机，\n\n    ssh localhost\n\n如果提示输入密码，说明不能，按如下步骤设置。\n\n    $ ssh-keygen -t dsa -P '' -f ~/.ssh/id_dsa \n    $ cat ~/.ssh/id_dsa.pub >> ~/.ssh/authorized_keys\n\n###2.2 下载，解压\n\n    $ wget wget http://mirror.esocc.com/apache/hbase/hbase-0.96.1.1/hbase-0.96.1.1-hadoop2-bin.tar.gz\n    $ tar zxf hbase-0.96.1.1-hadoop2-bin.tar.gz -C ~/local/opt\n\n###2.3 hbase-env.sh\n在这个文件中要指明JDK 安装在了哪里\n\n    $ echo $JAVA_HOME\n    /usr/lib/jvm/java\n    $ vim conf/hbase-env.sh\n\n取消`JAVA_HOME`那一行的注释，设置正确的JDK位置\n\n    export JAVA_HOME=/usr/lib/jvm/java\n\n###2.4 conf/hbase-site.xml\n内容如下\n\n    <configuration>\n      <property>\n        <name>hbase.rootdir</name>\n        <value>/home/hadoop/local/var/hadoop/hbase</value>\n      </property>\n      <property>\n        <name>hbase.cluster.distributed</name>\n        <value>true</value>\n      </property>\n      \n      <property>\n        <name>hbase.zookeeper.property.clientPort</name>\n        <value>2181</value>\n      </property>\n      <property>\n        <name>hbase.zookeeper.quorum</name>\n        <value>zk01, zk02, zk03</value>\n      </property>\n      <property>\n        <name>hbase.zookeeper.property.dataDir</name>\n        <value>/home/zookeeper/local/var/zookeeper</value>\n      </property>\n    </configuration>\n\n\n`hbase.rootdir`是HBase存放数据的目录，这个值应该从Hadoop集群的core-site.xml里的`fs.defaultFS`或`fs.default.name`拷贝过来。\n\n接下来关于ZooKeeper的三项配置都是从ZooKeeper集群的zoo.cfg里拷贝过来的。\n\n\n###2.5 启动\n\n    $ ./bin/start-hbase.sh\n    starting Master, logging to logs/hbase-user-master-example.org.out\n\n查看一下进程，\n\n    $ jps\n    26142 HMaster\n    26255 HRegionServer\n    26360 Jps\n\n启动了一个HMaster和一个HRegionServer。\n\n###2.6 试用一下HBase shell\n见第1.5节。\n\n###2.7 停止\n\n    $ ./bin/stop-hbase.sh\n    stopping hbase...............\n\n\n##3 完全分布式模式(Fully-distributed mode)\n\n###3.1 准备3台机器\n跟这篇文章[在CentOS上安装Hadoop 2.x 集群](http://www.yanjiuyanjiu.com/blog/20140205/)的第2.1节很类似。\n\n设3台机器的hostname分别是master, slave01, slave02, master作为HMaster，而slave01,slave02作为HRegionServer。\n\n###3.2 配置 master 无密码登陆到所有机器（包括master自己登陆自己）\n参考我的另一篇博客，[SSH无密码登录的配置](http://www.yanjiuyanjiu.com/blog/20120102/)\n\n###3.3 把HBase压缩包上传到所有机器，并解压\n将 hbase-0.96.1.1-hadoop2-bin.tar.gz 上传到所有机器，然后解压。**注意，所有机器的hbase路径必须一致，因为master会登陆到slave上执行命令，master认为slave的hbase路径与自己一样。**\n\n下面开始配置，配置好了后，把`conf/`目录scp到所有其他机器。\n\n###3.4 修改配置文件\n在第2节的基础上，增加下列修改。\n\n####3.4.1 conf/regionservers\n在这个文件里面添加slave，一行一个。\n\n    slave01\n    slave01\n\n####3.4.2 将conf/目录拷贝到所有slaves\n\n    $ scp -r conf/ hbase@slave01:$HBASE_HOME/\n    $ scp -r conf/ hbase@slave02:$HBASE_HOME/\n\n###3.5 启动HBase集群\n\n####3.5.1 启动\n在master上执行：\n\n    $ ./bin/start-hbase.sh\n\n####3.5.2 检查是否启动成功\n用`jps`查看java进程。\n\n在master上，应该有一个HMaster进程，在每台slave上，应该有一个HRegionServer进程。\n\n####3.5.3 Web UI\n\n* HMaster: <http://master:60010>\n* HRegionServer: <http://slave:60030>\n\n\n##4 客户端\n想要在另一台机器，或者另一个用户下访问HBase，怎么办？把hbase的安装目录整个拷贝过来即可，不用任何配置（跟Hadoop想比简单多了）。\n\n运行`./bin/hbase shell`，就可以使用HBase集群了。\n\n\n##参考资料\n\n1. [1.2. Quick Start](http://hbase.apache.org/book/quickstart.html)\n1. [2.2 HBase run modes: Standalone and Distributed](http://hbase.apache.org/book/standalone_dist.html)\n1. [2.4. Example Configurations](http://hbase.apache.org/book/example_config.html)\n1. [Chapter 17. ZooKeeper](http://hbase.apache.org/book/zookeeper.html)\n1. [CentOS分布式环境安装HBase-0.96.0](http://blog.csdn.net/iam333/article/details/16358087)\n\n","slug":"2014-02-08-install-hbase-on-centos","published":1,"updated":"2016-08-18T09:21:04.000Z","photos":[],"link":"","_id":"cis07pf4n003m01pqh6d77h1u","content":"<p>环境：CentOS 6.5, jdk 1.7, HBase 0.96.1.1</p>\n<p>##（可选）创建新用户，并配置好SSH无密码登录<br>一般我倾向于把需要启动daemon进程，对外提供服务的程序，即服务器类的程序，安装在单独的用户下面。这样可以做到隔离，运维方面，安全性也提高了。</p>\n<p>创建一个新的group,</p>\n<pre><code>$ sudo groupadd hbase\n</code></pre><p>创建一个新的用户，并加入group,</p>\n<pre><code>$ sudo useradd -g hbase hbase\n</code></pre><p>给新用户设置密码，</p>\n<pre><code>$ sudo passwd hbase\n</code></pre><p>在每台机器上创建hbase新用户，并配置好SSH无密码，参考我的另一篇博客，<a href=\"http://www.yanjiuyanjiu.com/blog/20120102/\" target=\"_blank\" rel=\"external\">SSH无密码登录的配置</a></p>\n<p>##1. 单机模式(Standalone mode)</p>\n<p>###1.1 下载，解压</p>\n<pre><code>$ wget wget http://mirror.esocc.com/apache/hbase/hbase-0.96.1.1/hbase-0.96.1.1-hadoop2-bin.tar.gz\n$ tar zxf hbase-0.96.1.1-hadoop2-bin.tar.gz -C ~/local/opt\n</code></pre><p>###1.2 hbase-env.sh<br>在这个文件中要指明JDK 安装在了哪里</p>\n<pre><code>$ echo $JAVA_HOME\n/usr/lib/jvm/java\n$ vim conf/hbase-env.sh\n</code></pre><p>取消<code>JAVA_HOME</code>那一行的注释，设置正确的JDK位置</p>\n<pre><code>export JAVA_HOME=/usr/lib/jvm/java\n</code></pre><p>###1.3 修改 conf/hbase-site.xml<br>内容如下</p>\n<pre><code>&lt;configuration&gt;\n  &lt;property&gt;\n    &lt;name&gt;hbase.rootdir&lt;/name&gt;\n    &lt;value&gt;/home/hbase/local/var/hbase&lt;/value&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;hbase.zookeeper.property.dataDir&lt;/name&gt;\n    &lt;value&gt;/home/hbase/local/var/zookeeper&lt;/value&gt;\n  &lt;/property&gt;\n&lt;/configuration&gt;\n</code></pre><p><code>hbase.rootdir</code>目录是用来存放HBase的相关信息的，默认值是<code>/tmp/hbase-${user.name}/hbase</code>； <code>hbase.zookeeper.property.dataDir</code>目录是用来存放zookeeper（HBase内置了zookeeper）的相关信息的，默认值是<code>/tmp/hbase-${user.name}/zookeeper</code>。</p>\n<p>###1.4 启动</p>\n<pre><code>$ ./bin/start-hbase.sh\nstarting Master, logging to logs/hbase-user-master-example.org.out\n</code></pre><a id=\"more\"></a>\n<p>###1.5 试用一下HBase shell<br>$ ./bin/hbase shell<br>    2014-02-09 23:56:28,637 INFO  [main] Configuration.deprecation: hadoop.native.lib is deprecated. Instead, use io.native.lib.available<br>    HBase Shell; enter ‘help<return>‘ for list of supported commands.<br>    Type “exit<return>“ to leave the HBase Shell<br>    Version 0.96.1.1-hadoop2, rUnknown, Tue Dec 17 12:22:12 PST 2013</return></return></p>\n<pre><code>hbase(main):001:0&gt;\n</code></pre><p>创建一张名字为<code>test</code>的表，只有一个列，名为<code>cf</code>。为了验证创建是否成功，用<code>list</code>命令查看所有的table，并用<code>put</code>命令插入一些值。</p>\n<pre><code>hbase(main):003:0&gt; create &apos;test&apos;, &apos;cf&apos;\n0 row(s) in 1.2200 seconds\nhbase(main):003:0&gt; list &apos;test&apos;\n..\n1 row(s) in 0.0550 seconds\nhbase(main):004:0&gt; put &apos;test&apos;, &apos;row1&apos;, &apos;cf:a&apos;, &apos;value1&apos;\n0 row(s) in 0.0560 seconds\nhbase(main):005:0&gt; put &apos;test&apos;, &apos;row2&apos;, &apos;cf:b&apos;, &apos;value2&apos;\n0 row(s) in 0.0370 seconds\nhbase(main):006:0&gt; put &apos;test&apos;, &apos;row3&apos;, &apos;cf:c&apos;, &apos;value3&apos;\n0 row(s) in 0.0450 seconds\n</code></pre><p>用<code>scan</code>命令扫描table，验证一下刚才的插入是否成功。</p>\n<pre><code>hbase(main):007:0&gt; scan &apos;test&apos;\nROW        COLUMN+CELL\nrow1       column=cf:a, timestamp=1288380727188, value=value1\nrow2       column=cf:b, timestamp=1288380738440, value=value2\nrow3       column=cf:c, timestamp=1288380747365, value=value3\n3 row(s) in 0.0590 seconds\n</code></pre><p>现在，disable并drop掉你的表，这会把上面的所有操作清零。</p>\n<pre><code>hbase(main):012:0&gt; disable &apos;test&apos;\n0 row(s) in 1.0930 seconds\nhbase(main):013:0&gt; drop &apos;test&apos;\n0 row(s) in 0.0770 seconds \n</code></pre><p>退出shell，</p>\n<pre><code>hbase(main):014:0&gt; exit\n</code></pre><p>###1.6 停止</p>\n<pre><code>$ ./bin/stop-hbase.sh\nstopping hbase...............\n</code></pre><p>##2 伪分布式模式(Pseudo-distributed mode)</p>\n<p>###前提</p>\n<p>HBase集群需要一个正在运行的zookeeper集群，要么用自带的，要么用外部的。</p>\n<p>用自带的很方便，不需要任何其他操作。</p>\n<p>如果用外部的，要先安装并启动一个ZK集群，参考我的这篇博客，<a href=\"http://www.yanjiuyanjiu.com/blog/20140207\" target=\"_blank\" rel=\"external\">在CentOS上安装ZooKeeper集群</a>。并在 conf/hbase-env.sh 里，设置<code>HBASE_MANAGES_ZK=false</code>。这个值默认为true，HBase自带了一个zk，启动HBase的时候也会先启动zk，如果把这个值设置为false，那么HBase就不会自己管理zk集群了。</p>\n<p>一般用外部的zk。因为一般情况下，公司会在集群上安装好zookeeper集群，然后多个项目共用一个zk集群，有利于提高资源利用率。</p>\n<p>HBase还需要一个正在运行的HDFS集群，如何搭建请参考我的这篇博客，<a href=\"http://www.yanjiuyanjiu.com/blog/20140205\" target=\"_blank\" rel=\"external\">在CentOS上安装Hadoop 2.x 集群</a>。</p>\n<p>###2.1 设置SSH无密码登录localhost<br>先检查一下是能够无密码登录本机，</p>\n<pre><code>ssh localhost\n</code></pre><p>如果提示输入密码，说明不能，按如下步骤设置。</p>\n<pre><code>$ ssh-keygen -t dsa -P &apos;&apos; -f ~/.ssh/id_dsa \n$ cat ~/.ssh/id_dsa.pub &gt;&gt; ~/.ssh/authorized_keys\n</code></pre><p>###2.2 下载，解压</p>\n<pre><code>$ wget wget http://mirror.esocc.com/apache/hbase/hbase-0.96.1.1/hbase-0.96.1.1-hadoop2-bin.tar.gz\n$ tar zxf hbase-0.96.1.1-hadoop2-bin.tar.gz -C ~/local/opt\n</code></pre><p>###2.3 hbase-env.sh<br>在这个文件中要指明JDK 安装在了哪里</p>\n<pre><code>$ echo $JAVA_HOME\n/usr/lib/jvm/java\n$ vim conf/hbase-env.sh\n</code></pre><p>取消<code>JAVA_HOME</code>那一行的注释，设置正确的JDK位置</p>\n<pre><code>export JAVA_HOME=/usr/lib/jvm/java\n</code></pre><p>###2.4 conf/hbase-site.xml<br>内容如下</p>\n<pre><code>&lt;configuration&gt;\n  &lt;property&gt;\n    &lt;name&gt;hbase.rootdir&lt;/name&gt;\n    &lt;value&gt;/home/hadoop/local/var/hadoop/hbase&lt;/value&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;hbase.cluster.distributed&lt;/name&gt;\n    &lt;value&gt;true&lt;/value&gt;\n  &lt;/property&gt;\n\n  &lt;property&gt;\n    &lt;name&gt;hbase.zookeeper.property.clientPort&lt;/name&gt;\n    &lt;value&gt;2181&lt;/value&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;hbase.zookeeper.quorum&lt;/name&gt;\n    &lt;value&gt;zk01, zk02, zk03&lt;/value&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;hbase.zookeeper.property.dataDir&lt;/name&gt;\n    &lt;value&gt;/home/zookeeper/local/var/zookeeper&lt;/value&gt;\n  &lt;/property&gt;\n&lt;/configuration&gt;\n</code></pre><p><code>hbase.rootdir</code>是HBase存放数据的目录，这个值应该从Hadoop集群的core-site.xml里的<code>fs.defaultFS</code>或<code>fs.default.name</code>拷贝过来。</p>\n<p>接下来关于ZooKeeper的三项配置都是从ZooKeeper集群的zoo.cfg里拷贝过来的。</p>\n<p>###2.5 启动</p>\n<pre><code>$ ./bin/start-hbase.sh\nstarting Master, logging to logs/hbase-user-master-example.org.out\n</code></pre><p>查看一下进程，</p>\n<pre><code>$ jps\n26142 HMaster\n26255 HRegionServer\n26360 Jps\n</code></pre><p>启动了一个HMaster和一个HRegionServer。</p>\n<p>###2.6 试用一下HBase shell<br>见第1.5节。</p>\n<p>###2.7 停止</p>\n<pre><code>$ ./bin/stop-hbase.sh\nstopping hbase...............\n</code></pre><p>##3 完全分布式模式(Fully-distributed mode)</p>\n<p>###3.1 准备3台机器<br>跟这篇文章<a href=\"http://www.yanjiuyanjiu.com/blog/20140205/\" target=\"_blank\" rel=\"external\">在CentOS上安装Hadoop 2.x 集群</a>的第2.1节很类似。</p>\n<p>设3台机器的hostname分别是master, slave01, slave02, master作为HMaster，而slave01,slave02作为HRegionServer。</p>\n<p>###3.2 配置 master 无密码登陆到所有机器（包括master自己登陆自己）<br>参考我的另一篇博客，<a href=\"http://www.yanjiuyanjiu.com/blog/20120102/\" target=\"_blank\" rel=\"external\">SSH无密码登录的配置</a></p>\n<p>###3.3 把HBase压缩包上传到所有机器，并解压<br>将 hbase-0.96.1.1-hadoop2-bin.tar.gz 上传到所有机器，然后解压。<strong>注意，所有机器的hbase路径必须一致，因为master会登陆到slave上执行命令，master认为slave的hbase路径与自己一样。</strong></p>\n<p>下面开始配置，配置好了后，把<code>conf/</code>目录scp到所有其他机器。</p>\n<p>###3.4 修改配置文件<br>在第2节的基础上，增加下列修改。</p>\n<p>####3.4.1 conf/regionservers<br>在这个文件里面添加slave，一行一个。</p>\n<pre><code>slave01\nslave01\n</code></pre><p>####3.4.2 将conf/目录拷贝到所有slaves</p>\n<pre><code>$ scp -r conf/ hbase@slave01:$HBASE_HOME/\n$ scp -r conf/ hbase@slave02:$HBASE_HOME/\n</code></pre><p>###3.5 启动HBase集群</p>\n<p>####3.5.1 启动<br>在master上执行：</p>\n<pre><code>$ ./bin/start-hbase.sh\n</code></pre><p>####3.5.2 检查是否启动成功<br>用<code>jps</code>查看java进程。</p>\n<p>在master上，应该有一个HMaster进程，在每台slave上，应该有一个HRegionServer进程。</p>\n<p>####3.5.3 Web UI</p>\n<ul>\n<li>HMaster: <a href=\"http://master:60010\" target=\"_blank\" rel=\"external\">http://master:60010</a></li>\n<li>HRegionServer: <a href=\"http://slave:60030\" target=\"_blank\" rel=\"external\">http://slave:60030</a></li>\n</ul>\n<p>##4 客户端<br>想要在另一台机器，或者另一个用户下访问HBase，怎么办？把hbase的安装目录整个拷贝过来即可，不用任何配置（跟Hadoop想比简单多了）。</p>\n<p>运行<code>./bin/hbase shell</code>，就可以使用HBase集群了。</p>\n<p>##参考资料</p>\n<ol>\n<li><a href=\"http://hbase.apache.org/book/quickstart.html\" target=\"_blank\" rel=\"external\">1.2. Quick Start</a></li>\n<li><a href=\"http://hbase.apache.org/book/standalone_dist.html\" target=\"_blank\" rel=\"external\">2.2 HBase run modes: Standalone and Distributed</a></li>\n<li><a href=\"http://hbase.apache.org/book/example_config.html\" target=\"_blank\" rel=\"external\">2.4. Example Configurations</a></li>\n<li><a href=\"http://hbase.apache.org/book/zookeeper.html\" target=\"_blank\" rel=\"external\">Chapter 17. ZooKeeper</a></li>\n<li><a href=\"http://blog.csdn.net/iam333/article/details/16358087\" target=\"_blank\" rel=\"external\">CentOS分布式环境安装HBase-0.96.0</a></li>\n</ol>\n","excerpt":"<p>环境：CentOS 6.5, jdk 1.7, HBase 0.96.1.1</p>\n<p>##（可选）创建新用户，并配置好SSH无密码登录<br>一般我倾向于把需要启动daemon进程，对外提供服务的程序，即服务器类的程序，安装在单独的用户下面。这样可以做到隔离，运维方面，安全性也提高了。</p>\n<p>创建一个新的group,</p>\n<pre><code>$ sudo groupadd hbase\n</code></pre><p>创建一个新的用户，并加入group,</p>\n<pre><code>$ sudo useradd -g hbase hbase\n</code></pre><p>给新用户设置密码，</p>\n<pre><code>$ sudo passwd hbase\n</code></pre><p>在每台机器上创建hbase新用户，并配置好SSH无密码，参考我的另一篇博客，<a href=\"http://www.yanjiuyanjiu.com/blog/20120102/\">SSH无密码登录的配置</a></p>\n<p>##1. 单机模式(Standalone mode)</p>\n<p>###1.1 下载，解压</p>\n<pre><code>$ wget wget http://mirror.esocc.com/apache/hbase/hbase-0.96.1.1/hbase-0.96.1.1-hadoop2-bin.tar.gz\n$ tar zxf hbase-0.96.1.1-hadoop2-bin.tar.gz -C ~/local/opt\n</code></pre><p>###1.2 hbase-env.sh<br>在这个文件中要指明JDK 安装在了哪里</p>\n<pre><code>$ echo $JAVA_HOME\n/usr/lib/jvm/java\n$ vim conf/hbase-env.sh\n</code></pre><p>取消<code>JAVA_HOME</code>那一行的注释，设置正确的JDK位置</p>\n<pre><code>export JAVA_HOME=/usr/lib/jvm/java\n</code></pre><p>###1.3 修改 conf/hbase-site.xml<br>内容如下</p>\n<pre><code>&lt;configuration&gt;\n  &lt;property&gt;\n    &lt;name&gt;hbase.rootdir&lt;/name&gt;\n    &lt;value&gt;/home/hbase/local/var/hbase&lt;/value&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;hbase.zookeeper.property.dataDir&lt;/name&gt;\n    &lt;value&gt;/home/hbase/local/var/zookeeper&lt;/value&gt;\n  &lt;/property&gt;\n&lt;/configuration&gt;\n</code></pre><p><code>hbase.rootdir</code>目录是用来存放HBase的相关信息的，默认值是<code>/tmp/hbase-${user.name}/hbase</code>； <code>hbase.zookeeper.property.dataDir</code>目录是用来存放zookeeper（HBase内置了zookeeper）的相关信息的，默认值是<code>/tmp/hbase-${user.name}/zookeeper</code>。</p>\n<p>###1.4 启动</p>\n<pre><code>$ ./bin/start-hbase.sh\nstarting Master, logging to logs/hbase-user-master-example.org.out\n</code></pre>","more":"<p>###1.5 试用一下HBase shell<br>$ ./bin/hbase shell<br>    2014-02-09 23:56:28,637 INFO  [main] Configuration.deprecation: hadoop.native.lib is deprecated. Instead, use io.native.lib.available<br>    HBase Shell; enter ‘help<RETURN>‘ for list of supported commands.<br>    Type “exit<RETURN>“ to leave the HBase Shell<br>    Version 0.96.1.1-hadoop2, rUnknown, Tue Dec 17 12:22:12 PST 2013</p>\n<pre><code>hbase(main):001:0&gt;\n</code></pre><p>创建一张名字为<code>test</code>的表，只有一个列，名为<code>cf</code>。为了验证创建是否成功，用<code>list</code>命令查看所有的table，并用<code>put</code>命令插入一些值。</p>\n<pre><code>hbase(main):003:0&gt; create &apos;test&apos;, &apos;cf&apos;\n0 row(s) in 1.2200 seconds\nhbase(main):003:0&gt; list &apos;test&apos;\n..\n1 row(s) in 0.0550 seconds\nhbase(main):004:0&gt; put &apos;test&apos;, &apos;row1&apos;, &apos;cf:a&apos;, &apos;value1&apos;\n0 row(s) in 0.0560 seconds\nhbase(main):005:0&gt; put &apos;test&apos;, &apos;row2&apos;, &apos;cf:b&apos;, &apos;value2&apos;\n0 row(s) in 0.0370 seconds\nhbase(main):006:0&gt; put &apos;test&apos;, &apos;row3&apos;, &apos;cf:c&apos;, &apos;value3&apos;\n0 row(s) in 0.0450 seconds\n</code></pre><p>用<code>scan</code>命令扫描table，验证一下刚才的插入是否成功。</p>\n<pre><code>hbase(main):007:0&gt; scan &apos;test&apos;\nROW        COLUMN+CELL\nrow1       column=cf:a, timestamp=1288380727188, value=value1\nrow2       column=cf:b, timestamp=1288380738440, value=value2\nrow3       column=cf:c, timestamp=1288380747365, value=value3\n3 row(s) in 0.0590 seconds\n</code></pre><p>现在，disable并drop掉你的表，这会把上面的所有操作清零。</p>\n<pre><code>hbase(main):012:0&gt; disable &apos;test&apos;\n0 row(s) in 1.0930 seconds\nhbase(main):013:0&gt; drop &apos;test&apos;\n0 row(s) in 0.0770 seconds \n</code></pre><p>退出shell，</p>\n<pre><code>hbase(main):014:0&gt; exit\n</code></pre><p>###1.6 停止</p>\n<pre><code>$ ./bin/stop-hbase.sh\nstopping hbase...............\n</code></pre><p>##2 伪分布式模式(Pseudo-distributed mode)</p>\n<p>###前提</p>\n<p>HBase集群需要一个正在运行的zookeeper集群，要么用自带的，要么用外部的。</p>\n<p>用自带的很方便，不需要任何其他操作。</p>\n<p>如果用外部的，要先安装并启动一个ZK集群，参考我的这篇博客，<a href=\"http://www.yanjiuyanjiu.com/blog/20140207\">在CentOS上安装ZooKeeper集群</a>。并在 conf/hbase-env.sh 里，设置<code>HBASE_MANAGES_ZK=false</code>。这个值默认为true，HBase自带了一个zk，启动HBase的时候也会先启动zk，如果把这个值设置为false，那么HBase就不会自己管理zk集群了。</p>\n<p>一般用外部的zk。因为一般情况下，公司会在集群上安装好zookeeper集群，然后多个项目共用一个zk集群，有利于提高资源利用率。</p>\n<p>HBase还需要一个正在运行的HDFS集群，如何搭建请参考我的这篇博客，<a href=\"http://www.yanjiuyanjiu.com/blog/20140205\">在CentOS上安装Hadoop 2.x 集群</a>。</p>\n<p>###2.1 设置SSH无密码登录localhost<br>先检查一下是能够无密码登录本机，</p>\n<pre><code>ssh localhost\n</code></pre><p>如果提示输入密码，说明不能，按如下步骤设置。</p>\n<pre><code>$ ssh-keygen -t dsa -P &apos;&apos; -f ~/.ssh/id_dsa \n$ cat ~/.ssh/id_dsa.pub &gt;&gt; ~/.ssh/authorized_keys\n</code></pre><p>###2.2 下载，解压</p>\n<pre><code>$ wget wget http://mirror.esocc.com/apache/hbase/hbase-0.96.1.1/hbase-0.96.1.1-hadoop2-bin.tar.gz\n$ tar zxf hbase-0.96.1.1-hadoop2-bin.tar.gz -C ~/local/opt\n</code></pre><p>###2.3 hbase-env.sh<br>在这个文件中要指明JDK 安装在了哪里</p>\n<pre><code>$ echo $JAVA_HOME\n/usr/lib/jvm/java\n$ vim conf/hbase-env.sh\n</code></pre><p>取消<code>JAVA_HOME</code>那一行的注释，设置正确的JDK位置</p>\n<pre><code>export JAVA_HOME=/usr/lib/jvm/java\n</code></pre><p>###2.4 conf/hbase-site.xml<br>内容如下</p>\n<pre><code>&lt;configuration&gt;\n  &lt;property&gt;\n    &lt;name&gt;hbase.rootdir&lt;/name&gt;\n    &lt;value&gt;/home/hadoop/local/var/hadoop/hbase&lt;/value&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;hbase.cluster.distributed&lt;/name&gt;\n    &lt;value&gt;true&lt;/value&gt;\n  &lt;/property&gt;\n\n  &lt;property&gt;\n    &lt;name&gt;hbase.zookeeper.property.clientPort&lt;/name&gt;\n    &lt;value&gt;2181&lt;/value&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;hbase.zookeeper.quorum&lt;/name&gt;\n    &lt;value&gt;zk01, zk02, zk03&lt;/value&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;hbase.zookeeper.property.dataDir&lt;/name&gt;\n    &lt;value&gt;/home/zookeeper/local/var/zookeeper&lt;/value&gt;\n  &lt;/property&gt;\n&lt;/configuration&gt;\n</code></pre><p><code>hbase.rootdir</code>是HBase存放数据的目录，这个值应该从Hadoop集群的core-site.xml里的<code>fs.defaultFS</code>或<code>fs.default.name</code>拷贝过来。</p>\n<p>接下来关于ZooKeeper的三项配置都是从ZooKeeper集群的zoo.cfg里拷贝过来的。</p>\n<p>###2.5 启动</p>\n<pre><code>$ ./bin/start-hbase.sh\nstarting Master, logging to logs/hbase-user-master-example.org.out\n</code></pre><p>查看一下进程，</p>\n<pre><code>$ jps\n26142 HMaster\n26255 HRegionServer\n26360 Jps\n</code></pre><p>启动了一个HMaster和一个HRegionServer。</p>\n<p>###2.6 试用一下HBase shell<br>见第1.5节。</p>\n<p>###2.7 停止</p>\n<pre><code>$ ./bin/stop-hbase.sh\nstopping hbase...............\n</code></pre><p>##3 完全分布式模式(Fully-distributed mode)</p>\n<p>###3.1 准备3台机器<br>跟这篇文章<a href=\"http://www.yanjiuyanjiu.com/blog/20140205/\">在CentOS上安装Hadoop 2.x 集群</a>的第2.1节很类似。</p>\n<p>设3台机器的hostname分别是master, slave01, slave02, master作为HMaster，而slave01,slave02作为HRegionServer。</p>\n<p>###3.2 配置 master 无密码登陆到所有机器（包括master自己登陆自己）<br>参考我的另一篇博客，<a href=\"http://www.yanjiuyanjiu.com/blog/20120102/\">SSH无密码登录的配置</a></p>\n<p>###3.3 把HBase压缩包上传到所有机器，并解压<br>将 hbase-0.96.1.1-hadoop2-bin.tar.gz 上传到所有机器，然后解压。<strong>注意，所有机器的hbase路径必须一致，因为master会登陆到slave上执行命令，master认为slave的hbase路径与自己一样。</strong></p>\n<p>下面开始配置，配置好了后，把<code>conf/</code>目录scp到所有其他机器。</p>\n<p>###3.4 修改配置文件<br>在第2节的基础上，增加下列修改。</p>\n<p>####3.4.1 conf/regionservers<br>在这个文件里面添加slave，一行一个。</p>\n<pre><code>slave01\nslave01\n</code></pre><p>####3.4.2 将conf/目录拷贝到所有slaves</p>\n<pre><code>$ scp -r conf/ hbase@slave01:$HBASE_HOME/\n$ scp -r conf/ hbase@slave02:$HBASE_HOME/\n</code></pre><p>###3.5 启动HBase集群</p>\n<p>####3.5.1 启动<br>在master上执行：</p>\n<pre><code>$ ./bin/start-hbase.sh\n</code></pre><p>####3.5.2 检查是否启动成功<br>用<code>jps</code>查看java进程。</p>\n<p>在master上，应该有一个HMaster进程，在每台slave上，应该有一个HRegionServer进程。</p>\n<p>####3.5.3 Web UI</p>\n<ul>\n<li>HMaster: <a href=\"http://master:60010\">http://master:60010</a></li>\n<li>HRegionServer: <a href=\"http://slave:60030\">http://slave:60030</a></li>\n</ul>\n<p>##4 客户端<br>想要在另一台机器，或者另一个用户下访问HBase，怎么办？把hbase的安装目录整个拷贝过来即可，不用任何配置（跟Hadoop想比简单多了）。</p>\n<p>运行<code>./bin/hbase shell</code>，就可以使用HBase集群了。</p>\n<p>##参考资料</p>\n<ol>\n<li><a href=\"http://hbase.apache.org/book/quickstart.html\">1.2. Quick Start</a></li>\n<li><a href=\"http://hbase.apache.org/book/standalone_dist.html\">2.2 HBase run modes: Standalone and Distributed</a></li>\n<li><a href=\"http://hbase.apache.org/book/example_config.html\">2.4. Example Configurations</a></li>\n<li><a href=\"http://hbase.apache.org/book/zookeeper.html\">Chapter 17. ZooKeeper</a></li>\n<li><a href=\"http://blog.csdn.net/iam333/article/details/16358087\">CentOS分布式环境安装HBase-0.96.0</a></li>\n</ol>"},{"layout":"post","title":"Caffe 安装配置(CentOS + 无GPU)","date":"2014-04-03T16:05:00.000Z","comments":1,"_content":"\n**环境**: CentOS 6.4\n\n由于我的CentOS服务器上没有Nvidia的显卡，不过 caffe 是可以在CPU模式下进行train和predict的，因此我尝试了在没有GPU的情况下把caffe跑起来。\n\n主要参考官网的文档，[Installation](http://caffe.berkeleyvision.org/installation.html)。\n\n安装 Caffe 前需要安装以下库：\n\n**Prerequisites**\n\n* CUDA (5.0 or 5.5)\n* Boost\n* MKL (but see the boost-eigen branch for a boost/Eigen3 port)\n* OpenCV\n* glog, gflags, protobuf, leveldb, snappy, hdf5\n* For the Python wrapper: python, numpy (>= 1.7 preferred), and boost_python\n* For the Matlab wrapper: Matlab with mex\n\n##1. 安装CUDA\n\n\twget http://developer.download.nvidia.com/compute/cuda/repos/rhel6/x86_64/cuda-repo-rhel6-5.5-0.x86_64.rpm\n\tsudo rpm -Uvh libgcc-4.4.7-4.el6.x86_64.rpm\n\tyum search cuda\n\tsudo yum install cuda\n\n或者\n\n    wget http://developer.download.nvidia.com/compute/cuda/5_5/rel/installers/cuda_5.5.22_linux_64.run\n    sudo ./cuda_5.5.22_linux_64.run\n\n##2. 安装Boost\n\n\tsudo yum install boost-devel\n\n<!-- more -->\n\n##3. 安装MKL\nMKL是Intel的商业软件，性能很高，也卖的很贵。还好可以申请非商业版，去这里 <https://registrationcenter.intel.com/RegCenter/NComForm.aspx?ProductID=1461&pass=yes> 申请，申请成功之后你会得到一个序列号以及下载地址，下载完并解压， 执行`sudo ./install.sh` ， 之后按提示安装就好了，这个安装特别简单。\n\n##4. 安装OpenCV\n\n    sudo yum install opencv-devel\n\n##5. 安装其他库\n\n    wget https://google-glog.googlecode.com/files/glog-0.3.3.tar.gz\n    tar zxf glog-0.3.3.tar.gz\n    cd glog-0.3.3\n    ./configure\n    make\n    sudo make install\n\n    sudo yum install gflags-devel protobuf-devel leveldb-devel snappy-devel hdf5-devel\n\n##6. 配置OpenCV环境\nCaffe作者默认你已经配置好了OpenCV环境，文档里没有说这一步。好在有人已经写好了配置OpenCV的脚本，<https://github.com/jayrambhia/Install-OpenCV> ，直接拿来用。\n\n    git clone https://github.com/jayrambhia/Install-OpenCV\n    cd Install-OpenCV/RedHat\n    sudo ./opencv_latest.sh\n\n如果脚本运行失败，则详细阅读`RetHat/opencv_install.sh`的代码，然后手工敲入命令进行安装。\n\n    mkdir OpenCV\n    cd OpenCV\n    wget -O opencv-2.4.7.tar.gz http://sourceforge.net/projects/opencvlibrary/files/opencv-unix/2.4.7/opencv-2.4.7.tar.gz/download\n    tar -zxf opencv-2.4.7.tar.gz\n    cd opencv-2.4.7\n    sed  -i '/string(MD5/d' cmake/cl2cpp.cmake\n    mkdir build\n    cd build\n    cmake -D CMAKE_BUILD_TYPE=RELEASE -D CMAKE_INSTALL_PREFIX=/usr/local ..\n    make -j 4\n    sudo make install\n    sudo sh -c 'echo \"/usr/local/lib\" > /etc/ld.so.conf.d/opencv.conf'\n    sudo ldconfig\n\n##7. 编译\n\n    cp Makefile.config.example Makefile.config\n    make all\n\n##8. 运行MNIST例子\n主要参考官网的 [Training MNIST with Caffe](http://caffe.berkeleyvision.org/mnist.html)\n\n###8.1 下载数据集\n\n    cd $CAFFE_ROOT/data/mnist\n    ./get_mnist.sh\n    cd $CAFFE_ROOT/examples/lenet\n    export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/cuda/lib64\n    ./create_mnist.sh\n    \n运行完上述命令后，应该会得到两个数据集，`mnist-train-leveldb/`, 和 `mnist-test-leveldb/`.\n\n最终的model，\n\n###8.2 切换到CPU模式\n由于服务器没有安装显卡，只能使用CPU训练。切换到CPU模式非常简单，只需要在`lenet_solver.prototxt`中修改一行：\n\n> \\# solver mode: 0 for CPU and 1 for GP   \n> solver_mode: 0\n\n###8.3 开始训练\n\n    ./train_lenet.sh\n\n经过一段时间运行，训练完成！最终的model，会存为一个二进制的protobuf文件，`lenet_iter_10000`. \n\n\n##参考资料\n\n1. [CNN之Caffe配置](http://www.cnblogs.com/alfredtofu/p/3577241.html)\n\n\n注意， CUDA 5.5 不支持 Visual Studio 2013，参考 [CUDA 5.5 release notes](http://docs.nvidia.com/cuda/cuda-toolkit-release-notes/index.html#windows-5-5)","source":"_posts/2014-04-03-caffe-installation.md","raw":"---\nlayout: post\ntitle: \"Caffe 安装配置(CentOS + 无GPU)\"\ndate: 2014-04-03 16:05\ncomments: true\ncategories: Deep-Learning\n---\n\n**环境**: CentOS 6.4\n\n由于我的CentOS服务器上没有Nvidia的显卡，不过 caffe 是可以在CPU模式下进行train和predict的，因此我尝试了在没有GPU的情况下把caffe跑起来。\n\n主要参考官网的文档，[Installation](http://caffe.berkeleyvision.org/installation.html)。\n\n安装 Caffe 前需要安装以下库：\n\n**Prerequisites**\n\n* CUDA (5.0 or 5.5)\n* Boost\n* MKL (but see the boost-eigen branch for a boost/Eigen3 port)\n* OpenCV\n* glog, gflags, protobuf, leveldb, snappy, hdf5\n* For the Python wrapper: python, numpy (>= 1.7 preferred), and boost_python\n* For the Matlab wrapper: Matlab with mex\n\n##1. 安装CUDA\n\n\twget http://developer.download.nvidia.com/compute/cuda/repos/rhel6/x86_64/cuda-repo-rhel6-5.5-0.x86_64.rpm\n\tsudo rpm -Uvh libgcc-4.4.7-4.el6.x86_64.rpm\n\tyum search cuda\n\tsudo yum install cuda\n\n或者\n\n    wget http://developer.download.nvidia.com/compute/cuda/5_5/rel/installers/cuda_5.5.22_linux_64.run\n    sudo ./cuda_5.5.22_linux_64.run\n\n##2. 安装Boost\n\n\tsudo yum install boost-devel\n\n<!-- more -->\n\n##3. 安装MKL\nMKL是Intel的商业软件，性能很高，也卖的很贵。还好可以申请非商业版，去这里 <https://registrationcenter.intel.com/RegCenter/NComForm.aspx?ProductID=1461&pass=yes> 申请，申请成功之后你会得到一个序列号以及下载地址，下载完并解压， 执行`sudo ./install.sh` ， 之后按提示安装就好了，这个安装特别简单。\n\n##4. 安装OpenCV\n\n    sudo yum install opencv-devel\n\n##5. 安装其他库\n\n    wget https://google-glog.googlecode.com/files/glog-0.3.3.tar.gz\n    tar zxf glog-0.3.3.tar.gz\n    cd glog-0.3.3\n    ./configure\n    make\n    sudo make install\n\n    sudo yum install gflags-devel protobuf-devel leveldb-devel snappy-devel hdf5-devel\n\n##6. 配置OpenCV环境\nCaffe作者默认你已经配置好了OpenCV环境，文档里没有说这一步。好在有人已经写好了配置OpenCV的脚本，<https://github.com/jayrambhia/Install-OpenCV> ，直接拿来用。\n\n    git clone https://github.com/jayrambhia/Install-OpenCV\n    cd Install-OpenCV/RedHat\n    sudo ./opencv_latest.sh\n\n如果脚本运行失败，则详细阅读`RetHat/opencv_install.sh`的代码，然后手工敲入命令进行安装。\n\n    mkdir OpenCV\n    cd OpenCV\n    wget -O opencv-2.4.7.tar.gz http://sourceforge.net/projects/opencvlibrary/files/opencv-unix/2.4.7/opencv-2.4.7.tar.gz/download\n    tar -zxf opencv-2.4.7.tar.gz\n    cd opencv-2.4.7\n    sed  -i '/string(MD5/d' cmake/cl2cpp.cmake\n    mkdir build\n    cd build\n    cmake -D CMAKE_BUILD_TYPE=RELEASE -D CMAKE_INSTALL_PREFIX=/usr/local ..\n    make -j 4\n    sudo make install\n    sudo sh -c 'echo \"/usr/local/lib\" > /etc/ld.so.conf.d/opencv.conf'\n    sudo ldconfig\n\n##7. 编译\n\n    cp Makefile.config.example Makefile.config\n    make all\n\n##8. 运行MNIST例子\n主要参考官网的 [Training MNIST with Caffe](http://caffe.berkeleyvision.org/mnist.html)\n\n###8.1 下载数据集\n\n    cd $CAFFE_ROOT/data/mnist\n    ./get_mnist.sh\n    cd $CAFFE_ROOT/examples/lenet\n    export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/cuda/lib64\n    ./create_mnist.sh\n    \n运行完上述命令后，应该会得到两个数据集，`mnist-train-leveldb/`, 和 `mnist-test-leveldb/`.\n\n最终的model，\n\n###8.2 切换到CPU模式\n由于服务器没有安装显卡，只能使用CPU训练。切换到CPU模式非常简单，只需要在`lenet_solver.prototxt`中修改一行：\n\n> \\# solver mode: 0 for CPU and 1 for GP   \n> solver_mode: 0\n\n###8.3 开始训练\n\n    ./train_lenet.sh\n\n经过一段时间运行，训练完成！最终的model，会存为一个二进制的protobuf文件，`lenet_iter_10000`. \n\n\n##参考资料\n\n1. [CNN之Caffe配置](http://www.cnblogs.com/alfredtofu/p/3577241.html)\n\n\n注意， CUDA 5.5 不支持 Visual Studio 2013，参考 [CUDA 5.5 release notes](http://docs.nvidia.com/cuda/cuda-toolkit-release-notes/index.html#windows-5-5)","slug":"2014-04-03-caffe-installation","published":1,"updated":"2016-08-18T09:21:04.000Z","photos":[],"link":"","_id":"cis07pf4o003o01pqf4c82wzr","content":"<p><strong>环境</strong>: CentOS 6.4</p>\n<p>由于我的CentOS服务器上没有Nvidia的显卡，不过 caffe 是可以在CPU模式下进行train和predict的，因此我尝试了在没有GPU的情况下把caffe跑起来。</p>\n<p>主要参考官网的文档，<a href=\"http://caffe.berkeleyvision.org/installation.html\" target=\"_blank\" rel=\"external\">Installation</a>。</p>\n<p>安装 Caffe 前需要安装以下库：</p>\n<p><strong>Prerequisites</strong></p>\n<ul>\n<li>CUDA (5.0 or 5.5)</li>\n<li>Boost</li>\n<li>MKL (but see the boost-eigen branch for a boost/Eigen3 port)</li>\n<li>OpenCV</li>\n<li>glog, gflags, protobuf, leveldb, snappy, hdf5</li>\n<li>For the Python wrapper: python, numpy (&gt;= 1.7 preferred), and boost_python</li>\n<li>For the Matlab wrapper: Matlab with mex</li>\n</ul>\n<p>##1. 安装CUDA</p>\n<pre><code>wget http://developer.download.nvidia.com/compute/cuda/repos/rhel6/x86_64/cuda-repo-rhel6-5.5-0.x86_64.rpm\nsudo rpm -Uvh libgcc-4.4.7-4.el6.x86_64.rpm\nyum search cuda\nsudo yum install cuda\n</code></pre><p>或者</p>\n<pre><code>wget http://developer.download.nvidia.com/compute/cuda/5_5/rel/installers/cuda_5.5.22_linux_64.run\nsudo ./cuda_5.5.22_linux_64.run\n</code></pre><p>##2. 安装Boost</p>\n<pre><code>sudo yum install boost-devel\n</code></pre><a id=\"more\"></a>\n<p>##3. 安装MKL<br>MKL是Intel的商业软件，性能很高，也卖的很贵。还好可以申请非商业版，去这里 <a href=\"https://registrationcenter.intel.com/RegCenter/NComForm.aspx?ProductID=1461&amp;pass=yes\" target=\"_blank\" rel=\"external\">https://registrationcenter.intel.com/RegCenter/NComForm.aspx?ProductID=1461&amp;pass=yes</a> 申请，申请成功之后你会得到一个序列号以及下载地址，下载完并解压， 执行<code>sudo ./install.sh</code> ， 之后按提示安装就好了，这个安装特别简单。</p>\n<p>##4. 安装OpenCV</p>\n<pre><code>sudo yum install opencv-devel\n</code></pre><p>##5. 安装其他库</p>\n<pre><code>wget https://google-glog.googlecode.com/files/glog-0.3.3.tar.gz\ntar zxf glog-0.3.3.tar.gz\ncd glog-0.3.3\n./configure\nmake\nsudo make install\n\nsudo yum install gflags-devel protobuf-devel leveldb-devel snappy-devel hdf5-devel\n</code></pre><p>##6. 配置OpenCV环境<br>Caffe作者默认你已经配置好了OpenCV环境，文档里没有说这一步。好在有人已经写好了配置OpenCV的脚本，<a href=\"https://github.com/jayrambhia/Install-OpenCV\" target=\"_blank\" rel=\"external\">https://github.com/jayrambhia/Install-OpenCV</a> ，直接拿来用。</p>\n<pre><code>git clone https://github.com/jayrambhia/Install-OpenCV\ncd Install-OpenCV/RedHat\nsudo ./opencv_latest.sh\n</code></pre><p>如果脚本运行失败，则详细阅读<code>RetHat/opencv_install.sh</code>的代码，然后手工敲入命令进行安装。</p>\n<pre><code>mkdir OpenCV\ncd OpenCV\nwget -O opencv-2.4.7.tar.gz http://sourceforge.net/projects/opencvlibrary/files/opencv-unix/2.4.7/opencv-2.4.7.tar.gz/download\ntar -zxf opencv-2.4.7.tar.gz\ncd opencv-2.4.7\nsed  -i &apos;/string(MD5/d&apos; cmake/cl2cpp.cmake\nmkdir build\ncd build\ncmake -D CMAKE_BUILD_TYPE=RELEASE -D CMAKE_INSTALL_PREFIX=/usr/local ..\nmake -j 4\nsudo make install\nsudo sh -c &apos;echo &quot;/usr/local/lib&quot; &gt; /etc/ld.so.conf.d/opencv.conf&apos;\nsudo ldconfig\n</code></pre><p>##7. 编译</p>\n<pre><code>cp Makefile.config.example Makefile.config\nmake all\n</code></pre><p>##8. 运行MNIST例子<br>主要参考官网的 <a href=\"http://caffe.berkeleyvision.org/mnist.html\" target=\"_blank\" rel=\"external\">Training MNIST with Caffe</a></p>\n<p>###8.1 下载数据集</p>\n<pre><code>cd $CAFFE_ROOT/data/mnist\n./get_mnist.sh\ncd $CAFFE_ROOT/examples/lenet\nexport LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/cuda/lib64\n./create_mnist.sh\n</code></pre><p>运行完上述命令后，应该会得到两个数据集，<code>mnist-train-leveldb/</code>, 和 <code>mnist-test-leveldb/</code>.</p>\n<p>最终的model，</p>\n<p>###8.2 切换到CPU模式<br>由于服务器没有安装显卡，只能使用CPU训练。切换到CPU模式非常简单，只需要在<code>lenet_solver.prototxt</code>中修改一行：</p>\n<blockquote>\n<p># solver mode: 0 for CPU and 1 for GP<br>solver_mode: 0</p>\n</blockquote>\n<p>###8.3 开始训练</p>\n<pre><code>./train_lenet.sh\n</code></pre><p>经过一段时间运行，训练完成！最终的model，会存为一个二进制的protobuf文件，<code>lenet_iter_10000</code>. </p>\n<p>##参考资料</p>\n<ol>\n<li><a href=\"http://www.cnblogs.com/alfredtofu/p/3577241.html\" target=\"_blank\" rel=\"external\">CNN之Caffe配置</a></li>\n</ol>\n<p>注意， CUDA 5.5 不支持 Visual Studio 2013，参考 <a href=\"http://docs.nvidia.com/cuda/cuda-toolkit-release-notes/index.html#windows-5-5\" target=\"_blank\" rel=\"external\">CUDA 5.5 release notes</a></p>\n","excerpt":"<p><strong>环境</strong>: CentOS 6.4</p>\n<p>由于我的CentOS服务器上没有Nvidia的显卡，不过 caffe 是可以在CPU模式下进行train和predict的，因此我尝试了在没有GPU的情况下把caffe跑起来。</p>\n<p>主要参考官网的文档，<a href=\"http://caffe.berkeleyvision.org/installation.html\">Installation</a>。</p>\n<p>安装 Caffe 前需要安装以下库：</p>\n<p><strong>Prerequisites</strong></p>\n<ul>\n<li>CUDA (5.0 or 5.5)</li>\n<li>Boost</li>\n<li>MKL (but see the boost-eigen branch for a boost/Eigen3 port)</li>\n<li>OpenCV</li>\n<li>glog, gflags, protobuf, leveldb, snappy, hdf5</li>\n<li>For the Python wrapper: python, numpy (&gt;= 1.7 preferred), and boost_python</li>\n<li>For the Matlab wrapper: Matlab with mex</li>\n</ul>\n<p>##1. 安装CUDA</p>\n<pre><code>wget http://developer.download.nvidia.com/compute/cuda/repos/rhel6/x86_64/cuda-repo-rhel6-5.5-0.x86_64.rpm\nsudo rpm -Uvh libgcc-4.4.7-4.el6.x86_64.rpm\nyum search cuda\nsudo yum install cuda\n</code></pre><p>或者</p>\n<pre><code>wget http://developer.download.nvidia.com/compute/cuda/5_5/rel/installers/cuda_5.5.22_linux_64.run\nsudo ./cuda_5.5.22_linux_64.run\n</code></pre><p>##2. 安装Boost</p>\n<pre><code>sudo yum install boost-devel\n</code></pre>","more":"<p>##3. 安装MKL<br>MKL是Intel的商业软件，性能很高，也卖的很贵。还好可以申请非商业版，去这里 <a href=\"https://registrationcenter.intel.com/RegCenter/NComForm.aspx?ProductID=1461&amp;pass=yes\">https://registrationcenter.intel.com/RegCenter/NComForm.aspx?ProductID=1461&amp;pass=yes</a> 申请，申请成功之后你会得到一个序列号以及下载地址，下载完并解压， 执行<code>sudo ./install.sh</code> ， 之后按提示安装就好了，这个安装特别简单。</p>\n<p>##4. 安装OpenCV</p>\n<pre><code>sudo yum install opencv-devel\n</code></pre><p>##5. 安装其他库</p>\n<pre><code>wget https://google-glog.googlecode.com/files/glog-0.3.3.tar.gz\ntar zxf glog-0.3.3.tar.gz\ncd glog-0.3.3\n./configure\nmake\nsudo make install\n\nsudo yum install gflags-devel protobuf-devel leveldb-devel snappy-devel hdf5-devel\n</code></pre><p>##6. 配置OpenCV环境<br>Caffe作者默认你已经配置好了OpenCV环境，文档里没有说这一步。好在有人已经写好了配置OpenCV的脚本，<a href=\"https://github.com/jayrambhia/Install-OpenCV\">https://github.com/jayrambhia/Install-OpenCV</a> ，直接拿来用。</p>\n<pre><code>git clone https://github.com/jayrambhia/Install-OpenCV\ncd Install-OpenCV/RedHat\nsudo ./opencv_latest.sh\n</code></pre><p>如果脚本运行失败，则详细阅读<code>RetHat/opencv_install.sh</code>的代码，然后手工敲入命令进行安装。</p>\n<pre><code>mkdir OpenCV\ncd OpenCV\nwget -O opencv-2.4.7.tar.gz http://sourceforge.net/projects/opencvlibrary/files/opencv-unix/2.4.7/opencv-2.4.7.tar.gz/download\ntar -zxf opencv-2.4.7.tar.gz\ncd opencv-2.4.7\nsed  -i &apos;/string(MD5/d&apos; cmake/cl2cpp.cmake\nmkdir build\ncd build\ncmake -D CMAKE_BUILD_TYPE=RELEASE -D CMAKE_INSTALL_PREFIX=/usr/local ..\nmake -j 4\nsudo make install\nsudo sh -c &apos;echo &quot;/usr/local/lib&quot; &gt; /etc/ld.so.conf.d/opencv.conf&apos;\nsudo ldconfig\n</code></pre><p>##7. 编译</p>\n<pre><code>cp Makefile.config.example Makefile.config\nmake all\n</code></pre><p>##8. 运行MNIST例子<br>主要参考官网的 <a href=\"http://caffe.berkeleyvision.org/mnist.html\">Training MNIST with Caffe</a></p>\n<p>###8.1 下载数据集</p>\n<pre><code>cd $CAFFE_ROOT/data/mnist\n./get_mnist.sh\ncd $CAFFE_ROOT/examples/lenet\nexport LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/cuda/lib64\n./create_mnist.sh\n</code></pre><p>运行完上述命令后，应该会得到两个数据集，<code>mnist-train-leveldb/</code>, 和 <code>mnist-test-leveldb/</code>.</p>\n<p>最终的model，</p>\n<p>###8.2 切换到CPU模式<br>由于服务器没有安装显卡，只能使用CPU训练。切换到CPU模式非常简单，只需要在<code>lenet_solver.prototxt</code>中修改一行：</p>\n<blockquote>\n<p># solver mode: 0 for CPU and 1 for GP<br>solver_mode: 0</p>\n</blockquote>\n<p>###8.3 开始训练</p>\n<pre><code>./train_lenet.sh\n</code></pre><p>经过一段时间运行，训练完成！最终的model，会存为一个二进制的protobuf文件，<code>lenet_iter_10000</code>. </p>\n<p>##参考资料</p>\n<ol>\n<li><a href=\"http://www.cnblogs.com/alfredtofu/p/3577241.html\">CNN之Caffe配置</a></li>\n</ol>\n<p>注意， CUDA 5.5 不支持 Visual Studio 2013，参考 <a href=\"http://docs.nvidia.com/cuda/cuda-toolkit-release-notes/index.html#windows-5-5\">CUDA 5.5 release notes</a></p>"},{"layout":"post","title":"Windows下使用VMware Workstation 安装 OS X 虚拟机","date":"2014-04-25T21:49:00.000Z","comments":1,"published":0,"_content":"环境: Windows 7, VMware Workstation 10.0.2, Mac OS X 10.9 Mavericks\n\n","source":"_posts/2014-04-25-install-os-x-mavericks-on-windows-using-vmware-workstation.md","raw":"---\nlayout: post\ntitle: \"Windows下使用VMware Workstation 安装 OS X 虚拟机\"\ndate: 2014-04-25 21:49\ncomments: true\ncategories: DevOps\npublished: false\n---\n环境: Windows 7, VMware Workstation 10.0.2, Mac OS X 10.9 Mavericks\n\n","slug":"2014-04-25-install-os-x-mavericks-on-windows-using-vmware-workstation","updated":"2016-08-18T09:21:04.000Z","photos":[],"link":"","_id":"cis07pf4q003q01pq986momkf","content":"<p>环境: Windows 7, VMware Workstation 10.0.2, Mac OS X 10.9 Mavericks</p>\n","excerpt":"","more":"<p>环境: Windows 7, VMware Workstation 10.0.2, Mac OS X 10.9 Mavericks</p>\n"},{"layout":"post","title":"安装基于Python3 的NumPy, SciPy和Scikit-Learn","date":"2014-08-06T09:04:00.000Z","comments":1,"_content":"软件版本：Ubuntun 14.04, Python 3.4, NumPy 1.8.1, SciPy 0.14.0, Scikit-Learn 0.16\n\nNumpy, SciPy 的官网安装文档，安装的是基于Python 2.7的，SciPy-Learn 官网的安装文档，也是Python 2.7的，如果想基于高大上的Python 3，该怎么安装呢？经过一堆的坑之后，我摸索出了方法。\n\n##1. 安装Python 3\n首先我们要安装Python 3, 不过，千万别因为有了Python 3, 就卸载系统自带的Python 2.7，很多软件依赖它，所以不能卸载\n\n``` bash\n$ sudo apt-get install python3\n```\n\n设置Python3为默认Python\n\n``` bash\n$ vi ~/.bash_aliases\n$ alias python=python3\n  wq\n```\n\n关闭当前Shell，重新开一个新Shell，输入python就发现进入Python 3.4 的交互环境了。\n\n##2. 安装 NumPy SciPy SymPy 等软件\n参考 <http://www.scipy.org/install.html> , 只不过改成了 python3\n\n``` bash\nsudo apt-get install python3-numpy python3-scipy python3-matplotlib ipython3 ipython3-notebook python3-pandas python-sympy python3-nose\n```\n\n##3. 安装 Scikit-Learn\n参考 <http://scikit-learn.org/stable/install.html>, 不过要修改成python3\n\n``` bash\nsudo apt-get install build-essential python3-dev python3-setuptools python3-numpy python3-scipy libatlas-dev libatlas3gf-base\nsudo update-alternatives --set libblas.so.3 /usr/lib/atlas-base/atlas/libblas.so.3\nsudo update-alternatives --set liblapack.so.3 /usr/lib/atlas-base/atlas/liblapack.so.3\nsudo apt-get install gfortran\n\nsudo apt-get install git, 并配置好git\nmkdir -p ~/local/src\ncd ~/local/src\ngit clone git@github.com:scikit-learn/scikit-learn.git\ncd scikit-learn\npython setup.py install --user #开始编译\nmake PYTHON=python3 NOSETESTS=nosetests3 #或者使用make编译\nnosetests3 -v sklearn #单元测试，可以在任何位置运行，不一定要在源码目录里\n```\n\n这里主要的坑是make, 刚开始我直接用 `make`, 失败，因为它默认是去找Python 2.7的 python.h 来编译，而我没有安装 python-dev, 只是安装了python3-dev，所以会编译失败。\n\n我给 Scikit-Learn 的邮件组发了封邮件，不久得到了回复，要在make 后面加上 `PYTHON=python3`，这次编译成功了，不过到单元测试时说找不到`nosetests`命令，当然找不到了，因为前面安装的是python3-nose而不是python-nose，于是我猜测了一把，用 `make PYTHON=python3 NOSETESTS=nosetests3`试试, 果然可以！\n","source":"_posts/2014-08-06-install-scikit-learn-with-python3.md","raw":"---\nlayout: post\ntitle: \"安装基于Python3 的NumPy, SciPy和Scikit-Learn\"\ndate: 2014-08-06 09:04\ncomments: true\ncategories: Python\n---\n软件版本：Ubuntun 14.04, Python 3.4, NumPy 1.8.1, SciPy 0.14.0, Scikit-Learn 0.16\n\nNumpy, SciPy 的官网安装文档，安装的是基于Python 2.7的，SciPy-Learn 官网的安装文档，也是Python 2.7的，如果想基于高大上的Python 3，该怎么安装呢？经过一堆的坑之后，我摸索出了方法。\n\n##1. 安装Python 3\n首先我们要安装Python 3, 不过，千万别因为有了Python 3, 就卸载系统自带的Python 2.7，很多软件依赖它，所以不能卸载\n\n``` bash\n$ sudo apt-get install python3\n```\n\n设置Python3为默认Python\n\n``` bash\n$ vi ~/.bash_aliases\n$ alias python=python3\n  wq\n```\n\n关闭当前Shell，重新开一个新Shell，输入python就发现进入Python 3.4 的交互环境了。\n\n##2. 安装 NumPy SciPy SymPy 等软件\n参考 <http://www.scipy.org/install.html> , 只不过改成了 python3\n\n``` bash\nsudo apt-get install python3-numpy python3-scipy python3-matplotlib ipython3 ipython3-notebook python3-pandas python-sympy python3-nose\n```\n\n##3. 安装 Scikit-Learn\n参考 <http://scikit-learn.org/stable/install.html>, 不过要修改成python3\n\n``` bash\nsudo apt-get install build-essential python3-dev python3-setuptools python3-numpy python3-scipy libatlas-dev libatlas3gf-base\nsudo update-alternatives --set libblas.so.3 /usr/lib/atlas-base/atlas/libblas.so.3\nsudo update-alternatives --set liblapack.so.3 /usr/lib/atlas-base/atlas/liblapack.so.3\nsudo apt-get install gfortran\n\nsudo apt-get install git, 并配置好git\nmkdir -p ~/local/src\ncd ~/local/src\ngit clone git@github.com:scikit-learn/scikit-learn.git\ncd scikit-learn\npython setup.py install --user #开始编译\nmake PYTHON=python3 NOSETESTS=nosetests3 #或者使用make编译\nnosetests3 -v sklearn #单元测试，可以在任何位置运行，不一定要在源码目录里\n```\n\n这里主要的坑是make, 刚开始我直接用 `make`, 失败，因为它默认是去找Python 2.7的 python.h 来编译，而我没有安装 python-dev, 只是安装了python3-dev，所以会编译失败。\n\n我给 Scikit-Learn 的邮件组发了封邮件，不久得到了回复，要在make 后面加上 `PYTHON=python3`，这次编译成功了，不过到单元测试时说找不到`nosetests`命令，当然找不到了，因为前面安装的是python3-nose而不是python-nose，于是我猜测了一把，用 `make PYTHON=python3 NOSETESTS=nosetests3`试试, 果然可以！\n","slug":"2014-08-06-install-scikit-learn-with-python3","published":1,"updated":"2016-08-18T09:21:04.000Z","photos":[],"link":"","_id":"cis07pf4r003t01pqoy4aq1xh","content":"<p>软件版本：Ubuntun 14.04, Python 3.4, NumPy 1.8.1, SciPy 0.14.0, Scikit-Learn 0.16</p>\n<p>Numpy, SciPy 的官网安装文档，安装的是基于Python 2.7的，SciPy-Learn 官网的安装文档，也是Python 2.7的，如果想基于高大上的Python 3，该怎么安装呢？经过一堆的坑之后，我摸索出了方法。</p>\n<p>##1. 安装Python 3<br>首先我们要安装Python 3, 不过，千万别因为有了Python 3, 就卸载系统自带的Python 2.7，很多软件依赖它，所以不能卸载</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">$ sudo apt-get install python3</div></pre></td></tr></table></figure>\n<p>设置Python3为默认Python</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">$ vi ~/.bash_aliases</div><div class=\"line\">$ <span class=\"built_in\">alias</span> python=python3</div><div class=\"line\">  wq</div></pre></td></tr></table></figure>\n<p>关闭当前Shell，重新开一个新Shell，输入python就发现进入Python 3.4 的交互环境了。</p>\n<p>##2. 安装 NumPy SciPy SymPy 等软件<br>参考 <a href=\"http://www.scipy.org/install.html\" target=\"_blank\" rel=\"external\">http://www.scipy.org/install.html</a> , 只不过改成了 python3</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">sudo apt-get install python3-numpy python3-scipy python3-matplotlib ipython3 ipython3-notebook python3-pandas python-sympy python3-nose</div></pre></td></tr></table></figure>\n<p>##3. 安装 Scikit-Learn<br>参考 <a href=\"http://scikit-learn.org/stable/install.html\" target=\"_blank\" rel=\"external\">http://scikit-learn.org/stable/install.html</a>, 不过要修改成python3</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div></pre></td><td class=\"code\"><pre><div class=\"line\">sudo apt-get install build-essential python3-dev python3-setuptools python3-numpy python3-scipy libatlas-dev libatlas3gf-base</div><div class=\"line\">sudo update-alternatives --set libblas.so.3 /usr/lib/atlas-base/atlas/libblas.so.3</div><div class=\"line\">sudo update-alternatives --set liblapack.so.3 /usr/lib/atlas-base/atlas/liblapack.so.3</div><div class=\"line\">sudo apt-get install gfortran</div><div class=\"line\"></div><div class=\"line\">sudo apt-get install git, 并配置好git</div><div class=\"line\">mkdir -p ~/<span class=\"built_in\">local</span>/src</div><div class=\"line\"><span class=\"built_in\">cd</span> ~/<span class=\"built_in\">local</span>/src</div><div class=\"line\">git <span class=\"built_in\">clone</span> git@github.com:scikit-learn/scikit-learn.git</div><div class=\"line\"><span class=\"built_in\">cd</span> scikit-learn</div><div class=\"line\">python setup.py install --user <span class=\"comment\">#开始编译</span></div><div class=\"line\">make PYTHON=python3 NOSETESTS=nosetests3 <span class=\"comment\">#或者使用make编译</span></div><div class=\"line\">nosetests3 -v sklearn <span class=\"comment\">#单元测试，可以在任何位置运行，不一定要在源码目录里</span></div></pre></td></tr></table></figure>\n<p>这里主要的坑是make, 刚开始我直接用 <code>make</code>, 失败，因为它默认是去找Python 2.7的 python.h 来编译，而我没有安装 python-dev, 只是安装了python3-dev，所以会编译失败。</p>\n<p>我给 Scikit-Learn 的邮件组发了封邮件，不久得到了回复，要在make 后面加上 <code>PYTHON=python3</code>，这次编译成功了，不过到单元测试时说找不到<code>nosetests</code>命令，当然找不到了，因为前面安装的是python3-nose而不是python-nose，于是我猜测了一把，用 <code>make PYTHON=python3 NOSETESTS=nosetests3</code>试试, 果然可以！</p>\n","excerpt":"","more":"<p>软件版本：Ubuntun 14.04, Python 3.4, NumPy 1.8.1, SciPy 0.14.0, Scikit-Learn 0.16</p>\n<p>Numpy, SciPy 的官网安装文档，安装的是基于Python 2.7的，SciPy-Learn 官网的安装文档，也是Python 2.7的，如果想基于高大上的Python 3，该怎么安装呢？经过一堆的坑之后，我摸索出了方法。</p>\n<p>##1. 安装Python 3<br>首先我们要安装Python 3, 不过，千万别因为有了Python 3, 就卸载系统自带的Python 2.7，很多软件依赖它，所以不能卸载</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">$ sudo apt-get install python3</div></pre></td></tr></table></figure>\n<p>设置Python3为默认Python</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">$ vi ~/.bash_aliases</div><div class=\"line\">$ <span class=\"built_in\">alias</span> python=python3</div><div class=\"line\">  wq</div></pre></td></tr></table></figure>\n<p>关闭当前Shell，重新开一个新Shell，输入python就发现进入Python 3.4 的交互环境了。</p>\n<p>##2. 安装 NumPy SciPy SymPy 等软件<br>参考 <a href=\"http://www.scipy.org/install.html\">http://www.scipy.org/install.html</a> , 只不过改成了 python3</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">sudo apt-get install python3-numpy python3-scipy python3-matplotlib ipython3 ipython3-notebook python3-pandas python-sympy python3-nose</div></pre></td></tr></table></figure>\n<p>##3. 安装 Scikit-Learn<br>参考 <a href=\"http://scikit-learn.org/stable/install.html\">http://scikit-learn.org/stable/install.html</a>, 不过要修改成python3</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div></pre></td><td class=\"code\"><pre><div class=\"line\">sudo apt-get install build-essential python3-dev python3-setuptools python3-numpy python3-scipy libatlas-dev libatlas3gf-base</div><div class=\"line\">sudo update-alternatives --set libblas.so.3 /usr/lib/atlas-base/atlas/libblas.so.3</div><div class=\"line\">sudo update-alternatives --set liblapack.so.3 /usr/lib/atlas-base/atlas/liblapack.so.3</div><div class=\"line\">sudo apt-get install gfortran</div><div class=\"line\"></div><div class=\"line\">sudo apt-get install git, 并配置好git</div><div class=\"line\">mkdir -p ~/<span class=\"built_in\">local</span>/src</div><div class=\"line\"><span class=\"built_in\">cd</span> ~/<span class=\"built_in\">local</span>/src</div><div class=\"line\">git <span class=\"built_in\">clone</span> git@github.com:scikit-learn/scikit-learn.git</div><div class=\"line\"><span class=\"built_in\">cd</span> scikit-learn</div><div class=\"line\">python setup.py install --user <span class=\"comment\">#开始编译</span></div><div class=\"line\">make PYTHON=python3 NOSETESTS=nosetests3 <span class=\"comment\">#或者使用make编译</span></div><div class=\"line\">nosetests3 -v sklearn <span class=\"comment\">#单元测试，可以在任何位置运行，不一定要在源码目录里</span></div></pre></td></tr></table></figure>\n<p>这里主要的坑是make, 刚开始我直接用 <code>make</code>, 失败，因为它默认是去找Python 2.7的 python.h 来编译，而我没有安装 python-dev, 只是安装了python3-dev，所以会编译失败。</p>\n<p>我给 Scikit-Learn 的邮件组发了封邮件，不久得到了回复，要在make 后面加上 <code>PYTHON=python3</code>，这次编译成功了，不过到单元测试时说找不到<code>nosetests</code>命令，当然找不到了，因为前面安装的是python3-nose而不是python-nose，于是我猜测了一把，用 <code>make PYTHON=python3 NOSETESTS=nosetests3</code>试试, 果然可以！</p>\n"},{"title":"我的深度学习工作站攒机过程记录","date":"2016-08-13T09:26:11.000Z","_content":"\n一年前就有攒一台深度学习工作站的想法了，今年 6月29号在Amazon 上抢到了一块 GTX 1080后，正式开始了攒机，经过了漫长了的一个半月，到今天8约13号，终于凑齐了所有零件并开机点亮了。为甚么这么漫长？因为本屌为了省钱几乎所有零件都是在 eBay和Amazon 上买的二手（除了GTX 1080太新没二手货）。\n\n\n\n## 硬件配置单\n\n\n### 结论\n\n懒人不想看过程的话，可以先看结论。\n\n以下是我的配置单：\n\n|    配件名   | 品牌型号   | 数量 | 价格 | 哪里买的 |\n|:------------:|:-----------:|:-----------:|:-----------:|:-----------:|\n| 机箱 | Corsair Carbide Air 540 | 1 | $130.57 | Amazon 二手 |\n|    主板    | Asus X99-E WS/USB3.1 | 1 | $563.84 | Amazon 新 |\n|    CPU    | Intel I7-5930K | 1 | $467.45 | eBay 二手 |\n|    CPU 水冷头    | Corsair H60 Cooler | 1 | $65.24 | Amazon 新 |\n| DDR4内存 | Kingston 32GB HX421C14FB2K4/32 | 4 | $139.19 | Amazon新 |\n| 显卡 | Zotac GTX 1080 Founders Edition | 1 | $761.24 | Amazon 新 |\n| 电源 | EVGA 1600W 80+ Gold 120-G2-1600-X1 | 1 | $241.74 | eBay二手 |\n| SSD | Samsung SM951 256GB M.2 NVMe MZVPV256HDGL | 1 | $129.5 | eBay二手 |\n| 机械硬盘 | WD Green 4TB | 1 | $162.36 | Amazon新 |\n\n总计：$2661.13\n\n以上价格已经包含了税。\n\n这个配置单基本齐全了，唯一还没有到位的是GPU显卡了，目前只有一块 GTX 1080。我打算等一年后 GTX 1080 有二手货了，再收3块二手的，这样就全了。\n\n接下来一项一项详细说明我为什么这么选择，展示我的决策过程。\n\n<!-- more -->\n\n\n### 机箱\n\n直接选跟 Nvidia DevBox 同款的机箱，即 Corsair Carbide Air 540\n\n\n### 主板\n\n硬性要求：\n\n1. X99平台\n1. 四个 PCI-E Gen3 x16 接口\n\n众所周知单机多卡进行训练时，总线带宽是瓶颈，所以主板有越多的PCI-e 3.0 接口越好，可以尽可能把显卡的性能发挥出来。计划上四块 GTX 1080，那么至少需要四路 PCI-e 3.0 的 x16 接口。\n\nNvidia DevBox 用的是 Asus X99-E WS 工作站主板，那我也在X99 主板里选了很久，\n\n这三块板子都有 4路 PCI-e 3.0 x16 接口，\n\n* Asus X99-E WS\n* Asus X99-E WS/USB 3.1\n* 技嘉 GA-X99P-SLI\n\n当时我还请教了一下 [@硬哥](http://weibo.com/1775948951/DESoMxdRf) ，问上四块 GTX 1080 显卡的话，用哪个主板好，\n\n![](/images/weibo-which-motherboard.png)\n\n华硕 X99-E WS/USB 3.1 是 Asus X99-E WS 的新版，本着买新不买旧的原则，那就买  Asus  X99-E WS/USB 3.1 吧。\n\n\n### CPU\n\n众所周知单机多卡进行训练时，总线带宽是瓶颈，所以 CPU 的 PCI-e  lane 越多越好，一般消费级的CPU，PCI-e总线根数是 16, 28 或 40，最大就是40，再大就需要上服务器CPU或者双路CPU了。选40， 这个条件下，有两款 CPU 入围，I7-5930K和 I7-5960X, 5860X太贵了，一般机器学习训练中CPU不是瓶颈，所以选 5930K就可以了，这也是 Nvidia 官方推出的 DevBox 工作站所使用的CPU。\n\n在知乎上看到不少人用 I7-5820K，这个CPU虽然很不错，可是只有 28条 PCI-e总线，所以还是加几百块钱上 5930k比较好。\n\n\n### CPU水冷头\n\n其实普通的风扇就可以了，不过水冷更加安静些，所以我选择了一个便宜的 Corsair H60 Cooler ，够用了。\n\n\n### 内存\n\nDDR4 64G\n\n再大就没必要了，李沐的这篇博客[GPU集群折腾手记](http://mli.github.io/gpu/2016/01/17/build-gpu-clusters/)  末尾有说到过，单机4卡的机器，64G内存绰绰有余了。\n\n况且消费级的I7 CPU，最大支持内存就是 64G。\n\n\n### 显卡\n\n这个最好选，GTX 1080\n\n最新出来的 GTX 1080 吊打 Maxwell 架构的 Titan , 价钱又便宜很多，所以显卡最好选。\n\n\n### 电源\n\n一般 Nvidia 的旗舰显卡，功耗都是压着 300W的线的，四卡就 1200W了，加上主板，CPU等耗电，选一个 1600W的电源吧。\n\nNvidia DevBox 用的是 EVGA 1600W 80+ Gold 120-G2-1600-X1 ，那我也用它吧。\n\n\n### SSD\n\n起码需要一块SSD作为系统盘。\n\n当前 SATA III 接口的SSD最普遍也最便宜，不过由于 Asus X99-E WS/USB 3.1 恰好有一个 M.2 接口，我决定买一个 M.2 NVMe 的SSD，不用就浪费了主板的这个接口了。在 eBay 上买了一块二手的 Samsung SM951 256GB M.2 NVMe MZVPV256HDGL 。\n\n\n### 机械硬盘\n\n随便选，我选择最便宜的绿盘。\n\n\n### 一些波折\n\n等了一个月终于凑齐了所有配件后，兴奋的开始装机，装完了后发现死活点不亮，<http://weibo.com/1663402687/E1vrO4VFn>\n\n![](/images/weibo-cannot-boot.png)\n\n尼玛，浪费了我2天时间在各种诊断，甚至一度怀疑自己的装机能力一直到怀疑人生。。。\n\n只好把主板和CPU退货了，又在 eBay上竞拍了一个二手 I7-5930K，这是 eBay 上的 Asus X99-E WS/USB 3.1 竟然没有二手货了，Amazon 也没有二手货，只有一个 refurbishment , 不敢买，只要在 Amazon 买了个全新的主板。\n\n等了一周多，今天终于齐了，可以开机进入操作系统了。不过有个小问题，按机箱上的开机键，没有反应，必须打开机箱按主板上的那个开机键。当时我内心是崩溃的，不可能每次开机需要打开机箱吧，那多烦啊。于是开始诊断，先用一根金属棒让 POWSER_SW 的两根针脚短路，可以开机，说明主板的POWSER_SW的两根针脚是好的，那么唯一的原因，就是机箱上的开机键不灵了，我打开机箱，把开机键后面焊接的细线按了几下，再开机，机箱上的开机键起作用了。可能是接触不良吧，我也没有深究了，盖上了机箱盖。\n\n\n## 一些配置和 tunning\n\n打开了TPU，EPU,DR.POWER , EZ_XMP四个开关，TPU推到了中间的 TPU I， 没敢到最右边的 TPU II\n\nGTX 1080 要插到 PCIE 1,3,5,7的位置上，这几个插槽是X16模式的，其他是x8模式的\n\n后续：\n\n[安装 Windows 10 和 Ubuntu 16.04 双系统](http://cn.soulmachine.me/2016-08-14-dual-install-windows-ubuntu/)\n[深度学习开发环境配置：Ubuntu1 6.04+Nvidia GTX 1080+CUDA 8.0](http://cn.soulmachine.me/2016-08-17-deep-learning-cuda-development-environment/)\n\n\n## 参考资料\n\n1. [Nvidia DevBox](https://developer.nvidia.com/devbox)\n1. [32-TFLOP Deep Learning GPU Box - hackaday](https://hackaday.io/project/12070-32-tflop-deep-learning-gpu-box)\n1. [如何配置一台适用于深度学习的工作站？- 知乎](https://www.zhihu.com/question/33996159)\n1. [Exxact Deep Learning Workstation](http://exxactcorp.com/deep-learning-workstations-servers.php)\n1. [GPU集群折腾手记 - 李沐](http://mli.github.io/gpu/2016/01/17/build-gpu-clusters/)\n","source":"_posts/2016-08-13-my-deep-learning-workstation-assemble-process-note.md","raw":"---\ntitle: 我的深度学习工作站攒机过程记录\ndate: 2016-08-13 09:26:11\ntags: 深度学习\ncategories: 深度学习\n---\n\n一年前就有攒一台深度学习工作站的想法了，今年 6月29号在Amazon 上抢到了一块 GTX 1080后，正式开始了攒机，经过了漫长了的一个半月，到今天8约13号，终于凑齐了所有零件并开机点亮了。为甚么这么漫长？因为本屌为了省钱几乎所有零件都是在 eBay和Amazon 上买的二手（除了GTX 1080太新没二手货）。\n\n\n\n## 硬件配置单\n\n\n### 结论\n\n懒人不想看过程的话，可以先看结论。\n\n以下是我的配置单：\n\n|    配件名   | 品牌型号   | 数量 | 价格 | 哪里买的 |\n|:------------:|:-----------:|:-----------:|:-----------:|:-----------:|\n| 机箱 | Corsair Carbide Air 540 | 1 | $130.57 | Amazon 二手 |\n|    主板    | Asus X99-E WS/USB3.1 | 1 | $563.84 | Amazon 新 |\n|    CPU    | Intel I7-5930K | 1 | $467.45 | eBay 二手 |\n|    CPU 水冷头    | Corsair H60 Cooler | 1 | $65.24 | Amazon 新 |\n| DDR4内存 | Kingston 32GB HX421C14FB2K4/32 | 4 | $139.19 | Amazon新 |\n| 显卡 | Zotac GTX 1080 Founders Edition | 1 | $761.24 | Amazon 新 |\n| 电源 | EVGA 1600W 80+ Gold 120-G2-1600-X1 | 1 | $241.74 | eBay二手 |\n| SSD | Samsung SM951 256GB M.2 NVMe MZVPV256HDGL | 1 | $129.5 | eBay二手 |\n| 机械硬盘 | WD Green 4TB | 1 | $162.36 | Amazon新 |\n\n总计：$2661.13\n\n以上价格已经包含了税。\n\n这个配置单基本齐全了，唯一还没有到位的是GPU显卡了，目前只有一块 GTX 1080。我打算等一年后 GTX 1080 有二手货了，再收3块二手的，这样就全了。\n\n接下来一项一项详细说明我为什么这么选择，展示我的决策过程。\n\n<!-- more -->\n\n\n### 机箱\n\n直接选跟 Nvidia DevBox 同款的机箱，即 Corsair Carbide Air 540\n\n\n### 主板\n\n硬性要求：\n\n1. X99平台\n1. 四个 PCI-E Gen3 x16 接口\n\n众所周知单机多卡进行训练时，总线带宽是瓶颈，所以主板有越多的PCI-e 3.0 接口越好，可以尽可能把显卡的性能发挥出来。计划上四块 GTX 1080，那么至少需要四路 PCI-e 3.0 的 x16 接口。\n\nNvidia DevBox 用的是 Asus X99-E WS 工作站主板，那我也在X99 主板里选了很久，\n\n这三块板子都有 4路 PCI-e 3.0 x16 接口，\n\n* Asus X99-E WS\n* Asus X99-E WS/USB 3.1\n* 技嘉 GA-X99P-SLI\n\n当时我还请教了一下 [@硬哥](http://weibo.com/1775948951/DESoMxdRf) ，问上四块 GTX 1080 显卡的话，用哪个主板好，\n\n![](/images/weibo-which-motherboard.png)\n\n华硕 X99-E WS/USB 3.1 是 Asus X99-E WS 的新版，本着买新不买旧的原则，那就买  Asus  X99-E WS/USB 3.1 吧。\n\n\n### CPU\n\n众所周知单机多卡进行训练时，总线带宽是瓶颈，所以 CPU 的 PCI-e  lane 越多越好，一般消费级的CPU，PCI-e总线根数是 16, 28 或 40，最大就是40，再大就需要上服务器CPU或者双路CPU了。选40， 这个条件下，有两款 CPU 入围，I7-5930K和 I7-5960X, 5860X太贵了，一般机器学习训练中CPU不是瓶颈，所以选 5930K就可以了，这也是 Nvidia 官方推出的 DevBox 工作站所使用的CPU。\n\n在知乎上看到不少人用 I7-5820K，这个CPU虽然很不错，可是只有 28条 PCI-e总线，所以还是加几百块钱上 5930k比较好。\n\n\n### CPU水冷头\n\n其实普通的风扇就可以了，不过水冷更加安静些，所以我选择了一个便宜的 Corsair H60 Cooler ，够用了。\n\n\n### 内存\n\nDDR4 64G\n\n再大就没必要了，李沐的这篇博客[GPU集群折腾手记](http://mli.github.io/gpu/2016/01/17/build-gpu-clusters/)  末尾有说到过，单机4卡的机器，64G内存绰绰有余了。\n\n况且消费级的I7 CPU，最大支持内存就是 64G。\n\n\n### 显卡\n\n这个最好选，GTX 1080\n\n最新出来的 GTX 1080 吊打 Maxwell 架构的 Titan , 价钱又便宜很多，所以显卡最好选。\n\n\n### 电源\n\n一般 Nvidia 的旗舰显卡，功耗都是压着 300W的线的，四卡就 1200W了，加上主板，CPU等耗电，选一个 1600W的电源吧。\n\nNvidia DevBox 用的是 EVGA 1600W 80+ Gold 120-G2-1600-X1 ，那我也用它吧。\n\n\n### SSD\n\n起码需要一块SSD作为系统盘。\n\n当前 SATA III 接口的SSD最普遍也最便宜，不过由于 Asus X99-E WS/USB 3.1 恰好有一个 M.2 接口，我决定买一个 M.2 NVMe 的SSD，不用就浪费了主板的这个接口了。在 eBay 上买了一块二手的 Samsung SM951 256GB M.2 NVMe MZVPV256HDGL 。\n\n\n### 机械硬盘\n\n随便选，我选择最便宜的绿盘。\n\n\n### 一些波折\n\n等了一个月终于凑齐了所有配件后，兴奋的开始装机，装完了后发现死活点不亮，<http://weibo.com/1663402687/E1vrO4VFn>\n\n![](/images/weibo-cannot-boot.png)\n\n尼玛，浪费了我2天时间在各种诊断，甚至一度怀疑自己的装机能力一直到怀疑人生。。。\n\n只好把主板和CPU退货了，又在 eBay上竞拍了一个二手 I7-5930K，这是 eBay 上的 Asus X99-E WS/USB 3.1 竟然没有二手货了，Amazon 也没有二手货，只有一个 refurbishment , 不敢买，只要在 Amazon 买了个全新的主板。\n\n等了一周多，今天终于齐了，可以开机进入操作系统了。不过有个小问题，按机箱上的开机键，没有反应，必须打开机箱按主板上的那个开机键。当时我内心是崩溃的，不可能每次开机需要打开机箱吧，那多烦啊。于是开始诊断，先用一根金属棒让 POWSER_SW 的两根针脚短路，可以开机，说明主板的POWSER_SW的两根针脚是好的，那么唯一的原因，就是机箱上的开机键不灵了，我打开机箱，把开机键后面焊接的细线按了几下，再开机，机箱上的开机键起作用了。可能是接触不良吧，我也没有深究了，盖上了机箱盖。\n\n\n## 一些配置和 tunning\n\n打开了TPU，EPU,DR.POWER , EZ_XMP四个开关，TPU推到了中间的 TPU I， 没敢到最右边的 TPU II\n\nGTX 1080 要插到 PCIE 1,3,5,7的位置上，这几个插槽是X16模式的，其他是x8模式的\n\n后续：\n\n[安装 Windows 10 和 Ubuntu 16.04 双系统](http://cn.soulmachine.me/2016-08-14-dual-install-windows-ubuntu/)\n[深度学习开发环境配置：Ubuntu1 6.04+Nvidia GTX 1080+CUDA 8.0](http://cn.soulmachine.me/2016-08-17-deep-learning-cuda-development-environment/)\n\n\n## 参考资料\n\n1. [Nvidia DevBox](https://developer.nvidia.com/devbox)\n1. [32-TFLOP Deep Learning GPU Box - hackaday](https://hackaday.io/project/12070-32-tflop-deep-learning-gpu-box)\n1. [如何配置一台适用于深度学习的工作站？- 知乎](https://www.zhihu.com/question/33996159)\n1. [Exxact Deep Learning Workstation](http://exxactcorp.com/deep-learning-workstations-servers.php)\n1. [GPU集群折腾手记 - 李沐](http://mli.github.io/gpu/2016/01/17/build-gpu-clusters/)\n","slug":"2016-08-13-my-deep-learning-workstation-assemble-process-note","published":1,"updated":"2016-08-18T10:36:03.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cis07pf4s003v01pq10uy6b3v","content":"<p>一年前就有攒一台深度学习工作站的想法了，今年 6月29号在Amazon 上抢到了一块 GTX 1080后，正式开始了攒机，经过了漫长了的一个半月，到今天8约13号，终于凑齐了所有零件并开机点亮了。为甚么这么漫长？因为本屌为了省钱几乎所有零件都是在 eBay和Amazon 上买的二手（除了GTX 1080太新没二手货）。</p>\n<h2 id=\"硬件配置单\"><a href=\"#硬件配置单\" class=\"headerlink\" title=\"硬件配置单\"></a>硬件配置单</h2><h3 id=\"结论\"><a href=\"#结论\" class=\"headerlink\" title=\"结论\"></a>结论</h3><p>懒人不想看过程的话，可以先看结论。</p>\n<p>以下是我的配置单：</p>\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">配件名</th>\n<th style=\"text-align:center\">品牌型号</th>\n<th style=\"text-align:center\">数量</th>\n<th style=\"text-align:center\">价格</th>\n<th style=\"text-align:center\">哪里买的</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">机箱</td>\n<td style=\"text-align:center\">Corsair Carbide Air 540</td>\n<td style=\"text-align:center\">1</td>\n<td style=\"text-align:center\">$130.57</td>\n<td style=\"text-align:center\">Amazon 二手</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">主板</td>\n<td style=\"text-align:center\">Asus X99-E WS/USB3.1</td>\n<td style=\"text-align:center\">1</td>\n<td style=\"text-align:center\">$563.84</td>\n<td style=\"text-align:center\">Amazon 新</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">CPU</td>\n<td style=\"text-align:center\">Intel I7-5930K</td>\n<td style=\"text-align:center\">1</td>\n<td style=\"text-align:center\">$467.45</td>\n<td style=\"text-align:center\">eBay 二手</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">CPU 水冷头</td>\n<td style=\"text-align:center\">Corsair H60 Cooler</td>\n<td style=\"text-align:center\">1</td>\n<td style=\"text-align:center\">$65.24</td>\n<td style=\"text-align:center\">Amazon 新</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">DDR4内存</td>\n<td style=\"text-align:center\">Kingston 32GB HX421C14FB2K4/32</td>\n<td style=\"text-align:center\">4</td>\n<td style=\"text-align:center\">$139.19</td>\n<td style=\"text-align:center\">Amazon新</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">显卡</td>\n<td style=\"text-align:center\">Zotac GTX 1080 Founders Edition</td>\n<td style=\"text-align:center\">1</td>\n<td style=\"text-align:center\">$761.24</td>\n<td style=\"text-align:center\">Amazon 新</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">电源</td>\n<td style=\"text-align:center\">EVGA 1600W 80+ Gold 120-G2-1600-X1</td>\n<td style=\"text-align:center\">1</td>\n<td style=\"text-align:center\">$241.74</td>\n<td style=\"text-align:center\">eBay二手</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">SSD</td>\n<td style=\"text-align:center\">Samsung SM951 256GB M.2 NVMe MZVPV256HDGL</td>\n<td style=\"text-align:center\">1</td>\n<td style=\"text-align:center\">$129.5</td>\n<td style=\"text-align:center\">eBay二手</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">机械硬盘</td>\n<td style=\"text-align:center\">WD Green 4TB</td>\n<td style=\"text-align:center\">1</td>\n<td style=\"text-align:center\">$162.36</td>\n<td style=\"text-align:center\">Amazon新</td>\n</tr>\n</tbody>\n</table>\n<p>总计：$2661.13</p>\n<p>以上价格已经包含了税。</p>\n<p>这个配置单基本齐全了，唯一还没有到位的是GPU显卡了，目前只有一块 GTX 1080。我打算等一年后 GTX 1080 有二手货了，再收3块二手的，这样就全了。</p>\n<p>接下来一项一项详细说明我为什么这么选择，展示我的决策过程。</p>\n<a id=\"more\"></a>\n<h3 id=\"机箱\"><a href=\"#机箱\" class=\"headerlink\" title=\"机箱\"></a>机箱</h3><p>直接选跟 Nvidia DevBox 同款的机箱，即 Corsair Carbide Air 540</p>\n<h3 id=\"主板\"><a href=\"#主板\" class=\"headerlink\" title=\"主板\"></a>主板</h3><p>硬性要求：</p>\n<ol>\n<li>X99平台</li>\n<li>四个 PCI-E Gen3 x16 接口</li>\n</ol>\n<p>众所周知单机多卡进行训练时，总线带宽是瓶颈，所以主板有越多的PCI-e 3.0 接口越好，可以尽可能把显卡的性能发挥出来。计划上四块 GTX 1080，那么至少需要四路 PCI-e 3.0 的 x16 接口。</p>\n<p>Nvidia DevBox 用的是 Asus X99-E WS 工作站主板，那我也在X99 主板里选了很久，</p>\n<p>这三块板子都有 4路 PCI-e 3.0 x16 接口，</p>\n<ul>\n<li>Asus X99-E WS</li>\n<li>Asus X99-E WS/USB 3.1</li>\n<li>技嘉 GA-X99P-SLI</li>\n</ul>\n<p>当时我还请教了一下 <a href=\"http://weibo.com/1775948951/DESoMxdRf\" target=\"_blank\" rel=\"external\">@硬哥</a> ，问上四块 GTX 1080 显卡的话，用哪个主板好，</p>\n<p><img src=\"/images/weibo-which-motherboard.png\" alt=\"\"></p>\n<p>华硕 X99-E WS/USB 3.1 是 Asus X99-E WS 的新版，本着买新不买旧的原则，那就买  Asus  X99-E WS/USB 3.1 吧。</p>\n<h3 id=\"CPU\"><a href=\"#CPU\" class=\"headerlink\" title=\"CPU\"></a>CPU</h3><p>众所周知单机多卡进行训练时，总线带宽是瓶颈，所以 CPU 的 PCI-e  lane 越多越好，一般消费级的CPU，PCI-e总线根数是 16, 28 或 40，最大就是40，再大就需要上服务器CPU或者双路CPU了。选40， 这个条件下，有两款 CPU 入围，I7-5930K和 I7-5960X, 5860X太贵了，一般机器学习训练中CPU不是瓶颈，所以选 5930K就可以了，这也是 Nvidia 官方推出的 DevBox 工作站所使用的CPU。</p>\n<p>在知乎上看到不少人用 I7-5820K，这个CPU虽然很不错，可是只有 28条 PCI-e总线，所以还是加几百块钱上 5930k比较好。</p>\n<h3 id=\"CPU水冷头\"><a href=\"#CPU水冷头\" class=\"headerlink\" title=\"CPU水冷头\"></a>CPU水冷头</h3><p>其实普通的风扇就可以了，不过水冷更加安静些，所以我选择了一个便宜的 Corsair H60 Cooler ，够用了。</p>\n<h3 id=\"内存\"><a href=\"#内存\" class=\"headerlink\" title=\"内存\"></a>内存</h3><p>DDR4 64G</p>\n<p>再大就没必要了，李沐的这篇博客<a href=\"http://mli.github.io/gpu/2016/01/17/build-gpu-clusters/\" target=\"_blank\" rel=\"external\">GPU集群折腾手记</a>  末尾有说到过，单机4卡的机器，64G内存绰绰有余了。</p>\n<p>况且消费级的I7 CPU，最大支持内存就是 64G。</p>\n<h3 id=\"显卡\"><a href=\"#显卡\" class=\"headerlink\" title=\"显卡\"></a>显卡</h3><p>这个最好选，GTX 1080</p>\n<p>最新出来的 GTX 1080 吊打 Maxwell 架构的 Titan , 价钱又便宜很多，所以显卡最好选。</p>\n<h3 id=\"电源\"><a href=\"#电源\" class=\"headerlink\" title=\"电源\"></a>电源</h3><p>一般 Nvidia 的旗舰显卡，功耗都是压着 300W的线的，四卡就 1200W了，加上主板，CPU等耗电，选一个 1600W的电源吧。</p>\n<p>Nvidia DevBox 用的是 EVGA 1600W 80+ Gold 120-G2-1600-X1 ，那我也用它吧。</p>\n<h3 id=\"SSD\"><a href=\"#SSD\" class=\"headerlink\" title=\"SSD\"></a>SSD</h3><p>起码需要一块SSD作为系统盘。</p>\n<p>当前 SATA III 接口的SSD最普遍也最便宜，不过由于 Asus X99-E WS/USB 3.1 恰好有一个 M.2 接口，我决定买一个 M.2 NVMe 的SSD，不用就浪费了主板的这个接口了。在 eBay 上买了一块二手的 Samsung SM951 256GB M.2 NVMe MZVPV256HDGL 。</p>\n<h3 id=\"机械硬盘\"><a href=\"#机械硬盘\" class=\"headerlink\" title=\"机械硬盘\"></a>机械硬盘</h3><p>随便选，我选择最便宜的绿盘。</p>\n<h3 id=\"一些波折\"><a href=\"#一些波折\" class=\"headerlink\" title=\"一些波折\"></a>一些波折</h3><p>等了一个月终于凑齐了所有配件后，兴奋的开始装机，装完了后发现死活点不亮，<a href=\"http://weibo.com/1663402687/E1vrO4VFn\" target=\"_blank\" rel=\"external\">http://weibo.com/1663402687/E1vrO4VFn</a></p>\n<p><img src=\"/images/weibo-cannot-boot.png\" alt=\"\"></p>\n<p>尼玛，浪费了我2天时间在各种诊断，甚至一度怀疑自己的装机能力一直到怀疑人生。。。</p>\n<p>只好把主板和CPU退货了，又在 eBay上竞拍了一个二手 I7-5930K，这是 eBay 上的 Asus X99-E WS/USB 3.1 竟然没有二手货了，Amazon 也没有二手货，只有一个 refurbishment , 不敢买，只要在 Amazon 买了个全新的主板。</p>\n<p>等了一周多，今天终于齐了，可以开机进入操作系统了。不过有个小问题，按机箱上的开机键，没有反应，必须打开机箱按主板上的那个开机键。当时我内心是崩溃的，不可能每次开机需要打开机箱吧，那多烦啊。于是开始诊断，先用一根金属棒让 POWSER_SW 的两根针脚短路，可以开机，说明主板的POWSER_SW的两根针脚是好的，那么唯一的原因，就是机箱上的开机键不灵了，我打开机箱，把开机键后面焊接的细线按了几下，再开机，机箱上的开机键起作用了。可能是接触不良吧，我也没有深究了，盖上了机箱盖。</p>\n<h2 id=\"一些配置和-tunning\"><a href=\"#一些配置和-tunning\" class=\"headerlink\" title=\"一些配置和 tunning\"></a>一些配置和 tunning</h2><p>打开了TPU，EPU,DR.POWER , EZ_XMP四个开关，TPU推到了中间的 TPU I， 没敢到最右边的 TPU II</p>\n<p>GTX 1080 要插到 PCIE 1,3,5,7的位置上，这几个插槽是X16模式的，其他是x8模式的</p>\n<p>后续：</p>\n<p><a href=\"http://cn.soulmachine.me/2016-08-14-dual-install-windows-ubuntu/\">安装 Windows 10 和 Ubuntu 16.04 双系统</a><br><a href=\"http://cn.soulmachine.me/2016-08-17-deep-learning-cuda-development-environment/\">深度学习开发环境配置：Ubuntu1 6.04+Nvidia GTX 1080+CUDA 8.0</a></p>\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><ol>\n<li><a href=\"https://developer.nvidia.com/devbox\" target=\"_blank\" rel=\"external\">Nvidia DevBox</a></li>\n<li><a href=\"https://hackaday.io/project/12070-32-tflop-deep-learning-gpu-box\" target=\"_blank\" rel=\"external\">32-TFLOP Deep Learning GPU Box - hackaday</a></li>\n<li><a href=\"https://www.zhihu.com/question/33996159\" target=\"_blank\" rel=\"external\">如何配置一台适用于深度学习的工作站？- 知乎</a></li>\n<li><a href=\"http://exxactcorp.com/deep-learning-workstations-servers.php\" target=\"_blank\" rel=\"external\">Exxact Deep Learning Workstation</a></li>\n<li><a href=\"http://mli.github.io/gpu/2016/01/17/build-gpu-clusters/\" target=\"_blank\" rel=\"external\">GPU集群折腾手记 - 李沐</a></li>\n</ol>\n","excerpt":"<p>一年前就有攒一台深度学习工作站的想法了，今年 6月29号在Amazon 上抢到了一块 GTX 1080后，正式开始了攒机，经过了漫长了的一个半月，到今天8约13号，终于凑齐了所有零件并开机点亮了。为甚么这么漫长？因为本屌为了省钱几乎所有零件都是在 eBay和Amazon 上买的二手（除了GTX 1080太新没二手货）。</p>\n<h2 id=\"硬件配置单\"><a href=\"#硬件配置单\" class=\"headerlink\" title=\"硬件配置单\"></a>硬件配置单</h2><h3 id=\"结论\"><a href=\"#结论\" class=\"headerlink\" title=\"结论\"></a>结论</h3><p>懒人不想看过程的话，可以先看结论。</p>\n<p>以下是我的配置单：</p>\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">配件名</th>\n<th style=\"text-align:center\">品牌型号</th>\n<th style=\"text-align:center\">数量</th>\n<th style=\"text-align:center\">价格</th>\n<th style=\"text-align:center\">哪里买的</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">机箱</td>\n<td style=\"text-align:center\">Corsair Carbide Air 540</td>\n<td style=\"text-align:center\">1</td>\n<td style=\"text-align:center\">$130.57</td>\n<td style=\"text-align:center\">Amazon 二手</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">主板</td>\n<td style=\"text-align:center\">Asus X99-E WS/USB3.1</td>\n<td style=\"text-align:center\">1</td>\n<td style=\"text-align:center\">$563.84</td>\n<td style=\"text-align:center\">Amazon 新</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">CPU</td>\n<td style=\"text-align:center\">Intel I7-5930K</td>\n<td style=\"text-align:center\">1</td>\n<td style=\"text-align:center\">$467.45</td>\n<td style=\"text-align:center\">eBay 二手</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">CPU 水冷头</td>\n<td style=\"text-align:center\">Corsair H60 Cooler</td>\n<td style=\"text-align:center\">1</td>\n<td style=\"text-align:center\">$65.24</td>\n<td style=\"text-align:center\">Amazon 新</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">DDR4内存</td>\n<td style=\"text-align:center\">Kingston 32GB HX421C14FB2K4/32</td>\n<td style=\"text-align:center\">4</td>\n<td style=\"text-align:center\">$139.19</td>\n<td style=\"text-align:center\">Amazon新</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">显卡</td>\n<td style=\"text-align:center\">Zotac GTX 1080 Founders Edition</td>\n<td style=\"text-align:center\">1</td>\n<td style=\"text-align:center\">$761.24</td>\n<td style=\"text-align:center\">Amazon 新</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">电源</td>\n<td style=\"text-align:center\">EVGA 1600W 80+ Gold 120-G2-1600-X1</td>\n<td style=\"text-align:center\">1</td>\n<td style=\"text-align:center\">$241.74</td>\n<td style=\"text-align:center\">eBay二手</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">SSD</td>\n<td style=\"text-align:center\">Samsung SM951 256GB M.2 NVMe MZVPV256HDGL</td>\n<td style=\"text-align:center\">1</td>\n<td style=\"text-align:center\">$129.5</td>\n<td style=\"text-align:center\">eBay二手</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">机械硬盘</td>\n<td style=\"text-align:center\">WD Green 4TB</td>\n<td style=\"text-align:center\">1</td>\n<td style=\"text-align:center\">$162.36</td>\n<td style=\"text-align:center\">Amazon新</td>\n</tr>\n</tbody>\n</table>\n<p>总计：$2661.13</p>\n<p>以上价格已经包含了税。</p>\n<p>这个配置单基本齐全了，唯一还没有到位的是GPU显卡了，目前只有一块 GTX 1080。我打算等一年后 GTX 1080 有二手货了，再收3块二手的，这样就全了。</p>\n<p>接下来一项一项详细说明我为什么这么选择，展示我的决策过程。</p>","more":"<h3 id=\"机箱\"><a href=\"#机箱\" class=\"headerlink\" title=\"机箱\"></a>机箱</h3><p>直接选跟 Nvidia DevBox 同款的机箱，即 Corsair Carbide Air 540</p>\n<h3 id=\"主板\"><a href=\"#主板\" class=\"headerlink\" title=\"主板\"></a>主板</h3><p>硬性要求：</p>\n<ol>\n<li>X99平台</li>\n<li>四个 PCI-E Gen3 x16 接口</li>\n</ol>\n<p>众所周知单机多卡进行训练时，总线带宽是瓶颈，所以主板有越多的PCI-e 3.0 接口越好，可以尽可能把显卡的性能发挥出来。计划上四块 GTX 1080，那么至少需要四路 PCI-e 3.0 的 x16 接口。</p>\n<p>Nvidia DevBox 用的是 Asus X99-E WS 工作站主板，那我也在X99 主板里选了很久，</p>\n<p>这三块板子都有 4路 PCI-e 3.0 x16 接口，</p>\n<ul>\n<li>Asus X99-E WS</li>\n<li>Asus X99-E WS/USB 3.1</li>\n<li>技嘉 GA-X99P-SLI</li>\n</ul>\n<p>当时我还请教了一下 <a href=\"http://weibo.com/1775948951/DESoMxdRf\">@硬哥</a> ，问上四块 GTX 1080 显卡的话，用哪个主板好，</p>\n<p><img src=\"/images/weibo-which-motherboard.png\" alt=\"\"></p>\n<p>华硕 X99-E WS/USB 3.1 是 Asus X99-E WS 的新版，本着买新不买旧的原则，那就买  Asus  X99-E WS/USB 3.1 吧。</p>\n<h3 id=\"CPU\"><a href=\"#CPU\" class=\"headerlink\" title=\"CPU\"></a>CPU</h3><p>众所周知单机多卡进行训练时，总线带宽是瓶颈，所以 CPU 的 PCI-e  lane 越多越好，一般消费级的CPU，PCI-e总线根数是 16, 28 或 40，最大就是40，再大就需要上服务器CPU或者双路CPU了。选40， 这个条件下，有两款 CPU 入围，I7-5930K和 I7-5960X, 5860X太贵了，一般机器学习训练中CPU不是瓶颈，所以选 5930K就可以了，这也是 Nvidia 官方推出的 DevBox 工作站所使用的CPU。</p>\n<p>在知乎上看到不少人用 I7-5820K，这个CPU虽然很不错，可是只有 28条 PCI-e总线，所以还是加几百块钱上 5930k比较好。</p>\n<h3 id=\"CPU水冷头\"><a href=\"#CPU水冷头\" class=\"headerlink\" title=\"CPU水冷头\"></a>CPU水冷头</h3><p>其实普通的风扇就可以了，不过水冷更加安静些，所以我选择了一个便宜的 Corsair H60 Cooler ，够用了。</p>\n<h3 id=\"内存\"><a href=\"#内存\" class=\"headerlink\" title=\"内存\"></a>内存</h3><p>DDR4 64G</p>\n<p>再大就没必要了，李沐的这篇博客<a href=\"http://mli.github.io/gpu/2016/01/17/build-gpu-clusters/\">GPU集群折腾手记</a>  末尾有说到过，单机4卡的机器，64G内存绰绰有余了。</p>\n<p>况且消费级的I7 CPU，最大支持内存就是 64G。</p>\n<h3 id=\"显卡\"><a href=\"#显卡\" class=\"headerlink\" title=\"显卡\"></a>显卡</h3><p>这个最好选，GTX 1080</p>\n<p>最新出来的 GTX 1080 吊打 Maxwell 架构的 Titan , 价钱又便宜很多，所以显卡最好选。</p>\n<h3 id=\"电源\"><a href=\"#电源\" class=\"headerlink\" title=\"电源\"></a>电源</h3><p>一般 Nvidia 的旗舰显卡，功耗都是压着 300W的线的，四卡就 1200W了，加上主板，CPU等耗电，选一个 1600W的电源吧。</p>\n<p>Nvidia DevBox 用的是 EVGA 1600W 80+ Gold 120-G2-1600-X1 ，那我也用它吧。</p>\n<h3 id=\"SSD\"><a href=\"#SSD\" class=\"headerlink\" title=\"SSD\"></a>SSD</h3><p>起码需要一块SSD作为系统盘。</p>\n<p>当前 SATA III 接口的SSD最普遍也最便宜，不过由于 Asus X99-E WS/USB 3.1 恰好有一个 M.2 接口，我决定买一个 M.2 NVMe 的SSD，不用就浪费了主板的这个接口了。在 eBay 上买了一块二手的 Samsung SM951 256GB M.2 NVMe MZVPV256HDGL 。</p>\n<h3 id=\"机械硬盘\"><a href=\"#机械硬盘\" class=\"headerlink\" title=\"机械硬盘\"></a>机械硬盘</h3><p>随便选，我选择最便宜的绿盘。</p>\n<h3 id=\"一些波折\"><a href=\"#一些波折\" class=\"headerlink\" title=\"一些波折\"></a>一些波折</h3><p>等了一个月终于凑齐了所有配件后，兴奋的开始装机，装完了后发现死活点不亮，<a href=\"http://weibo.com/1663402687/E1vrO4VFn\">http://weibo.com/1663402687/E1vrO4VFn</a></p>\n<p><img src=\"/images/weibo-cannot-boot.png\" alt=\"\"></p>\n<p>尼玛，浪费了我2天时间在各种诊断，甚至一度怀疑自己的装机能力一直到怀疑人生。。。</p>\n<p>只好把主板和CPU退货了，又在 eBay上竞拍了一个二手 I7-5930K，这是 eBay 上的 Asus X99-E WS/USB 3.1 竟然没有二手货了，Amazon 也没有二手货，只有一个 refurbishment , 不敢买，只要在 Amazon 买了个全新的主板。</p>\n<p>等了一周多，今天终于齐了，可以开机进入操作系统了。不过有个小问题，按机箱上的开机键，没有反应，必须打开机箱按主板上的那个开机键。当时我内心是崩溃的，不可能每次开机需要打开机箱吧，那多烦啊。于是开始诊断，先用一根金属棒让 POWSER_SW 的两根针脚短路，可以开机，说明主板的POWSER_SW的两根针脚是好的，那么唯一的原因，就是机箱上的开机键不灵了，我打开机箱，把开机键后面焊接的细线按了几下，再开机，机箱上的开机键起作用了。可能是接触不良吧，我也没有深究了，盖上了机箱盖。</p>\n<h2 id=\"一些配置和-tunning\"><a href=\"#一些配置和-tunning\" class=\"headerlink\" title=\"一些配置和 tunning\"></a>一些配置和 tunning</h2><p>打开了TPU，EPU,DR.POWER , EZ_XMP四个开关，TPU推到了中间的 TPU I， 没敢到最右边的 TPU II</p>\n<p>GTX 1080 要插到 PCIE 1,3,5,7的位置上，这几个插槽是X16模式的，其他是x8模式的</p>\n<p>后续：</p>\n<p><a href=\"http://cn.soulmachine.me/2016-08-14-dual-install-windows-ubuntu/\">安装 Windows 10 和 Ubuntu 16.04 双系统</a><br><a href=\"http://cn.soulmachine.me/2016-08-17-deep-learning-cuda-development-environment/\">深度学习开发环境配置：Ubuntu1 6.04+Nvidia GTX 1080+CUDA 8.0</a></p>\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><ol>\n<li><a href=\"https://developer.nvidia.com/devbox\">Nvidia DevBox</a></li>\n<li><a href=\"https://hackaday.io/project/12070-32-tflop-deep-learning-gpu-box\">32-TFLOP Deep Learning GPU Box - hackaday</a></li>\n<li><a href=\"https://www.zhihu.com/question/33996159\">如何配置一台适用于深度学习的工作站？- 知乎</a></li>\n<li><a href=\"http://exxactcorp.com/deep-learning-workstations-servers.php\">Exxact Deep Learning Workstation</a></li>\n<li><a href=\"http://mli.github.io/gpu/2016/01/17/build-gpu-clusters/\">GPU集群折腾手记 - 李沐</a></li>\n</ol>"},{"title":"安装 Windows 10 和 Ubuntu 16.04 双系统","date":"2016-08-14T22:23:11.000Z","_content":"\n本文是上一篇文章[我的深度学习工作站攒机过程记录](http://cn.soulmachine.me/2016-08-13-my-deep-learning-workstation-assemble-process-note/)的续集。\n\n\n## 前提条件\n\n1. 主板BIOS是 UEFI 模式\n\n    首先确认下你的主板的BIOS是UEFI模式，例如 Asus X99-E WS/USB 3.1 主板的BIOS默认就是UEFI模式。\n\n1. 两个U盘，一个是可启动的Ubuntu 16.04.1 安装盘，一个是Windows 10 1607 x64 安装盘\n\n    制作可启动安装盘很简单，下载 `cn_windows_10_multiple_editions_version_1511_updated_apr_2016_x64_dvd_8712460.iso` 和 `ubuntu-16.04.1-desktop-amd64.iso` ，找一台 Windows 电脑，安装 UltraISO这个小软件，启动软件，点击 `打开`，打开操作系统的ISO文件，点击菜单`启动->写入硬盘映像`，即可开始刻录U盘。\n\n    如果你只有一个U盘，有没问题，先刻录Windows，装完了Windows后，格式化U盘，再刻录一个Ubuntu 进去。\n\n1. 关闭主板的 Fast Startup\n\n    进入 UEFI BIOS 界面，点击 Boot 菜单，找打 Fast Boot, 改为 `Disabled`\n\n1. 关闭主板的 SRT（Intel Smart Response Technology)\n\n    进入 UEFI BIOS 界面，点击 Advanced菜单，找到 Intel Rapid Storage Technology, 点击进去，如果你没有RAID模式的磁盘，这个RST一般是灰色的，没有启用。\n\n1. 禁用主板的 Secure Boot\n\n    如果你想要装Windows和 Linux 双操作系统，那么必须要禁用主板的 Secure Boot ，因为主板内置的公钥只有一个，就是微软的，因为微软影响力大。更具体信息请参考 [反Secure Boot垄断：兼谈如何在Windows 8电脑上安装Linux - 阮一峰](http://www.ruanyifeng.com/blog/2013/01/secure_boot.html)\n\n    Ubuntu 已经买了这个证书，所以微软的这个公钥，也能允许Ubuntu安装在主板上。看到这里，你会问，那岂不是不用禁用 Secure Boot 了？\n\n    不尽然，在Ubuntu 下安装 GTX 1080 的 Nvidia 驱动的时候，会警告 `UEFI Secure Boot is not compatible with the use of third-party drivers.` 如果没有禁用Secure Boot, 安装了显卡驱动后，开机，输入密码时，会进不去系统，屏幕会闪一下，有回到了登录界面，死循环 。。。\n\n    具体步骤请参考 [How to Disable or Enable Secure Boot on Your Computer via ASUS UEFI BIOS Utility](http://www.technorms.com/45538/disable-enable-secure-boot-asus-motherboard-uefi-bios-utility) ：\n\n    * 进入 UEFI BIOS界面，选择 `Boot->Secure Boot-> Key Management -> Save Secure Boot Keys`，插入U盘，备份key到这个U盘，会有四个文件,  `PK`, `KEK`, `DB` 和 `DBX` 写入到U盘。\n    * 删除 Platform Key. 选择 `Delete PK`，点击OK确认删除。删除后回到上一级菜单，可以看到 Secure Boot 已经变成 disabled 了。\n\n1. 顺序上，最好是先安装 Windows 再安装 Ubuntu，本文的方法1和方法2都是这个顺序\n1. 安装了Wiondows后，必须要关闭Windows的 Fast Startup。\n\n    进入`控制面板->电源`，找到 Fast Startup，禁用掉。\n\n\n## Windows 和 Ubuntu 安装在同一块硬盘上\n\n开机，按住 DEL 键进入BIOS，点击Boot Menu(F8)菜单，选择从U盘启动，且注意要选择UEFI模式的U盘\n\n<!-- more -->\n\n开始安装Windows, 安装完后，重启，进入Windows 后，关闭Windows的 Fast Startup，即进入`控制面板->电源`，找到 Fast Startup，禁用掉。\n\n把 Ubuntu U盘启动盘插上，开机，按DEL键进入BIOS，选择从这个U盘启动，要选择UEFI模式的U盘，开始安装，记得选择 `Install Ubuntu alongside Windows Boot Manager`\n\n\n## Windows 和 Ubuntu 分别安装不同的硬盘上\n\n先按照方法一中的步骤，安装好Windows，然后关机，把这块硬盘拆下来，当做它不存在。\n\n开始安装Ubuntu，安装到另一块硬盘上。选择 `Erase disk and install Ubuntu`，接下来选择安装到 SM951 NVMe SSD 这块磁盘上。\n\n把 Windows 那块硬盘在接入主板。\n\n这样，两块硬盘就分别安装了独立的操作系统，具体进入哪个，由UEFI BIOS里的启动优先级来决定。你想默认启动Windows，那就把Windows那块硬盘拖动到第一的位置，如果你想默认启动Ubuntu，那就把Ubuntu那块硬盘拖动到第一的位置。\n\n【可选项】如果你不想通过UEFI BIOS来切换操作系统，你还可以把Windows加入 Ubuntu的 grub 菜单，开机进入Ubuntu后，执行\n\n    sudo update-grub\n\n这个命令会自动扫描其他硬盘上的操作系统，并加入grub 开机启动菜单。\n\n\n## 参考资料\n\n* [UEFI - Ubuntu](https://help.ubuntu.com/community/UEFI)\n* [在Win8基础上加装Ubuntu，得先搞清楚Win8是以何种方式安装的](http://forum.ubuntu.org.cn/viewtopic.php?t=467746)\n* [How to dual-boot Windows 10 and Ubuntu 15.10 on two hard drives](http://linuxbsdos.com/2015/10/31/how-to-dual-boot-windows-10-and-ubuntu-15-10-on-two-hard-drives/)\n","source":"_posts/2016-08-14-dual-install-windows-ubuntu.md","raw":"---\ntitle: 安装 Windows 10 和 Ubuntu 16.04 双系统\ndate: 2016-08-14 22:23:11\ntags: 深度学习\ncategories: 深度学习\n---\n\n本文是上一篇文章[我的深度学习工作站攒机过程记录](http://cn.soulmachine.me/2016-08-13-my-deep-learning-workstation-assemble-process-note/)的续集。\n\n\n## 前提条件\n\n1. 主板BIOS是 UEFI 模式\n\n    首先确认下你的主板的BIOS是UEFI模式，例如 Asus X99-E WS/USB 3.1 主板的BIOS默认就是UEFI模式。\n\n1. 两个U盘，一个是可启动的Ubuntu 16.04.1 安装盘，一个是Windows 10 1607 x64 安装盘\n\n    制作可启动安装盘很简单，下载 `cn_windows_10_multiple_editions_version_1511_updated_apr_2016_x64_dvd_8712460.iso` 和 `ubuntu-16.04.1-desktop-amd64.iso` ，找一台 Windows 电脑，安装 UltraISO这个小软件，启动软件，点击 `打开`，打开操作系统的ISO文件，点击菜单`启动->写入硬盘映像`，即可开始刻录U盘。\n\n    如果你只有一个U盘，有没问题，先刻录Windows，装完了Windows后，格式化U盘，再刻录一个Ubuntu 进去。\n\n1. 关闭主板的 Fast Startup\n\n    进入 UEFI BIOS 界面，点击 Boot 菜单，找打 Fast Boot, 改为 `Disabled`\n\n1. 关闭主板的 SRT（Intel Smart Response Technology)\n\n    进入 UEFI BIOS 界面，点击 Advanced菜单，找到 Intel Rapid Storage Technology, 点击进去，如果你没有RAID模式的磁盘，这个RST一般是灰色的，没有启用。\n\n1. 禁用主板的 Secure Boot\n\n    如果你想要装Windows和 Linux 双操作系统，那么必须要禁用主板的 Secure Boot ，因为主板内置的公钥只有一个，就是微软的，因为微软影响力大。更具体信息请参考 [反Secure Boot垄断：兼谈如何在Windows 8电脑上安装Linux - 阮一峰](http://www.ruanyifeng.com/blog/2013/01/secure_boot.html)\n\n    Ubuntu 已经买了这个证书，所以微软的这个公钥，也能允许Ubuntu安装在主板上。看到这里，你会问，那岂不是不用禁用 Secure Boot 了？\n\n    不尽然，在Ubuntu 下安装 GTX 1080 的 Nvidia 驱动的时候，会警告 `UEFI Secure Boot is not compatible with the use of third-party drivers.` 如果没有禁用Secure Boot, 安装了显卡驱动后，开机，输入密码时，会进不去系统，屏幕会闪一下，有回到了登录界面，死循环 。。。\n\n    具体步骤请参考 [How to Disable or Enable Secure Boot on Your Computer via ASUS UEFI BIOS Utility](http://www.technorms.com/45538/disable-enable-secure-boot-asus-motherboard-uefi-bios-utility) ：\n\n    * 进入 UEFI BIOS界面，选择 `Boot->Secure Boot-> Key Management -> Save Secure Boot Keys`，插入U盘，备份key到这个U盘，会有四个文件,  `PK`, `KEK`, `DB` 和 `DBX` 写入到U盘。\n    * 删除 Platform Key. 选择 `Delete PK`，点击OK确认删除。删除后回到上一级菜单，可以看到 Secure Boot 已经变成 disabled 了。\n\n1. 顺序上，最好是先安装 Windows 再安装 Ubuntu，本文的方法1和方法2都是这个顺序\n1. 安装了Wiondows后，必须要关闭Windows的 Fast Startup。\n\n    进入`控制面板->电源`，找到 Fast Startup，禁用掉。\n\n\n## Windows 和 Ubuntu 安装在同一块硬盘上\n\n开机，按住 DEL 键进入BIOS，点击Boot Menu(F8)菜单，选择从U盘启动，且注意要选择UEFI模式的U盘\n\n<!-- more -->\n\n开始安装Windows, 安装完后，重启，进入Windows 后，关闭Windows的 Fast Startup，即进入`控制面板->电源`，找到 Fast Startup，禁用掉。\n\n把 Ubuntu U盘启动盘插上，开机，按DEL键进入BIOS，选择从这个U盘启动，要选择UEFI模式的U盘，开始安装，记得选择 `Install Ubuntu alongside Windows Boot Manager`\n\n\n## Windows 和 Ubuntu 分别安装不同的硬盘上\n\n先按照方法一中的步骤，安装好Windows，然后关机，把这块硬盘拆下来，当做它不存在。\n\n开始安装Ubuntu，安装到另一块硬盘上。选择 `Erase disk and install Ubuntu`，接下来选择安装到 SM951 NVMe SSD 这块磁盘上。\n\n把 Windows 那块硬盘在接入主板。\n\n这样，两块硬盘就分别安装了独立的操作系统，具体进入哪个，由UEFI BIOS里的启动优先级来决定。你想默认启动Windows，那就把Windows那块硬盘拖动到第一的位置，如果你想默认启动Ubuntu，那就把Ubuntu那块硬盘拖动到第一的位置。\n\n【可选项】如果你不想通过UEFI BIOS来切换操作系统，你还可以把Windows加入 Ubuntu的 grub 菜单，开机进入Ubuntu后，执行\n\n    sudo update-grub\n\n这个命令会自动扫描其他硬盘上的操作系统，并加入grub 开机启动菜单。\n\n\n## 参考资料\n\n* [UEFI - Ubuntu](https://help.ubuntu.com/community/UEFI)\n* [在Win8基础上加装Ubuntu，得先搞清楚Win8是以何种方式安装的](http://forum.ubuntu.org.cn/viewtopic.php?t=467746)\n* [How to dual-boot Windows 10 and Ubuntu 15.10 on two hard drives](http://linuxbsdos.com/2015/10/31/how-to-dual-boot-windows-10-and-ubuntu-15-10-on-two-hard-drives/)\n","slug":"2016-08-14-dual-install-windows-ubuntu","published":1,"updated":"2016-08-18T10:19:17.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cis07pf4t003x01pqhu7o1ywx","content":"<p>本文是上一篇文章<a href=\"http://cn.soulmachine.me/2016-08-13-my-deep-learning-workstation-assemble-process-note/\">我的深度学习工作站攒机过程记录</a>的续集。</p>\n<h2 id=\"前提条件\"><a href=\"#前提条件\" class=\"headerlink\" title=\"前提条件\"></a>前提条件</h2><ol>\n<li><p>主板BIOS是 UEFI 模式</p>\n<p> 首先确认下你的主板的BIOS是UEFI模式，例如 Asus X99-E WS/USB 3.1 主板的BIOS默认就是UEFI模式。</p>\n</li>\n<li><p>两个U盘，一个是可启动的Ubuntu 16.04.1 安装盘，一个是Windows 10 1607 x64 安装盘</p>\n<p> 制作可启动安装盘很简单，下载 <code>cn_windows_10_multiple_editions_version_1511_updated_apr_2016_x64_dvd_8712460.iso</code> 和 <code>ubuntu-16.04.1-desktop-amd64.iso</code> ，找一台 Windows 电脑，安装 UltraISO这个小软件，启动软件，点击 <code>打开</code>，打开操作系统的ISO文件，点击菜单<code>启动-&gt;写入硬盘映像</code>，即可开始刻录U盘。</p>\n<p> 如果你只有一个U盘，有没问题，先刻录Windows，装完了Windows后，格式化U盘，再刻录一个Ubuntu 进去。</p>\n</li>\n<li><p>关闭主板的 Fast Startup</p>\n<p> 进入 UEFI BIOS 界面，点击 Boot 菜单，找打 Fast Boot, 改为 <code>Disabled</code></p>\n</li>\n<li><p>关闭主板的 SRT（Intel Smart Response Technology)</p>\n<p> 进入 UEFI BIOS 界面，点击 Advanced菜单，找到 Intel Rapid Storage Technology, 点击进去，如果你没有RAID模式的磁盘，这个RST一般是灰色的，没有启用。</p>\n</li>\n<li><p>禁用主板的 Secure Boot</p>\n<p> 如果你想要装Windows和 Linux 双操作系统，那么必须要禁用主板的 Secure Boot ，因为主板内置的公钥只有一个，就是微软的，因为微软影响力大。更具体信息请参考 <a href=\"http://www.ruanyifeng.com/blog/2013/01/secure_boot.html\" target=\"_blank\" rel=\"external\">反Secure Boot垄断：兼谈如何在Windows 8电脑上安装Linux - 阮一峰</a></p>\n<p> Ubuntu 已经买了这个证书，所以微软的这个公钥，也能允许Ubuntu安装在主板上。看到这里，你会问，那岂不是不用禁用 Secure Boot 了？</p>\n<p> 不尽然，在Ubuntu 下安装 GTX 1080 的 Nvidia 驱动的时候，会警告 <code>UEFI Secure Boot is not compatible with the use of third-party drivers.</code> 如果没有禁用Secure Boot, 安装了显卡驱动后，开机，输入密码时，会进不去系统，屏幕会闪一下，有回到了登录界面，死循环 。。。</p>\n<p> 具体步骤请参考 <a href=\"http://www.technorms.com/45538/disable-enable-secure-boot-asus-motherboard-uefi-bios-utility\" target=\"_blank\" rel=\"external\">How to Disable or Enable Secure Boot on Your Computer via ASUS UEFI BIOS Utility</a> ：</p>\n<ul>\n<li>进入 UEFI BIOS界面，选择 <code>Boot-&gt;Secure Boot-&gt; Key Management -&gt; Save Secure Boot Keys</code>，插入U盘，备份key到这个U盘，会有四个文件,  <code>PK</code>, <code>KEK</code>, <code>DB</code> 和 <code>DBX</code> 写入到U盘。</li>\n<li>删除 Platform Key. 选择 <code>Delete PK</code>，点击OK确认删除。删除后回到上一级菜单，可以看到 Secure Boot 已经变成 disabled 了。</li>\n</ul>\n</li>\n<li><p>顺序上，最好是先安装 Windows 再安装 Ubuntu，本文的方法1和方法2都是这个顺序</p>\n</li>\n<li><p>安装了Wiondows后，必须要关闭Windows的 Fast Startup。</p>\n<p> 进入<code>控制面板-&gt;电源</code>，找到 Fast Startup，禁用掉。</p>\n</li>\n</ol>\n<h2 id=\"Windows-和-Ubuntu-安装在同一块硬盘上\"><a href=\"#Windows-和-Ubuntu-安装在同一块硬盘上\" class=\"headerlink\" title=\"Windows 和 Ubuntu 安装在同一块硬盘上\"></a>Windows 和 Ubuntu 安装在同一块硬盘上</h2><p>开机，按住 DEL 键进入BIOS，点击Boot Menu(F8)菜单，选择从U盘启动，且注意要选择UEFI模式的U盘</p>\n<a id=\"more\"></a>\n<p>开始安装Windows, 安装完后，重启，进入Windows 后，关闭Windows的 Fast Startup，即进入<code>控制面板-&gt;电源</code>，找到 Fast Startup，禁用掉。</p>\n<p>把 Ubuntu U盘启动盘插上，开机，按DEL键进入BIOS，选择从这个U盘启动，要选择UEFI模式的U盘，开始安装，记得选择 <code>Install Ubuntu alongside Windows Boot Manager</code></p>\n<h2 id=\"Windows-和-Ubuntu-分别安装不同的硬盘上\"><a href=\"#Windows-和-Ubuntu-分别安装不同的硬盘上\" class=\"headerlink\" title=\"Windows 和 Ubuntu 分别安装不同的硬盘上\"></a>Windows 和 Ubuntu 分别安装不同的硬盘上</h2><p>先按照方法一中的步骤，安装好Windows，然后关机，把这块硬盘拆下来，当做它不存在。</p>\n<p>开始安装Ubuntu，安装到另一块硬盘上。选择 <code>Erase disk and install Ubuntu</code>，接下来选择安装到 SM951 NVMe SSD 这块磁盘上。</p>\n<p>把 Windows 那块硬盘在接入主板。</p>\n<p>这样，两块硬盘就分别安装了独立的操作系统，具体进入哪个，由UEFI BIOS里的启动优先级来决定。你想默认启动Windows，那就把Windows那块硬盘拖动到第一的位置，如果你想默认启动Ubuntu，那就把Ubuntu那块硬盘拖动到第一的位置。</p>\n<p>【可选项】如果你不想通过UEFI BIOS来切换操作系统，你还可以把Windows加入 Ubuntu的 grub 菜单，开机进入Ubuntu后，执行</p>\n<pre><code>sudo update-grub\n</code></pre><p>这个命令会自动扫描其他硬盘上的操作系统，并加入grub 开机启动菜单。</p>\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><ul>\n<li><a href=\"https://help.ubuntu.com/community/UEFI\" target=\"_blank\" rel=\"external\">UEFI - Ubuntu</a></li>\n<li><a href=\"http://forum.ubuntu.org.cn/viewtopic.php?t=467746\" target=\"_blank\" rel=\"external\">在Win8基础上加装Ubuntu，得先搞清楚Win8是以何种方式安装的</a></li>\n<li><a href=\"http://linuxbsdos.com/2015/10/31/how-to-dual-boot-windows-10-and-ubuntu-15-10-on-two-hard-drives/\" target=\"_blank\" rel=\"external\">How to dual-boot Windows 10 and Ubuntu 15.10 on two hard drives</a></li>\n</ul>\n","excerpt":"<p>本文是上一篇文章<a href=\"http://cn.soulmachine.me/2016-08-13-my-deep-learning-workstation-assemble-process-note/\">我的深度学习工作站攒机过程记录</a>的续集。</p>\n<h2 id=\"前提条件\"><a href=\"#前提条件\" class=\"headerlink\" title=\"前提条件\"></a>前提条件</h2><ol>\n<li><p>主板BIOS是 UEFI 模式</p>\n<p> 首先确认下你的主板的BIOS是UEFI模式，例如 Asus X99-E WS/USB 3.1 主板的BIOS默认就是UEFI模式。</p>\n</li>\n<li><p>两个U盘，一个是可启动的Ubuntu 16.04.1 安装盘，一个是Windows 10 1607 x64 安装盘</p>\n<p> 制作可启动安装盘很简单，下载 <code>cn_windows_10_multiple_editions_version_1511_updated_apr_2016_x64_dvd_8712460.iso</code> 和 <code>ubuntu-16.04.1-desktop-amd64.iso</code> ，找一台 Windows 电脑，安装 UltraISO这个小软件，启动软件，点击 <code>打开</code>，打开操作系统的ISO文件，点击菜单<code>启动-&gt;写入硬盘映像</code>，即可开始刻录U盘。</p>\n<p> 如果你只有一个U盘，有没问题，先刻录Windows，装完了Windows后，格式化U盘，再刻录一个Ubuntu 进去。</p>\n</li>\n<li><p>关闭主板的 Fast Startup</p>\n<p> 进入 UEFI BIOS 界面，点击 Boot 菜单，找打 Fast Boot, 改为 <code>Disabled</code></p>\n</li>\n<li><p>关闭主板的 SRT（Intel Smart Response Technology)</p>\n<p> 进入 UEFI BIOS 界面，点击 Advanced菜单，找到 Intel Rapid Storage Technology, 点击进去，如果你没有RAID模式的磁盘，这个RST一般是灰色的，没有启用。</p>\n</li>\n<li><p>禁用主板的 Secure Boot</p>\n<p> 如果你想要装Windows和 Linux 双操作系统，那么必须要禁用主板的 Secure Boot ，因为主板内置的公钥只有一个，就是微软的，因为微软影响力大。更具体信息请参考 <a href=\"http://www.ruanyifeng.com/blog/2013/01/secure_boot.html\">反Secure Boot垄断：兼谈如何在Windows 8电脑上安装Linux - 阮一峰</a></p>\n<p> Ubuntu 已经买了这个证书，所以微软的这个公钥，也能允许Ubuntu安装在主板上。看到这里，你会问，那岂不是不用禁用 Secure Boot 了？</p>\n<p> 不尽然，在Ubuntu 下安装 GTX 1080 的 Nvidia 驱动的时候，会警告 <code>UEFI Secure Boot is not compatible with the use of third-party drivers.</code> 如果没有禁用Secure Boot, 安装了显卡驱动后，开机，输入密码时，会进不去系统，屏幕会闪一下，有回到了登录界面，死循环 。。。</p>\n<p> 具体步骤请参考 <a href=\"http://www.technorms.com/45538/disable-enable-secure-boot-asus-motherboard-uefi-bios-utility\">How to Disable or Enable Secure Boot on Your Computer via ASUS UEFI BIOS Utility</a> ：</p>\n<ul>\n<li>进入 UEFI BIOS界面，选择 <code>Boot-&gt;Secure Boot-&gt; Key Management -&gt; Save Secure Boot Keys</code>，插入U盘，备份key到这个U盘，会有四个文件,  <code>PK</code>, <code>KEK</code>, <code>DB</code> 和 <code>DBX</code> 写入到U盘。</li>\n<li>删除 Platform Key. 选择 <code>Delete PK</code>，点击OK确认删除。删除后回到上一级菜单，可以看到 Secure Boot 已经变成 disabled 了。</li>\n</ul>\n</li>\n<li><p>顺序上，最好是先安装 Windows 再安装 Ubuntu，本文的方法1和方法2都是这个顺序</p>\n</li>\n<li><p>安装了Wiondows后，必须要关闭Windows的 Fast Startup。</p>\n<p> 进入<code>控制面板-&gt;电源</code>，找到 Fast Startup，禁用掉。</p>\n</li>\n</ol>\n<h2 id=\"Windows-和-Ubuntu-安装在同一块硬盘上\"><a href=\"#Windows-和-Ubuntu-安装在同一块硬盘上\" class=\"headerlink\" title=\"Windows 和 Ubuntu 安装在同一块硬盘上\"></a>Windows 和 Ubuntu 安装在同一块硬盘上</h2><p>开机，按住 DEL 键进入BIOS，点击Boot Menu(F8)菜单，选择从U盘启动，且注意要选择UEFI模式的U盘</p>","more":"<p>开始安装Windows, 安装完后，重启，进入Windows 后，关闭Windows的 Fast Startup，即进入<code>控制面板-&gt;电源</code>，找到 Fast Startup，禁用掉。</p>\n<p>把 Ubuntu U盘启动盘插上，开机，按DEL键进入BIOS，选择从这个U盘启动，要选择UEFI模式的U盘，开始安装，记得选择 <code>Install Ubuntu alongside Windows Boot Manager</code></p>\n<h2 id=\"Windows-和-Ubuntu-分别安装不同的硬盘上\"><a href=\"#Windows-和-Ubuntu-分别安装不同的硬盘上\" class=\"headerlink\" title=\"Windows 和 Ubuntu 分别安装不同的硬盘上\"></a>Windows 和 Ubuntu 分别安装不同的硬盘上</h2><p>先按照方法一中的步骤，安装好Windows，然后关机，把这块硬盘拆下来，当做它不存在。</p>\n<p>开始安装Ubuntu，安装到另一块硬盘上。选择 <code>Erase disk and install Ubuntu</code>，接下来选择安装到 SM951 NVMe SSD 这块磁盘上。</p>\n<p>把 Windows 那块硬盘在接入主板。</p>\n<p>这样，两块硬盘就分别安装了独立的操作系统，具体进入哪个，由UEFI BIOS里的启动优先级来决定。你想默认启动Windows，那就把Windows那块硬盘拖动到第一的位置，如果你想默认启动Ubuntu，那就把Ubuntu那块硬盘拖动到第一的位置。</p>\n<p>【可选项】如果你不想通过UEFI BIOS来切换操作系统，你还可以把Windows加入 Ubuntu的 grub 菜单，开机进入Ubuntu后，执行</p>\n<pre><code>sudo update-grub\n</code></pre><p>这个命令会自动扫描其他硬盘上的操作系统，并加入grub 开机启动菜单。</p>\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><ul>\n<li><a href=\"https://help.ubuntu.com/community/UEFI\">UEFI - Ubuntu</a></li>\n<li><a href=\"http://forum.ubuntu.org.cn/viewtopic.php?t=467746\">在Win8基础上加装Ubuntu，得先搞清楚Win8是以何种方式安装的</a></li>\n<li><a href=\"http://linuxbsdos.com/2015/10/31/how-to-dual-boot-windows-10-and-ubuntu-15-10-on-two-hard-drives/\">How to dual-boot Windows 10 and Ubuntu 15.10 on two hard drives</a></li>\n</ul>"},{"layout":"post","title":"安装和配置Ubuntu服务器的详细步骤","date":"2014-04-17T22:05:00.000Z","comments":1,"published":0,"_content":"\n这是我安装Ubuntu服务器的过程，记录下来，与大家一起分享。CentOS请见[安装和配置CentOS服务器的详细步骤](http://cn.soulmachine.me/blog/20120423/)。\n\n##安装操作系统\nubuntu-12.04.4-desktop-amd64.iso\n\n安装 CentOS时，选择 \"Basic Server\"  \nroot密码：root123  \nCentOS 自带了ssh  \n \n安装完操作系统后，添加一个用户 manong\n\n``` bash\n[root@localhost ~]$ useradd manong\n\n```\n然后密码设为 manong123\n\n``` bash\n[root@localhost ~]$ passwd manong\n```\n\n给予 sudo 权限\n\n``` bash\n[root@localhost ~]$ chmod u+w /etc/sudoers\n[root@localhost ~]$ vim /etc/sudoers\n# 在root ALL=(ALL) ALL 下 添加manong ALL=(ALL) ALL\n[root@localhost ~]$ chmod u-w /etc/sudoers \n```\n\n##设置上网\n安装完操作系统后，还不能上网，配置DHCP方式上网：\n\n``` bash\nvim /etc/sysconfig/network-scripts/ifcfg-eth0\nDEVICE=\"eth0\"\nHWADDR=\"00:0C:29:BD:E1:19\"\nNM_CONTROLLED=\"yes\"\nONBOOT=\"yes\"\nBOOTPROTO=dhcp\nUSECTL=no\nTYPE=Ethernet\nPEERDNS=yes\n#保存退出\nsudo service network restart\n```\n\n<!-- more -->\n\n或者，配置静态IP\n\n``` bash\nDEVICE=\"eth0\"\nHWADDR=\"00:0C:29:10:F4:4C\"\nONBOOT=\"yes\"\nBOOTPROTO=static\nTYPE=Ethernet\nIPADDR=192.168.0.162\nNETMASK=255.255.255.0\nBROADCAST=192.168.0.255\nNETWORK=192.168.0.0\n#保存退出  \n#修改/etc/sysconfig/network\nsudo vim /etc/sysconfig/network\nNETWORKING=yes\nHOSTNAME=localhost.localdomain\nGATEWAY=192.168.0.1\n#保存退出，重启网络\nsudo service network restart\n```\n如果失败，比如IP已被占用，换一个IP试试\n\n修改DNS，即时生效\n\n``` bash\nsudo vim /etc/resolv.conf\nnameserver 192.168.0.1\n# google提供的域名服务器\nnameserver 8.8.8.8\nsearch localhost\n```\n\n##安装常用软件\n有两种方式，方法一，去官网下载已经编译好的二进制文件，或源代码，编译安装\n方法二，用`apt-get`命令安装，安装官方源里已经编译好的程序包。  \n第一种方式要敲很多命令，比yum麻烦，但是可以预先下载好文件，省略了下载的时间，批量给很多服务器安装时，可以节省很多流量，速度比yum安装方式快很多，而且可以安装最新版。\n\n第二种方式操作简单，敲打的命令少，但是往往官方源的更新速度跟不上各个软件的官网速度，用apt安装的版本经常比较旧。但是这种方式安装简单，更新也简单，推荐第这种方式。\n\n`apt`的命令形式一般是如下：`apt [options] [command] [package ...]`，其中的[options]是可选的，选项包括-h（帮助），-y（当安装过程提示选择全部为\"yes\"），-q（不显示安装的过程）等等。[command]为所要进行的操作，[package ...]是操作的对象。\n\n``` bash\n#apt-cache search package-name # 在线搜索包 \n#apt-get list installed # 列出所有已经安装的包\n#\n#sudo apt-get install package-name # 安装程序包 \n#sudo yum groupinsall group-name 安装程序组\n#\n#sudo yum remove package-name 删除程序包\n#sudo yum groupremove group-name 删除程序组\n#\n#yum update #全部更新\n#yum update package-name #更新程序包\n#sudo yum groupupdate groupn-name 升级程序组\n#sudo yum upgrade # 更新源列表\n#yum upgrade package-name #升级程序包\n#sudo yum clean all # 清除缓存\n#更新\nsudo yum update\n#清理缓存\nsudo yum clean all && yum clean metadata && yum clean dbcache\n```\n\n##安装GCC\n\n###方法一 编译源码安装\n去 http://gcc.gnu.org/ 下载源码\n\n``` bash\n# TODO\n```\n\n###方法二 apt安装\n\n``` bash\nsudo apt-get install build-essential\n```\n该命令的作用是批量安装编译所需要的软件包，会自动安装一下软件包：autoconf automake bison byacc cscope ctags diffstat doxygen flex gcc gcc-c++ gcc-gfortran git indent intltool libtool patchutils rcs redhat-rpm-config rpm-build subversion swig systemtap，同时安装了以下依赖包：apr, apr-util, 等等。\n\n\n##安装JDK\n\n###方法1：安装OpenJDK\n\n``` bash\nsudo apt-get install openjdk-7-jdk\n#检测一下\n$ java -version\n```\n\n如果机器上已经安装了OpenJDK6，可以升级到OpenJDK7，\n\n###升级OpenJDK, OpenJDK6-->OpenJDK7\n\n``` bash\n#查看已安装的JDK，是 java 6\n$ update-java-alternatives -l\njava-1.6.0-openjdk-amd64 1061 /usr/lib/jvm/java-1.6.0-openjdk-amd64\n#先安装OpenJDK7\n$ sudo apt-get install openjdk-7-jdk\n#现在有两个JDK了\n$ update-java-alternatives -l\njava-1.6.0-openjdk-amd64 1061 /usr/lib/jvm/java-1.6.0-openjdk-amd64\njava-1.7.0-openjdk-amd64 1051 /usr/lib/jvm/java-1.7.0-openjdk-amd64\n#设置OpenJDK为默认\n$ sudo apt-get install icedtea-7-plugin\n$ sudo update-java-alternatives -s java-1.7.0-openjdk-amd64\n#检测一下\n$ java -version\n#删除OpenJDK6\n$ sudo apt-get remove openjdk-6-jdk\n#现在只有一个JDK了\n$ update-java-alternatives -l\njava-1.6.0-openjdk-amd64 1061 /usr/lib/jvm/java-1.6.0-openjdk-amd64\njava-1.7.0-openjdk-amd64 1051 /usr/lib/jvm/java-1.7.0-openjdk-amd64\n为什么还是有两个？\n```\n\n\n###方法2：安装Oracal JDK\nOracal JDK是有专利的，所以Ubuntu的官方源没有Oracal JDK，只能去官方下载并安装。\n\n``` bash\n#从官网下载JDK, 当前最新版是 jdk-8u5-linux-x64.tar.gz\n#开始安装\nchmod u+x chmod u+x jdk-6u32-linux-x64-rpm.bin\nsudo ./jdk-6u32-linux-x64-rpm.bin\n#设置环境变量，.bash_profile是当前用户，/etc/profile是所有用户的\nsudo vim /etc/profile\n#在末尾添加\nexport JAVA_HOME=/usr/java/default\nexport JRE_HOME=$JAVA_HOME/jre\nexport PATH=$PATH:$JAVA_HOME/bin\nexport CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar\n# 保存退出，输入以下命令使之立即生效：\nsource /etc/profile\n# 测试\njava -version\n```\n\n###方法二\n\n``` bash\nyum search jdk\n# java-1.6.0-openjdk只包含了JRE，如果在这台机器上开发java程序，则需要安装JDK，\n# 要选择 java-1.6.0-openjdk-devel，在服务器上我们只需要运行java程序，因此选择前者\nsudo yum install java-1.6.0-openjdk-devel\n# 使用 alternatives 工具设置默认JDK，参考：Installing a Java Development Kit on Red Hat Enterprise Linux\n/usr/sbin/alternatives --config java\n/usr/sbin/alternatives --config javac\n# 设置环境变量\n# 查询JDK路径\nwhereis java\nll /usr/bin/java\nll /etc/alternatives/java #这是可以看到JDK路径了\nsudo vim /etc/profile\n# 在末尾添加\nexport JAVA_HOME=/usr/lib/jvm/jre-1.6.0-openjdk.x86_64\nexport JRE_HOME=$JAVA_HOME/jre\nexport PATH=$PATH:$JAVA_HOME/bin\nexport CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar\n#保存退出，输入以下命令使之立即生效：\n# source /etc/profile\n# 测试\njava -version\n```\n\n##安装 apache\n\n###方法一\n源码在官网 http://httpd.apache.org/ 下载。  \n先下载apt, apr-util, pcre三个库，httpd 在编译时需要用到这三个库  \napr, apr-util官网 http://apr.apache.org , pcre官网为 [http://pcre.org ](http://pcre.org )\n\n``` bash\n# 编译，安装 apr\ntar -jxf apr-1.4.6.tar.bz2\ncd apr-1.4.6\n./configure\nmake\nsudo make install    # 默认会安装到 /usr/local/apr/\ncd ~\n#编译，安装 apr-util\ntar -jxf apr-util-1.4.1.tar.bz2\ncd apr-util-1.4.1\n./configure --with-apr=/usr/local/apr/\nmake\nsudo make install    # 默认会安装到 /usr/local/apr/\ncd ~\n#编译，安装 pcre\ntar -jxf pcre-8.30.tar.bz2\ncd  pcre-8.30\n./configure --with-apr=/usr/local/apr/\nmake\n# By default, `make install' installs the package's commands under\n#`/usr/local/bin', include files under `/usr/local/include', etc. \nsudo make install\ncd ~\n#编译，安装 apache\ntar -jxf httpd-2.2.22.tar.bz2\ncd httpd-2.2.22\n./configure\nmake\nsudo make install    # 默认会安装到/usr/local/apache2/\ncd ~\n#添加防火墙规则，让防火墙允许 apache的端口 80通过\nsudo vim /etc/sysconfig/iptables\n#添加如下一行（实际上是拷贝了原来的一行，仅仅改变了端口号），位置必须#要放在 含有 \"REJECT --reject-with\" 的行的前面\n-A INPUT -m state --state NEW -m tcp -p tcp --dport 80 -j ACCEPT\nsudo service iptables restart\n#测试\nsudo /usr/local/apache2/bin/apachectl start\n#在浏览器输入 http://ip地址 ，如果看到“It works”，说明安装成功\n/usr/local/apache2/bin/apachectl stop\n\n\n#设置为开机启动\n#将httpd注册为服务，通过chkconfig实现开机启动\n#以apachectl 为模板\nsudo cp /usr/local/apache2/bin/apachectl /etc/init.d/httpd\nsudo vim /etc/init.d/httpd\n# 在第一行 #!/bin/sh，添加如下一行，使其支持chkconfig命令\n# chkconfig: 2345 85 15\n# 保存，退出VIM编辑器\nsudo chmod u+x /etc/init.d/httpd\nsudo chkconfig --add httpd\nsudo chkconfig httpd on\n#检查一下，是否添加成功\nchkconfig --list httpd \n```\n\n###方法二\n\n``` bash\nsudo yum install httpd\n#可选？sudo yum install httpd-devel\n#测试\n#启动 apache http server\nsudo service httpd start\n#添加规则，让防火墙允许 apache的端口 80\nsudo vim /etc/sysconfig/iptables\n#添加如下一行，位置必须要放在 含有 \"REJECT --reject-with\" 的行的前面\n-A INPUT -m state --state NEW -m tcp -p tcp --dport 80 -j ACCEPT\nsudo service iptables restart\n#可以在浏览器输入 http://ip地址 测试了\n#设置为开机启动\nsudo chkconfig httpd on\n```\n\n##安装 mysql\n\n###方法一\n\n``` bash\n#去官网下载 Oracle & Red Hat 6的安装包，64位为MySQL-5.5.23-1.el6.x86_64.tar，\n#32位为 MySQL-5.5.23-1.el6.i686.tar\ntar -xf MySQL-5.5.23-1.el6.x86_64.tar\n#加 --force 是因为可能会与mysqllib库冲突\nsudo rpm -ivh --force  MySQL-server-5.5.23-1.el6.x86_64.rpm\nsudo rpm -ivh MySQL-client-5.5.23-1.el6.x86_64.rpm\n# 启动 mysql 服务器\nsudo service mysql start\n#设置为开机启动\nsudo chkconfig mysql on\n```\n\n###方法二\n\n``` bash\nsudo yum install mysql-server\nsudo chgrp -R mysql /var/lib/mysql\nsudo chmod -R 770 /var/lib/mysql\n# 启动 mysql 服务器\nsudo service mysqld start\n#设置为开机启动\nsudo chkconfig mysqld on\n```\n\n###公共的操作\n\n``` bash\n# root 初始密码为空，修改root密码\nmysql -u root\nmysql> use mysql;\nmysql> update user set password=password('root123') where user='root' AND host='localhost';\nmysql> flush privileges;\n# 打开MySQL中root账户的远程登录，参考：如何打开MySQL中root账户的远程登录mysql> GRANT ALL PRIVILEGES ON *.* TO root@\"%\" IDENTIFIED BY \"root\";\nmysql> update user set password=password('root123') where user='root' AND host='%';\nmysql> flush privileges;\nmysql> quit;\n#添加防火墙规则，让防火墙允许 mysql 的端口 3306通过\nsudo vim /etc/sysconfig/iptables\n#添加如下一行（实际上是拷贝了原来的一行，仅仅改变了端口号），位置必须#要放在 含有 \"REJECT --reject-with\" 的行的前面\n-A INPUT -m state --state NEW -m tcp -p tcp --dport 3306 -j ACCEPT\nsudo service iptables restart\n```\n\n##安装 php5\n\n###方法一\nTODO\n\n###方法二\n\n``` bash\nsudo yum install php php-pear\n#重启 apache，以确保apache 加载PHP模块\nsudo service httpd restart\n# 在 /var/www/html/下新建一个index.php文件，用于测试\ncd /var/www/html\nsudo vim index.php\n# 添加如下一行\n<?php phpinfo(); ?>\n# 在浏览器输入 http://xxx.xxx.xxx.xxx/index.php ，测试PHP是否成功安装\n\n# 如果需要在PHP中支持mysql，则需要安装 php-mysql 模块\nsudo yum install php-mysql\n# 如果需要在PHP中支持memcached，则需要安装 php-pecl-memcache 模块\nsudo yum install php-pecl-memcache\n#安装一些常用的PHP扩展模块\nsudo yum install php-devel php-gd php-mbstring php-xml\n\n#可以安装一个wordpress进行测试，注意要修改文件夹权限\nsudo chown -R apache.apache /var/www/html\n```\n\n## 安装 memcached\n\n###方法一\n\n``` bash\n# memcached依赖libevent，首先要安装 libevent\n# 去 http://libevent.org/ 下载libevent源码，然后编译，安装\ntar -zxf libevent-2.0.18-stable.tar.gz\ncd libevent-2.0.18-stable\n./configure\nmake\nsudo make install\n# 对于64位操作系统(32位不需要)，还需要配置：\nsudo ln -s /usr/local/lib/libevent-2.0.so.5 /usr/lib64//libevent-2.0.so.5\n# 去 http://www.memcached.org/ 下载 memcached，然后编译，安装\ntar -zxf memcached-1.4.13.tar.gz\ncd memcached-1.4.13\n./configure\nmake\nsudo make install\n# 启动, -p，端口,-m，内存, -u\nmemcached -p 11211 -m 512m -u root -d\n# 开机启动\n# centos设置开机启动有两种方式，一是把启动程序的命令添加到/etc/rc.d/rc.local文件中，二是把写好的启动脚本添加到目录/etc/rc.d/init.d/，然后使用命令chkconfig设置开机启动。第二种方式可以用 service xxx start|stop来启动或停止，所以推荐第二种。\n#将 memcached启动命令注册为一个服务\ncd /etc/init.d/\nsudo vim memcached\n#代码如下，参考：Linux中将memcached注册成服务并可以随机器启动时启动服务\n#chkconfig: 345 60 60\n#!/bin/bash\n\nstart()\n{\n        echo -n $\"Starting memcached: \"\n        /usr/local/bin/memcached -p 11211 -m 512m -u root -d\n        echo \"[OK]\"\n}\nstop()\n{\n        echo -n $\"Shutting down memcached: \"\n        memcached_pid_list=`pidof memcached` \n        kill -9 $memcached_pid_list\n        echo \"[OK]\"\n}\ncase \"$1\" in\n  start)\n        start\n        ;;\n  stop)\n        stop\n        ;;\n  restart)\n        stop\n        sleep 3\n        start\n        ;;\n    *)\n             echo $\"Usage: $0 {start|stop|restart}\"\n        exit 1\nesac\nexit 0\n#保存退出\nsudo chmod u+x memcached\nsudo chkconfig --add memcached\nsudo chkconfig  memcached on\n```\n\n###方法二\nTODO\n\n##安装 tomcat6\n\n###方法一\n\n``` bash\n# 去 http://tomcat.apache.org 下载 apache-tomcat-6.0.35.tar.gz\ntar -zxf apache-tomcat-6.0.35.tar.gz\nsudo mv apache-tomcat-6.0.35 /usr/local/\ncd /usr/local/apache-tomcat-6.0.35/bin\n#【可选】添加环境变量\nsudo vim /etc/profile\nexport CATALINA_HOME=/usr/local/apache-tomcat-6.0.35\n#启动 tomcat \nsudo ./startup.sh\n# 在浏览器输入 http://xxx.xxx.xxx.xxx:8080/ ，如果能看见tomcat页面，则表示安装成功了\n#设置开机启动\n#将 tomcat启动命令注册为一个服务\ncd /etc/init.d/\nsudo vim tomcatd\n#代码如下\n#chkconfig: 345 60 60\n#!/bin/bash\nCATALINA_HOME=/usr/local/apache-tomcat-6.0.35\n\nstart()\n{\n        echo -n $\"Starting Tomcat: \"\n        $CATALINA_HOME/bin/startup.sh\n        echo \"[OK]\"\n}\nstop()\n{\n        echo -n $\"Shutting down Tomcat: \"\n        $CATALINA_HOME/bin/shutdown.sh\n        echo \"[OK]\"\n}\ncase \"$1\" in\n  start)\n        start\n        ;;\n  stop)\n        stop\n        ;;\n  restart)\n        stop\n        sleep 3\n        start\n        ;;\n    *)\n             echo $\"Usage: $0 {start|stop|restart}\"\n        exit 1\nesac\nexit 0\n#保存退出\nsudo chmod u+x tomcatd\nsudo chkconfig --add tomcatd\nsudo chkconfig tomcatd on\n\n#添加防火墙规则，让防火墙允许 tomcat 的端口 8080 通过\nsudo vim /etc/sysconfig/iptables\n#添加如下一行（实际上是拷贝了原来的一行，仅仅改变了端口号），位置必须#要放在 含有 \"REJECT --reject-with\" 的行的前面\n-A INPUT -m state --state NEW -m tcp -p tcp --dport 8080 -j ACCEPT\nsudo service iptables restart\n```\n\n###方法二\n\n``` bash\n#搜索一下 tomcat包的名字\nyum search tomcat\nsudo yum search tomcat6.noarch\n```\n\n##安装Python\n\n###方法一：去[官网](http://www.python.org)下载源码，编译，安装\n\n``` bash\n#开始解压，编译，安装\ntar -jxf Python-3.2.3.tar.bz2\ncd Python-3.2.3\n# 查看一下说明, vim README\nsudo yum install zlib-devel bzip2-devel openssl-devel ncurses-devel sqlite-devel readline-devel tk-devel\n./configure\nmake\n#为了加快安装速度，这步可以省略\nmake test\n#卸载旧的python，注意，不能用 yum remove python，这会卸载几百个包，最终损坏系统\nsudo rpm -evf --nodeps python\nsudo make install\n#默认安装在 /usr/local/bin/python3\n```\n\n###方法二\n\n``` bash\nsudo yum install python\n```\n\n##安装ruby\n\n###方法一\n\n``` bash\n# http://www.ruby-lang.org/en/downloads/ ，选择 \"Stable Snapshot\"\ntar -zxf ruby-1.9-stable.tar.gz\ncd  cd ruby-1.9.3-p194/\n./configure\nmake\nsudo make install\n```\n\n###方法二\n\n``` bash\nsudo yum install ruby\n```\n\n##安装go\n\n``` bash\n#去官网 http://code.google.com/p/go/downloads 下载，go1.0.1.linux-i386.tar.gz (32位)，go1.0.1.linux-amd64.tar.gz（64位）\ntar -zxf go1.0.1.linux-amd64.tar.gz\nsudo mv go/ /usr/local/\n#设置环境变量\nsudo vim /etc/profile\nexport GOROOT=/usr/local/go\nexport PATH=$PATH:$GOROOT/bin\nsource /etc/profile\n#测试一下\ngo version\n```\n\n##安装lua\n\n``` bash\n# 去官网下载源码，编译，安装。由于官网仅提供源码，故推荐源码编译安装方式。\n# 去官网 http://www.lua.org/ 下载源码，lua-5.2.0.tar.gz\ntar -zxf lua-5.2.0.tar.gz \ncd lua-5.2.0\n# lua 依赖 readline.h 头文件\nsudo yum install  readline-devel\nmake linux\nsudo make install\n#安装 google protobuf\n#去官网 http://code.google.com/p/protobuf/下载\ntar -jxf protobuf-2.4.1.tar.bz2\ncd protobuf-2.4.1\n./configure\nmake\nsudo make install\n#测试\nprotoc\n```\n\n##清理安装包\n\n``` bash\ncd ~\nrm * -rf\n```\n\n##压缩打包\n安装完后，可以Clone，压缩打包成一个zip文件，方便分享给别人。\n\n在关机之前，有一件事需要做，\n\n\tsudo vim /etc/sysconfig/network-scripts/ifcfg-eth0, 把HWADDR=.... 这行删掉\n\tsudo rm /etc/udev/rules.d/70-persistent-net.rules\n\tsudo shutdown -h now\n\n如果没有执行上述命令，克隆后的虚拟机，开机后无法上网，重启网络，`sudo service network restart`也没有效果，会出现错误“Device eth0 does not seem to be present, delaying initialization.” \n\n这是因为克隆后的虚拟机，它的MAC地址变了，即在它的.vmx文件里，MAC地址变了（`ethernet0.generatedAddress`这项），但是linux不知道这个变化，网络配置文件还是旧的，这样跟它的而真实mac不匹配，网络就无法启动。\n\n执行上述命令，删除了`70-persistent-net.rules`后，相当于删除了旧的配置文件，在开机时会生成新的配置文件。\n\n关机后，右击标签，选择\"Manage->Clone\"，选择\"Create a full clone\"，克隆完成后，关闭这台虚拟机的标签（否则文件夹里有一些临时垃圾文件），然后把文件夹压缩打包。以后就可以把这个zip包拷贝给周围的人，别人就不用经历一遍重装的过程了。\n\n\n##参考资料\n1. [Is there a way to update all Java related alternatives?](http://askubuntu.com/questions/141791/is-there-a-way-to-update-all-java-related-alternatives)\n\n[CentOS - Installing Apache and PHP5](http://articles.slicehost.com/2008/2/6/centos-installing-apache-and-php5)\n\n[Setting up a LAMP stack](http://fedorasolved.org/server-solutions/lamp-stack)\n\n[CentOS5.5使用yum来安装LAMP](http://myohmy.blog.51cto.com/140917/327310)\n\n[Install Java JDK on CentOS without prompts using an automated script!](http://it.megocollector.com/?p=1719)","source":"_posts/2014-04-17-install-and-configure-a-ubuntu-server-from-scratch.md","raw":"---\nlayout: post\ntitle: \"安装和配置Ubuntu服务器的详细步骤\"\ndate: 2014-04-17 22:05\ncomments: true\ncategories: DevOps\npublished: false\n---\n\n这是我安装Ubuntu服务器的过程，记录下来，与大家一起分享。CentOS请见[安装和配置CentOS服务器的详细步骤](http://cn.soulmachine.me/blog/20120423/)。\n\n##安装操作系统\nubuntu-12.04.4-desktop-amd64.iso\n\n安装 CentOS时，选择 \"Basic Server\"  \nroot密码：root123  \nCentOS 自带了ssh  \n \n安装完操作系统后，添加一个用户 manong\n\n``` bash\n[root@localhost ~]$ useradd manong\n\n```\n然后密码设为 manong123\n\n``` bash\n[root@localhost ~]$ passwd manong\n```\n\n给予 sudo 权限\n\n``` bash\n[root@localhost ~]$ chmod u+w /etc/sudoers\n[root@localhost ~]$ vim /etc/sudoers\n# 在root ALL=(ALL) ALL 下 添加manong ALL=(ALL) ALL\n[root@localhost ~]$ chmod u-w /etc/sudoers \n```\n\n##设置上网\n安装完操作系统后，还不能上网，配置DHCP方式上网：\n\n``` bash\nvim /etc/sysconfig/network-scripts/ifcfg-eth0\nDEVICE=\"eth0\"\nHWADDR=\"00:0C:29:BD:E1:19\"\nNM_CONTROLLED=\"yes\"\nONBOOT=\"yes\"\nBOOTPROTO=dhcp\nUSECTL=no\nTYPE=Ethernet\nPEERDNS=yes\n#保存退出\nsudo service network restart\n```\n\n<!-- more -->\n\n或者，配置静态IP\n\n``` bash\nDEVICE=\"eth0\"\nHWADDR=\"00:0C:29:10:F4:4C\"\nONBOOT=\"yes\"\nBOOTPROTO=static\nTYPE=Ethernet\nIPADDR=192.168.0.162\nNETMASK=255.255.255.0\nBROADCAST=192.168.0.255\nNETWORK=192.168.0.0\n#保存退出  \n#修改/etc/sysconfig/network\nsudo vim /etc/sysconfig/network\nNETWORKING=yes\nHOSTNAME=localhost.localdomain\nGATEWAY=192.168.0.1\n#保存退出，重启网络\nsudo service network restart\n```\n如果失败，比如IP已被占用，换一个IP试试\n\n修改DNS，即时生效\n\n``` bash\nsudo vim /etc/resolv.conf\nnameserver 192.168.0.1\n# google提供的域名服务器\nnameserver 8.8.8.8\nsearch localhost\n```\n\n##安装常用软件\n有两种方式，方法一，去官网下载已经编译好的二进制文件，或源代码，编译安装\n方法二，用`apt-get`命令安装，安装官方源里已经编译好的程序包。  \n第一种方式要敲很多命令，比yum麻烦，但是可以预先下载好文件，省略了下载的时间，批量给很多服务器安装时，可以节省很多流量，速度比yum安装方式快很多，而且可以安装最新版。\n\n第二种方式操作简单，敲打的命令少，但是往往官方源的更新速度跟不上各个软件的官网速度，用apt安装的版本经常比较旧。但是这种方式安装简单，更新也简单，推荐第这种方式。\n\n`apt`的命令形式一般是如下：`apt [options] [command] [package ...]`，其中的[options]是可选的，选项包括-h（帮助），-y（当安装过程提示选择全部为\"yes\"），-q（不显示安装的过程）等等。[command]为所要进行的操作，[package ...]是操作的对象。\n\n``` bash\n#apt-cache search package-name # 在线搜索包 \n#apt-get list installed # 列出所有已经安装的包\n#\n#sudo apt-get install package-name # 安装程序包 \n#sudo yum groupinsall group-name 安装程序组\n#\n#sudo yum remove package-name 删除程序包\n#sudo yum groupremove group-name 删除程序组\n#\n#yum update #全部更新\n#yum update package-name #更新程序包\n#sudo yum groupupdate groupn-name 升级程序组\n#sudo yum upgrade # 更新源列表\n#yum upgrade package-name #升级程序包\n#sudo yum clean all # 清除缓存\n#更新\nsudo yum update\n#清理缓存\nsudo yum clean all && yum clean metadata && yum clean dbcache\n```\n\n##安装GCC\n\n###方法一 编译源码安装\n去 http://gcc.gnu.org/ 下载源码\n\n``` bash\n# TODO\n```\n\n###方法二 apt安装\n\n``` bash\nsudo apt-get install build-essential\n```\n该命令的作用是批量安装编译所需要的软件包，会自动安装一下软件包：autoconf automake bison byacc cscope ctags diffstat doxygen flex gcc gcc-c++ gcc-gfortran git indent intltool libtool patchutils rcs redhat-rpm-config rpm-build subversion swig systemtap，同时安装了以下依赖包：apr, apr-util, 等等。\n\n\n##安装JDK\n\n###方法1：安装OpenJDK\n\n``` bash\nsudo apt-get install openjdk-7-jdk\n#检测一下\n$ java -version\n```\n\n如果机器上已经安装了OpenJDK6，可以升级到OpenJDK7，\n\n###升级OpenJDK, OpenJDK6-->OpenJDK7\n\n``` bash\n#查看已安装的JDK，是 java 6\n$ update-java-alternatives -l\njava-1.6.0-openjdk-amd64 1061 /usr/lib/jvm/java-1.6.0-openjdk-amd64\n#先安装OpenJDK7\n$ sudo apt-get install openjdk-7-jdk\n#现在有两个JDK了\n$ update-java-alternatives -l\njava-1.6.0-openjdk-amd64 1061 /usr/lib/jvm/java-1.6.0-openjdk-amd64\njava-1.7.0-openjdk-amd64 1051 /usr/lib/jvm/java-1.7.0-openjdk-amd64\n#设置OpenJDK为默认\n$ sudo apt-get install icedtea-7-plugin\n$ sudo update-java-alternatives -s java-1.7.0-openjdk-amd64\n#检测一下\n$ java -version\n#删除OpenJDK6\n$ sudo apt-get remove openjdk-6-jdk\n#现在只有一个JDK了\n$ update-java-alternatives -l\njava-1.6.0-openjdk-amd64 1061 /usr/lib/jvm/java-1.6.0-openjdk-amd64\njava-1.7.0-openjdk-amd64 1051 /usr/lib/jvm/java-1.7.0-openjdk-amd64\n为什么还是有两个？\n```\n\n\n###方法2：安装Oracal JDK\nOracal JDK是有专利的，所以Ubuntu的官方源没有Oracal JDK，只能去官方下载并安装。\n\n``` bash\n#从官网下载JDK, 当前最新版是 jdk-8u5-linux-x64.tar.gz\n#开始安装\nchmod u+x chmod u+x jdk-6u32-linux-x64-rpm.bin\nsudo ./jdk-6u32-linux-x64-rpm.bin\n#设置环境变量，.bash_profile是当前用户，/etc/profile是所有用户的\nsudo vim /etc/profile\n#在末尾添加\nexport JAVA_HOME=/usr/java/default\nexport JRE_HOME=$JAVA_HOME/jre\nexport PATH=$PATH:$JAVA_HOME/bin\nexport CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar\n# 保存退出，输入以下命令使之立即生效：\nsource /etc/profile\n# 测试\njava -version\n```\n\n###方法二\n\n``` bash\nyum search jdk\n# java-1.6.0-openjdk只包含了JRE，如果在这台机器上开发java程序，则需要安装JDK，\n# 要选择 java-1.6.0-openjdk-devel，在服务器上我们只需要运行java程序，因此选择前者\nsudo yum install java-1.6.0-openjdk-devel\n# 使用 alternatives 工具设置默认JDK，参考：Installing a Java Development Kit on Red Hat Enterprise Linux\n/usr/sbin/alternatives --config java\n/usr/sbin/alternatives --config javac\n# 设置环境变量\n# 查询JDK路径\nwhereis java\nll /usr/bin/java\nll /etc/alternatives/java #这是可以看到JDK路径了\nsudo vim /etc/profile\n# 在末尾添加\nexport JAVA_HOME=/usr/lib/jvm/jre-1.6.0-openjdk.x86_64\nexport JRE_HOME=$JAVA_HOME/jre\nexport PATH=$PATH:$JAVA_HOME/bin\nexport CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar\n#保存退出，输入以下命令使之立即生效：\n# source /etc/profile\n# 测试\njava -version\n```\n\n##安装 apache\n\n###方法一\n源码在官网 http://httpd.apache.org/ 下载。  \n先下载apt, apr-util, pcre三个库，httpd 在编译时需要用到这三个库  \napr, apr-util官网 http://apr.apache.org , pcre官网为 [http://pcre.org ](http://pcre.org )\n\n``` bash\n# 编译，安装 apr\ntar -jxf apr-1.4.6.tar.bz2\ncd apr-1.4.6\n./configure\nmake\nsudo make install    # 默认会安装到 /usr/local/apr/\ncd ~\n#编译，安装 apr-util\ntar -jxf apr-util-1.4.1.tar.bz2\ncd apr-util-1.4.1\n./configure --with-apr=/usr/local/apr/\nmake\nsudo make install    # 默认会安装到 /usr/local/apr/\ncd ~\n#编译，安装 pcre\ntar -jxf pcre-8.30.tar.bz2\ncd  pcre-8.30\n./configure --with-apr=/usr/local/apr/\nmake\n# By default, `make install' installs the package's commands under\n#`/usr/local/bin', include files under `/usr/local/include', etc. \nsudo make install\ncd ~\n#编译，安装 apache\ntar -jxf httpd-2.2.22.tar.bz2\ncd httpd-2.2.22\n./configure\nmake\nsudo make install    # 默认会安装到/usr/local/apache2/\ncd ~\n#添加防火墙规则，让防火墙允许 apache的端口 80通过\nsudo vim /etc/sysconfig/iptables\n#添加如下一行（实际上是拷贝了原来的一行，仅仅改变了端口号），位置必须#要放在 含有 \"REJECT --reject-with\" 的行的前面\n-A INPUT -m state --state NEW -m tcp -p tcp --dport 80 -j ACCEPT\nsudo service iptables restart\n#测试\nsudo /usr/local/apache2/bin/apachectl start\n#在浏览器输入 http://ip地址 ，如果看到“It works”，说明安装成功\n/usr/local/apache2/bin/apachectl stop\n\n\n#设置为开机启动\n#将httpd注册为服务，通过chkconfig实现开机启动\n#以apachectl 为模板\nsudo cp /usr/local/apache2/bin/apachectl /etc/init.d/httpd\nsudo vim /etc/init.d/httpd\n# 在第一行 #!/bin/sh，添加如下一行，使其支持chkconfig命令\n# chkconfig: 2345 85 15\n# 保存，退出VIM编辑器\nsudo chmod u+x /etc/init.d/httpd\nsudo chkconfig --add httpd\nsudo chkconfig httpd on\n#检查一下，是否添加成功\nchkconfig --list httpd \n```\n\n###方法二\n\n``` bash\nsudo yum install httpd\n#可选？sudo yum install httpd-devel\n#测试\n#启动 apache http server\nsudo service httpd start\n#添加规则，让防火墙允许 apache的端口 80\nsudo vim /etc/sysconfig/iptables\n#添加如下一行，位置必须要放在 含有 \"REJECT --reject-with\" 的行的前面\n-A INPUT -m state --state NEW -m tcp -p tcp --dport 80 -j ACCEPT\nsudo service iptables restart\n#可以在浏览器输入 http://ip地址 测试了\n#设置为开机启动\nsudo chkconfig httpd on\n```\n\n##安装 mysql\n\n###方法一\n\n``` bash\n#去官网下载 Oracle & Red Hat 6的安装包，64位为MySQL-5.5.23-1.el6.x86_64.tar，\n#32位为 MySQL-5.5.23-1.el6.i686.tar\ntar -xf MySQL-5.5.23-1.el6.x86_64.tar\n#加 --force 是因为可能会与mysqllib库冲突\nsudo rpm -ivh --force  MySQL-server-5.5.23-1.el6.x86_64.rpm\nsudo rpm -ivh MySQL-client-5.5.23-1.el6.x86_64.rpm\n# 启动 mysql 服务器\nsudo service mysql start\n#设置为开机启动\nsudo chkconfig mysql on\n```\n\n###方法二\n\n``` bash\nsudo yum install mysql-server\nsudo chgrp -R mysql /var/lib/mysql\nsudo chmod -R 770 /var/lib/mysql\n# 启动 mysql 服务器\nsudo service mysqld start\n#设置为开机启动\nsudo chkconfig mysqld on\n```\n\n###公共的操作\n\n``` bash\n# root 初始密码为空，修改root密码\nmysql -u root\nmysql> use mysql;\nmysql> update user set password=password('root123') where user='root' AND host='localhost';\nmysql> flush privileges;\n# 打开MySQL中root账户的远程登录，参考：如何打开MySQL中root账户的远程登录mysql> GRANT ALL PRIVILEGES ON *.* TO root@\"%\" IDENTIFIED BY \"root\";\nmysql> update user set password=password('root123') where user='root' AND host='%';\nmysql> flush privileges;\nmysql> quit;\n#添加防火墙规则，让防火墙允许 mysql 的端口 3306通过\nsudo vim /etc/sysconfig/iptables\n#添加如下一行（实际上是拷贝了原来的一行，仅仅改变了端口号），位置必须#要放在 含有 \"REJECT --reject-with\" 的行的前面\n-A INPUT -m state --state NEW -m tcp -p tcp --dport 3306 -j ACCEPT\nsudo service iptables restart\n```\n\n##安装 php5\n\n###方法一\nTODO\n\n###方法二\n\n``` bash\nsudo yum install php php-pear\n#重启 apache，以确保apache 加载PHP模块\nsudo service httpd restart\n# 在 /var/www/html/下新建一个index.php文件，用于测试\ncd /var/www/html\nsudo vim index.php\n# 添加如下一行\n<?php phpinfo(); ?>\n# 在浏览器输入 http://xxx.xxx.xxx.xxx/index.php ，测试PHP是否成功安装\n\n# 如果需要在PHP中支持mysql，则需要安装 php-mysql 模块\nsudo yum install php-mysql\n# 如果需要在PHP中支持memcached，则需要安装 php-pecl-memcache 模块\nsudo yum install php-pecl-memcache\n#安装一些常用的PHP扩展模块\nsudo yum install php-devel php-gd php-mbstring php-xml\n\n#可以安装一个wordpress进行测试，注意要修改文件夹权限\nsudo chown -R apache.apache /var/www/html\n```\n\n## 安装 memcached\n\n###方法一\n\n``` bash\n# memcached依赖libevent，首先要安装 libevent\n# 去 http://libevent.org/ 下载libevent源码，然后编译，安装\ntar -zxf libevent-2.0.18-stable.tar.gz\ncd libevent-2.0.18-stable\n./configure\nmake\nsudo make install\n# 对于64位操作系统(32位不需要)，还需要配置：\nsudo ln -s /usr/local/lib/libevent-2.0.so.5 /usr/lib64//libevent-2.0.so.5\n# 去 http://www.memcached.org/ 下载 memcached，然后编译，安装\ntar -zxf memcached-1.4.13.tar.gz\ncd memcached-1.4.13\n./configure\nmake\nsudo make install\n# 启动, -p，端口,-m，内存, -u\nmemcached -p 11211 -m 512m -u root -d\n# 开机启动\n# centos设置开机启动有两种方式，一是把启动程序的命令添加到/etc/rc.d/rc.local文件中，二是把写好的启动脚本添加到目录/etc/rc.d/init.d/，然后使用命令chkconfig设置开机启动。第二种方式可以用 service xxx start|stop来启动或停止，所以推荐第二种。\n#将 memcached启动命令注册为一个服务\ncd /etc/init.d/\nsudo vim memcached\n#代码如下，参考：Linux中将memcached注册成服务并可以随机器启动时启动服务\n#chkconfig: 345 60 60\n#!/bin/bash\n\nstart()\n{\n        echo -n $\"Starting memcached: \"\n        /usr/local/bin/memcached -p 11211 -m 512m -u root -d\n        echo \"[OK]\"\n}\nstop()\n{\n        echo -n $\"Shutting down memcached: \"\n        memcached_pid_list=`pidof memcached` \n        kill -9 $memcached_pid_list\n        echo \"[OK]\"\n}\ncase \"$1\" in\n  start)\n        start\n        ;;\n  stop)\n        stop\n        ;;\n  restart)\n        stop\n        sleep 3\n        start\n        ;;\n    *)\n             echo $\"Usage: $0 {start|stop|restart}\"\n        exit 1\nesac\nexit 0\n#保存退出\nsudo chmod u+x memcached\nsudo chkconfig --add memcached\nsudo chkconfig  memcached on\n```\n\n###方法二\nTODO\n\n##安装 tomcat6\n\n###方法一\n\n``` bash\n# 去 http://tomcat.apache.org 下载 apache-tomcat-6.0.35.tar.gz\ntar -zxf apache-tomcat-6.0.35.tar.gz\nsudo mv apache-tomcat-6.0.35 /usr/local/\ncd /usr/local/apache-tomcat-6.0.35/bin\n#【可选】添加环境变量\nsudo vim /etc/profile\nexport CATALINA_HOME=/usr/local/apache-tomcat-6.0.35\n#启动 tomcat \nsudo ./startup.sh\n# 在浏览器输入 http://xxx.xxx.xxx.xxx:8080/ ，如果能看见tomcat页面，则表示安装成功了\n#设置开机启动\n#将 tomcat启动命令注册为一个服务\ncd /etc/init.d/\nsudo vim tomcatd\n#代码如下\n#chkconfig: 345 60 60\n#!/bin/bash\nCATALINA_HOME=/usr/local/apache-tomcat-6.0.35\n\nstart()\n{\n        echo -n $\"Starting Tomcat: \"\n        $CATALINA_HOME/bin/startup.sh\n        echo \"[OK]\"\n}\nstop()\n{\n        echo -n $\"Shutting down Tomcat: \"\n        $CATALINA_HOME/bin/shutdown.sh\n        echo \"[OK]\"\n}\ncase \"$1\" in\n  start)\n        start\n        ;;\n  stop)\n        stop\n        ;;\n  restart)\n        stop\n        sleep 3\n        start\n        ;;\n    *)\n             echo $\"Usage: $0 {start|stop|restart}\"\n        exit 1\nesac\nexit 0\n#保存退出\nsudo chmod u+x tomcatd\nsudo chkconfig --add tomcatd\nsudo chkconfig tomcatd on\n\n#添加防火墙规则，让防火墙允许 tomcat 的端口 8080 通过\nsudo vim /etc/sysconfig/iptables\n#添加如下一行（实际上是拷贝了原来的一行，仅仅改变了端口号），位置必须#要放在 含有 \"REJECT --reject-with\" 的行的前面\n-A INPUT -m state --state NEW -m tcp -p tcp --dport 8080 -j ACCEPT\nsudo service iptables restart\n```\n\n###方法二\n\n``` bash\n#搜索一下 tomcat包的名字\nyum search tomcat\nsudo yum search tomcat6.noarch\n```\n\n##安装Python\n\n###方法一：去[官网](http://www.python.org)下载源码，编译，安装\n\n``` bash\n#开始解压，编译，安装\ntar -jxf Python-3.2.3.tar.bz2\ncd Python-3.2.3\n# 查看一下说明, vim README\nsudo yum install zlib-devel bzip2-devel openssl-devel ncurses-devel sqlite-devel readline-devel tk-devel\n./configure\nmake\n#为了加快安装速度，这步可以省略\nmake test\n#卸载旧的python，注意，不能用 yum remove python，这会卸载几百个包，最终损坏系统\nsudo rpm -evf --nodeps python\nsudo make install\n#默认安装在 /usr/local/bin/python3\n```\n\n###方法二\n\n``` bash\nsudo yum install python\n```\n\n##安装ruby\n\n###方法一\n\n``` bash\n# http://www.ruby-lang.org/en/downloads/ ，选择 \"Stable Snapshot\"\ntar -zxf ruby-1.9-stable.tar.gz\ncd  cd ruby-1.9.3-p194/\n./configure\nmake\nsudo make install\n```\n\n###方法二\n\n``` bash\nsudo yum install ruby\n```\n\n##安装go\n\n``` bash\n#去官网 http://code.google.com/p/go/downloads 下载，go1.0.1.linux-i386.tar.gz (32位)，go1.0.1.linux-amd64.tar.gz（64位）\ntar -zxf go1.0.1.linux-amd64.tar.gz\nsudo mv go/ /usr/local/\n#设置环境变量\nsudo vim /etc/profile\nexport GOROOT=/usr/local/go\nexport PATH=$PATH:$GOROOT/bin\nsource /etc/profile\n#测试一下\ngo version\n```\n\n##安装lua\n\n``` bash\n# 去官网下载源码，编译，安装。由于官网仅提供源码，故推荐源码编译安装方式。\n# 去官网 http://www.lua.org/ 下载源码，lua-5.2.0.tar.gz\ntar -zxf lua-5.2.0.tar.gz \ncd lua-5.2.0\n# lua 依赖 readline.h 头文件\nsudo yum install  readline-devel\nmake linux\nsudo make install\n#安装 google protobuf\n#去官网 http://code.google.com/p/protobuf/下载\ntar -jxf protobuf-2.4.1.tar.bz2\ncd protobuf-2.4.1\n./configure\nmake\nsudo make install\n#测试\nprotoc\n```\n\n##清理安装包\n\n``` bash\ncd ~\nrm * -rf\n```\n\n##压缩打包\n安装完后，可以Clone，压缩打包成一个zip文件，方便分享给别人。\n\n在关机之前，有一件事需要做，\n\n\tsudo vim /etc/sysconfig/network-scripts/ifcfg-eth0, 把HWADDR=.... 这行删掉\n\tsudo rm /etc/udev/rules.d/70-persistent-net.rules\n\tsudo shutdown -h now\n\n如果没有执行上述命令，克隆后的虚拟机，开机后无法上网，重启网络，`sudo service network restart`也没有效果，会出现错误“Device eth0 does not seem to be present, delaying initialization.” \n\n这是因为克隆后的虚拟机，它的MAC地址变了，即在它的.vmx文件里，MAC地址变了（`ethernet0.generatedAddress`这项），但是linux不知道这个变化，网络配置文件还是旧的，这样跟它的而真实mac不匹配，网络就无法启动。\n\n执行上述命令，删除了`70-persistent-net.rules`后，相当于删除了旧的配置文件，在开机时会生成新的配置文件。\n\n关机后，右击标签，选择\"Manage->Clone\"，选择\"Create a full clone\"，克隆完成后，关闭这台虚拟机的标签（否则文件夹里有一些临时垃圾文件），然后把文件夹压缩打包。以后就可以把这个zip包拷贝给周围的人，别人就不用经历一遍重装的过程了。\n\n\n##参考资料\n1. [Is there a way to update all Java related alternatives?](http://askubuntu.com/questions/141791/is-there-a-way-to-update-all-java-related-alternatives)\n\n[CentOS - Installing Apache and PHP5](http://articles.slicehost.com/2008/2/6/centos-installing-apache-and-php5)\n\n[Setting up a LAMP stack](http://fedorasolved.org/server-solutions/lamp-stack)\n\n[CentOS5.5使用yum来安装LAMP](http://myohmy.blog.51cto.com/140917/327310)\n\n[Install Java JDK on CentOS without prompts using an automated script!](http://it.megocollector.com/?p=1719)","slug":"2014-04-17-install-and-configure-a-ubuntu-server-from-scratch","updated":"2016-08-18T09:21:04.000Z","photos":[],"link":"","_id":"cis07pf4u004101pqaibf01sc","content":"<p>这是我安装Ubuntu服务器的过程，记录下来，与大家一起分享。CentOS请见<a href=\"http://cn.soulmachine.me/blog/20120423/\">安装和配置CentOS服务器的详细步骤</a>。</p>\n<p>##安装操作系统<br>ubuntu-12.04.4-desktop-amd64.iso</p>\n<p>安装 CentOS时，选择 “Basic Server”<br>root密码：root123<br>CentOS 自带了ssh  </p>\n<p>安装完操作系统后，添加一个用户 manong</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">[root@localhost ~]$ useradd manong</div></pre></td></tr></table></figure>\n<p>然后密码设为 manong123</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">[root@localhost ~]$ passwd manong</div></pre></td></tr></table></figure>\n<p>给予 sudo 权限</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\">[root@localhost ~]$ chmod u+w /etc/sudoers</div><div class=\"line\">[root@localhost ~]$ vim /etc/sudoers</div><div class=\"line\"><span class=\"comment\"># 在root ALL=(ALL) ALL 下 添加manong ALL=(ALL) ALL</span></div><div class=\"line\">[root@localhost ~]$ chmod u-w /etc/sudoers</div></pre></td></tr></table></figure>\n<p>##设置上网<br>安装完操作系统后，还不能上网，配置DHCP方式上网：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div></pre></td><td class=\"code\"><pre><div class=\"line\">vim /etc/sysconfig/network-scripts/ifcfg-eth0</div><div class=\"line\">DEVICE=<span class=\"string\">\"eth0\"</span></div><div class=\"line\">HWADDR=<span class=\"string\">\"00:0C:29:BD:E1:19\"</span></div><div class=\"line\">NM_CONTROLLED=<span class=\"string\">\"yes\"</span></div><div class=\"line\">ONBOOT=<span class=\"string\">\"yes\"</span></div><div class=\"line\">BOOTPROTO=dhcp</div><div class=\"line\">USECTL=no</div><div class=\"line\">TYPE=Ethernet</div><div class=\"line\">PEERDNS=yes</div><div class=\"line\"><span class=\"comment\">#保存退出</span></div><div class=\"line\">sudo service network restart</div></pre></td></tr></table></figure>\n<a id=\"more\"></a>\n<p>或者，配置静态IP</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div></pre></td><td class=\"code\"><pre><div class=\"line\">DEVICE=<span class=\"string\">\"eth0\"</span></div><div class=\"line\">HWADDR=<span class=\"string\">\"00:0C:29:10:F4:4C\"</span></div><div class=\"line\">ONBOOT=<span class=\"string\">\"yes\"</span></div><div class=\"line\">BOOTPROTO=static</div><div class=\"line\">TYPE=Ethernet</div><div class=\"line\">IPADDR=192.168.0.162</div><div class=\"line\">NETMASK=255.255.255.0</div><div class=\"line\">BROADCAST=192.168.0.255</div><div class=\"line\">NETWORK=192.168.0.0</div><div class=\"line\"><span class=\"comment\">#保存退出  </span></div><div class=\"line\"><span class=\"comment\">#修改/etc/sysconfig/network</span></div><div class=\"line\">sudo vim /etc/sysconfig/network</div><div class=\"line\">NETWORKING=yes</div><div class=\"line\">HOSTNAME=localhost.localdomain</div><div class=\"line\">GATEWAY=192.168.0.1</div><div class=\"line\"><span class=\"comment\">#保存退出，重启网络</span></div><div class=\"line\">sudo service network restart</div></pre></td></tr></table></figure>\n<p>如果失败，比如IP已被占用，换一个IP试试</p>\n<p>修改DNS，即时生效</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\">sudo vim /etc/resolv.conf</div><div class=\"line\">nameserver 192.168.0.1</div><div class=\"line\"><span class=\"comment\"># google提供的域名服务器</span></div><div class=\"line\">nameserver 8.8.8.8</div><div class=\"line\">search localhost</div></pre></td></tr></table></figure>\n<p>##安装常用软件<br>有两种方式，方法一，去官网下载已经编译好的二进制文件，或源代码，编译安装<br>方法二，用<code>apt-get</code>命令安装，安装官方源里已经编译好的程序包。<br>第一种方式要敲很多命令，比yum麻烦，但是可以预先下载好文件，省略了下载的时间，批量给很多服务器安装时，可以节省很多流量，速度比yum安装方式快很多，而且可以安装最新版。</p>\n<p>第二种方式操作简单，敲打的命令少，但是往往官方源的更新速度跟不上各个软件的官网速度，用apt安装的版本经常比较旧。但是这种方式安装简单，更新也简单，推荐第这种方式。</p>\n<p><code>apt</code>的命令形式一般是如下：<code>apt [options] [command] [package ...]</code>，其中的[options]是可选的，选项包括-h（帮助），-y（当安装过程提示选择全部为”yes”），-q（不显示安装的过程）等等。[command]为所要进行的操作，[package …]是操作的对象。</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">#apt-cache search package-name # 在线搜索包 </span></div><div class=\"line\"><span class=\"comment\">#apt-get list installed # 列出所有已经安装的包</span></div><div class=\"line\"><span class=\"comment\">#</span></div><div class=\"line\"><span class=\"comment\">#sudo apt-get install package-name # 安装程序包 </span></div><div class=\"line\"><span class=\"comment\">#sudo yum groupinsall group-name 安装程序组</span></div><div class=\"line\"><span class=\"comment\">#</span></div><div class=\"line\"><span class=\"comment\">#sudo yum remove package-name 删除程序包</span></div><div class=\"line\"><span class=\"comment\">#sudo yum groupremove group-name 删除程序组</span></div><div class=\"line\"><span class=\"comment\">#</span></div><div class=\"line\"><span class=\"comment\">#yum update #全部更新</span></div><div class=\"line\"><span class=\"comment\">#yum update package-name #更新程序包</span></div><div class=\"line\"><span class=\"comment\">#sudo yum groupupdate groupn-name 升级程序组</span></div><div class=\"line\"><span class=\"comment\">#sudo yum upgrade # 更新源列表</span></div><div class=\"line\"><span class=\"comment\">#yum upgrade package-name #升级程序包</span></div><div class=\"line\"><span class=\"comment\">#sudo yum clean all # 清除缓存</span></div><div class=\"line\"><span class=\"comment\">#更新</span></div><div class=\"line\">sudo yum update</div><div class=\"line\"><span class=\"comment\">#清理缓存</span></div><div class=\"line\">sudo yum clean all &amp;&amp; yum clean metadata &amp;&amp; yum clean dbcache</div></pre></td></tr></table></figure>\n<p>##安装GCC</p>\n<p>###方法一 编译源码安装<br>去 <a href=\"http://gcc.gnu.org/\" target=\"_blank\" rel=\"external\">http://gcc.gnu.org/</a> 下载源码</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># TODO</span></div></pre></td></tr></table></figure>\n<p>###方法二 apt安装</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">sudo apt-get install build-essential</div></pre></td></tr></table></figure>\n<p>该命令的作用是批量安装编译所需要的软件包，会自动安装一下软件包：autoconf automake bison byacc cscope ctags diffstat doxygen flex gcc gcc-c++ gcc-gfortran git indent intltool libtool patchutils rcs redhat-rpm-config rpm-build subversion swig systemtap，同时安装了以下依赖包：apr, apr-util, 等等。</p>\n<p>##安装JDK</p>\n<p>###方法1：安装OpenJDK</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">sudo apt-get install openjdk-7-jdk</div><div class=\"line\"><span class=\"comment\">#检测一下</span></div><div class=\"line\">$ java -version</div></pre></td></tr></table></figure>\n<p>如果机器上已经安装了OpenJDK6，可以升级到OpenJDK7，</p>\n<p>###升级OpenJDK, OpenJDK6–&gt;OpenJDK7</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">#查看已安装的JDK，是 java 6</span></div><div class=\"line\">$ update-java-alternatives <span class=\"_\">-l</span></div><div class=\"line\">java-1.6.0-openjdk-amd64 1061 /usr/lib/jvm/java-1.6.0-openjdk-amd64</div><div class=\"line\"><span class=\"comment\">#先安装OpenJDK7</span></div><div class=\"line\">$ sudo apt-get install openjdk-7-jdk</div><div class=\"line\"><span class=\"comment\">#现在有两个JDK了</span></div><div class=\"line\">$ update-java-alternatives <span class=\"_\">-l</span></div><div class=\"line\">java-1.6.0-openjdk-amd64 1061 /usr/lib/jvm/java-1.6.0-openjdk-amd64</div><div class=\"line\">java-1.7.0-openjdk-amd64 1051 /usr/lib/jvm/java-1.7.0-openjdk-amd64</div><div class=\"line\"><span class=\"comment\">#设置OpenJDK为默认</span></div><div class=\"line\">$ sudo apt-get install icedtea-7-plugin</div><div class=\"line\">$ sudo update-java-alternatives <span class=\"_\">-s</span> java-1.7.0-openjdk-amd64</div><div class=\"line\"><span class=\"comment\">#检测一下</span></div><div class=\"line\">$ java -version</div><div class=\"line\"><span class=\"comment\">#删除OpenJDK6</span></div><div class=\"line\">$ sudo apt-get remove openjdk-6-jdk</div><div class=\"line\"><span class=\"comment\">#现在只有一个JDK了</span></div><div class=\"line\">$ update-java-alternatives <span class=\"_\">-l</span></div><div class=\"line\">java-1.6.0-openjdk-amd64 1061 /usr/lib/jvm/java-1.6.0-openjdk-amd64</div><div class=\"line\">java-1.7.0-openjdk-amd64 1051 /usr/lib/jvm/java-1.7.0-openjdk-amd64</div><div class=\"line\">为什么还是有两个？</div></pre></td></tr></table></figure>\n<p>###方法2：安装Oracal JDK<br>Oracal JDK是有专利的，所以Ubuntu的官方源没有Oracal JDK，只能去官方下载并安装。</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">#从官网下载JDK, 当前最新版是 jdk-8u5-linux-x64.tar.gz</span></div><div class=\"line\"><span class=\"comment\">#开始安装</span></div><div class=\"line\">chmod u+x chmod u+x jdk-6u32-linux-x64-rpm.bin</div><div class=\"line\">sudo ./jdk-6u32-linux-x64-rpm.bin</div><div class=\"line\"><span class=\"comment\">#设置环境变量，.bash_profile是当前用户，/etc/profile是所有用户的</span></div><div class=\"line\">sudo vim /etc/profile</div><div class=\"line\"><span class=\"comment\">#在末尾添加</span></div><div class=\"line\"><span class=\"built_in\">export</span> JAVA_HOME=/usr/java/default</div><div class=\"line\"><span class=\"built_in\">export</span> JRE_HOME=<span class=\"variable\">$JAVA_HOME</span>/jre</div><div class=\"line\"><span class=\"built_in\">export</span> PATH=<span class=\"variable\">$PATH</span>:<span class=\"variable\">$JAVA_HOME</span>/bin</div><div class=\"line\"><span class=\"built_in\">export</span> CLASSPATH=.:<span class=\"variable\">$JAVA_HOME</span>/lib/dt.jar:<span class=\"variable\">$JAVA_HOME</span>/lib/tools.jar</div><div class=\"line\"><span class=\"comment\"># 保存退出，输入以下命令使之立即生效：</span></div><div class=\"line\"><span class=\"built_in\">source</span> /etc/profile</div><div class=\"line\"><span class=\"comment\"># 测试</span></div><div class=\"line\">java -version</div></pre></td></tr></table></figure>\n<p>###方法二</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div></pre></td><td class=\"code\"><pre><div class=\"line\">yum search jdk</div><div class=\"line\"><span class=\"comment\"># java-1.6.0-openjdk只包含了JRE，如果在这台机器上开发java程序，则需要安装JDK，</span></div><div class=\"line\"><span class=\"comment\"># 要选择 java-1.6.0-openjdk-devel，在服务器上我们只需要运行java程序，因此选择前者</span></div><div class=\"line\">sudo yum install java-1.6.0-openjdk-devel</div><div class=\"line\"><span class=\"comment\"># 使用 alternatives 工具设置默认JDK，参考：Installing a Java Development Kit on Red Hat Enterprise Linux</span></div><div class=\"line\">/usr/sbin/alternatives --config java</div><div class=\"line\">/usr/sbin/alternatives --config javac</div><div class=\"line\"><span class=\"comment\"># 设置环境变量</span></div><div class=\"line\"><span class=\"comment\"># 查询JDK路径</span></div><div class=\"line\">whereis java</div><div class=\"line\">ll /usr/bin/java</div><div class=\"line\">ll /etc/alternatives/java <span class=\"comment\">#这是可以看到JDK路径了</span></div><div class=\"line\">sudo vim /etc/profile</div><div class=\"line\"><span class=\"comment\"># 在末尾添加</span></div><div class=\"line\"><span class=\"built_in\">export</span> JAVA_HOME=/usr/lib/jvm/jre-1.6.0-openjdk.x86_64</div><div class=\"line\"><span class=\"built_in\">export</span> JRE_HOME=<span class=\"variable\">$JAVA_HOME</span>/jre</div><div class=\"line\"><span class=\"built_in\">export</span> PATH=<span class=\"variable\">$PATH</span>:<span class=\"variable\">$JAVA_HOME</span>/bin</div><div class=\"line\"><span class=\"built_in\">export</span> CLASSPATH=.:<span class=\"variable\">$JAVA_HOME</span>/lib/dt.jar:<span class=\"variable\">$JAVA_HOME</span>/lib/tools.jar</div><div class=\"line\"><span class=\"comment\">#保存退出，输入以下命令使之立即生效：</span></div><div class=\"line\"><span class=\"comment\"># source /etc/profile</span></div><div class=\"line\"><span class=\"comment\"># 测试</span></div><div class=\"line\">java -version</div></pre></td></tr></table></figure>\n<p>##安装 apache</p>\n<p>###方法一<br>源码在官网 <a href=\"http://httpd.apache.org/\" target=\"_blank\" rel=\"external\">http://httpd.apache.org/</a> 下载。<br>先下载apt, apr-util, pcre三个库，httpd 在编译时需要用到这三个库<br>apr, apr-util官网 <a href=\"http://apr.apache.org\" target=\"_blank\" rel=\"external\">http://apr.apache.org</a> , pcre官网为 <a href=\"http://pcre.org\" target=\"_blank\" rel=\"external\">http://pcre.org </a></p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div><div class=\"line\">51</div><div class=\"line\">52</div><div class=\"line\">53</div><div class=\"line\">54</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># 编译，安装 apr</span></div><div class=\"line\">tar -jxf apr-1.4.6.tar.bz2</div><div class=\"line\"><span class=\"built_in\">cd</span> apr-1.4.6</div><div class=\"line\">./configure</div><div class=\"line\">make</div><div class=\"line\">sudo make install    <span class=\"comment\"># 默认会安装到 /usr/local/apr/</span></div><div class=\"line\"><span class=\"built_in\">cd</span> ~</div><div class=\"line\"><span class=\"comment\">#编译，安装 apr-util</span></div><div class=\"line\">tar -jxf apr-util-1.4.1.tar.bz2</div><div class=\"line\"><span class=\"built_in\">cd</span> apr-util-1.4.1</div><div class=\"line\">./configure --with-apr=/usr/<span class=\"built_in\">local</span>/apr/</div><div class=\"line\">make</div><div class=\"line\">sudo make install    <span class=\"comment\"># 默认会安装到 /usr/local/apr/</span></div><div class=\"line\"><span class=\"built_in\">cd</span> ~</div><div class=\"line\"><span class=\"comment\">#编译，安装 pcre</span></div><div class=\"line\">tar -jxf pcre-8.30.tar.bz2</div><div class=\"line\"><span class=\"built_in\">cd</span>  pcre-8.30</div><div class=\"line\">./configure --with-apr=/usr/<span class=\"built_in\">local</span>/apr/</div><div class=\"line\">make</div><div class=\"line\"><span class=\"comment\"># By default, `make install' installs the package's commands under</span></div><div class=\"line\"><span class=\"comment\">#`/usr/local/bin', include files under `/usr/local/include', etc. </span></div><div class=\"line\">sudo make install</div><div class=\"line\"><span class=\"built_in\">cd</span> ~</div><div class=\"line\"><span class=\"comment\">#编译，安装 apache</span></div><div class=\"line\">tar -jxf httpd-2.2.22.tar.bz2</div><div class=\"line\"><span class=\"built_in\">cd</span> httpd-2.2.22</div><div class=\"line\">./configure</div><div class=\"line\">make</div><div class=\"line\">sudo make install    <span class=\"comment\"># 默认会安装到/usr/local/apache2/</span></div><div class=\"line\"><span class=\"built_in\">cd</span> ~</div><div class=\"line\"><span class=\"comment\">#添加防火墙规则，让防火墙允许 apache的端口 80通过</span></div><div class=\"line\">sudo vim /etc/sysconfig/iptables</div><div class=\"line\"><span class=\"comment\">#添加如下一行（实际上是拷贝了原来的一行，仅仅改变了端口号），位置必须#要放在 含有 \"REJECT --reject-with\" 的行的前面</span></div><div class=\"line\">-A INPUT -m state --state NEW -m tcp -p tcp --dport 80 -j ACCEPT</div><div class=\"line\">sudo service iptables restart</div><div class=\"line\"><span class=\"comment\">#测试</span></div><div class=\"line\">sudo /usr/<span class=\"built_in\">local</span>/apache2/bin/apachectl start</div><div class=\"line\"><span class=\"comment\">#在浏览器输入 http://ip地址 ，如果看到“It works”，说明安装成功</span></div><div class=\"line\">/usr/<span class=\"built_in\">local</span>/apache2/bin/apachectl stop</div><div class=\"line\"></div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\">#设置为开机启动</span></div><div class=\"line\"><span class=\"comment\">#将httpd注册为服务，通过chkconfig实现开机启动</span></div><div class=\"line\"><span class=\"comment\">#以apachectl 为模板</span></div><div class=\"line\">sudo cp /usr/<span class=\"built_in\">local</span>/apache2/bin/apachectl /etc/init.d/httpd</div><div class=\"line\">sudo vim /etc/init.d/httpd</div><div class=\"line\"><span class=\"comment\"># 在第一行 #!/bin/sh，添加如下一行，使其支持chkconfig命令</span></div><div class=\"line\"><span class=\"comment\"># chkconfig: 2345 85 15</span></div><div class=\"line\"><span class=\"comment\"># 保存，退出VIM编辑器</span></div><div class=\"line\">sudo chmod u+x /etc/init.d/httpd</div><div class=\"line\">sudo chkconfig --add httpd</div><div class=\"line\">sudo chkconfig httpd on</div><div class=\"line\"><span class=\"comment\">#检查一下，是否添加成功</span></div><div class=\"line\">chkconfig --list httpd</div></pre></td></tr></table></figure>\n<p>###方法二</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div></pre></td><td class=\"code\"><pre><div class=\"line\">sudo yum install httpd</div><div class=\"line\"><span class=\"comment\">#可选？sudo yum install httpd-devel</span></div><div class=\"line\"><span class=\"comment\">#测试</span></div><div class=\"line\"><span class=\"comment\">#启动 apache http server</span></div><div class=\"line\">sudo service httpd start</div><div class=\"line\"><span class=\"comment\">#添加规则，让防火墙允许 apache的端口 80</span></div><div class=\"line\">sudo vim /etc/sysconfig/iptables</div><div class=\"line\"><span class=\"comment\">#添加如下一行，位置必须要放在 含有 \"REJECT --reject-with\" 的行的前面</span></div><div class=\"line\">-A INPUT -m state --state NEW -m tcp -p tcp --dport 80 -j ACCEPT</div><div class=\"line\">sudo service iptables restart</div><div class=\"line\"><span class=\"comment\">#可以在浏览器输入 http://ip地址 测试了</span></div><div class=\"line\"><span class=\"comment\">#设置为开机启动</span></div><div class=\"line\">sudo chkconfig httpd on</div></pre></td></tr></table></figure>\n<p>##安装 mysql</p>\n<p>###方法一</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">#去官网下载 Oracle &amp; Red Hat 6的安装包，64位为MySQL-5.5.23-1.el6.x86_64.tar，</span></div><div class=\"line\"><span class=\"comment\">#32位为 MySQL-5.5.23-1.el6.i686.tar</span></div><div class=\"line\">tar -xf MySQL-5.5.23-1.el6.x86_64.tar</div><div class=\"line\"><span class=\"comment\">#加 --force 是因为可能会与mysqllib库冲突</span></div><div class=\"line\">sudo rpm -ivh --force  MySQL-server-5.5.23-1.el6.x86_64.rpm</div><div class=\"line\">sudo rpm -ivh MySQL-client-5.5.23-1.el6.x86_64.rpm</div><div class=\"line\"><span class=\"comment\"># 启动 mysql 服务器</span></div><div class=\"line\">sudo service mysql start</div><div class=\"line\"><span class=\"comment\">#设置为开机启动</span></div><div class=\"line\">sudo chkconfig mysql on</div></pre></td></tr></table></figure>\n<p>###方法二</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div></pre></td><td class=\"code\"><pre><div class=\"line\">sudo yum install mysql-server</div><div class=\"line\">sudo chgrp -R mysql /var/lib/mysql</div><div class=\"line\">sudo chmod -R 770 /var/lib/mysql</div><div class=\"line\"><span class=\"comment\"># 启动 mysql 服务器</span></div><div class=\"line\">sudo service mysqld start</div><div class=\"line\"><span class=\"comment\">#设置为开机启动</span></div><div class=\"line\">sudo chkconfig mysqld on</div></pre></td></tr></table></figure>\n<p>###公共的操作</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># root 初始密码为空，修改root密码</span></div><div class=\"line\">mysql -u root</div><div class=\"line\">mysql&gt; use mysql;</div><div class=\"line\">mysql&gt; update user <span class=\"built_in\">set</span> password=password(<span class=\"string\">'root123'</span>) <span class=\"built_in\">where</span> user=<span class=\"string\">'root'</span> AND host=<span class=\"string\">'localhost'</span>;</div><div class=\"line\">mysql&gt; flush privileges;</div><div class=\"line\"><span class=\"comment\"># 打开MySQL中root账户的远程登录，参考：如何打开MySQL中root账户的远程登录mysql&gt; GRANT ALL PRIVILEGES ON *.* TO root@\"%\" IDENTIFIED BY \"root\";</span></div><div class=\"line\">mysql&gt; update user <span class=\"built_in\">set</span> password=password(<span class=\"string\">'root123'</span>) <span class=\"built_in\">where</span> user=<span class=\"string\">'root'</span> AND host=<span class=\"string\">'%'</span>;</div><div class=\"line\">mysql&gt; flush privileges;</div><div class=\"line\">mysql&gt; quit;</div><div class=\"line\"><span class=\"comment\">#添加防火墙规则，让防火墙允许 mysql 的端口 3306通过</span></div><div class=\"line\">sudo vim /etc/sysconfig/iptables</div><div class=\"line\"><span class=\"comment\">#添加如下一行（实际上是拷贝了原来的一行，仅仅改变了端口号），位置必须#要放在 含有 \"REJECT --reject-with\" 的行的前面</span></div><div class=\"line\">-A INPUT -m state --state NEW -m tcp -p tcp --dport 3306 -j ACCEPT</div><div class=\"line\">sudo service iptables restart</div></pre></td></tr></table></figure>\n<p>##安装 php5</p>\n<p>###方法一<br>TODO</p>\n<p>###方法二</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div></pre></td><td class=\"code\"><pre><div class=\"line\">sudo yum install php php-pear</div><div class=\"line\"><span class=\"comment\">#重启 apache，以确保apache 加载PHP模块</span></div><div class=\"line\">sudo service httpd restart</div><div class=\"line\"><span class=\"comment\"># 在 /var/www/html/下新建一个index.php文件，用于测试</span></div><div class=\"line\"><span class=\"built_in\">cd</span> /var/www/html</div><div class=\"line\">sudo vim index.php</div><div class=\"line\"><span class=\"comment\"># 添加如下一行</span></div><div class=\"line\">&lt;?php phpinfo(); ?&gt;</div><div class=\"line\"><span class=\"comment\"># 在浏览器输入 http://xxx.xxx.xxx.xxx/index.php ，测试PHP是否成功安装</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\"># 如果需要在PHP中支持mysql，则需要安装 php-mysql 模块</span></div><div class=\"line\">sudo yum install php-mysql</div><div class=\"line\"><span class=\"comment\"># 如果需要在PHP中支持memcached，则需要安装 php-pecl-memcache 模块</span></div><div class=\"line\">sudo yum install php-pecl-memcache</div><div class=\"line\"><span class=\"comment\">#安装一些常用的PHP扩展模块</span></div><div class=\"line\">sudo yum install php-devel php-gd php-mbstring php-xml</div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\">#可以安装一个wordpress进行测试，注意要修改文件夹权限</span></div><div class=\"line\">sudo chown -R apache.apache /var/www/html</div></pre></td></tr></table></figure>\n<h2 id=\"安装-memcached\"><a href=\"#安装-memcached\" class=\"headerlink\" title=\"安装 memcached\"></a>安装 memcached</h2><p>###方法一</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div><div class=\"line\">51</div><div class=\"line\">52</div><div class=\"line\">53</div><div class=\"line\">54</div><div class=\"line\">55</div><div class=\"line\">56</div><div class=\"line\">57</div><div class=\"line\">58</div><div class=\"line\">59</div><div class=\"line\">60</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># memcached依赖libevent，首先要安装 libevent</span></div><div class=\"line\"><span class=\"comment\"># 去 http://libevent.org/ 下载libevent源码，然后编译，安装</span></div><div class=\"line\">tar -zxf libevent-2.0.18-stable.tar.gz</div><div class=\"line\"><span class=\"built_in\">cd</span> libevent-2.0.18-stable</div><div class=\"line\">./configure</div><div class=\"line\">make</div><div class=\"line\">sudo make install</div><div class=\"line\"><span class=\"comment\"># 对于64位操作系统(32位不需要)，还需要配置：</span></div><div class=\"line\">sudo ln <span class=\"_\">-s</span> /usr/<span class=\"built_in\">local</span>/lib/libevent-2.0.so.5 /usr/lib64//libevent-2.0.so.5</div><div class=\"line\"><span class=\"comment\"># 去 http://www.memcached.org/ 下载 memcached，然后编译，安装</span></div><div class=\"line\">tar -zxf memcached-1.4.13.tar.gz</div><div class=\"line\"><span class=\"built_in\">cd</span> memcached-1.4.13</div><div class=\"line\">./configure</div><div class=\"line\">make</div><div class=\"line\">sudo make install</div><div class=\"line\"><span class=\"comment\"># 启动, -p，端口,-m，内存, -u</span></div><div class=\"line\">memcached -p 11211 -m 512m -u root <span class=\"_\">-d</span></div><div class=\"line\"><span class=\"comment\"># 开机启动</span></div><div class=\"line\"><span class=\"comment\"># centos设置开机启动有两种方式，一是把启动程序的命令添加到/etc/rc.d/rc.local文件中，二是把写好的启动脚本添加到目录/etc/rc.d/init.d/，然后使用命令chkconfig设置开机启动。第二种方式可以用 service xxx start|stop来启动或停止，所以推荐第二种。</span></div><div class=\"line\"><span class=\"comment\">#将 memcached启动命令注册为一个服务</span></div><div class=\"line\"><span class=\"built_in\">cd</span> /etc/init.d/</div><div class=\"line\">sudo vim memcached</div><div class=\"line\"><span class=\"comment\">#代码如下，参考：Linux中将memcached注册成服务并可以随机器启动时启动服务</span></div><div class=\"line\"><span class=\"comment\">#chkconfig: 345 60 60</span></div><div class=\"line\"><span class=\"meta\">#!/bin/bash</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"function\"><span class=\"title\">start</span></span>()</div><div class=\"line\">&#123;</div><div class=\"line\">        <span class=\"built_in\">echo</span> -n $<span class=\"string\">\"Starting memcached: \"</span></div><div class=\"line\">        /usr/<span class=\"built_in\">local</span>/bin/memcached -p 11211 -m 512m -u root <span class=\"_\">-d</span></div><div class=\"line\">        <span class=\"built_in\">echo</span> <span class=\"string\">\"[OK]\"</span></div><div class=\"line\">&#125;</div><div class=\"line\"><span class=\"function\"><span class=\"title\">stop</span></span>()</div><div class=\"line\">&#123;</div><div class=\"line\">        <span class=\"built_in\">echo</span> -n $<span class=\"string\">\"Shutting down memcached: \"</span></div><div class=\"line\">        memcached_pid_list=`pidof memcached` </div><div class=\"line\">        <span class=\"built_in\">kill</span> -9 <span class=\"variable\">$memcached_pid_list</span></div><div class=\"line\">        <span class=\"built_in\">echo</span> <span class=\"string\">\"[OK]\"</span></div><div class=\"line\">&#125;</div><div class=\"line\"><span class=\"keyword\">case</span> <span class=\"string\">\"<span class=\"variable\">$1</span>\"</span> <span class=\"keyword\">in</span></div><div class=\"line\">  start)</div><div class=\"line\">        start</div><div class=\"line\">        ;;</div><div class=\"line\">  stop)</div><div class=\"line\">        stop</div><div class=\"line\">        ;;</div><div class=\"line\">  restart)</div><div class=\"line\">        stop</div><div class=\"line\">        sleep 3</div><div class=\"line\">        start</div><div class=\"line\">        ;;</div><div class=\"line\">    *)</div><div class=\"line\">             <span class=\"built_in\">echo</span> $<span class=\"string\">\"Usage: <span class=\"variable\">$0</span> &#123;start|stop|restart&#125;\"</span></div><div class=\"line\">        <span class=\"built_in\">exit</span> 1</div><div class=\"line\"><span class=\"keyword\">esac</span></div><div class=\"line\"><span class=\"built_in\">exit</span> 0</div><div class=\"line\"><span class=\"comment\">#保存退出</span></div><div class=\"line\">sudo chmod u+x memcached</div><div class=\"line\">sudo chkconfig --add memcached</div><div class=\"line\">sudo chkconfig  memcached on</div></pre></td></tr></table></figure>\n<p>###方法二<br>TODO</p>\n<p>##安装 tomcat6</p>\n<p>###方法一</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div><div class=\"line\">51</div><div class=\"line\">52</div><div class=\"line\">53</div><div class=\"line\">54</div><div class=\"line\">55</div><div class=\"line\">56</div><div class=\"line\">57</div><div class=\"line\">58</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># 去 http://tomcat.apache.org 下载 apache-tomcat-6.0.35.tar.gz</span></div><div class=\"line\">tar -zxf apache-tomcat-6.0.35.tar.gz</div><div class=\"line\">sudo mv apache-tomcat-6.0.35 /usr/<span class=\"built_in\">local</span>/</div><div class=\"line\"><span class=\"built_in\">cd</span> /usr/<span class=\"built_in\">local</span>/apache-tomcat-6.0.35/bin</div><div class=\"line\"><span class=\"comment\">#【可选】添加环境变量</span></div><div class=\"line\">sudo vim /etc/profile</div><div class=\"line\"><span class=\"built_in\">export</span> CATALINA_HOME=/usr/<span class=\"built_in\">local</span>/apache-tomcat-6.0.35</div><div class=\"line\"><span class=\"comment\">#启动 tomcat </span></div><div class=\"line\">sudo ./startup.sh</div><div class=\"line\"><span class=\"comment\"># 在浏览器输入 http://xxx.xxx.xxx.xxx:8080/ ，如果能看见tomcat页面，则表示安装成功了</span></div><div class=\"line\"><span class=\"comment\">#设置开机启动</span></div><div class=\"line\"><span class=\"comment\">#将 tomcat启动命令注册为一个服务</span></div><div class=\"line\"><span class=\"built_in\">cd</span> /etc/init.d/</div><div class=\"line\">sudo vim tomcatd</div><div class=\"line\"><span class=\"comment\">#代码如下</span></div><div class=\"line\"><span class=\"comment\">#chkconfig: 345 60 60</span></div><div class=\"line\"><span class=\"meta\">#!/bin/bash</span></div><div class=\"line\">CATALINA_HOME=/usr/<span class=\"built_in\">local</span>/apache-tomcat-6.0.35</div><div class=\"line\"></div><div class=\"line\"><span class=\"function\"><span class=\"title\">start</span></span>()</div><div class=\"line\">&#123;</div><div class=\"line\">        <span class=\"built_in\">echo</span> -n $<span class=\"string\">\"Starting Tomcat: \"</span></div><div class=\"line\">        <span class=\"variable\">$CATALINA_HOME</span>/bin/startup.sh</div><div class=\"line\">        <span class=\"built_in\">echo</span> <span class=\"string\">\"[OK]\"</span></div><div class=\"line\">&#125;</div><div class=\"line\"><span class=\"function\"><span class=\"title\">stop</span></span>()</div><div class=\"line\">&#123;</div><div class=\"line\">        <span class=\"built_in\">echo</span> -n $<span class=\"string\">\"Shutting down Tomcat: \"</span></div><div class=\"line\">        <span class=\"variable\">$CATALINA_HOME</span>/bin/shutdown.sh</div><div class=\"line\">        <span class=\"built_in\">echo</span> <span class=\"string\">\"[OK]\"</span></div><div class=\"line\">&#125;</div><div class=\"line\"><span class=\"keyword\">case</span> <span class=\"string\">\"<span class=\"variable\">$1</span>\"</span> <span class=\"keyword\">in</span></div><div class=\"line\">  start)</div><div class=\"line\">        start</div><div class=\"line\">        ;;</div><div class=\"line\">  stop)</div><div class=\"line\">        stop</div><div class=\"line\">        ;;</div><div class=\"line\">  restart)</div><div class=\"line\">        stop</div><div class=\"line\">        sleep 3</div><div class=\"line\">        start</div><div class=\"line\">        ;;</div><div class=\"line\">    *)</div><div class=\"line\">             <span class=\"built_in\">echo</span> $<span class=\"string\">\"Usage: <span class=\"variable\">$0</span> &#123;start|stop|restart&#125;\"</span></div><div class=\"line\">        <span class=\"built_in\">exit</span> 1</div><div class=\"line\"><span class=\"keyword\">esac</span></div><div class=\"line\"><span class=\"built_in\">exit</span> 0</div><div class=\"line\"><span class=\"comment\">#保存退出</span></div><div class=\"line\">sudo chmod u+x tomcatd</div><div class=\"line\">sudo chkconfig --add tomcatd</div><div class=\"line\">sudo chkconfig tomcatd on</div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\">#添加防火墙规则，让防火墙允许 tomcat 的端口 8080 通过</span></div><div class=\"line\">sudo vim /etc/sysconfig/iptables</div><div class=\"line\"><span class=\"comment\">#添加如下一行（实际上是拷贝了原来的一行，仅仅改变了端口号），位置必须#要放在 含有 \"REJECT --reject-with\" 的行的前面</span></div><div class=\"line\">-A INPUT -m state --state NEW -m tcp -p tcp --dport 8080 -j ACCEPT</div><div class=\"line\">sudo service iptables restart</div></pre></td></tr></table></figure>\n<p>###方法二</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">#搜索一下 tomcat包的名字</span></div><div class=\"line\">yum search tomcat</div><div class=\"line\">sudo yum search tomcat6.noarch</div></pre></td></tr></table></figure>\n<p>##安装Python</p>\n<p>###方法一：去<a href=\"http://www.python.org\" target=\"_blank\" rel=\"external\">官网</a>下载源码，编译，安装</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">#开始解压，编译，安装</span></div><div class=\"line\">tar -jxf Python-3.2.3.tar.bz2</div><div class=\"line\"><span class=\"built_in\">cd</span> Python-3.2.3</div><div class=\"line\"><span class=\"comment\"># 查看一下说明, vim README</span></div><div class=\"line\">sudo yum install zlib-devel bzip2-devel openssl-devel ncurses-devel sqlite-devel readline-devel tk-devel</div><div class=\"line\">./configure</div><div class=\"line\">make</div><div class=\"line\"><span class=\"comment\">#为了加快安装速度，这步可以省略</span></div><div class=\"line\">make <span class=\"built_in\">test</span></div><div class=\"line\"><span class=\"comment\">#卸载旧的python，注意，不能用 yum remove python，这会卸载几百个包，最终损坏系统</span></div><div class=\"line\">sudo rpm -evf --nodeps python</div><div class=\"line\">sudo make install</div><div class=\"line\"><span class=\"comment\">#默认安装在 /usr/local/bin/python3</span></div></pre></td></tr></table></figure>\n<p>###方法二</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">sudo yum install python</div></pre></td></tr></table></figure>\n<p>##安装ruby</p>\n<p>###方法一</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># http://www.ruby-lang.org/en/downloads/ ，选择 \"Stable Snapshot\"</span></div><div class=\"line\">tar -zxf ruby-1.9-stable.tar.gz</div><div class=\"line\"><span class=\"built_in\">cd</span>  <span class=\"built_in\">cd</span> ruby-1.9.3-p194/</div><div class=\"line\">./configure</div><div class=\"line\">make</div><div class=\"line\">sudo make install</div></pre></td></tr></table></figure>\n<p>###方法二</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">sudo yum install ruby</div></pre></td></tr></table></figure>\n<p>##安装go</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">#去官网 http://code.google.com/p/go/downloads 下载，go1.0.1.linux-i386.tar.gz (32位)，go1.0.1.linux-amd64.tar.gz（64位）</span></div><div class=\"line\">tar -zxf go1.0.1.linux-amd64.tar.gz</div><div class=\"line\">sudo mv go/ /usr/<span class=\"built_in\">local</span>/</div><div class=\"line\"><span class=\"comment\">#设置环境变量</span></div><div class=\"line\">sudo vim /etc/profile</div><div class=\"line\"><span class=\"built_in\">export</span> GOROOT=/usr/<span class=\"built_in\">local</span>/go</div><div class=\"line\"><span class=\"built_in\">export</span> PATH=<span class=\"variable\">$PATH</span>:<span class=\"variable\">$GOROOT</span>/bin</div><div class=\"line\"><span class=\"built_in\">source</span> /etc/profile</div><div class=\"line\"><span class=\"comment\">#测试一下</span></div><div class=\"line\">go version</div></pre></td></tr></table></figure>\n<p>##安装lua</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># 去官网下载源码，编译，安装。由于官网仅提供源码，故推荐源码编译安装方式。</span></div><div class=\"line\"><span class=\"comment\"># 去官网 http://www.lua.org/ 下载源码，lua-5.2.0.tar.gz</span></div><div class=\"line\">tar -zxf lua-5.2.0.tar.gz </div><div class=\"line\"><span class=\"built_in\">cd</span> lua-5.2.0</div><div class=\"line\"><span class=\"comment\"># lua 依赖 readline.h 头文件</span></div><div class=\"line\">sudo yum install  readline-devel</div><div class=\"line\">make linux</div><div class=\"line\">sudo make install</div><div class=\"line\"><span class=\"comment\">#安装 google protobuf</span></div><div class=\"line\"><span class=\"comment\">#去官网 http://code.google.com/p/protobuf/下载</span></div><div class=\"line\">tar -jxf protobuf-2.4.1.tar.bz2</div><div class=\"line\"><span class=\"built_in\">cd</span> protobuf-2.4.1</div><div class=\"line\">./configure</div><div class=\"line\">make</div><div class=\"line\">sudo make install</div><div class=\"line\"><span class=\"comment\">#测试</span></div><div class=\"line\">protoc</div></pre></td></tr></table></figure>\n<p>##清理安装包</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"built_in\">cd</span> ~</div><div class=\"line\">rm * -rf</div></pre></td></tr></table></figure>\n<p>##压缩打包<br>安装完后，可以Clone，压缩打包成一个zip文件，方便分享给别人。</p>\n<p>在关机之前，有一件事需要做，</p>\n<pre><code>sudo vim /etc/sysconfig/network-scripts/ifcfg-eth0, 把HWADDR=.... 这行删掉\nsudo rm /etc/udev/rules.d/70-persistent-net.rules\nsudo shutdown -h now\n</code></pre><p>如果没有执行上述命令，克隆后的虚拟机，开机后无法上网，重启网络，<code>sudo service network restart</code>也没有效果，会出现错误“Device eth0 does not seem to be present, delaying initialization.” </p>\n<p>这是因为克隆后的虚拟机，它的MAC地址变了，即在它的.vmx文件里，MAC地址变了（<code>ethernet0.generatedAddress</code>这项），但是linux不知道这个变化，网络配置文件还是旧的，这样跟它的而真实mac不匹配，网络就无法启动。</p>\n<p>执行上述命令，删除了<code>70-persistent-net.rules</code>后，相当于删除了旧的配置文件，在开机时会生成新的配置文件。</p>\n<p>关机后，右击标签，选择”Manage-&gt;Clone”，选择”Create a full clone”，克隆完成后，关闭这台虚拟机的标签（否则文件夹里有一些临时垃圾文件），然后把文件夹压缩打包。以后就可以把这个zip包拷贝给周围的人，别人就不用经历一遍重装的过程了。</p>\n<p>##参考资料</p>\n<ol>\n<li><a href=\"http://askubuntu.com/questions/141791/is-there-a-way-to-update-all-java-related-alternatives\" target=\"_blank\" rel=\"external\">Is there a way to update all Java related alternatives?</a></li>\n</ol>\n<p><a href=\"http://articles.slicehost.com/2008/2/6/centos-installing-apache-and-php5\" target=\"_blank\" rel=\"external\">CentOS - Installing Apache and PHP5</a></p>\n<p><a href=\"http://fedorasolved.org/server-solutions/lamp-stack\" target=\"_blank\" rel=\"external\">Setting up a LAMP stack</a></p>\n<p><a href=\"http://myohmy.blog.51cto.com/140917/327310\" target=\"_blank\" rel=\"external\">CentOS5.5使用yum来安装LAMP</a></p>\n<p><a href=\"http://it.megocollector.com/?p=1719\" target=\"_blank\" rel=\"external\">Install Java JDK on CentOS without prompts using an automated script!</a></p>\n","excerpt":"<p>这是我安装Ubuntu服务器的过程，记录下来，与大家一起分享。CentOS请见<a href=\"http://cn.soulmachine.me/blog/20120423/\">安装和配置CentOS服务器的详细步骤</a>。</p>\n<p>##安装操作系统<br>ubuntu-12.04.4-desktop-amd64.iso</p>\n<p>安装 CentOS时，选择 “Basic Server”<br>root密码：root123<br>CentOS 自带了ssh  </p>\n<p>安装完操作系统后，添加一个用户 manong</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">[root@localhost ~]$ useradd manong</div></pre></td></tr></table></figure>\n<p>然后密码设为 manong123</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">[root@localhost ~]$ passwd manong</div></pre></td></tr></table></figure>\n<p>给予 sudo 权限</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\">[root@localhost ~]$ chmod u+w /etc/sudoers</div><div class=\"line\">[root@localhost ~]$ vim /etc/sudoers</div><div class=\"line\"><span class=\"comment\"># 在root ALL=(ALL) ALL 下 添加manong ALL=(ALL) ALL</span></div><div class=\"line\">[root@localhost ~]$ chmod u-w /etc/sudoers</div></pre></td></tr></table></figure>\n<p>##设置上网<br>安装完操作系统后，还不能上网，配置DHCP方式上网：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div></pre></td><td class=\"code\"><pre><div class=\"line\">vim /etc/sysconfig/network-scripts/ifcfg-eth0</div><div class=\"line\">DEVICE=<span class=\"string\">\"eth0\"</span></div><div class=\"line\">HWADDR=<span class=\"string\">\"00:0C:29:BD:E1:19\"</span></div><div class=\"line\">NM_CONTROLLED=<span class=\"string\">\"yes\"</span></div><div class=\"line\">ONBOOT=<span class=\"string\">\"yes\"</span></div><div class=\"line\">BOOTPROTO=dhcp</div><div class=\"line\">USECTL=no</div><div class=\"line\">TYPE=Ethernet</div><div class=\"line\">PEERDNS=yes</div><div class=\"line\"><span class=\"comment\">#保存退出</span></div><div class=\"line\">sudo service network restart</div></pre></td></tr></table></figure>","more":"<p>或者，配置静态IP</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div></pre></td><td class=\"code\"><pre><div class=\"line\">DEVICE=<span class=\"string\">\"eth0\"</span></div><div class=\"line\">HWADDR=<span class=\"string\">\"00:0C:29:10:F4:4C\"</span></div><div class=\"line\">ONBOOT=<span class=\"string\">\"yes\"</span></div><div class=\"line\">BOOTPROTO=static</div><div class=\"line\">TYPE=Ethernet</div><div class=\"line\">IPADDR=192.168.0.162</div><div class=\"line\">NETMASK=255.255.255.0</div><div class=\"line\">BROADCAST=192.168.0.255</div><div class=\"line\">NETWORK=192.168.0.0</div><div class=\"line\"><span class=\"comment\">#保存退出  </span></div><div class=\"line\"><span class=\"comment\">#修改/etc/sysconfig/network</span></div><div class=\"line\">sudo vim /etc/sysconfig/network</div><div class=\"line\">NETWORKING=yes</div><div class=\"line\">HOSTNAME=localhost.localdomain</div><div class=\"line\">GATEWAY=192.168.0.1</div><div class=\"line\"><span class=\"comment\">#保存退出，重启网络</span></div><div class=\"line\">sudo service network restart</div></pre></td></tr></table></figure>\n<p>如果失败，比如IP已被占用，换一个IP试试</p>\n<p>修改DNS，即时生效</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\">sudo vim /etc/resolv.conf</div><div class=\"line\">nameserver 192.168.0.1</div><div class=\"line\"><span class=\"comment\"># google提供的域名服务器</span></div><div class=\"line\">nameserver 8.8.8.8</div><div class=\"line\">search localhost</div></pre></td></tr></table></figure>\n<p>##安装常用软件<br>有两种方式，方法一，去官网下载已经编译好的二进制文件，或源代码，编译安装<br>方法二，用<code>apt-get</code>命令安装，安装官方源里已经编译好的程序包。<br>第一种方式要敲很多命令，比yum麻烦，但是可以预先下载好文件，省略了下载的时间，批量给很多服务器安装时，可以节省很多流量，速度比yum安装方式快很多，而且可以安装最新版。</p>\n<p>第二种方式操作简单，敲打的命令少，但是往往官方源的更新速度跟不上各个软件的官网速度，用apt安装的版本经常比较旧。但是这种方式安装简单，更新也简单，推荐第这种方式。</p>\n<p><code>apt</code>的命令形式一般是如下：<code>apt [options] [command] [package ...]</code>，其中的[options]是可选的，选项包括-h（帮助），-y（当安装过程提示选择全部为”yes”），-q（不显示安装的过程）等等。[command]为所要进行的操作，[package …]是操作的对象。</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">#apt-cache search package-name # 在线搜索包 </span></div><div class=\"line\"><span class=\"comment\">#apt-get list installed # 列出所有已经安装的包</span></div><div class=\"line\"><span class=\"comment\">#</span></div><div class=\"line\"><span class=\"comment\">#sudo apt-get install package-name # 安装程序包 </span></div><div class=\"line\"><span class=\"comment\">#sudo yum groupinsall group-name 安装程序组</span></div><div class=\"line\"><span class=\"comment\">#</span></div><div class=\"line\"><span class=\"comment\">#sudo yum remove package-name 删除程序包</span></div><div class=\"line\"><span class=\"comment\">#sudo yum groupremove group-name 删除程序组</span></div><div class=\"line\"><span class=\"comment\">#</span></div><div class=\"line\"><span class=\"comment\">#yum update #全部更新</span></div><div class=\"line\"><span class=\"comment\">#yum update package-name #更新程序包</span></div><div class=\"line\"><span class=\"comment\">#sudo yum groupupdate groupn-name 升级程序组</span></div><div class=\"line\"><span class=\"comment\">#sudo yum upgrade # 更新源列表</span></div><div class=\"line\"><span class=\"comment\">#yum upgrade package-name #升级程序包</span></div><div class=\"line\"><span class=\"comment\">#sudo yum clean all # 清除缓存</span></div><div class=\"line\"><span class=\"comment\">#更新</span></div><div class=\"line\">sudo yum update</div><div class=\"line\"><span class=\"comment\">#清理缓存</span></div><div class=\"line\">sudo yum clean all &amp;&amp; yum clean metadata &amp;&amp; yum clean dbcache</div></pre></td></tr></table></figure>\n<p>##安装GCC</p>\n<p>###方法一 编译源码安装<br>去 <a href=\"http://gcc.gnu.org/\">http://gcc.gnu.org/</a> 下载源码</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># TODO</span></div></pre></td></tr></table></figure>\n<p>###方法二 apt安装</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">sudo apt-get install build-essential</div></pre></td></tr></table></figure>\n<p>该命令的作用是批量安装编译所需要的软件包，会自动安装一下软件包：autoconf automake bison byacc cscope ctags diffstat doxygen flex gcc gcc-c++ gcc-gfortran git indent intltool libtool patchutils rcs redhat-rpm-config rpm-build subversion swig systemtap，同时安装了以下依赖包：apr, apr-util, 等等。</p>\n<p>##安装JDK</p>\n<p>###方法1：安装OpenJDK</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">sudo apt-get install openjdk-7-jdk</div><div class=\"line\"><span class=\"comment\">#检测一下</span></div><div class=\"line\">$ java -version</div></pre></td></tr></table></figure>\n<p>如果机器上已经安装了OpenJDK6，可以升级到OpenJDK7，</p>\n<p>###升级OpenJDK, OpenJDK6–&gt;OpenJDK7</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">#查看已安装的JDK，是 java 6</span></div><div class=\"line\">$ update-java-alternatives <span class=\"_\">-l</span></div><div class=\"line\">java-1.6.0-openjdk-amd64 1061 /usr/lib/jvm/java-1.6.0-openjdk-amd64</div><div class=\"line\"><span class=\"comment\">#先安装OpenJDK7</span></div><div class=\"line\">$ sudo apt-get install openjdk-7-jdk</div><div class=\"line\"><span class=\"comment\">#现在有两个JDK了</span></div><div class=\"line\">$ update-java-alternatives <span class=\"_\">-l</span></div><div class=\"line\">java-1.6.0-openjdk-amd64 1061 /usr/lib/jvm/java-1.6.0-openjdk-amd64</div><div class=\"line\">java-1.7.0-openjdk-amd64 1051 /usr/lib/jvm/java-1.7.0-openjdk-amd64</div><div class=\"line\"><span class=\"comment\">#设置OpenJDK为默认</span></div><div class=\"line\">$ sudo apt-get install icedtea-7-plugin</div><div class=\"line\">$ sudo update-java-alternatives <span class=\"_\">-s</span> java-1.7.0-openjdk-amd64</div><div class=\"line\"><span class=\"comment\">#检测一下</span></div><div class=\"line\">$ java -version</div><div class=\"line\"><span class=\"comment\">#删除OpenJDK6</span></div><div class=\"line\">$ sudo apt-get remove openjdk-6-jdk</div><div class=\"line\"><span class=\"comment\">#现在只有一个JDK了</span></div><div class=\"line\">$ update-java-alternatives <span class=\"_\">-l</span></div><div class=\"line\">java-1.6.0-openjdk-amd64 1061 /usr/lib/jvm/java-1.6.0-openjdk-amd64</div><div class=\"line\">java-1.7.0-openjdk-amd64 1051 /usr/lib/jvm/java-1.7.0-openjdk-amd64</div><div class=\"line\">为什么还是有两个？</div></pre></td></tr></table></figure>\n<p>###方法2：安装Oracal JDK<br>Oracal JDK是有专利的，所以Ubuntu的官方源没有Oracal JDK，只能去官方下载并安装。</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">#从官网下载JDK, 当前最新版是 jdk-8u5-linux-x64.tar.gz</span></div><div class=\"line\"><span class=\"comment\">#开始安装</span></div><div class=\"line\">chmod u+x chmod u+x jdk-6u32-linux-x64-rpm.bin</div><div class=\"line\">sudo ./jdk-6u32-linux-x64-rpm.bin</div><div class=\"line\"><span class=\"comment\">#设置环境变量，.bash_profile是当前用户，/etc/profile是所有用户的</span></div><div class=\"line\">sudo vim /etc/profile</div><div class=\"line\"><span class=\"comment\">#在末尾添加</span></div><div class=\"line\"><span class=\"built_in\">export</span> JAVA_HOME=/usr/java/default</div><div class=\"line\"><span class=\"built_in\">export</span> JRE_HOME=<span class=\"variable\">$JAVA_HOME</span>/jre</div><div class=\"line\"><span class=\"built_in\">export</span> PATH=<span class=\"variable\">$PATH</span>:<span class=\"variable\">$JAVA_HOME</span>/bin</div><div class=\"line\"><span class=\"built_in\">export</span> CLASSPATH=.:<span class=\"variable\">$JAVA_HOME</span>/lib/dt.jar:<span class=\"variable\">$JAVA_HOME</span>/lib/tools.jar</div><div class=\"line\"><span class=\"comment\"># 保存退出，输入以下命令使之立即生效：</span></div><div class=\"line\"><span class=\"built_in\">source</span> /etc/profile</div><div class=\"line\"><span class=\"comment\"># 测试</span></div><div class=\"line\">java -version</div></pre></td></tr></table></figure>\n<p>###方法二</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div></pre></td><td class=\"code\"><pre><div class=\"line\">yum search jdk</div><div class=\"line\"><span class=\"comment\"># java-1.6.0-openjdk只包含了JRE，如果在这台机器上开发java程序，则需要安装JDK，</span></div><div class=\"line\"><span class=\"comment\"># 要选择 java-1.6.0-openjdk-devel，在服务器上我们只需要运行java程序，因此选择前者</span></div><div class=\"line\">sudo yum install java-1.6.0-openjdk-devel</div><div class=\"line\"><span class=\"comment\"># 使用 alternatives 工具设置默认JDK，参考：Installing a Java Development Kit on Red Hat Enterprise Linux</span></div><div class=\"line\">/usr/sbin/alternatives --config java</div><div class=\"line\">/usr/sbin/alternatives --config javac</div><div class=\"line\"><span class=\"comment\"># 设置环境变量</span></div><div class=\"line\"><span class=\"comment\"># 查询JDK路径</span></div><div class=\"line\">whereis java</div><div class=\"line\">ll /usr/bin/java</div><div class=\"line\">ll /etc/alternatives/java <span class=\"comment\">#这是可以看到JDK路径了</span></div><div class=\"line\">sudo vim /etc/profile</div><div class=\"line\"><span class=\"comment\"># 在末尾添加</span></div><div class=\"line\"><span class=\"built_in\">export</span> JAVA_HOME=/usr/lib/jvm/jre-1.6.0-openjdk.x86_64</div><div class=\"line\"><span class=\"built_in\">export</span> JRE_HOME=<span class=\"variable\">$JAVA_HOME</span>/jre</div><div class=\"line\"><span class=\"built_in\">export</span> PATH=<span class=\"variable\">$PATH</span>:<span class=\"variable\">$JAVA_HOME</span>/bin</div><div class=\"line\"><span class=\"built_in\">export</span> CLASSPATH=.:<span class=\"variable\">$JAVA_HOME</span>/lib/dt.jar:<span class=\"variable\">$JAVA_HOME</span>/lib/tools.jar</div><div class=\"line\"><span class=\"comment\">#保存退出，输入以下命令使之立即生效：</span></div><div class=\"line\"><span class=\"comment\"># source /etc/profile</span></div><div class=\"line\"><span class=\"comment\"># 测试</span></div><div class=\"line\">java -version</div></pre></td></tr></table></figure>\n<p>##安装 apache</p>\n<p>###方法一<br>源码在官网 <a href=\"http://httpd.apache.org/\">http://httpd.apache.org/</a> 下载。<br>先下载apt, apr-util, pcre三个库，httpd 在编译时需要用到这三个库<br>apr, apr-util官网 <a href=\"http://apr.apache.org\">http://apr.apache.org</a> , pcre官网为 <a href=\"http://pcre.org\">http://pcre.org </a></p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div><div class=\"line\">51</div><div class=\"line\">52</div><div class=\"line\">53</div><div class=\"line\">54</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># 编译，安装 apr</span></div><div class=\"line\">tar -jxf apr-1.4.6.tar.bz2</div><div class=\"line\"><span class=\"built_in\">cd</span> apr-1.4.6</div><div class=\"line\">./configure</div><div class=\"line\">make</div><div class=\"line\">sudo make install    <span class=\"comment\"># 默认会安装到 /usr/local/apr/</span></div><div class=\"line\"><span class=\"built_in\">cd</span> ~</div><div class=\"line\"><span class=\"comment\">#编译，安装 apr-util</span></div><div class=\"line\">tar -jxf apr-util-1.4.1.tar.bz2</div><div class=\"line\"><span class=\"built_in\">cd</span> apr-util-1.4.1</div><div class=\"line\">./configure --with-apr=/usr/<span class=\"built_in\">local</span>/apr/</div><div class=\"line\">make</div><div class=\"line\">sudo make install    <span class=\"comment\"># 默认会安装到 /usr/local/apr/</span></div><div class=\"line\"><span class=\"built_in\">cd</span> ~</div><div class=\"line\"><span class=\"comment\">#编译，安装 pcre</span></div><div class=\"line\">tar -jxf pcre-8.30.tar.bz2</div><div class=\"line\"><span class=\"built_in\">cd</span>  pcre-8.30</div><div class=\"line\">./configure --with-apr=/usr/<span class=\"built_in\">local</span>/apr/</div><div class=\"line\">make</div><div class=\"line\"><span class=\"comment\"># By default, `make install' installs the package's commands under</span></div><div class=\"line\"><span class=\"comment\">#`/usr/local/bin', include files under `/usr/local/include', etc. </span></div><div class=\"line\">sudo make install</div><div class=\"line\"><span class=\"built_in\">cd</span> ~</div><div class=\"line\"><span class=\"comment\">#编译，安装 apache</span></div><div class=\"line\">tar -jxf httpd-2.2.22.tar.bz2</div><div class=\"line\"><span class=\"built_in\">cd</span> httpd-2.2.22</div><div class=\"line\">./configure</div><div class=\"line\">make</div><div class=\"line\">sudo make install    <span class=\"comment\"># 默认会安装到/usr/local/apache2/</span></div><div class=\"line\"><span class=\"built_in\">cd</span> ~</div><div class=\"line\"><span class=\"comment\">#添加防火墙规则，让防火墙允许 apache的端口 80通过</span></div><div class=\"line\">sudo vim /etc/sysconfig/iptables</div><div class=\"line\"><span class=\"comment\">#添加如下一行（实际上是拷贝了原来的一行，仅仅改变了端口号），位置必须#要放在 含有 \"REJECT --reject-with\" 的行的前面</span></div><div class=\"line\">-A INPUT -m state --state NEW -m tcp -p tcp --dport 80 -j ACCEPT</div><div class=\"line\">sudo service iptables restart</div><div class=\"line\"><span class=\"comment\">#测试</span></div><div class=\"line\">sudo /usr/<span class=\"built_in\">local</span>/apache2/bin/apachectl start</div><div class=\"line\"><span class=\"comment\">#在浏览器输入 http://ip地址 ，如果看到“It works”，说明安装成功</span></div><div class=\"line\">/usr/<span class=\"built_in\">local</span>/apache2/bin/apachectl stop</div><div class=\"line\"></div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\">#设置为开机启动</span></div><div class=\"line\"><span class=\"comment\">#将httpd注册为服务，通过chkconfig实现开机启动</span></div><div class=\"line\"><span class=\"comment\">#以apachectl 为模板</span></div><div class=\"line\">sudo cp /usr/<span class=\"built_in\">local</span>/apache2/bin/apachectl /etc/init.d/httpd</div><div class=\"line\">sudo vim /etc/init.d/httpd</div><div class=\"line\"><span class=\"comment\"># 在第一行 #!/bin/sh，添加如下一行，使其支持chkconfig命令</span></div><div class=\"line\"><span class=\"comment\"># chkconfig: 2345 85 15</span></div><div class=\"line\"><span class=\"comment\"># 保存，退出VIM编辑器</span></div><div class=\"line\">sudo chmod u+x /etc/init.d/httpd</div><div class=\"line\">sudo chkconfig --add httpd</div><div class=\"line\">sudo chkconfig httpd on</div><div class=\"line\"><span class=\"comment\">#检查一下，是否添加成功</span></div><div class=\"line\">chkconfig --list httpd</div></pre></td></tr></table></figure>\n<p>###方法二</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div></pre></td><td class=\"code\"><pre><div class=\"line\">sudo yum install httpd</div><div class=\"line\"><span class=\"comment\">#可选？sudo yum install httpd-devel</span></div><div class=\"line\"><span class=\"comment\">#测试</span></div><div class=\"line\"><span class=\"comment\">#启动 apache http server</span></div><div class=\"line\">sudo service httpd start</div><div class=\"line\"><span class=\"comment\">#添加规则，让防火墙允许 apache的端口 80</span></div><div class=\"line\">sudo vim /etc/sysconfig/iptables</div><div class=\"line\"><span class=\"comment\">#添加如下一行，位置必须要放在 含有 \"REJECT --reject-with\" 的行的前面</span></div><div class=\"line\">-A INPUT -m state --state NEW -m tcp -p tcp --dport 80 -j ACCEPT</div><div class=\"line\">sudo service iptables restart</div><div class=\"line\"><span class=\"comment\">#可以在浏览器输入 http://ip地址 测试了</span></div><div class=\"line\"><span class=\"comment\">#设置为开机启动</span></div><div class=\"line\">sudo chkconfig httpd on</div></pre></td></tr></table></figure>\n<p>##安装 mysql</p>\n<p>###方法一</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">#去官网下载 Oracle &amp; Red Hat 6的安装包，64位为MySQL-5.5.23-1.el6.x86_64.tar，</span></div><div class=\"line\"><span class=\"comment\">#32位为 MySQL-5.5.23-1.el6.i686.tar</span></div><div class=\"line\">tar -xf MySQL-5.5.23-1.el6.x86_64.tar</div><div class=\"line\"><span class=\"comment\">#加 --force 是因为可能会与mysqllib库冲突</span></div><div class=\"line\">sudo rpm -ivh --force  MySQL-server-5.5.23-1.el6.x86_64.rpm</div><div class=\"line\">sudo rpm -ivh MySQL-client-5.5.23-1.el6.x86_64.rpm</div><div class=\"line\"><span class=\"comment\"># 启动 mysql 服务器</span></div><div class=\"line\">sudo service mysql start</div><div class=\"line\"><span class=\"comment\">#设置为开机启动</span></div><div class=\"line\">sudo chkconfig mysql on</div></pre></td></tr></table></figure>\n<p>###方法二</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div></pre></td><td class=\"code\"><pre><div class=\"line\">sudo yum install mysql-server</div><div class=\"line\">sudo chgrp -R mysql /var/lib/mysql</div><div class=\"line\">sudo chmod -R 770 /var/lib/mysql</div><div class=\"line\"><span class=\"comment\"># 启动 mysql 服务器</span></div><div class=\"line\">sudo service mysqld start</div><div class=\"line\"><span class=\"comment\">#设置为开机启动</span></div><div class=\"line\">sudo chkconfig mysqld on</div></pre></td></tr></table></figure>\n<p>###公共的操作</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># root 初始密码为空，修改root密码</span></div><div class=\"line\">mysql -u root</div><div class=\"line\">mysql&gt; use mysql;</div><div class=\"line\">mysql&gt; update user <span class=\"built_in\">set</span> password=password(<span class=\"string\">'root123'</span>) <span class=\"built_in\">where</span> user=<span class=\"string\">'root'</span> AND host=<span class=\"string\">'localhost'</span>;</div><div class=\"line\">mysql&gt; flush privileges;</div><div class=\"line\"><span class=\"comment\"># 打开MySQL中root账户的远程登录，参考：如何打开MySQL中root账户的远程登录mysql&gt; GRANT ALL PRIVILEGES ON *.* TO root@\"%\" IDENTIFIED BY \"root\";</span></div><div class=\"line\">mysql&gt; update user <span class=\"built_in\">set</span> password=password(<span class=\"string\">'root123'</span>) <span class=\"built_in\">where</span> user=<span class=\"string\">'root'</span> AND host=<span class=\"string\">'%'</span>;</div><div class=\"line\">mysql&gt; flush privileges;</div><div class=\"line\">mysql&gt; quit;</div><div class=\"line\"><span class=\"comment\">#添加防火墙规则，让防火墙允许 mysql 的端口 3306通过</span></div><div class=\"line\">sudo vim /etc/sysconfig/iptables</div><div class=\"line\"><span class=\"comment\">#添加如下一行（实际上是拷贝了原来的一行，仅仅改变了端口号），位置必须#要放在 含有 \"REJECT --reject-with\" 的行的前面</span></div><div class=\"line\">-A INPUT -m state --state NEW -m tcp -p tcp --dport 3306 -j ACCEPT</div><div class=\"line\">sudo service iptables restart</div></pre></td></tr></table></figure>\n<p>##安装 php5</p>\n<p>###方法一<br>TODO</p>\n<p>###方法二</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div></pre></td><td class=\"code\"><pre><div class=\"line\">sudo yum install php php-pear</div><div class=\"line\"><span class=\"comment\">#重启 apache，以确保apache 加载PHP模块</span></div><div class=\"line\">sudo service httpd restart</div><div class=\"line\"><span class=\"comment\"># 在 /var/www/html/下新建一个index.php文件，用于测试</span></div><div class=\"line\"><span class=\"built_in\">cd</span> /var/www/html</div><div class=\"line\">sudo vim index.php</div><div class=\"line\"><span class=\"comment\"># 添加如下一行</span></div><div class=\"line\">&lt;?php phpinfo(); ?&gt;</div><div class=\"line\"><span class=\"comment\"># 在浏览器输入 http://xxx.xxx.xxx.xxx/index.php ，测试PHP是否成功安装</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\"># 如果需要在PHP中支持mysql，则需要安装 php-mysql 模块</span></div><div class=\"line\">sudo yum install php-mysql</div><div class=\"line\"><span class=\"comment\"># 如果需要在PHP中支持memcached，则需要安装 php-pecl-memcache 模块</span></div><div class=\"line\">sudo yum install php-pecl-memcache</div><div class=\"line\"><span class=\"comment\">#安装一些常用的PHP扩展模块</span></div><div class=\"line\">sudo yum install php-devel php-gd php-mbstring php-xml</div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\">#可以安装一个wordpress进行测试，注意要修改文件夹权限</span></div><div class=\"line\">sudo chown -R apache.apache /var/www/html</div></pre></td></tr></table></figure>\n<h2 id=\"安装-memcached\"><a href=\"#安装-memcached\" class=\"headerlink\" title=\"安装 memcached\"></a>安装 memcached</h2><p>###方法一</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div><div class=\"line\">51</div><div class=\"line\">52</div><div class=\"line\">53</div><div class=\"line\">54</div><div class=\"line\">55</div><div class=\"line\">56</div><div class=\"line\">57</div><div class=\"line\">58</div><div class=\"line\">59</div><div class=\"line\">60</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># memcached依赖libevent，首先要安装 libevent</span></div><div class=\"line\"><span class=\"comment\"># 去 http://libevent.org/ 下载libevent源码，然后编译，安装</span></div><div class=\"line\">tar -zxf libevent-2.0.18-stable.tar.gz</div><div class=\"line\"><span class=\"built_in\">cd</span> libevent-2.0.18-stable</div><div class=\"line\">./configure</div><div class=\"line\">make</div><div class=\"line\">sudo make install</div><div class=\"line\"><span class=\"comment\"># 对于64位操作系统(32位不需要)，还需要配置：</span></div><div class=\"line\">sudo ln <span class=\"_\">-s</span> /usr/<span class=\"built_in\">local</span>/lib/libevent-2.0.so.5 /usr/lib64//libevent-2.0.so.5</div><div class=\"line\"><span class=\"comment\"># 去 http://www.memcached.org/ 下载 memcached，然后编译，安装</span></div><div class=\"line\">tar -zxf memcached-1.4.13.tar.gz</div><div class=\"line\"><span class=\"built_in\">cd</span> memcached-1.4.13</div><div class=\"line\">./configure</div><div class=\"line\">make</div><div class=\"line\">sudo make install</div><div class=\"line\"><span class=\"comment\"># 启动, -p，端口,-m，内存, -u</span></div><div class=\"line\">memcached -p 11211 -m 512m -u root <span class=\"_\">-d</span></div><div class=\"line\"><span class=\"comment\"># 开机启动</span></div><div class=\"line\"><span class=\"comment\"># centos设置开机启动有两种方式，一是把启动程序的命令添加到/etc/rc.d/rc.local文件中，二是把写好的启动脚本添加到目录/etc/rc.d/init.d/，然后使用命令chkconfig设置开机启动。第二种方式可以用 service xxx start|stop来启动或停止，所以推荐第二种。</span></div><div class=\"line\"><span class=\"comment\">#将 memcached启动命令注册为一个服务</span></div><div class=\"line\"><span class=\"built_in\">cd</span> /etc/init.d/</div><div class=\"line\">sudo vim memcached</div><div class=\"line\"><span class=\"comment\">#代码如下，参考：Linux中将memcached注册成服务并可以随机器启动时启动服务</span></div><div class=\"line\"><span class=\"comment\">#chkconfig: 345 60 60</span></div><div class=\"line\"><span class=\"meta\">#!/bin/bash</div><div class=\"line\"></span></div><div class=\"line\"><span class=\"function\"><span class=\"title\">start</span></span>()</div><div class=\"line\">&#123;</div><div class=\"line\">        <span class=\"built_in\">echo</span> -n $<span class=\"string\">\"Starting memcached: \"</span></div><div class=\"line\">        /usr/<span class=\"built_in\">local</span>/bin/memcached -p 11211 -m 512m -u root <span class=\"_\">-d</span></div><div class=\"line\">        <span class=\"built_in\">echo</span> <span class=\"string\">\"[OK]\"</span></div><div class=\"line\">&#125;</div><div class=\"line\"><span class=\"function\"><span class=\"title\">stop</span></span>()</div><div class=\"line\">&#123;</div><div class=\"line\">        <span class=\"built_in\">echo</span> -n $<span class=\"string\">\"Shutting down memcached: \"</span></div><div class=\"line\">        memcached_pid_list=`pidof memcached` </div><div class=\"line\">        <span class=\"built_in\">kill</span> -9 <span class=\"variable\">$memcached_pid_list</span></div><div class=\"line\">        <span class=\"built_in\">echo</span> <span class=\"string\">\"[OK]\"</span></div><div class=\"line\">&#125;</div><div class=\"line\"><span class=\"keyword\">case</span> <span class=\"string\">\"<span class=\"variable\">$1</span>\"</span> <span class=\"keyword\">in</span></div><div class=\"line\">  start)</div><div class=\"line\">        start</div><div class=\"line\">        ;;</div><div class=\"line\">  stop)</div><div class=\"line\">        stop</div><div class=\"line\">        ;;</div><div class=\"line\">  restart)</div><div class=\"line\">        stop</div><div class=\"line\">        sleep 3</div><div class=\"line\">        start</div><div class=\"line\">        ;;</div><div class=\"line\">    *)</div><div class=\"line\">             <span class=\"built_in\">echo</span> $<span class=\"string\">\"Usage: <span class=\"variable\">$0</span> &#123;start|stop|restart&#125;\"</span></div><div class=\"line\">        <span class=\"built_in\">exit</span> 1</div><div class=\"line\"><span class=\"keyword\">esac</span></div><div class=\"line\"><span class=\"built_in\">exit</span> 0</div><div class=\"line\"><span class=\"comment\">#保存退出</span></div><div class=\"line\">sudo chmod u+x memcached</div><div class=\"line\">sudo chkconfig --add memcached</div><div class=\"line\">sudo chkconfig  memcached on</div></pre></td></tr></table></figure>\n<p>###方法二<br>TODO</p>\n<p>##安装 tomcat6</p>\n<p>###方法一</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div><div class=\"line\">51</div><div class=\"line\">52</div><div class=\"line\">53</div><div class=\"line\">54</div><div class=\"line\">55</div><div class=\"line\">56</div><div class=\"line\">57</div><div class=\"line\">58</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># 去 http://tomcat.apache.org 下载 apache-tomcat-6.0.35.tar.gz</span></div><div class=\"line\">tar -zxf apache-tomcat-6.0.35.tar.gz</div><div class=\"line\">sudo mv apache-tomcat-6.0.35 /usr/<span class=\"built_in\">local</span>/</div><div class=\"line\"><span class=\"built_in\">cd</span> /usr/<span class=\"built_in\">local</span>/apache-tomcat-6.0.35/bin</div><div class=\"line\"><span class=\"comment\">#【可选】添加环境变量</span></div><div class=\"line\">sudo vim /etc/profile</div><div class=\"line\"><span class=\"built_in\">export</span> CATALINA_HOME=/usr/<span class=\"built_in\">local</span>/apache-tomcat-6.0.35</div><div class=\"line\"><span class=\"comment\">#启动 tomcat </span></div><div class=\"line\">sudo ./startup.sh</div><div class=\"line\"><span class=\"comment\"># 在浏览器输入 http://xxx.xxx.xxx.xxx:8080/ ，如果能看见tomcat页面，则表示安装成功了</span></div><div class=\"line\"><span class=\"comment\">#设置开机启动</span></div><div class=\"line\"><span class=\"comment\">#将 tomcat启动命令注册为一个服务</span></div><div class=\"line\"><span class=\"built_in\">cd</span> /etc/init.d/</div><div class=\"line\">sudo vim tomcatd</div><div class=\"line\"><span class=\"comment\">#代码如下</span></div><div class=\"line\"><span class=\"comment\">#chkconfig: 345 60 60</span></div><div class=\"line\"><span class=\"meta\">#!/bin/bash</span></div><div class=\"line\">CATALINA_HOME=/usr/<span class=\"built_in\">local</span>/apache-tomcat-6.0.35</div><div class=\"line\"></div><div class=\"line\"><span class=\"function\"><span class=\"title\">start</span></span>()</div><div class=\"line\">&#123;</div><div class=\"line\">        <span class=\"built_in\">echo</span> -n $<span class=\"string\">\"Starting Tomcat: \"</span></div><div class=\"line\">        <span class=\"variable\">$CATALINA_HOME</span>/bin/startup.sh</div><div class=\"line\">        <span class=\"built_in\">echo</span> <span class=\"string\">\"[OK]\"</span></div><div class=\"line\">&#125;</div><div class=\"line\"><span class=\"function\"><span class=\"title\">stop</span></span>()</div><div class=\"line\">&#123;</div><div class=\"line\">        <span class=\"built_in\">echo</span> -n $<span class=\"string\">\"Shutting down Tomcat: \"</span></div><div class=\"line\">        <span class=\"variable\">$CATALINA_HOME</span>/bin/shutdown.sh</div><div class=\"line\">        <span class=\"built_in\">echo</span> <span class=\"string\">\"[OK]\"</span></div><div class=\"line\">&#125;</div><div class=\"line\"><span class=\"keyword\">case</span> <span class=\"string\">\"<span class=\"variable\">$1</span>\"</span> <span class=\"keyword\">in</span></div><div class=\"line\">  start)</div><div class=\"line\">        start</div><div class=\"line\">        ;;</div><div class=\"line\">  stop)</div><div class=\"line\">        stop</div><div class=\"line\">        ;;</div><div class=\"line\">  restart)</div><div class=\"line\">        stop</div><div class=\"line\">        sleep 3</div><div class=\"line\">        start</div><div class=\"line\">        ;;</div><div class=\"line\">    *)</div><div class=\"line\">             <span class=\"built_in\">echo</span> $<span class=\"string\">\"Usage: <span class=\"variable\">$0</span> &#123;start|stop|restart&#125;\"</span></div><div class=\"line\">        <span class=\"built_in\">exit</span> 1</div><div class=\"line\"><span class=\"keyword\">esac</span></div><div class=\"line\"><span class=\"built_in\">exit</span> 0</div><div class=\"line\"><span class=\"comment\">#保存退出</span></div><div class=\"line\">sudo chmod u+x tomcatd</div><div class=\"line\">sudo chkconfig --add tomcatd</div><div class=\"line\">sudo chkconfig tomcatd on</div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\">#添加防火墙规则，让防火墙允许 tomcat 的端口 8080 通过</span></div><div class=\"line\">sudo vim /etc/sysconfig/iptables</div><div class=\"line\"><span class=\"comment\">#添加如下一行（实际上是拷贝了原来的一行，仅仅改变了端口号），位置必须#要放在 含有 \"REJECT --reject-with\" 的行的前面</span></div><div class=\"line\">-A INPUT -m state --state NEW -m tcp -p tcp --dport 8080 -j ACCEPT</div><div class=\"line\">sudo service iptables restart</div></pre></td></tr></table></figure>\n<p>###方法二</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">#搜索一下 tomcat包的名字</span></div><div class=\"line\">yum search tomcat</div><div class=\"line\">sudo yum search tomcat6.noarch</div></pre></td></tr></table></figure>\n<p>##安装Python</p>\n<p>###方法一：去<a href=\"http://www.python.org\">官网</a>下载源码，编译，安装</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">#开始解压，编译，安装</span></div><div class=\"line\">tar -jxf Python-3.2.3.tar.bz2</div><div class=\"line\"><span class=\"built_in\">cd</span> Python-3.2.3</div><div class=\"line\"><span class=\"comment\"># 查看一下说明, vim README</span></div><div class=\"line\">sudo yum install zlib-devel bzip2-devel openssl-devel ncurses-devel sqlite-devel readline-devel tk-devel</div><div class=\"line\">./configure</div><div class=\"line\">make</div><div class=\"line\"><span class=\"comment\">#为了加快安装速度，这步可以省略</span></div><div class=\"line\">make <span class=\"built_in\">test</span></div><div class=\"line\"><span class=\"comment\">#卸载旧的python，注意，不能用 yum remove python，这会卸载几百个包，最终损坏系统</span></div><div class=\"line\">sudo rpm -evf --nodeps python</div><div class=\"line\">sudo make install</div><div class=\"line\"><span class=\"comment\">#默认安装在 /usr/local/bin/python3</span></div></pre></td></tr></table></figure>\n<p>###方法二</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">sudo yum install python</div></pre></td></tr></table></figure>\n<p>##安装ruby</p>\n<p>###方法一</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># http://www.ruby-lang.org/en/downloads/ ，选择 \"Stable Snapshot\"</span></div><div class=\"line\">tar -zxf ruby-1.9-stable.tar.gz</div><div class=\"line\"><span class=\"built_in\">cd</span>  <span class=\"built_in\">cd</span> ruby-1.9.3-p194/</div><div class=\"line\">./configure</div><div class=\"line\">make</div><div class=\"line\">sudo make install</div></pre></td></tr></table></figure>\n<p>###方法二</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">sudo yum install ruby</div></pre></td></tr></table></figure>\n<p>##安装go</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">#去官网 http://code.google.com/p/go/downloads 下载，go1.0.1.linux-i386.tar.gz (32位)，go1.0.1.linux-amd64.tar.gz（64位）</span></div><div class=\"line\">tar -zxf go1.0.1.linux-amd64.tar.gz</div><div class=\"line\">sudo mv go/ /usr/<span class=\"built_in\">local</span>/</div><div class=\"line\"><span class=\"comment\">#设置环境变量</span></div><div class=\"line\">sudo vim /etc/profile</div><div class=\"line\"><span class=\"built_in\">export</span> GOROOT=/usr/<span class=\"built_in\">local</span>/go</div><div class=\"line\"><span class=\"built_in\">export</span> PATH=<span class=\"variable\">$PATH</span>:<span class=\"variable\">$GOROOT</span>/bin</div><div class=\"line\"><span class=\"built_in\">source</span> /etc/profile</div><div class=\"line\"><span class=\"comment\">#测试一下</span></div><div class=\"line\">go version</div></pre></td></tr></table></figure>\n<p>##安装lua</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># 去官网下载源码，编译，安装。由于官网仅提供源码，故推荐源码编译安装方式。</span></div><div class=\"line\"><span class=\"comment\"># 去官网 http://www.lua.org/ 下载源码，lua-5.2.0.tar.gz</span></div><div class=\"line\">tar -zxf lua-5.2.0.tar.gz </div><div class=\"line\"><span class=\"built_in\">cd</span> lua-5.2.0</div><div class=\"line\"><span class=\"comment\"># lua 依赖 readline.h 头文件</span></div><div class=\"line\">sudo yum install  readline-devel</div><div class=\"line\">make linux</div><div class=\"line\">sudo make install</div><div class=\"line\"><span class=\"comment\">#安装 google protobuf</span></div><div class=\"line\"><span class=\"comment\">#去官网 http://code.google.com/p/protobuf/下载</span></div><div class=\"line\">tar -jxf protobuf-2.4.1.tar.bz2</div><div class=\"line\"><span class=\"built_in\">cd</span> protobuf-2.4.1</div><div class=\"line\">./configure</div><div class=\"line\">make</div><div class=\"line\">sudo make install</div><div class=\"line\"><span class=\"comment\">#测试</span></div><div class=\"line\">protoc</div></pre></td></tr></table></figure>\n<p>##清理安装包</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"built_in\">cd</span> ~</div><div class=\"line\">rm * -rf</div></pre></td></tr></table></figure>\n<p>##压缩打包<br>安装完后，可以Clone，压缩打包成一个zip文件，方便分享给别人。</p>\n<p>在关机之前，有一件事需要做，</p>\n<pre><code>sudo vim /etc/sysconfig/network-scripts/ifcfg-eth0, 把HWADDR=.... 这行删掉\nsudo rm /etc/udev/rules.d/70-persistent-net.rules\nsudo shutdown -h now\n</code></pre><p>如果没有执行上述命令，克隆后的虚拟机，开机后无法上网，重启网络，<code>sudo service network restart</code>也没有效果，会出现错误“Device eth0 does not seem to be present, delaying initialization.” </p>\n<p>这是因为克隆后的虚拟机，它的MAC地址变了，即在它的.vmx文件里，MAC地址变了（<code>ethernet0.generatedAddress</code>这项），但是linux不知道这个变化，网络配置文件还是旧的，这样跟它的而真实mac不匹配，网络就无法启动。</p>\n<p>执行上述命令，删除了<code>70-persistent-net.rules</code>后，相当于删除了旧的配置文件，在开机时会生成新的配置文件。</p>\n<p>关机后，右击标签，选择”Manage-&gt;Clone”，选择”Create a full clone”，克隆完成后，关闭这台虚拟机的标签（否则文件夹里有一些临时垃圾文件），然后把文件夹压缩打包。以后就可以把这个zip包拷贝给周围的人，别人就不用经历一遍重装的过程了。</p>\n<p>##参考资料</p>\n<ol>\n<li><a href=\"http://askubuntu.com/questions/141791/is-there-a-way-to-update-all-java-related-alternatives\">Is there a way to update all Java related alternatives?</a></li>\n</ol>\n<p><a href=\"http://articles.slicehost.com/2008/2/6/centos-installing-apache-and-php5\">CentOS - Installing Apache and PHP5</a></p>\n<p><a href=\"http://fedorasolved.org/server-solutions/lamp-stack\">Setting up a LAMP stack</a></p>\n<p><a href=\"http://myohmy.blog.51cto.com/140917/327310\">CentOS5.5使用yum来安装LAMP</a></p>\n<p><a href=\"http://it.megocollector.com/?p=1719\">Install Java JDK on CentOS without prompts using an automated script!</a></p>"},{"title":"深度学习开发环境配置：Ubuntu1 6.04+Nvidia GTX 1080+CUDA 8.0","date":"2016-08-17T23:59:11.000Z","_content":"\n前提条件，已经安装好了 Ubuntu 16.04 操作系统， 见[安装 Windows 10 和 Ubuntu 16.04 双系统](http://cn.soulmachine.me/2016-08-14-dual-install-windows-ubuntu/)\n\n\n\n## 1. 安装 Nvidia 驱动\n\n\n```shell\nsudo add-apt-repository -qy ppa:graphics-drivers/ppa\nsudo apt-get -qy update\nsudo apt-get -qy install nvidia-370\nsudo apt-get -qy install mesa-common-dev\nsudo apt-get -qy install freeglut3-dev\nsudo reboot\n```\n\n注意，一般比较新的主板，默认是UEFI BIOS，默认启用了 Secure Boot，否则开机后登陆不进去。老主板没有这个问题。\n\n\n## 2. 安装 CUDA 8.x\n\n去 [CUDA 8.x 下载页面](https://developer.nvidia.com/cuda-release-candidate-download)，一定要下载 runfile 安装方式的安装包，参考资料里的好几篇都是选择这种方式，貌似 deb包有坑？\n\n<!-- more -->\n\n```shell\nchmod u+x ./cuda_8.0.27_linux.run\nsudo ./cuda_8.0.27_linux.run --tmpdir=/tmp\n```\n\n执行后会有一系列提示让你确认，第一个就是问你是否安装显卡驱动，由于前一步已经安装了显卡驱动，所以这里就不需要了，况且 runfile 自带的驱动版本不是最新的。 因此 `Install NVIDIA Accelerated Graphics Driver for Linux-x86_64 361.77?` 这里选择 no。\n\n```shell\nDo you accept the previously read EULA?\naccept/decline/quit: accept\n\nInstall NVIDIA Accelerated Graphics Driver for Linux-x86_64 361.77?\n(y)es/(n)o/(q)uit: n\n\nInstall the CUDA 8.0 Toolkit?\n(y)es/(n)o/(q)uit: y\n\nEnter Toolkit Location\n [ default is /usr/local/cuda-8.0 ]: \n\nDo you want to install a symbolic link at /usr/local/cuda?\n(y)es/(n)o/(q)uit: y\n\nInstall the CUDA 8.0 Samples?\n(y)es/(n)o/(q)uit: y\n\nEnter CUDA Samples Location\n [ default is /home/programmer ]:\n```\n\n你以为你会成功安装吗？并不是，你一定会碰到一个错误，` Installation Failed. Using unsupported Compiler.` ，这是因为 Ubuntu 16.04 默认的 GCC 5.4 对于 CUDA 8.x来说过于新了，CUDA 安装脚本还不能识别新版本的 GCC。\n\n看了一下安装日志，解决方案也很简单，加一个 `--override` 选项，\n\n```shell\nsudo ./cuda_8.0.27_linux.run --tmpdir=/tmp --override\n```\n\n这次可以成功了。\n\n```\n===========\n= Summary =\n===========\n\nDriver:   Not Selected\nToolkit:  Installed in /usr/local/cuda-8.0\nSamples:  Installed in /home/programmer, but missing recommended libraries\n\nPlease make sure that\n -   PATH includes /usr/local/cuda-8.0/bin\n -   LD_LIBRARY_PATH includes /usr/local/cuda-8.0/lib64, or, add /usr/local/cuda-8.0/lib64 to /etc/ld.so.conf and run ldconfig as root\n\nTo uninstall the CUDA Toolkit, run the uninstall script in /usr/local/cuda-8.0/bin\n\nPlease see CUDA_Installation_Guide_Linux.pdf in /usr/local/cuda-8.0/doc/pdf for detailed information on setting up CUDA.\n\n***WARNING: Incomplete installation! This installation did not install the CUDA Driver. A driver of version at least 361.00 is required for CUDA 8.0 functionality to work.\n\nTo install the driver using this installer, run the following command, replacing <CudaInstaller> with the name of this run file:\n\n    sudo <CudaInstaller>.run -silent -driver\n\nLogfile is /tmp/cuda_install_6794.log\n\nSignal caught, cleaning up\n```\n\n把以下两行加入到 `.bashrc`，\n\n```shell\nexport PATH=/usr/local/cuda-8.0/bin${PATH:+:${PATH}}\nexport LD_LIBRARY_PATH=/usr/local/cuda-8.0/lib64${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}}\n```\n\n## 安装补丁\n\n```shell\nchmod u+x ./cuda_8.0.27.1_linux.run\nsudo ./cuda_8.0.27.1_linux.run\n```\n\n\n## 测试是否安装成功\n\n最后再来测试一下CUDA，运行：\n\n```shell\nnvidia-smi\n```\n\n结果如下所示：\n\n```\n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 370.23                 Driver Version: 370.23                    |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|===============================+======================+======================|\n|   0  GeForce GTX 1080    Off  | 0000:05:00.0      On |                  N/A |\n| 27%   29C    P8     9W / 180W |    515MiB /  8110MiB |      4%      Default |\n+-------------------------------+----------------------+----------------------+\n\n+-----------------------------------------------------------------------------+\n| Processes:                                                       GPU Memory |\n|  GPU       PID  Type  Process name                               Usage      |\n|=============================================================================|\n|    0      4761    G   /usr/lib/xorg/Xorg                             259MiB |\n|    0      5224    G   compiz                                         253MiB |\n+-----------------------------------------------------------------------------+\n```\n\n再来试几个CUDA例子：\n\n```shell\ncd ~/NVIDIA_CUDA-8.0_Samples/1_Utilities/deviceQuery\nmake\n```\n\n执行 `./deviceQuery`，得到：\n\n```\nCUDA Device Query (Runtime API) version (CUDART static linking)\n\nDetected 1 CUDA Capable device(s)\n\nDevice 0: \"GeForce GTX 1080\"\n  CUDA Driver Version / Runtime Version          8.0 / 8.0\n  CUDA Capability Major/Minor version number:    6.1\n  Total amount of global memory:                 8110 MBytes (8504279040 bytes)\n  (20) Multiprocessors, (128) CUDA Cores/MP:     2560 CUDA Cores\n  GPU Max Clock rate:                            1734 MHz (1.73 GHz)\n  Memory Clock rate:                             5005 Mhz\n  Memory Bus Width:                              256-bit\n  L2 Cache Size:                                 2097152 bytes\n  Maximum Texture Dimension Size (x,y,z)         1D=(131072), 2D=(131072, 65536), 3D=(16384, 16384, 16384)\n  Maximum Layered 1D Texture Size, (num) layers  1D=(32768), 2048 layers\n  Maximum Layered 2D Texture Size, (num) layers  2D=(32768, 32768), 2048 layers\n  Total amount of constant memory:               65536 bytes\n  Total amount of shared memory per block:       49152 bytes\n  Total number of registers available per block: 65536\n  Warp size:                                     32\n  Maximum number of threads per multiprocessor:  2048\n  Maximum number of threads per block:           1024\n  Max dimension size of a thread block (x,y,z): (1024, 1024, 64)\n  Max dimension size of a grid size    (x,y,z): (2147483647, 65535, 65535)\n  Maximum memory pitch:                          2147483647 bytes\n  Texture alignment:                             512 bytes\n  Concurrent copy and kernel execution:          Yes with 2 copy engine(s)\n  Run time limit on kernels:                     Yes\n  Integrated GPU sharing Host Memory:            No\n  Support host page-locked memory mapping:       Yes\n  Alignment requirement for Surfaces:            Yes\n  Device has ECC support:                        Disabled\n  Device supports Unified Addressing (UVA):      Yes\n  Device PCI Domain ID / Bus ID / location ID:   0 / 5 / 0\n\n  Compute Mode:\n     < Default (multiple host threads can use ::cudaSetDevice() with device simultaneously) >\n\ndeviceQuery, CUDA Driver = CUDART, CUDA Driver Version = 8.0, CUDA Runtime Version = 8.0, NumDevs = 1, Device0 = GeForce GTX 1080\nResult = PASS\n```\n\n再测试试一下nobody：\n\n```shell\ncd ~/NVIDIA_CUDA-8.0_Samples/5_Simulations/nbody/\nmake\n```\n\n执行：\n\n```shell\n./nbody -benchmark -numbodies=256000 -device=0\n```\n\n得到：\n\n```\n> Windowed mode\n> Simulation data stored in video memory\n> Single precision floating point simulation\n> 1 Devices used for simulation\ngpuDeviceInit() CUDA Device [0]: \"GeForce GTX 1080\n> Compute 6.1 CUDA device: [GeForce GTX 1080]\nnumber of bodies = 256000\n256000 bodies, total time for 10 iterations: 2364.286 ms\n= 277.192 billion interactions per second\n= 5543.830 single-precision GFLOP/s at 20 flops per interaction\n```\n\n至此，说明 CUDA 8.x 安装成功了。\n\n\n## 参考资料\n\n* [深度学习主机环境配置: Ubuntu16.04+Nvidia GTX 1080+CUDA8.0](http://www.52nlp.cn/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%BB%E6%9C%BA%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE-ubuntu-16-04-nvidia-gtx-1080-cuda-8)\n* [Nvidia GTX 1080 on Ubuntu 16.04 for Deep Learning - Changjiang](http://yangcha.github.io/GTX-1080/)\n* [Build Personal Deep Learning Rig: GTX 1080 + Ubuntu 16.04 + CUDA 8.0RC + CuDnn 7 + Tensorflow/Mxnet/Caffe/Darknet - by Guanghan Ning](http://guanghan.info/blog/en/my-works/building-our-personal-deep-learning-rig-gtx-1080-ubuntu-16-04-cuda-8-0rc-cudnn-7-tensorflowmxnetcaffedarknet/)\n* [GeForce GTX 1080, CUDA 8.0, Ubuntu 16.04, Caffe](https://github.com/BVLC/caffe/wiki/GeForce-GTX-1080,---CUDA-8.0,---Ubuntu-16.04,---Caffe)\n","source":"_posts/2016-08-17-deep-learning-cuda-development-environment.md","raw":"---\ntitle: 深度学习开发环境配置：Ubuntu1 6.04+Nvidia GTX 1080+CUDA 8.0\ndate: 2016-08-17 23:59:11\ntags: 深度学习\ncategories: 深度学习\n---\n\n前提条件，已经安装好了 Ubuntu 16.04 操作系统， 见[安装 Windows 10 和 Ubuntu 16.04 双系统](http://cn.soulmachine.me/2016-08-14-dual-install-windows-ubuntu/)\n\n\n\n## 1. 安装 Nvidia 驱动\n\n\n```shell\nsudo add-apt-repository -qy ppa:graphics-drivers/ppa\nsudo apt-get -qy update\nsudo apt-get -qy install nvidia-370\nsudo apt-get -qy install mesa-common-dev\nsudo apt-get -qy install freeglut3-dev\nsudo reboot\n```\n\n注意，一般比较新的主板，默认是UEFI BIOS，默认启用了 Secure Boot，否则开机后登陆不进去。老主板没有这个问题。\n\n\n## 2. 安装 CUDA 8.x\n\n去 [CUDA 8.x 下载页面](https://developer.nvidia.com/cuda-release-candidate-download)，一定要下载 runfile 安装方式的安装包，参考资料里的好几篇都是选择这种方式，貌似 deb包有坑？\n\n<!-- more -->\n\n```shell\nchmod u+x ./cuda_8.0.27_linux.run\nsudo ./cuda_8.0.27_linux.run --tmpdir=/tmp\n```\n\n执行后会有一系列提示让你确认，第一个就是问你是否安装显卡驱动，由于前一步已经安装了显卡驱动，所以这里就不需要了，况且 runfile 自带的驱动版本不是最新的。 因此 `Install NVIDIA Accelerated Graphics Driver for Linux-x86_64 361.77?` 这里选择 no。\n\n```shell\nDo you accept the previously read EULA?\naccept/decline/quit: accept\n\nInstall NVIDIA Accelerated Graphics Driver for Linux-x86_64 361.77?\n(y)es/(n)o/(q)uit: n\n\nInstall the CUDA 8.0 Toolkit?\n(y)es/(n)o/(q)uit: y\n\nEnter Toolkit Location\n [ default is /usr/local/cuda-8.0 ]: \n\nDo you want to install a symbolic link at /usr/local/cuda?\n(y)es/(n)o/(q)uit: y\n\nInstall the CUDA 8.0 Samples?\n(y)es/(n)o/(q)uit: y\n\nEnter CUDA Samples Location\n [ default is /home/programmer ]:\n```\n\n你以为你会成功安装吗？并不是，你一定会碰到一个错误，` Installation Failed. Using unsupported Compiler.` ，这是因为 Ubuntu 16.04 默认的 GCC 5.4 对于 CUDA 8.x来说过于新了，CUDA 安装脚本还不能识别新版本的 GCC。\n\n看了一下安装日志，解决方案也很简单，加一个 `--override` 选项，\n\n```shell\nsudo ./cuda_8.0.27_linux.run --tmpdir=/tmp --override\n```\n\n这次可以成功了。\n\n```\n===========\n= Summary =\n===========\n\nDriver:   Not Selected\nToolkit:  Installed in /usr/local/cuda-8.0\nSamples:  Installed in /home/programmer, but missing recommended libraries\n\nPlease make sure that\n -   PATH includes /usr/local/cuda-8.0/bin\n -   LD_LIBRARY_PATH includes /usr/local/cuda-8.0/lib64, or, add /usr/local/cuda-8.0/lib64 to /etc/ld.so.conf and run ldconfig as root\n\nTo uninstall the CUDA Toolkit, run the uninstall script in /usr/local/cuda-8.0/bin\n\nPlease see CUDA_Installation_Guide_Linux.pdf in /usr/local/cuda-8.0/doc/pdf for detailed information on setting up CUDA.\n\n***WARNING: Incomplete installation! This installation did not install the CUDA Driver. A driver of version at least 361.00 is required for CUDA 8.0 functionality to work.\n\nTo install the driver using this installer, run the following command, replacing <CudaInstaller> with the name of this run file:\n\n    sudo <CudaInstaller>.run -silent -driver\n\nLogfile is /tmp/cuda_install_6794.log\n\nSignal caught, cleaning up\n```\n\n把以下两行加入到 `.bashrc`，\n\n```shell\nexport PATH=/usr/local/cuda-8.0/bin${PATH:+:${PATH}}\nexport LD_LIBRARY_PATH=/usr/local/cuda-8.0/lib64${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}}\n```\n\n## 安装补丁\n\n```shell\nchmod u+x ./cuda_8.0.27.1_linux.run\nsudo ./cuda_8.0.27.1_linux.run\n```\n\n\n## 测试是否安装成功\n\n最后再来测试一下CUDA，运行：\n\n```shell\nnvidia-smi\n```\n\n结果如下所示：\n\n```\n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 370.23                 Driver Version: 370.23                    |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|===============================+======================+======================|\n|   0  GeForce GTX 1080    Off  | 0000:05:00.0      On |                  N/A |\n| 27%   29C    P8     9W / 180W |    515MiB /  8110MiB |      4%      Default |\n+-------------------------------+----------------------+----------------------+\n\n+-----------------------------------------------------------------------------+\n| Processes:                                                       GPU Memory |\n|  GPU       PID  Type  Process name                               Usage      |\n|=============================================================================|\n|    0      4761    G   /usr/lib/xorg/Xorg                             259MiB |\n|    0      5224    G   compiz                                         253MiB |\n+-----------------------------------------------------------------------------+\n```\n\n再来试几个CUDA例子：\n\n```shell\ncd ~/NVIDIA_CUDA-8.0_Samples/1_Utilities/deviceQuery\nmake\n```\n\n执行 `./deviceQuery`，得到：\n\n```\nCUDA Device Query (Runtime API) version (CUDART static linking)\n\nDetected 1 CUDA Capable device(s)\n\nDevice 0: \"GeForce GTX 1080\"\n  CUDA Driver Version / Runtime Version          8.0 / 8.0\n  CUDA Capability Major/Minor version number:    6.1\n  Total amount of global memory:                 8110 MBytes (8504279040 bytes)\n  (20) Multiprocessors, (128) CUDA Cores/MP:     2560 CUDA Cores\n  GPU Max Clock rate:                            1734 MHz (1.73 GHz)\n  Memory Clock rate:                             5005 Mhz\n  Memory Bus Width:                              256-bit\n  L2 Cache Size:                                 2097152 bytes\n  Maximum Texture Dimension Size (x,y,z)         1D=(131072), 2D=(131072, 65536), 3D=(16384, 16384, 16384)\n  Maximum Layered 1D Texture Size, (num) layers  1D=(32768), 2048 layers\n  Maximum Layered 2D Texture Size, (num) layers  2D=(32768, 32768), 2048 layers\n  Total amount of constant memory:               65536 bytes\n  Total amount of shared memory per block:       49152 bytes\n  Total number of registers available per block: 65536\n  Warp size:                                     32\n  Maximum number of threads per multiprocessor:  2048\n  Maximum number of threads per block:           1024\n  Max dimension size of a thread block (x,y,z): (1024, 1024, 64)\n  Max dimension size of a grid size    (x,y,z): (2147483647, 65535, 65535)\n  Maximum memory pitch:                          2147483647 bytes\n  Texture alignment:                             512 bytes\n  Concurrent copy and kernel execution:          Yes with 2 copy engine(s)\n  Run time limit on kernels:                     Yes\n  Integrated GPU sharing Host Memory:            No\n  Support host page-locked memory mapping:       Yes\n  Alignment requirement for Surfaces:            Yes\n  Device has ECC support:                        Disabled\n  Device supports Unified Addressing (UVA):      Yes\n  Device PCI Domain ID / Bus ID / location ID:   0 / 5 / 0\n\n  Compute Mode:\n     < Default (multiple host threads can use ::cudaSetDevice() with device simultaneously) >\n\ndeviceQuery, CUDA Driver = CUDART, CUDA Driver Version = 8.0, CUDA Runtime Version = 8.0, NumDevs = 1, Device0 = GeForce GTX 1080\nResult = PASS\n```\n\n再测试试一下nobody：\n\n```shell\ncd ~/NVIDIA_CUDA-8.0_Samples/5_Simulations/nbody/\nmake\n```\n\n执行：\n\n```shell\n./nbody -benchmark -numbodies=256000 -device=0\n```\n\n得到：\n\n```\n> Windowed mode\n> Simulation data stored in video memory\n> Single precision floating point simulation\n> 1 Devices used for simulation\ngpuDeviceInit() CUDA Device [0]: \"GeForce GTX 1080\n> Compute 6.1 CUDA device: [GeForce GTX 1080]\nnumber of bodies = 256000\n256000 bodies, total time for 10 iterations: 2364.286 ms\n= 277.192 billion interactions per second\n= 5543.830 single-precision GFLOP/s at 20 flops per interaction\n```\n\n至此，说明 CUDA 8.x 安装成功了。\n\n\n## 参考资料\n\n* [深度学习主机环境配置: Ubuntu16.04+Nvidia GTX 1080+CUDA8.0](http://www.52nlp.cn/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%BB%E6%9C%BA%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE-ubuntu-16-04-nvidia-gtx-1080-cuda-8)\n* [Nvidia GTX 1080 on Ubuntu 16.04 for Deep Learning - Changjiang](http://yangcha.github.io/GTX-1080/)\n* [Build Personal Deep Learning Rig: GTX 1080 + Ubuntu 16.04 + CUDA 8.0RC + CuDnn 7 + Tensorflow/Mxnet/Caffe/Darknet - by Guanghan Ning](http://guanghan.info/blog/en/my-works/building-our-personal-deep-learning-rig-gtx-1080-ubuntu-16-04-cuda-8-0rc-cudnn-7-tensorflowmxnetcaffedarknet/)\n* [GeForce GTX 1080, CUDA 8.0, Ubuntu 16.04, Caffe](https://github.com/BVLC/caffe/wiki/GeForce-GTX-1080,---CUDA-8.0,---Ubuntu-16.04,---Caffe)\n","slug":"2016-08-17-deep-learning-cuda-development-environment","published":1,"updated":"2016-08-18T10:23:42.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cis07pf4v004301pq7kt3f57a","content":"<p>前提条件，已经安装好了 Ubuntu 16.04 操作系统， 见<a href=\"http://cn.soulmachine.me/2016-08-14-dual-install-windows-ubuntu/\">安装 Windows 10 和 Ubuntu 16.04 双系统</a></p>\n<h2 id=\"1-安装-Nvidia-驱动\"><a href=\"#1-安装-Nvidia-驱动\" class=\"headerlink\" title=\"1. 安装 Nvidia 驱动\"></a>1. 安装 Nvidia 驱动</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div></pre></td><td class=\"code\"><pre><div class=\"line\">sudo add-apt-repository -qy ppa:graphics-drivers/ppa</div><div class=\"line\">sudo apt-get -qy update</div><div class=\"line\">sudo apt-get -qy install nvidia-370</div><div class=\"line\">sudo apt-get -qy install mesa-common-dev</div><div class=\"line\">sudo apt-get -qy install freeglut3-dev</div><div class=\"line\">sudo reboot</div></pre></td></tr></table></figure>\n<p>注意，一般比较新的主板，默认是UEFI BIOS，默认启用了 Secure Boot，否则开机后登陆不进去。老主板没有这个问题。</p>\n<h2 id=\"2-安装-CUDA-8-x\"><a href=\"#2-安装-CUDA-8-x\" class=\"headerlink\" title=\"2. 安装 CUDA 8.x\"></a>2. 安装 CUDA 8.x</h2><p>去 <a href=\"https://developer.nvidia.com/cuda-release-candidate-download\" target=\"_blank\" rel=\"external\">CUDA 8.x 下载页面</a>，一定要下载 runfile 安装方式的安装包，参考资料里的好几篇都是选择这种方式，貌似 deb包有坑？</p>\n<a id=\"more\"></a>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">chmod u+x ./cuda_8.0.27_linux.run</div><div class=\"line\">sudo ./cuda_8.0.27_linux.run --tmpdir=/tmp</div></pre></td></tr></table></figure>\n<p>执行后会有一系列提示让你确认，第一个就是问你是否安装显卡驱动，由于前一步已经安装了显卡驱动，所以这里就不需要了，况且 runfile 自带的驱动版本不是最新的。 因此 <code>Install NVIDIA Accelerated Graphics Driver for Linux-x86_64 361.77?</code> 这里选择 no。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div></pre></td><td class=\"code\"><pre><div class=\"line\">Do you accept the previously read EULA?</div><div class=\"line\">accept/decline/quit: accept</div><div class=\"line\"></div><div class=\"line\">Install NVIDIA Accelerated Graphics Driver for Linux-x86_64 361.77?</div><div class=\"line\">(y)es/(n)o/(q)uit: n</div><div class=\"line\"></div><div class=\"line\">Install the CUDA 8.0 Toolkit?</div><div class=\"line\">(y)es/(n)o/(q)uit: y</div><div class=\"line\"></div><div class=\"line\">Enter Toolkit Location</div><div class=\"line\"> [ default is /usr/local/cuda-8.0 ]: </div><div class=\"line\"></div><div class=\"line\">Do you want to install a symbolic link at /usr/local/cuda?</div><div class=\"line\">(y)es/(n)o/(q)uit: y</div><div class=\"line\"></div><div class=\"line\">Install the CUDA 8.0 Samples?</div><div class=\"line\">(y)es/(n)o/(q)uit: y</div><div class=\"line\"></div><div class=\"line\">Enter CUDA Samples Location</div><div class=\"line\"> [ default is /home/programmer ]:</div></pre></td></tr></table></figure>\n<p>你以为你会成功安装吗？并不是，你一定会碰到一个错误，<code>Installation Failed. Using unsupported Compiler.</code> ，这是因为 Ubuntu 16.04 默认的 GCC 5.4 对于 CUDA 8.x来说过于新了，CUDA 安装脚本还不能识别新版本的 GCC。</p>\n<p>看了一下安装日志，解决方案也很简单，加一个 <code>--override</code> 选项，</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">sudo ./cuda_8.0.27_linux.run --tmpdir=/tmp --override</div></pre></td></tr></table></figure>\n<p>这次可以成功了。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div></pre></td><td class=\"code\"><pre><div class=\"line\">===========</div><div class=\"line\">= Summary =</div><div class=\"line\">===========</div><div class=\"line\"></div><div class=\"line\">Driver:   Not Selected</div><div class=\"line\">Toolkit:  Installed in /usr/local/cuda-8.0</div><div class=\"line\">Samples:  Installed in /home/programmer, but missing recommended libraries</div><div class=\"line\"></div><div class=\"line\">Please make sure that</div><div class=\"line\"> -   PATH includes /usr/local/cuda-8.0/bin</div><div class=\"line\"> -   LD_LIBRARY_PATH includes /usr/local/cuda-8.0/lib64, or, add /usr/local/cuda-8.0/lib64 to /etc/ld.so.conf and run ldconfig as root</div><div class=\"line\"></div><div class=\"line\">To uninstall the CUDA Toolkit, run the uninstall script in /usr/local/cuda-8.0/bin</div><div class=\"line\"></div><div class=\"line\">Please see CUDA_Installation_Guide_Linux.pdf in /usr/local/cuda-8.0/doc/pdf for detailed information on setting up CUDA.</div><div class=\"line\"></div><div class=\"line\">***WARNING: Incomplete installation! This installation did not install the CUDA Driver. A driver of version at least 361.00 is required for CUDA 8.0 functionality to work.</div><div class=\"line\"></div><div class=\"line\">To install the driver using this installer, run the following command, replacing &lt;CudaInstaller&gt; with the name of this run file:</div><div class=\"line\"></div><div class=\"line\">    sudo &lt;CudaInstaller&gt;.run -silent -driver</div><div class=\"line\"></div><div class=\"line\">Logfile is /tmp/cuda_install_6794.log</div><div class=\"line\"></div><div class=\"line\">Signal caught, cleaning up</div></pre></td></tr></table></figure>\n<p>把以下两行加入到 <code>.bashrc</code>，</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">export PATH=/usr/local/cuda-8.0/bin$&#123;PATH:+:$&#123;PATH&#125;&#125;</div><div class=\"line\">export LD_LIBRARY_PATH=/usr/local/cuda-8.0/lib64$&#123;LD_LIBRARY_PATH:+:$&#123;LD_LIBRARY_PATH&#125;&#125;</div></pre></td></tr></table></figure>\n<h2 id=\"安装补丁\"><a href=\"#安装补丁\" class=\"headerlink\" title=\"安装补丁\"></a>安装补丁</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">chmod u+x ./cuda_8.0.27.1_linux.run</div><div class=\"line\">sudo ./cuda_8.0.27.1_linux.run</div></pre></td></tr></table></figure>\n<h2 id=\"测试是否安装成功\"><a href=\"#测试是否安装成功\" class=\"headerlink\" title=\"测试是否安装成功\"></a>测试是否安装成功</h2><p>最后再来测试一下CUDA，运行：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">nvidia-smi</div></pre></td></tr></table></figure>\n<p>结果如下所示：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div></pre></td><td class=\"code\"><pre><div class=\"line\">+-----------------------------------------------------------------------------+</div><div class=\"line\">| NVIDIA-SMI 370.23                 Driver Version: 370.23                    |</div><div class=\"line\">|-------------------------------+----------------------+----------------------+</div><div class=\"line\">| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |</div><div class=\"line\">| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |</div><div class=\"line\">|===============================+======================+======================|</div><div class=\"line\">|   0  GeForce GTX 1080    Off  | 0000:05:00.0      On |                  N/A |</div><div class=\"line\">| 27%   29C    P8     9W / 180W |    515MiB /  8110MiB |      4%      Default |</div><div class=\"line\">+-------------------------------+----------------------+----------------------+</div><div class=\"line\"></div><div class=\"line\">+-----------------------------------------------------------------------------+</div><div class=\"line\">| Processes:                                                       GPU Memory |</div><div class=\"line\">|  GPU       PID  Type  Process name                               Usage      |</div><div class=\"line\">|=============================================================================|</div><div class=\"line\">|    0      4761    G   /usr/lib/xorg/Xorg                             259MiB |</div><div class=\"line\">|    0      5224    G   compiz                                         253MiB |</div><div class=\"line\">+-----------------------------------------------------------------------------+</div></pre></td></tr></table></figure>\n<p>再来试几个CUDA例子：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">cd ~/NVIDIA_CUDA-8.0_Samples/1_Utilities/deviceQuery</div><div class=\"line\">make</div></pre></td></tr></table></figure>\n<p>执行 <code>./deviceQuery</code>，得到：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div></pre></td><td class=\"code\"><pre><div class=\"line\">CUDA Device Query (Runtime API) version (CUDART static linking)</div><div class=\"line\"></div><div class=\"line\">Detected 1 CUDA Capable device(s)</div><div class=\"line\"></div><div class=\"line\">Device 0: &quot;GeForce GTX 1080&quot;</div><div class=\"line\">  CUDA Driver Version / Runtime Version          8.0 / 8.0</div><div class=\"line\">  CUDA Capability Major/Minor version number:    6.1</div><div class=\"line\">  Total amount of global memory:                 8110 MBytes (8504279040 bytes)</div><div class=\"line\">  (20) Multiprocessors, (128) CUDA Cores/MP:     2560 CUDA Cores</div><div class=\"line\">  GPU Max Clock rate:                            1734 MHz (1.73 GHz)</div><div class=\"line\">  Memory Clock rate:                             5005 Mhz</div><div class=\"line\">  Memory Bus Width:                              256-bit</div><div class=\"line\">  L2 Cache Size:                                 2097152 bytes</div><div class=\"line\">  Maximum Texture Dimension Size (x,y,z)         1D=(131072), 2D=(131072, 65536), 3D=(16384, 16384, 16384)</div><div class=\"line\">  Maximum Layered 1D Texture Size, (num) layers  1D=(32768), 2048 layers</div><div class=\"line\">  Maximum Layered 2D Texture Size, (num) layers  2D=(32768, 32768), 2048 layers</div><div class=\"line\">  Total amount of constant memory:               65536 bytes</div><div class=\"line\">  Total amount of shared memory per block:       49152 bytes</div><div class=\"line\">  Total number of registers available per block: 65536</div><div class=\"line\">  Warp size:                                     32</div><div class=\"line\">  Maximum number of threads per multiprocessor:  2048</div><div class=\"line\">  Maximum number of threads per block:           1024</div><div class=\"line\">  Max dimension size of a thread block (x,y,z): (1024, 1024, 64)</div><div class=\"line\">  Max dimension size of a grid size    (x,y,z): (2147483647, 65535, 65535)</div><div class=\"line\">  Maximum memory pitch:                          2147483647 bytes</div><div class=\"line\">  Texture alignment:                             512 bytes</div><div class=\"line\">  Concurrent copy and kernel execution:          Yes with 2 copy engine(s)</div><div class=\"line\">  Run time limit on kernels:                     Yes</div><div class=\"line\">  Integrated GPU sharing Host Memory:            No</div><div class=\"line\">  Support host page-locked memory mapping:       Yes</div><div class=\"line\">  Alignment requirement for Surfaces:            Yes</div><div class=\"line\">  Device has ECC support:                        Disabled</div><div class=\"line\">  Device supports Unified Addressing (UVA):      Yes</div><div class=\"line\">  Device PCI Domain ID / Bus ID / location ID:   0 / 5 / 0</div><div class=\"line\"></div><div class=\"line\">  Compute Mode:</div><div class=\"line\">     &lt; Default (multiple host threads can use ::cudaSetDevice() with device simultaneously) &gt;</div><div class=\"line\"></div><div class=\"line\">deviceQuery, CUDA Driver = CUDART, CUDA Driver Version = 8.0, CUDA Runtime Version = 8.0, NumDevs = 1, Device0 = GeForce GTX 1080</div><div class=\"line\">Result = PASS</div></pre></td></tr></table></figure>\n<p>再测试试一下nobody：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">cd ~/NVIDIA_CUDA-8.0_Samples/5_Simulations/nbody/</div><div class=\"line\">make</div></pre></td></tr></table></figure>\n<p>执行：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">./nbody -benchmark -numbodies=256000 -device=0</div></pre></td></tr></table></figure>\n<p>得到：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div></pre></td><td class=\"code\"><pre><div class=\"line\">&gt; Windowed mode</div><div class=\"line\">&gt; Simulation data stored in video memory</div><div class=\"line\">&gt; Single precision floating point simulation</div><div class=\"line\">&gt; 1 Devices used for simulation</div><div class=\"line\">gpuDeviceInit() CUDA Device [0]: &quot;GeForce GTX 1080</div><div class=\"line\">&gt; Compute 6.1 CUDA device: [GeForce GTX 1080]</div><div class=\"line\">number of bodies = 256000</div><div class=\"line\">256000 bodies, total time for 10 iterations: 2364.286 ms</div><div class=\"line\">= 277.192 billion interactions per second</div><div class=\"line\">= 5543.830 single-precision GFLOP/s at 20 flops per interaction</div></pre></td></tr></table></figure>\n<p>至此，说明 CUDA 8.x 安装成功了。</p>\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><ul>\n<li><a href=\"http://www.52nlp.cn/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%BB%E6%9C%BA%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE-ubuntu-16-04-nvidia-gtx-1080-cuda-8\" target=\"_blank\" rel=\"external\">深度学习主机环境配置: Ubuntu16.04+Nvidia GTX 1080+CUDA8.0</a></li>\n<li><a href=\"http://yangcha.github.io/GTX-1080/\" target=\"_blank\" rel=\"external\">Nvidia GTX 1080 on Ubuntu 16.04 for Deep Learning - Changjiang</a></li>\n<li><a href=\"http://guanghan.info/blog/en/my-works/building-our-personal-deep-learning-rig-gtx-1080-ubuntu-16-04-cuda-8-0rc-cudnn-7-tensorflowmxnetcaffedarknet/\" target=\"_blank\" rel=\"external\">Build Personal Deep Learning Rig: GTX 1080 + Ubuntu 16.04 + CUDA 8.0RC + CuDnn 7 + Tensorflow/Mxnet/Caffe/Darknet - by Guanghan Ning</a></li>\n<li><a href=\"https://github.com/BVLC/caffe/wiki/GeForce-GTX-1080,---CUDA-8.0,---Ubuntu-16.04,---Caffe\" target=\"_blank\" rel=\"external\">GeForce GTX 1080, CUDA 8.0, Ubuntu 16.04, Caffe</a></li>\n</ul>\n","excerpt":"<p>前提条件，已经安装好了 Ubuntu 16.04 操作系统， 见<a href=\"http://cn.soulmachine.me/2016-08-14-dual-install-windows-ubuntu/\">安装 Windows 10 和 Ubuntu 16.04 双系统</a></p>\n<h2 id=\"1-安装-Nvidia-驱动\"><a href=\"#1-安装-Nvidia-驱动\" class=\"headerlink\" title=\"1. 安装 Nvidia 驱动\"></a>1. 安装 Nvidia 驱动</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div></pre></td><td class=\"code\"><pre><div class=\"line\">sudo add-apt-repository -qy ppa:graphics-drivers/ppa</div><div class=\"line\">sudo apt-get -qy update</div><div class=\"line\">sudo apt-get -qy install nvidia-370</div><div class=\"line\">sudo apt-get -qy install mesa-common-dev</div><div class=\"line\">sudo apt-get -qy install freeglut3-dev</div><div class=\"line\">sudo reboot</div></pre></td></tr></table></figure>\n<p>注意，一般比较新的主板，默认是UEFI BIOS，默认启用了 Secure Boot，否则开机后登陆不进去。老主板没有这个问题。</p>\n<h2 id=\"2-安装-CUDA-8-x\"><a href=\"#2-安装-CUDA-8-x\" class=\"headerlink\" title=\"2. 安装 CUDA 8.x\"></a>2. 安装 CUDA 8.x</h2><p>去 <a href=\"https://developer.nvidia.com/cuda-release-candidate-download\">CUDA 8.x 下载页面</a>，一定要下载 runfile 安装方式的安装包，参考资料里的好几篇都是选择这种方式，貌似 deb包有坑？</p>","more":"<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">chmod u+x ./cuda_8.0.27_linux.run</div><div class=\"line\">sudo ./cuda_8.0.27_linux.run --tmpdir=/tmp</div></pre></td></tr></table></figure>\n<p>执行后会有一系列提示让你确认，第一个就是问你是否安装显卡驱动，由于前一步已经安装了显卡驱动，所以这里就不需要了，况且 runfile 自带的驱动版本不是最新的。 因此 <code>Install NVIDIA Accelerated Graphics Driver for Linux-x86_64 361.77?</code> 这里选择 no。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div></pre></td><td class=\"code\"><pre><div class=\"line\">Do you accept the previously read EULA?</div><div class=\"line\">accept/decline/quit: accept</div><div class=\"line\"></div><div class=\"line\">Install NVIDIA Accelerated Graphics Driver for Linux-x86_64 361.77?</div><div class=\"line\">(y)es/(n)o/(q)uit: n</div><div class=\"line\"></div><div class=\"line\">Install the CUDA 8.0 Toolkit?</div><div class=\"line\">(y)es/(n)o/(q)uit: y</div><div class=\"line\"></div><div class=\"line\">Enter Toolkit Location</div><div class=\"line\"> [ default is /usr/local/cuda-8.0 ]: </div><div class=\"line\"></div><div class=\"line\">Do you want to install a symbolic link at /usr/local/cuda?</div><div class=\"line\">(y)es/(n)o/(q)uit: y</div><div class=\"line\"></div><div class=\"line\">Install the CUDA 8.0 Samples?</div><div class=\"line\">(y)es/(n)o/(q)uit: y</div><div class=\"line\"></div><div class=\"line\">Enter CUDA Samples Location</div><div class=\"line\"> [ default is /home/programmer ]:</div></pre></td></tr></table></figure>\n<p>你以为你会成功安装吗？并不是，你一定会碰到一个错误，<code>Installation Failed. Using unsupported Compiler.</code> ，这是因为 Ubuntu 16.04 默认的 GCC 5.4 对于 CUDA 8.x来说过于新了，CUDA 安装脚本还不能识别新版本的 GCC。</p>\n<p>看了一下安装日志，解决方案也很简单，加一个 <code>--override</code> 选项，</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">sudo ./cuda_8.0.27_linux.run --tmpdir=/tmp --override</div></pre></td></tr></table></figure>\n<p>这次可以成功了。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div></pre></td><td class=\"code\"><pre><div class=\"line\">===========</div><div class=\"line\">= Summary =</div><div class=\"line\">===========</div><div class=\"line\"></div><div class=\"line\">Driver:   Not Selected</div><div class=\"line\">Toolkit:  Installed in /usr/local/cuda-8.0</div><div class=\"line\">Samples:  Installed in /home/programmer, but missing recommended libraries</div><div class=\"line\"></div><div class=\"line\">Please make sure that</div><div class=\"line\"> -   PATH includes /usr/local/cuda-8.0/bin</div><div class=\"line\"> -   LD_LIBRARY_PATH includes /usr/local/cuda-8.0/lib64, or, add /usr/local/cuda-8.0/lib64 to /etc/ld.so.conf and run ldconfig as root</div><div class=\"line\"></div><div class=\"line\">To uninstall the CUDA Toolkit, run the uninstall script in /usr/local/cuda-8.0/bin</div><div class=\"line\"></div><div class=\"line\">Please see CUDA_Installation_Guide_Linux.pdf in /usr/local/cuda-8.0/doc/pdf for detailed information on setting up CUDA.</div><div class=\"line\"></div><div class=\"line\">***WARNING: Incomplete installation! This installation did not install the CUDA Driver. A driver of version at least 361.00 is required for CUDA 8.0 functionality to work.</div><div class=\"line\"></div><div class=\"line\">To install the driver using this installer, run the following command, replacing &lt;CudaInstaller&gt; with the name of this run file:</div><div class=\"line\"></div><div class=\"line\">    sudo &lt;CudaInstaller&gt;.run -silent -driver</div><div class=\"line\"></div><div class=\"line\">Logfile is /tmp/cuda_install_6794.log</div><div class=\"line\"></div><div class=\"line\">Signal caught, cleaning up</div></pre></td></tr></table></figure>\n<p>把以下两行加入到 <code>.bashrc</code>，</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">export PATH=/usr/local/cuda-8.0/bin$&#123;PATH:+:$&#123;PATH&#125;&#125;</div><div class=\"line\">export LD_LIBRARY_PATH=/usr/local/cuda-8.0/lib64$&#123;LD_LIBRARY_PATH:+:$&#123;LD_LIBRARY_PATH&#125;&#125;</div></pre></td></tr></table></figure>\n<h2 id=\"安装补丁\"><a href=\"#安装补丁\" class=\"headerlink\" title=\"安装补丁\"></a>安装补丁</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">chmod u+x ./cuda_8.0.27.1_linux.run</div><div class=\"line\">sudo ./cuda_8.0.27.1_linux.run</div></pre></td></tr></table></figure>\n<h2 id=\"测试是否安装成功\"><a href=\"#测试是否安装成功\" class=\"headerlink\" title=\"测试是否安装成功\"></a>测试是否安装成功</h2><p>最后再来测试一下CUDA，运行：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">nvidia-smi</div></pre></td></tr></table></figure>\n<p>结果如下所示：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div></pre></td><td class=\"code\"><pre><div class=\"line\">+-----------------------------------------------------------------------------+</div><div class=\"line\">| NVIDIA-SMI 370.23                 Driver Version: 370.23                    |</div><div class=\"line\">|-------------------------------+----------------------+----------------------+</div><div class=\"line\">| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |</div><div class=\"line\">| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |</div><div class=\"line\">|===============================+======================+======================|</div><div class=\"line\">|   0  GeForce GTX 1080    Off  | 0000:05:00.0      On |                  N/A |</div><div class=\"line\">| 27%   29C    P8     9W / 180W |    515MiB /  8110MiB |      4%      Default |</div><div class=\"line\">+-------------------------------+----------------------+----------------------+</div><div class=\"line\"></div><div class=\"line\">+-----------------------------------------------------------------------------+</div><div class=\"line\">| Processes:                                                       GPU Memory |</div><div class=\"line\">|  GPU       PID  Type  Process name                               Usage      |</div><div class=\"line\">|=============================================================================|</div><div class=\"line\">|    0      4761    G   /usr/lib/xorg/Xorg                             259MiB |</div><div class=\"line\">|    0      5224    G   compiz                                         253MiB |</div><div class=\"line\">+-----------------------------------------------------------------------------+</div></pre></td></tr></table></figure>\n<p>再来试几个CUDA例子：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">cd ~/NVIDIA_CUDA-8.0_Samples/1_Utilities/deviceQuery</div><div class=\"line\">make</div></pre></td></tr></table></figure>\n<p>执行 <code>./deviceQuery</code>，得到：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div></pre></td><td class=\"code\"><pre><div class=\"line\">CUDA Device Query (Runtime API) version (CUDART static linking)</div><div class=\"line\"></div><div class=\"line\">Detected 1 CUDA Capable device(s)</div><div class=\"line\"></div><div class=\"line\">Device 0: &quot;GeForce GTX 1080&quot;</div><div class=\"line\">  CUDA Driver Version / Runtime Version          8.0 / 8.0</div><div class=\"line\">  CUDA Capability Major/Minor version number:    6.1</div><div class=\"line\">  Total amount of global memory:                 8110 MBytes (8504279040 bytes)</div><div class=\"line\">  (20) Multiprocessors, (128) CUDA Cores/MP:     2560 CUDA Cores</div><div class=\"line\">  GPU Max Clock rate:                            1734 MHz (1.73 GHz)</div><div class=\"line\">  Memory Clock rate:                             5005 Mhz</div><div class=\"line\">  Memory Bus Width:                              256-bit</div><div class=\"line\">  L2 Cache Size:                                 2097152 bytes</div><div class=\"line\">  Maximum Texture Dimension Size (x,y,z)         1D=(131072), 2D=(131072, 65536), 3D=(16384, 16384, 16384)</div><div class=\"line\">  Maximum Layered 1D Texture Size, (num) layers  1D=(32768), 2048 layers</div><div class=\"line\">  Maximum Layered 2D Texture Size, (num) layers  2D=(32768, 32768), 2048 layers</div><div class=\"line\">  Total amount of constant memory:               65536 bytes</div><div class=\"line\">  Total amount of shared memory per block:       49152 bytes</div><div class=\"line\">  Total number of registers available per block: 65536</div><div class=\"line\">  Warp size:                                     32</div><div class=\"line\">  Maximum number of threads per multiprocessor:  2048</div><div class=\"line\">  Maximum number of threads per block:           1024</div><div class=\"line\">  Max dimension size of a thread block (x,y,z): (1024, 1024, 64)</div><div class=\"line\">  Max dimension size of a grid size    (x,y,z): (2147483647, 65535, 65535)</div><div class=\"line\">  Maximum memory pitch:                          2147483647 bytes</div><div class=\"line\">  Texture alignment:                             512 bytes</div><div class=\"line\">  Concurrent copy and kernel execution:          Yes with 2 copy engine(s)</div><div class=\"line\">  Run time limit on kernels:                     Yes</div><div class=\"line\">  Integrated GPU sharing Host Memory:            No</div><div class=\"line\">  Support host page-locked memory mapping:       Yes</div><div class=\"line\">  Alignment requirement for Surfaces:            Yes</div><div class=\"line\">  Device has ECC support:                        Disabled</div><div class=\"line\">  Device supports Unified Addressing (UVA):      Yes</div><div class=\"line\">  Device PCI Domain ID / Bus ID / location ID:   0 / 5 / 0</div><div class=\"line\"></div><div class=\"line\">  Compute Mode:</div><div class=\"line\">     &lt; Default (multiple host threads can use ::cudaSetDevice() with device simultaneously) &gt;</div><div class=\"line\"></div><div class=\"line\">deviceQuery, CUDA Driver = CUDART, CUDA Driver Version = 8.0, CUDA Runtime Version = 8.0, NumDevs = 1, Device0 = GeForce GTX 1080</div><div class=\"line\">Result = PASS</div></pre></td></tr></table></figure>\n<p>再测试试一下nobody：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">cd ~/NVIDIA_CUDA-8.0_Samples/5_Simulations/nbody/</div><div class=\"line\">make</div></pre></td></tr></table></figure>\n<p>执行：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">./nbody -benchmark -numbodies=256000 -device=0</div></pre></td></tr></table></figure>\n<p>得到：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div></pre></td><td class=\"code\"><pre><div class=\"line\">&gt; Windowed mode</div><div class=\"line\">&gt; Simulation data stored in video memory</div><div class=\"line\">&gt; Single precision floating point simulation</div><div class=\"line\">&gt; 1 Devices used for simulation</div><div class=\"line\">gpuDeviceInit() CUDA Device [0]: &quot;GeForce GTX 1080</div><div class=\"line\">&gt; Compute 6.1 CUDA device: [GeForce GTX 1080]</div><div class=\"line\">number of bodies = 256000</div><div class=\"line\">256000 bodies, total time for 10 iterations: 2364.286 ms</div><div class=\"line\">= 277.192 billion interactions per second</div><div class=\"line\">= 5543.830 single-precision GFLOP/s at 20 flops per interaction</div></pre></td></tr></table></figure>\n<p>至此，说明 CUDA 8.x 安装成功了。</p>\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><ul>\n<li><a href=\"http://www.52nlp.cn/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%BB%E6%9C%BA%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE-ubuntu-16-04-nvidia-gtx-1080-cuda-8\">深度学习主机环境配置: Ubuntu16.04+Nvidia GTX 1080+CUDA8.0</a></li>\n<li><a href=\"http://yangcha.github.io/GTX-1080/\">Nvidia GTX 1080 on Ubuntu 16.04 for Deep Learning - Changjiang</a></li>\n<li><a href=\"http://guanghan.info/blog/en/my-works/building-our-personal-deep-learning-rig-gtx-1080-ubuntu-16-04-cuda-8-0rc-cudnn-7-tensorflowmxnetcaffedarknet/\">Build Personal Deep Learning Rig: GTX 1080 + Ubuntu 16.04 + CUDA 8.0RC + CuDnn 7 + Tensorflow/Mxnet/Caffe/Darknet - by Guanghan Ning</a></li>\n<li><a href=\"https://github.com/BVLC/caffe/wiki/GeForce-GTX-1080,---CUDA-8.0,---Ubuntu-16.04,---Caffe\">GeForce GTX 1080, CUDA 8.0, Ubuntu 16.04, Caffe</a></li>\n</ul>"}],"PostAsset":[],"PostCategory":[{"post_id":"cis07peu1000001pq47uvm9d9","category_id":"cis07peup000101pqouklpfo6","_id":"cis07peuz000201pq939zvse2"},{"post_id":"cis07pf1g000301pqv3a7otwa","category_id":"cis07peup000101pqouklpfo6","_id":"cis07pf1s000601pqn68y5vku"},{"post_id":"cis07pf1k000401pqx4q6heub","category_id":"cis07peup000101pqouklpfo6","_id":"cis07pf23000901pq2j1qnlqe"},{"post_id":"cis07pf1t000701pq0alsvk9a","category_id":"cis07peup000101pqouklpfo6","_id":"cis07pf26000c01pqq35mjion"},{"post_id":"cis07pf1q000501pqasii4xlw","category_id":"cis07pf23000801pq08b0ttbv","_id":"cis07pf2g000g01pqsehlt6u1"},{"post_id":"cis07pf23000a01pqs6xv4xnv","category_id":"cis07pf23000801pq08b0ttbv","_id":"cis07pf2i000k01pqfthss4df"},{"post_id":"cis07pf2g000h01pqpp5xbo3h","category_id":"cis07peup000101pqouklpfo6","_id":"cis07pf2l000n01pqw8m9fwp7"},{"post_id":"cis07pf2h000j01pqgbjoy4zt","category_id":"cis07peup000101pqouklpfo6","_id":"cis07pf2m000p01pqc0g8tneb"},{"post_id":"cis07pf26000b01pqunhuxk3z","category_id":"cis07pf2g000i01pq8vda41tw","_id":"cis07pf2q000s01pqrocui2o1"},{"post_id":"cis07pf2m000o01pq830elqf6","category_id":"cis07pf2g000i01pq8vda41tw","_id":"cis07pf2y000u01pqw448lo34"},{"post_id":"cis07pf27000d01pqt2w98y24","category_id":"cis07pf2l000m01pqsc5pm4zu","_id":"cis07pf2z000x01pqi55g3lcr"},{"post_id":"cis07pf2o000q01pq3a1o7p73","category_id":"cis07pf2g000i01pq8vda41tw","_id":"cis07pf30000z01pqkdbj343z"},{"post_id":"cis07pf2w000t01pq7ejnbj9c","category_id":"cis07peup000101pqouklpfo6","_id":"cis07pf34001101pqbgndre2v"},{"post_id":"cis07pf2f000f01pqcuzjmhg0","category_id":"cis07pf2q000r01pqdvkmdjze","_id":"cis07pf35001401pqopndkycd"},{"post_id":"cis07pf2z000y01pqe6l2wfjh","category_id":"cis07pf2g000i01pq8vda41tw","_id":"cis07pf36001601pqm0r628wy"},{"post_id":"cis07pf30001001pqcalznrdr","category_id":"cis07peup000101pqouklpfo6","_id":"cis07pf38001801pqeag49fgm"},{"post_id":"cis07pf2j000l01pqc0ll7fra","category_id":"cis07pf2z000w01pqc1q9efel","_id":"cis07pf3a001c01pqypzo0yvw"},{"post_id":"cis07pf34001201pqa3sdfm28","category_id":"cis07peup000101pqouklpfo6","_id":"cis07pf3d001e01pq817070dj"},{"post_id":"cis07pf35001501pqehzwkx74","category_id":"cis07peup000101pqouklpfo6","_id":"cis07pf3e001h01pqfqazu5ha"},{"post_id":"cis07pf2y000v01pqx5o6blp2","category_id":"cis07pf35001301pqoxdytt9y","_id":"cis07pf3g001k01pq2ee1zvwu"},{"post_id":"cis07pf39001901pq4t6gp8fj","category_id":"cis07pf23000801pq08b0ttbv","_id":"cis07pf3h001m01pqkxo5jis6"},{"post_id":"cis07pf3d001f01pqvhet8up1","category_id":"cis07pf3a001b01pq78kknjv4","_id":"cis07pf3k001q01pqqcj0kkxy"},{"post_id":"cis07pf37001701pqf0p2omkn","category_id":"cis07pf3a001b01pq78kknjv4","_id":"cis07pf3m001t01pquc6a8l5t"},{"post_id":"cis07pf3e001i01pqxb6u0uj5","category_id":"cis07pf3a001b01pq78kknjv4","_id":"cis07pf3n001v01pqqymbn7s7"},{"post_id":"cis07pf3b001d01pqbbvmrs7t","category_id":"cis07pf3a001b01pq78kknjv4","_id":"cis07pf3q001y01pq2phn7hmf"},{"post_id":"cis07pf3m001u01pqn52pmfc2","category_id":"cis07pf2l000m01pqsc5pm4zu","_id":"cis07pf3r002001pqyz4o0ne5"},{"post_id":"cis07pf3g001l01pqoqnmlc5z","category_id":"cis07pf3j001o01pq4jmlr1kc","_id":"cis07pf3s002301pqj7c902h9"},{"post_id":"cis07pf3i001n01pqs5rnprl7","category_id":"cis07pf3j001o01pq4jmlr1kc","_id":"cis07pf3v002501pqaon2kuc6"},{"post_id":"cis07pf3r002101pqcu3r8bms","category_id":"cis07pf3a001b01pq78kknjv4","_id":"cis07pf3x002801pq1960iwx7"},{"post_id":"cis07pf3k001r01pqkh9wfsxz","category_id":"cis07pf3r002201pqyfwf5cwr","_id":"cis07pf3y002c01pqfsarcw7r"},{"post_id":"cis07pf3v002601pqlioibhgp","category_id":"cis07pf2g000i01pq8vda41tw","_id":"cis07pf3z002f01pql44pklek"},{"post_id":"cis07pf3n001w01pqgckpy06e","category_id":"cis07pf3w002701pqaeykd1qt","_id":"cis07pf41002i01pquu4lyiza"},{"post_id":"cis07pf3y002b01pqh3pzd03v","category_id":"cis07pf2l000m01pqsc5pm4zu","_id":"cis07pf43002l01pq278jtmbs"},{"post_id":"cis07pf3z002e01pq41pw8rnm","category_id":"cis07pf2l000m01pqsc5pm4zu","_id":"cis07pf44002n01pqadwj2gp8"},{"post_id":"cis07pf3q001z01pqfs8ehycj","category_id":"cis07pf3r002201pqyfwf5cwr","_id":"cis07pf46002q01pq8cm94su5"},{"post_id":"cis07pf40002h01pqf4bup683","category_id":"cis07pf3r002201pqyfwf5cwr","_id":"cis07pf47002t01pqudpqvao2"},{"post_id":"cis07pf42002k01pqrgegud7a","category_id":"cis07pf2l000m01pqsc5pm4zu","_id":"cis07pf48002v01pqbygofxez"},{"post_id":"cis07pf3u002401pqbj4bvk5i","category_id":"cis07pf3w002701pqaeykd1qt","_id":"cis07pf4a002x01pq3fqzjjuq"},{"post_id":"cis07pf43002m01pqxb0z9mti","category_id":"cis07pf2l000m01pqsc5pm4zu","_id":"cis07pf4c002z01pq4wnu9jo2"},{"post_id":"cis07pf45002p01pqy57h1pru","category_id":"cis07peup000101pqouklpfo6","_id":"cis07pf4d003101pqb1dfk0tv"},{"post_id":"cis07pf46002s01pqnv5lbqpd","category_id":"cis07pf2l000m01pqsc5pm4zu","_id":"cis07pf4e003301pq0xwc7vrd"},{"post_id":"cis07pf48002u01pqeb8z2s8e","category_id":"cis07pf2l000m01pqsc5pm4zu","_id":"cis07pf4e003501pqp7o5wxl9"},{"post_id":"cis07pf49002w01pqvrurrks1","category_id":"cis07pf2q000r01pqdvkmdjze","_id":"cis07pf4f003701pqnazmzuu6"},{"post_id":"cis07pf4a002y01pqfgtclqzm","category_id":"cis07pf3a001b01pq78kknjv4","_id":"cis07pf4g003901pqtakznpv4"},{"post_id":"cis07pf4c003001pqi7u8mewr","category_id":"cis07pf2l000m01pqsc5pm4zu","_id":"cis07pf4i003b01pqupnmaekz"},{"post_id":"cis07pf4d003201pqxphvm1n1","category_id":"cis07pf3w002701pqaeykd1qt","_id":"cis07pf4j003d01pqo0qiwt7l"},{"post_id":"cis07pf4e003401pqabqqjd6y","category_id":"cis07pf2q000r01pqdvkmdjze","_id":"cis07pf4k003f01pqfmg0s80u"},{"post_id":"cis07pf4e003601pqvr6qu9sk","category_id":"cis07pf3w002701pqaeykd1qt","_id":"cis07pf4l003h01pqg3obk51c"},{"post_id":"cis07pf4g003801pqyvy2uthc","category_id":"cis07pf2q000r01pqdvkmdjze","_id":"cis07pf4m003j01pq2ury7lox"},{"post_id":"cis07pf4h003a01pq43firns7","category_id":"cis07pf2q000r01pqdvkmdjze","_id":"cis07pf4n003l01pqctf185x8"},{"post_id":"cis07pf4i003c01pq6i28gg07","category_id":"cis07pf2q000r01pqdvkmdjze","_id":"cis07pf4o003n01pq6qb36wrn"},{"post_id":"cis07pf4j003e01pqgmomq6mo","category_id":"cis07peup000101pqouklpfo6","_id":"cis07pf4q003p01pqak5wlsmd"},{"post_id":"cis07pf4k003g01pqdz2odcjo","category_id":"cis07pf2q000r01pqdvkmdjze","_id":"cis07pf4r003r01pqxfwvlgi7"},{"post_id":"cis07pf4l003i01pqbd5p02t1","category_id":"cis07pf2l000m01pqsc5pm4zu","_id":"cis07pf4s003u01pq53yc67d9"},{"post_id":"cis07pf4m003k01pq9dzandz2","category_id":"cis07pf3w002701pqaeykd1qt","_id":"cis07pf4t003w01pq5sm72yuu"},{"post_id":"cis07pf4n003m01pqh6d77h1u","category_id":"cis07pf2q000r01pqdvkmdjze","_id":"cis07pf4u003z01pqru0w4iv1"},{"post_id":"cis07pf4q003q01pq986momkf","category_id":"cis07pf2l000m01pqsc5pm4zu","_id":"cis07pf4v004201pqaohn8h3r"},{"post_id":"cis07pf4o003o01pqf4c82wzr","category_id":"cis07pf4r003s01pqhthv3ali","_id":"cis07pf4w004501pq3usjpqif"},{"post_id":"cis07pf4u004101pqaibf01sc","category_id":"cis07pf2l000m01pqsc5pm4zu","_id":"cis07pf4x004801pqprrr50mw"},{"post_id":"cis07pf4r003t01pqoy4aq1xh","category_id":"cis07pf4u003y01pqbuinyg41","_id":"cis07pf4y004b01pqjq2cvooq"},{"post_id":"cis07pf4s003v01pq10uy6b3v","category_id":"cis07pf4w004401pqewxnoaad","_id":"cis07pf4y004d01pqytl8as7g"},{"post_id":"cis07pf4t003x01pqhu7o1ywx","category_id":"cis07pf4w004401pqewxnoaad","_id":"cis07pf4z004f01pq172a83nr"},{"post_id":"cis07pf4v004301pq7kt3f57a","category_id":"cis07pf4w004401pqewxnoaad","_id":"cis07pf4z004g01pqrjqzcmnk"}],"PostTag":[{"post_id":"cis07pf37001701pqf0p2omkn","tag_id":"cis07pf3a001a01pq7hza3xei","_id":"cis07pf3k001p01pq8qf7l2ue"},{"post_id":"cis07pf37001701pqf0p2omkn","tag_id":"cis07pf3e001g01pq9zvg1dfy","_id":"cis07pf3m001s01pq7d4udah4"},{"post_id":"cis07pf3v002601pqlioibhgp","tag_id":"cis07pf3x002a01pq4qus2l32","_id":"cis07pf45002o01pqq4lnxxym"},{"post_id":"cis07pf3v002601pqlioibhgp","tag_id":"cis07pf40002g01pq6bukswwp","_id":"cis07pf46002r01pqkt0csor2"},{"post_id":"cis07pf4v004301pq7kt3f57a","tag_id":"cis07pf4u004001pqpx2toc6w","_id":"cis07pf4x004701pq2wfcpjjl"},{"post_id":"cis07pf4s003v01pq10uy6b3v","tag_id":"cis07pf4u004001pqpx2toc6w","_id":"cis07pf4x004901pqb17i0tvo"},{"post_id":"cis07pf4t003x01pqhu7o1ywx","tag_id":"cis07pf4u004001pqpx2toc6w","_id":"cis07pf4y004c01pqnd6jqm46"}],"Tag":[{"name":"scala","_id":"cis07pf3a001a01pq7hza3xei"},{"name":"spark","_id":"cis07pf3e001g01pq9zvg1dfy"},{"name":"mahout","_id":"cis07pf3x002a01pq4qus2l32"},{"name":"naive bayes","_id":"cis07pf40002g01pq6bukswwp"},{"name":"深度学习","_id":"cis07pf4u004001pqpx2toc6w"}]}}